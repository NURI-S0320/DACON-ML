{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Preparing data...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'모델가격(달러)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '모델가격(달러)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 87\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR2 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 67\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# 데이터 준비\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m X, y, test_data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mprepare_data\u001b[1;34m(train, test)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_data\u001b[39m(train, test):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# 타겟 변수 분리\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m모델가격(달러)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# 불필요한 컬럼 제거\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     features_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델가격(달러)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '모델가격(달러)'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 데이터 불러오기\n",
    "def load_data():\n",
    "    train = pd.read_csv('./train.csv')\n",
    "    test = pd.read_csv('./test.csv')\n",
    "    return train, test\n",
    "\n",
    "# 특성과 타겟 분리\n",
    "def prepare_data(train, test):\n",
    "    # 타겟 변수 분리\n",
    "    y = train['모델가격(달러)']\n",
    "    \n",
    "    # 불필요한 컬럼 제거\n",
    "    features_to_drop = ['ID', '모델가격(달러)']\n",
    "    X = train.drop(features_to_drop, axis=1)\n",
    "    test_data = test.drop(['ID'], axis=1)\n",
    "    \n",
    "    return X, y, test_data\n",
    "\n",
    "# LightGBM 모델 학습\n",
    "def train_model(X, y):\n",
    "    # 기본 모델 파라미터\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.9,\n",
    "        'n_estimators': 1000,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # 모델 초기화 및 학습\n",
    "    model = LGBMRegressor(**params)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 예측 및 제출 파일 생성\n",
    "def make_predictions(model, test_data, test_ids):\n",
    "    # 예측\n",
    "    predictions = model.predict(test_data)\n",
    "    \n",
    "    # 제출 파일 생성\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_ids,\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    # 제출 파일 저장\n",
    "    submission.to_csv('./submission.csv', index=False)\n",
    "    return submission\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    print(\"Loading data...\")\n",
    "    train, test = load_data()\n",
    "    \n",
    "    # 데이터 준비\n",
    "    print(\"Preparing data...\")\n",
    "    X, y, test_data = prepare_data(train, test)\n",
    "    \n",
    "    # 모델 학습\n",
    "    print(\"Training model...\")\n",
    "    model = train_model(X, y)\n",
    "    \n",
    "    # 예측 및 제출 파일 생성\n",
    "    print(\"Making predictions...\")\n",
    "    submission = make_predictions(model, test_data, test['ID'])\n",
    "    print(\"Submission file created successfully!\")\n",
    "    \n",
    "    # 간단한 모델 성능 평가\n",
    "    train_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, train_pred))\n",
    "    r2 = r2_score(y, train_pred)\n",
    "    print(f\"\\nModel Performance on Training Data:\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3014032924.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 특성 중요도 ===\n",
      "               feature    importance\n",
      "0           brand_tier  7.888420e-01\n",
      "4     battery_capacity  1.045067e-01\n",
      "1  brand_model_encoded  9.245663e-02\n",
      "2   drive_type_encoded  5.297148e-03\n",
      "6             warranty  3.508743e-03\n",
      "5         log_distance  3.362346e-03\n",
      "3    condition_encoded  1.608771e-03\n",
      "7                  age  4.175338e-04\n",
      "8             accident  1.457310e-07\n",
      "\n",
      "학습 데이터 RMSE: 1.35\n",
      "학습 데이터 R2 Score: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3014032924.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class HierarchicalPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.brand_model_encoder = LabelEncoder()\n",
    "        self.drive_type_encoder = LabelEncoder()\n",
    "        self.condition_encoder = LabelEncoder()\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "    def create_brand_tier(self, manufacturer):\n",
    "        if manufacturer == 'P사':\n",
    "            return 3  # Premium\n",
    "        elif manufacturer in ['A사', 'T사', 'B사']:\n",
    "            return 2  # Mid-high\n",
    "        else:\n",
    "            return 1  # Mass market\n",
    "            \n",
    "    def preprocess_data(self, df):\n",
    "        # 브랜드 티어 생성\n",
    "        df['brand_tier'] = df['제조사'].apply(self.create_brand_tier)\n",
    "        \n",
    "        # 브랜드-모델 조합 생성\n",
    "        df['brand_model'] = df['제조사'] + '_' + df['모델']\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        df['brand_model_encoded'] = self.brand_model_encoder.fit_transform(df['brand_model'])\n",
    "        df['drive_type_encoded'] = self.drive_type_encoder.fit_transform(df['구동방식'])\n",
    "        df['condition_encoded'] = self.condition_encoder.fit_transform(df['차량상태'])\n",
    "        \n",
    "        # 주행거리 로그 변환\n",
    "        df['log_distance'] = np.log1p(df['주행거리(km)'])\n",
    "        \n",
    "        # 배터리 용량 결측치 처리\n",
    "        df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'), inplace=True)\n",
    "        \n",
    "        # 사고이력 수치화\n",
    "        df['accident_num'] = (df['사고이력'] == 'Yes').astype(int)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def create_features(self, df):\n",
    "        features = pd.DataFrame({\n",
    "            'brand_tier': df['brand_tier'],\n",
    "            'brand_model_encoded': df['brand_model_encoded'],\n",
    "            'drive_type_encoded': df['drive_type_encoded'],\n",
    "            'condition_encoded': df['condition_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'log_distance': df['log_distance'],\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'age': df['연식(년)'],\n",
    "            'accident': df['accident_num']\n",
    "        })\n",
    "        return features\n",
    "        \n",
    "    def fit(self, train_df):\n",
    "        processed_df = self.preprocess_data(train_df)\n",
    "        X = self.create_features(processed_df)\n",
    "        y = processed_df['가격(백만원)']\n",
    "        \n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        # 특성 중요도 출력\n",
    "        importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "        print(\"\\n=== 특성 중요도 ===\")\n",
    "        print(importance.sort_values('importance', ascending=False))\n",
    "        \n",
    "        # 학습 성능 평가\n",
    "        train_pred = self.model.predict(X)\n",
    "        train_rmse = np.sqrt(mean_squared_error(y, train_pred))\n",
    "        train_r2 = r2_score(y, train_pred)\n",
    "        \n",
    "        print(f\"\\n학습 데이터 RMSE: {train_rmse:.2f}\")\n",
    "        print(f\"학습 데이터 R2 Score: {train_r2:.4f}\")\n",
    "        \n",
    "    def predict(self, test_df):\n",
    "        processed_df = self.preprocess_data(test_df)\n",
    "        X = self.create_features(processed_df)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = HierarchicalPricePredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "# 예측 및 제출 파일 생성\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "submission.to_csv('hierarchical_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3014032924.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'), inplace=True)\n",
      "[I 2024-12-19 10:39:56,980] A new study created in memory with name: no-name-89321955-7b5a-4df7-80e8-ee5b96ee5470\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3445331684.py:18: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3445331684.py:22: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0)\n",
      "[I 2024-12-19 10:40:01,374] Trial 0 finished with value: 1.4595112315638734 and parameters: {'n_estimators': 749, 'learning_rate': 0.03281244118003403, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.6634923374117248}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:03,196] Trial 1 finished with value: 30.441667784178662 and parameters: {'n_estimators': 154, 'learning_rate': 0.0012098706930029368, 'max_depth': 8, 'min_samples_split': 12, 'min_samples_leaf': 4, 'subsample': 0.6196778422438164}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:06,888] Trial 2 finished with value: 3.79530534055869 and parameters: {'n_estimators': 425, 'learning_rate': 0.006058294121450942, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 10, 'subsample': 0.9961933289191905}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:09,326] Trial 3 finished with value: 3.3943724038700616 and parameters: {'n_estimators': 320, 'learning_rate': 0.007984511116618107, 'max_depth': 9, 'min_samples_split': 15, 'min_samples_leaf': 9, 'subsample': 0.6245041043315328}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:10,873] Trial 4 finished with value: 2.455573143120975 and parameters: {'n_estimators': 304, 'learning_rate': 0.010839516296740247, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.6776314113818876}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:13,442] Trial 5 finished with value: 2.27199962923083 and parameters: {'n_estimators': 375, 'learning_rate': 0.008760138259243676, 'max_depth': 8, 'min_samples_split': 16, 'min_samples_leaf': 8, 'subsample': 0.8981197470325796}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:14,490] Trial 6 finished with value: 23.02026255126639 and parameters: {'n_estimators': 265, 'learning_rate': 0.0018377382125848096, 'max_depth': 5, 'min_samples_split': 19, 'min_samples_leaf': 7, 'subsample': 0.6955727232987291}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:18,777] Trial 7 finished with value: 1.6172731619269285 and parameters: {'n_estimators': 788, 'learning_rate': 0.0950771214683519, 'max_depth': 7, 'min_samples_split': 19, 'min_samples_leaf': 3, 'subsample': 0.6966143825772236}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:20,320] Trial 8 finished with value: 10.875938096303294 and parameters: {'n_estimators': 431, 'learning_rate': 0.0035399023575089852, 'max_depth': 4, 'min_samples_split': 8, 'min_samples_leaf': 1, 'subsample': 0.7622929383100199}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:26,660] Trial 9 finished with value: 12.161413769127918 and parameters: {'n_estimators': 924, 'learning_rate': 0.0012011150968592075, 'max_depth': 10, 'min_samples_split': 17, 'min_samples_leaf': 1, 'subsample': 0.7542956811510109}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:28,778] Trial 10 finished with value: 1.8740451642824005 and parameters: {'n_estimators': 679, 'learning_rate': 0.03784911822792912, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 5, 'subsample': 0.8259356110053616}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:31,919] Trial 11 finished with value: 1.5377958049876899 and parameters: {'n_estimators': 751, 'learning_rate': 0.07972929402189206, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 3, 'subsample': 0.6953245181446445}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:34,856] Trial 12 finished with value: 1.4782284850190912 and parameters: {'n_estimators': 633, 'learning_rate': 0.03699667356008384, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 3, 'subsample': 0.820718715281921}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:37,768] Trial 13 finished with value: 1.4846107540769478 and parameters: {'n_estimators': 608, 'learning_rate': 0.025385231427437666, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 3, 'subsample': 0.844153621401458}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:41,012] Trial 14 finished with value: 2.021781854544165 and parameters: {'n_estimators': 992, 'learning_rate': 0.025319212910682988, 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 6, 'subsample': 0.9036920414233345}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:43,948] Trial 15 finished with value: 1.4781982908342166 and parameters: {'n_estimators': 573, 'learning_rate': 0.0423732753248423, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2, 'subsample': 0.7658416788519219}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:46,423] Trial 16 finished with value: 1.477395920856067 and parameters: {'n_estimators': 504, 'learning_rate': 0.017014291728444243, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 2, 'subsample': 0.7570629026834699}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:48,661] Trial 17 finished with value: 1.5659406681965637 and parameters: {'n_estimators': 503, 'learning_rate': 0.017263446958412698, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 5, 'subsample': 0.6613521048540145}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:51,593] Trial 18 finished with value: 1.808976490045594 and parameters: {'n_estimators': 837, 'learning_rate': 0.015045991863626004, 'max_depth': 4, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.7273346547433839}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:53,759] Trial 19 finished with value: 4.974937439312724 and parameters: {'n_estimators': 718, 'learning_rate': 0.004570643531797828, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 4, 'subsample': 0.6120976449451421}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:40:57,696] Trial 20 finished with value: 1.5889559113608942 and parameters: {'n_estimators': 864, 'learning_rate': 0.06359930927729208, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.6550586283970816}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:41:00,559] Trial 21 finished with value: 1.4866303487025472 and parameters: {'n_estimators': 531, 'learning_rate': 0.04679608209464259, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2, 'subsample': 0.7747469584691078}. Best is trial 0 with value: 1.4595112315638734.\n",
      "[I 2024-12-19 10:41:03,162] Trial 22 finished with value: 1.44744352691559 and parameters: {'n_estimators': 535, 'learning_rate': 0.023897362110491257, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 2, 'subsample': 0.7354730803072546}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:06,042] Trial 23 finished with value: 1.472365091880453 and parameters: {'n_estimators': 483, 'learning_rate': 0.01363306163693396, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.7441030353544801}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:10,108] Trial 24 finished with value: 1.497101265551437 and parameters: {'n_estimators': 654, 'learning_rate': 0.024675687427406022, 'max_depth': 8, 'min_samples_split': 14, 'min_samples_leaf': 4, 'subsample': 0.7244479782397174}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:13,079] Trial 25 finished with value: 1.468414444086709 and parameters: {'n_estimators': 471, 'learning_rate': 0.011507928879640871, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 4, 'subsample': 0.7281908957944832}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:14,491] Trial 26 finished with value: 1.4968196723234066 and parameters: {'n_estimators': 189, 'learning_rate': 0.02509233815680138, 'max_depth': 10, 'min_samples_split': 13, 'min_samples_leaf': 2, 'subsample': 0.793325150358378}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:17,036] Trial 27 finished with value: 1.544729140488672 and parameters: {'n_estimators': 418, 'learning_rate': 0.05289699984499948, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 5, 'subsample': 0.6467949250181458}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:20,679] Trial 28 finished with value: 1.4917359863314938 and parameters: {'n_estimators': 573, 'learning_rate': 0.010718440762215828, 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 1, 'subsample': 0.7179941831589679}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:21,634] Trial 29 finished with value: 11.609566952136381 and parameters: {'n_estimators': 183, 'learning_rate': 0.006443503216943024, 'max_depth': 7, 'min_samples_split': 12, 'min_samples_leaf': 3, 'subsample': 0.6351336847656336}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:23,886] Trial 30 finished with value: 1.5225847796354994 and parameters: {'n_estimators': 732, 'learning_rate': 0.03098086714027941, 'max_depth': 4, 'min_samples_split': 10, 'min_samples_leaf': 4, 'subsample': 0.6019794790648365}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:26,814] Trial 31 finished with value: 1.4725763358553596 and parameters: {'n_estimators': 491, 'learning_rate': 0.013503649014219016, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.7341244315812814}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:30,055] Trial 32 finished with value: 1.463875065666002 and parameters: {'n_estimators': 457, 'learning_rate': 0.013004651900190085, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 4, 'subsample': 0.7975499231079692}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:32,844] Trial 33 finished with value: 1.476315834250596 and parameters: {'n_estimators': 396, 'learning_rate': 0.018916815740339477, 'max_depth': 9, 'min_samples_split': 13, 'min_samples_leaf': 5, 'subsample': 0.7888006120356841}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:35,466] Trial 34 finished with value: 3.5391534644168003 and parameters: {'n_estimators': 340, 'learning_rate': 0.007243159759467831, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 7, 'subsample': 0.8630263169519279}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:37,782] Trial 35 finished with value: 2.1529340169540268 and parameters: {'n_estimators': 449, 'learning_rate': 0.009334081513010638, 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 10, 'subsample': 0.680090252770212}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:39,645] Trial 36 finished with value: 8.936866258611655 and parameters: {'n_estimators': 269, 'learning_rate': 0.0052967989197749915, 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 3, 'subsample': 0.8101126722498296}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:41,487] Trial 37 finished with value: 14.79690567812886 and parameters: {'n_estimators': 350, 'learning_rate': 0.002797968772509762, 'max_depth': 5, 'min_samples_split': 14, 'min_samples_leaf': 2, 'subsample': 0.9870356939760198}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:44,804] Trial 38 finished with value: 1.4794514824222893 and parameters: {'n_estimators': 591, 'learning_rate': 0.01971110683513887, 'max_depth': 7, 'min_samples_split': 17, 'min_samples_leaf': 1, 'subsample': 0.704314935638944}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:48,088] Trial 39 finished with value: 1.5818543197039854 and parameters: {'n_estimators': 542, 'learning_rate': 0.012238595100845786, 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 6, 'subsample': 0.6810651000675227}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:51,637] Trial 40 finished with value: 1.682249016460716 and parameters: {'n_estimators': 455, 'learning_rate': 0.008969071377330442, 'max_depth': 10, 'min_samples_split': 7, 'min_samples_leaf': 7, 'subsample': 0.8812223288609146}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:54,485] Trial 41 finished with value: 1.4875294581009746 and parameters: {'n_estimators': 479, 'learning_rate': 0.012688971887319276, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.747424828772755}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:56,343] Trial 42 finished with value: 1.4721989156530249 and parameters: {'n_estimators': 295, 'learning_rate': 0.031248488768036174, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 4, 'subsample': 0.7757584685239312}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:41:58,158] Trial 43 finished with value: 1.4767180258998025 and parameters: {'n_estimators': 288, 'learning_rate': 0.03439925812762861, 'max_depth': 8, 'min_samples_split': 13, 'min_samples_leaf': 3, 'subsample': 0.7779213398461189}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:01,032] Trial 44 finished with value: 1.534966233895164 and parameters: {'n_estimators': 365, 'learning_rate': 0.054532837824318746, 'max_depth': 9, 'min_samples_split': 12, 'min_samples_leaf': 5, 'subsample': 0.8405744193265858}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:05,160] Trial 45 finished with value: 1.5055242730487122 and parameters: {'n_estimators': 682, 'learning_rate': 0.029420730400701436, 'max_depth': 7, 'min_samples_split': 11, 'min_samples_leaf': 3, 'subsample': 0.8073199610686939}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:06,794] Trial 46 finished with value: 1.658100775387248 and parameters: {'n_estimators': 399, 'learning_rate': 0.022628515398129392, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.708639325629608}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:08,634] Trial 47 finished with value: 1.542780392646191 and parameters: {'n_estimators': 317, 'learning_rate': 0.07321654337009127, 'max_depth': 8, 'min_samples_split': 11, 'min_samples_leaf': 1, 'subsample': 0.6707223850850794}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:10,232] Trial 48 finished with value: 1.6124558826055195 and parameters: {'n_estimators': 227, 'learning_rate': 0.021447651407876543, 'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 9, 'subsample': 0.783294703352398}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:14,146] Trial 49 finished with value: 1.602263606698306 and parameters: {'n_estimators': 789, 'learning_rate': 0.09904800293598098, 'max_depth': 6, 'min_samples_split': 15, 'min_samples_leaf': 2, 'subsample': 0.7399655173909501}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:18,637] Trial 50 finished with value: 1.4938281845511805 and parameters: {'n_estimators': 615, 'learning_rate': 0.015767042112782088, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 3, 'subsample': 0.8330864099754044}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:22,073] Trial 51 finished with value: 1.4907967845881593 and parameters: {'n_estimators': 546, 'learning_rate': 0.010634604285399626, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 4, 'subsample': 0.7525452522201356}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:25,840] Trial 52 finished with value: 1.5173407274544928 and parameters: {'n_estimators': 471, 'learning_rate': 0.03097691835889987, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 3, 'subsample': 0.7630374229642796}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:30,780] Trial 53 finished with value: 1.5412343486073414 and parameters: {'n_estimators': 514, 'learning_rate': 0.014175192820249212, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 5, 'subsample': 0.6865754823572114}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:32,277] Trial 54 finished with value: 1.59067260420556 and parameters: {'n_estimators': 126, 'learning_rate': 0.04383360506771568, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 6, 'subsample': 0.708748303167441}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:35,851] Trial 55 finished with value: 4.096604027171126 and parameters: {'n_estimators': 422, 'learning_rate': 0.007686072617967011, 'max_depth': 5, 'min_samples_split': 12, 'min_samples_leaf': 4, 'subsample': 0.8014627542715231}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:43,405] Trial 56 finished with value: 1.4961916187764068 and parameters: {'n_estimators': 658, 'learning_rate': 0.016610943504875925, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5, 'subsample': 0.7389071902216807}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:48,962] Trial 57 finished with value: 1.4567672136496659 and parameters: {'n_estimators': 573, 'learning_rate': 0.02741082827709635, 'max_depth': 6, 'min_samples_split': 20, 'min_samples_leaf': 2, 'subsample': 0.7667275704118115}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:42:57,737] Trial 58 finished with value: 1.5098760463907923 and parameters: {'n_estimators': 916, 'learning_rate': 0.036187082103378836, 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 2, 'subsample': 0.764502862219389}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:05,899] Trial 59 finished with value: 1.474337273849619 and parameters: {'n_estimators': 810, 'learning_rate': 0.02813273185192043, 'max_depth': 6, 'min_samples_split': 19, 'min_samples_leaf': 2, 'subsample': 0.8199453311057325}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:09,997] Trial 60 finished with value: 21.14212367323722 and parameters: {'n_estimators': 578, 'learning_rate': 0.0010020604405225019, 'max_depth': 5, 'min_samples_split': 17, 'min_samples_leaf': 1, 'subsample': 0.6308981164854823}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:15,185] Trial 61 finished with value: 1.4792142677771996 and parameters: {'n_estimators': 517, 'learning_rate': 0.01998823791594373, 'max_depth': 7, 'min_samples_split': 20, 'min_samples_leaf': 3, 'subsample': 0.7173298293397555}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:21,850] Trial 62 finished with value: 1.4942321837321584 and parameters: {'n_estimators': 698, 'learning_rate': 0.01198604366705928, 'max_depth': 6, 'min_samples_split': 11, 'min_samples_leaf': 4, 'subsample': 0.7809446800604872}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:25,125] Trial 63 finished with value: 1.5140399321171638 and parameters: {'n_estimators': 387, 'learning_rate': 0.03887419576178885, 'max_depth': 5, 'min_samples_split': 13, 'min_samples_leaf': 2, 'subsample': 0.7717494743156208}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:31,204] Trial 64 finished with value: 1.5024435906753293 and parameters: {'n_estimators': 446, 'learning_rate': 0.023814211529191463, 'max_depth': 10, 'min_samples_split': 18, 'min_samples_leaf': 1, 'subsample': 0.7484613815515633}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:35,263] Trial 65 finished with value: 1.9013708292804439 and parameters: {'n_estimators': 605, 'learning_rate': 0.018809014060289418, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 4, 'subsample': 0.7267152491716358}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:42,935] Trial 66 finished with value: 1.5606334447846217 and parameters: {'n_estimators': 753, 'learning_rate': 0.047777245352981786, 'max_depth': 7, 'min_samples_split': 10, 'min_samples_leaf': 3, 'subsample': 0.696035282598436}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:49,314] Trial 67 finished with value: 1.4539646930614503 and parameters: {'n_estimators': 644, 'learning_rate': 0.02708284907703357, 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 2, 'subsample': 0.796390288540762}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:43:55,972] Trial 68 finished with value: 1.509170965275354 and parameters: {'n_estimators': 637, 'learning_rate': 0.060675012833242, 'max_depth': 6, 'min_samples_split': 14, 'min_samples_leaf': 1, 'subsample': 0.8567020256280387}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:44:00,743] Trial 69 finished with value: 1.48448389137181 and parameters: {'n_estimators': 565, 'learning_rate': 0.028523507825341656, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.7881431065605116}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:44:07,186] Trial 70 finished with value: 1.486825985625163 and parameters: {'n_estimators': 642, 'learning_rate': 0.04085795230399006, 'max_depth': 6, 'min_samples_split': 12, 'min_samples_leaf': 2, 'subsample': 0.8168750921490879}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:44:12,665] Trial 71 finished with value: 1.4545569648620444 and parameters: {'n_estimators': 550, 'learning_rate': 0.0330122191336203, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 3, 'subsample': 0.8035564985452597}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:44:17,866] Trial 72 finished with value: 1.4515392519118178 and parameters: {'n_estimators': 526, 'learning_rate': 0.03268116656861141, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 3, 'subsample': 0.7905546145469385}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:44:23,354] Trial 73 finished with value: 1.4554447513678945 and parameters: {'n_estimators': 553, 'learning_rate': 0.03469471860612505, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.7940835867484028}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:44:28,731] Trial 74 finished with value: 1.4623763859232963 and parameters: {'n_estimators': 537, 'learning_rate': 0.0348960244283249, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.7971799585535462}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:44:34,301] Trial 75 finished with value: 1.4779755764803844 and parameters: {'n_estimators': 549, 'learning_rate': 0.05026441529662217, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 3, 'subsample': 0.8286012806807238}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:44:40,449] Trial 76 finished with value: 1.4789856596906865 and parameters: {'n_estimators': 614, 'learning_rate': 0.03403507115917047, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 2, 'subsample': 0.799567335084564}. Best is trial 22 with value: 1.44744352691559.\n",
      "[I 2024-12-19 10:44:45,678] Trial 77 finished with value: 1.4450410555490731 and parameters: {'n_estimators': 521, 'learning_rate': 0.025142463570636514, 'max_depth': 6, 'min_samples_split': 6, 'min_samples_leaf': 2, 'subsample': 0.8154904674312935}. Best is trial 77 with value: 1.4450410555490731.\n",
      "[I 2024-12-19 10:44:51,711] Trial 78 finished with value: 1.4518059685636202 and parameters: {'n_estimators': 669, 'learning_rate': 0.025838600208058966, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.8491879694294974}. Best is trial 77 with value: 1.4450410555490731.\n",
      "[I 2024-12-19 10:44:56,954] Trial 79 finished with value: 1.498680516628043 and parameters: {'n_estimators': 587, 'learning_rate': 0.040866800626499965, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 1, 'subsample': 0.8493654608424154}. Best is trial 77 with value: 1.4450410555490731.\n",
      "[I 2024-12-19 10:45:02,407] Trial 80 finished with value: 1.4552964652183644 and parameters: {'n_estimators': 674, 'learning_rate': 0.025865623017557862, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.8741524564065999}. Best is trial 77 with value: 1.4450410555490731.\n",
      "[I 2024-12-19 10:45:06,199] Trial 81 finished with value: 1.4478341171753115 and parameters: {'n_estimators': 667, 'learning_rate': 0.02485281629174029, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.8863699616979926}. Best is trial 77 with value: 1.4450410555490731.\n",
      "[I 2024-12-19 10:45:10,147] Trial 82 finished with value: 1.4421303153615308 and parameters: {'n_estimators': 677, 'learning_rate': 0.021911456696934582, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.9037655684026549}. Best is trial 82 with value: 1.4421303153615308.\n",
      "[I 2024-12-19 10:45:14,395] Trial 83 finished with value: 1.4411007955163986 and parameters: {'n_estimators': 715, 'learning_rate': 0.023432444724758052, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.9228924163284712}. Best is trial 83 with value: 1.4411007955163986.\n",
      "[I 2024-12-19 10:45:19,464] Trial 84 finished with value: 1.4769757444269538 and parameters: {'n_estimators': 756, 'learning_rate': 0.02162070764157811, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.9285805556603448}. Best is trial 83 with value: 1.4411007955163986.\n",
      "[I 2024-12-19 10:45:23,646] Trial 85 finished with value: 1.4280484822928456 and parameters: {'n_estimators': 718, 'learning_rate': 0.017725077124713506, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9197350660796557}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:45:27,310] Trial 86 finished with value: 1.519827286111824 and parameters: {'n_estimators': 726, 'learning_rate': 0.01778049732950169, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 2, 'subsample': 0.9336889015939815}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:45:31,374] Trial 87 finished with value: 1.4449001223306779 and parameters: {'n_estimators': 701, 'learning_rate': 0.021210663205555907, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9078066726920969}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:45:34,877] Trial 88 finished with value: 1.467637299724868 and parameters: {'n_estimators': 705, 'learning_rate': 0.022065416738473755, 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.9089293267714921}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:45:40,148] Trial 89 finished with value: 1.455670729190866 and parameters: {'n_estimators': 778, 'learning_rate': 0.015165193612535929, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 1, 'subsample': 0.9507871500646031}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:45:44,013] Trial 90 finished with value: 1.446897400322706 and parameters: {'n_estimators': 676, 'learning_rate': 0.023705749851964414, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2, 'subsample': 0.9012807056362764}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:45:47,895] Trial 91 finished with value: 1.454375194958145 and parameters: {'n_estimators': 678, 'learning_rate': 0.02417922719728988, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 2, 'subsample': 0.890565188492262}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:45:51,965] Trial 92 finished with value: 1.4435593381729457 and parameters: {'n_estimators': 705, 'learning_rate': 0.020371223512876162, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9134822137521295}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:45:56,233] Trial 93 finished with value: 1.4403039429166842 and parameters: {'n_estimators': 736, 'learning_rate': 0.021186463625478383, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9220836882546856}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:46:00,470] Trial 94 finished with value: 1.4437901456856868 and parameters: {'n_estimators': 737, 'learning_rate': 0.020110801569882708, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9137445320859533}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:46:04,781] Trial 95 finished with value: 1.4431599713530192 and parameters: {'n_estimators': 741, 'learning_rate': 0.019883896981459686, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9133801229056041}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:46:10,344] Trial 96 finished with value: 1.4663830601642522 and parameters: {'n_estimators': 853, 'learning_rate': 0.01774121823726796, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 2, 'subsample': 0.9097549487616838}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:46:15,073] Trial 97 finished with value: 1.4445851893540034 and parameters: {'n_estimators': 813, 'learning_rate': 0.02021167453805169, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 1, 'subsample': 0.9266646126597856}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:46:19,985] Trial 98 finished with value: 1.4416217892961363 and parameters: {'n_estimators': 816, 'learning_rate': 0.01939591231962444, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.9598382991147966}. Best is trial 85 with value: 1.4280484822928456.\n",
      "[I 2024-12-19 10:46:24,882] Trial 99 finished with value: 1.439303077525553 and parameters: {'n_estimators': 803, 'learning_rate': 0.01965417676605557, 'max_depth': 6, 'min_samples_split': 3, 'min_samples_leaf': 1, 'subsample': 0.9615872197222981}. Best is trial 85 with value: 1.4280484822928456.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 최적 하이퍼파라미터 ===\n",
      "{'n_estimators': 718, 'learning_rate': 0.017725077124713506, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 2, 'subsample': 0.9197350660796557}\n",
      "\n",
      "교차 검증 RMSE: 1.4280 (+/- 0.2182)\n",
      "\n",
      "=== 특성 중요도 ===\n",
      "               feature  importance\n",
      "0           brand_tier    0.788361\n",
      "4     battery_capacity    0.101547\n",
      "1  brand_model_encoded    0.095457\n",
      "2   drive_type_encoded    0.004445\n",
      "5         log_distance    0.004288\n",
      "6             warranty    0.004073\n",
      "3    condition_encoded    0.001463\n",
      "7                  age    0.000361\n",
      "8             accident    0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3014032924.py:44: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "\n",
    "class TunedPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.best_params = None\n",
    "        self.model = None\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def objective(self, trial, X, y):\n",
    "        # 하이퍼파라미터 탐색 공간 정의\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.6, 1.0)\n",
    "        }\n",
    "        \n",
    "        # 교차 검증 점수 계산\n",
    "        model = GradientBoostingRegressor(**params, random_state=42)\n",
    "        scores = cross_val_score(model, X, y, \n",
    "                               scoring='neg_root_mean_squared_error',\n",
    "                               cv=self.kf,\n",
    "                               n_jobs=-1)\n",
    "        \n",
    "        return -scores.mean()  # 최소화할 RMSE 반환\n",
    "    \n",
    "    def tune_model(self, X, y, n_trials=100):\n",
    "        # Optuna를 사용한 하이퍼파라미터 최적화\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(lambda trial: self.objective(trial, X, y), \n",
    "                      n_trials=n_trials)\n",
    "        \n",
    "        self.best_params = study.best_params\n",
    "        print(\"\\n=== 최적 하이퍼파라미터 ===\")\n",
    "        print(self.best_params)\n",
    "        \n",
    "        # 최적 파라미터로 최종 모델 학습\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            **self.best_params,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # 교차 검증으로 성능 평가\n",
    "        cv_scores = cross_val_score(self.model, X, y,\n",
    "                                  scoring='neg_root_mean_squared_error',\n",
    "                                  cv=self.kf,\n",
    "                                  n_jobs=-1)\n",
    "        \n",
    "        print(f\"\\n교차 검증 RMSE: {-cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "        \n",
    "        # 전체 데이터로 최종 모델 학습\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        # 특성 중요도 출력\n",
    "        importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "        print(\"\\n=== 특성 중요도 ===\")\n",
    "        print(importance.sort_values('importance', ascending=False))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# 기존의 전처리 코드는 그대로 사용\n",
    "# (이전 코드의 preprocess_data와 create_features 함수 활용)\n",
    "\n",
    "# 모델 튜닝 실행\n",
    "train_data = pd.read_csv('train.csv')\n",
    "predictor = HierarchicalPricePredictor()  # 이전 코드의 전처리 클래스\n",
    "processed_df = predictor.preprocess_data(train_data)\n",
    "X = predictor.create_features(processed_df)\n",
    "y = processed_df['가격(백만원)']\n",
    "\n",
    "tuned_predictor = TunedPricePredictor()\n",
    "tuned_predictor.tune_model(X, y)\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "test_data = pd.read_csv('test.csv')\n",
    "processed_test = predictor.preprocess_data(test_data)\n",
    "X_test = predictor.create_features(processed_test)\n",
    "predictions = tuned_predictor.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "submission.to_csv('tuned_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 구동방식별 통계 ===\n",
      "     가격(백만원)                              연식(년)      \n",
      "       count   mean    std    min     max  mean   std\n",
      "구동방식                                                 \n",
      "AWD     5167  72.29  38.04  16.56  161.09  0.21  0.55\n",
      "FWD     1267  28.11   9.01   9.00   49.08  0.30  0.66\n",
      "RWD     1063  54.70  20.15  21.72   81.15  0.20  0.54\n",
      "\n",
      "=== 연식별 구동방식 통계 ===\n",
      "           가격(백만원)              \n",
      "             count   mean    std\n",
      "연식(년) 구동방식                      \n",
      "0     AWD     4454  72.47  37.82\n",
      "      FWD     1026  29.18   9.35\n",
      "      RWD      915  56.14  20.22\n",
      "1     AWD      354  71.71  39.89\n",
      "      FWD      102  23.87   5.39\n",
      "      RWD       80  46.92  16.46\n",
      "2     AWD      359  70.66  38.97\n",
      "      FWD      139  23.31   5.43\n",
      "      RWD       68  44.42  18.19\n",
      "\n",
      "=== 구동방식별 연식에 따른 가격 ===\n",
      "        mean               count          \n",
      "연식(년)      0      1      2     0    1    2\n",
      "구동방식                                      \n",
      "AWD    72.47  71.71  70.66  4454  354  359\n",
      "FWD    29.18  23.87  23.31  1026  102  139\n",
      "RWD    56.14  46.92  44.42   915   80   68\n",
      "\n",
      "=== 구동방식별 주행거리와 가격 통계 ===\n",
      "      주행거리(km)                       가격(백만원)       \n",
      "          mean       std min     max    mean    std\n",
      "구동방식                                               \n",
      "AWD   44215.39  55801.78   3  199827   72.29  38.04\n",
      "FWD   44130.41  51782.84  15  199323   28.11   9.01\n",
      "RWD   44828.63  56271.36  36  198583   54.70  20.15\n",
      "\n",
      "=== 연식별 가격 변화 ===\n",
      "        mean    std  count\n",
      "연식(년)                     \n",
      "0      63.19  36.35   6395\n",
      "1      58.91  38.20    536\n",
      "2      55.88  37.74    566\n",
      "\n",
      "=== 전체 평균 대비 가격 비율 ===\n",
      "연식(년)  구동방식\n",
      "0      AWD     1.16\n",
      "       FWD     0.47\n",
      "       RWD     0.90\n",
      "1      AWD     1.15\n",
      "       FWD     0.38\n",
      "       RWD     0.75\n",
      "2      AWD     1.13\n",
      "       FWD     0.37\n",
      "       RWD     0.71\n",
      "Name: 가격(백만원), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "# 1. 구동방식별 기본 통계\n",
    "drive_stats = df.groupby('구동방식').agg({\n",
    "    '가격(백만원)': ['count', 'mean', 'std', 'min', 'max'],\n",
    "    '연식(년)': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "print(\"=== 구동방식별 통계 ===\")\n",
    "print(drive_stats)\n",
    "\n",
    "# 2. 연식별 구동방식 분포와 가격\n",
    "year_drive_stats = df.groupby(['연식(년)', '구동방식']).agg({\n",
    "    '가격(백만원)': ['count', 'mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\n=== 연식별 구동방식 통계 ===\")\n",
    "print(year_drive_stats)\n",
    "\n",
    "# 3. 구동방식별 가격 분포 (연식 구분)\n",
    "price_by_drive_year = pd.pivot_table(\n",
    "    df,\n",
    "    values='가격(백만원)',\n",
    "    index='구동방식',\n",
    "    columns='연식(년)',\n",
    "    aggfunc=['mean', 'count']\n",
    ").round(2)\n",
    "\n",
    "print(\"\\n=== 구동방식별 연식에 따른 가격 ===\")\n",
    "print(price_by_drive_year)\n",
    "\n",
    "# 4. 추가 분석: 구동방식별 주행거리와 가격 관계\n",
    "drive_distance_stats = df.groupby('구동방식').agg({\n",
    "    '주행거리(km)': ['mean', 'std', 'min', 'max'],\n",
    "    '가격(백만원)': ['mean', 'std']\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\n=== 구동방식별 주행거리와 가격 통계 ===\")\n",
    "print(drive_distance_stats)\n",
    "\n",
    "# 5. 연식대별 평균 가격 변화율\n",
    "year_price_change = df.groupby('연식(년)')['가격(백만원)'].agg(['mean', 'std', 'count']).round(2)\n",
    "\n",
    "print(\"\\n=== 연식별 가격 변화 ===\")\n",
    "print(year_price_change)\n",
    "\n",
    "# 6. 연식과 구동방식에 따른 가격 비율 분석\n",
    "overall_mean_price = df['가격(백만원)'].mean()\n",
    "price_ratio = df.groupby(['연식(년)', '구동방식'])['가격(백만원)'].mean() / overall_mean_price\n",
    "\n",
    "print(\"\\n=== 전체 평균 대비 가격 비율 ===\")\n",
    "print(price_ratio.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 특성 중요도 ===\n",
      "                feature  importance\n",
      "2  brand_drive_combined    0.420520\n",
      "0            brand_tier    0.368591\n",
      "4      battery_capacity    0.104599\n",
      "3         model_encoded    0.097604\n",
      "5          log_distance    0.004124\n",
      "7              warranty    0.002515\n",
      "6     condition_encoded    0.001534\n",
      "1          drive_weight    0.000378\n",
      "8                   age    0.000130\n",
      "9              accident    0.000005\n",
      "\n",
      "학습 데이터 RMSE: 1.2102\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class WeightedPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            n_estimators=700,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            random_state=42\n",
    "        )\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        # 레이블 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(df[col])\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 브랜드 티어 생성 (가중치 부여)\n",
    "        brand_tier_map = {\n",
    "            'P사': 3,\n",
    "            'A사': 2, 'T사': 2, 'B사': 2,\n",
    "            'V사': 1, 'H사': 1, 'K사': 1\n",
    "        }\n",
    "        df['brand_tier'] = df['제조사'].map(brand_tier_map)\n",
    "        \n",
    "        # 구동방식 가중치 부여\n",
    "        drive_weight_map = {\n",
    "            'AWD': 3,\n",
    "            'RWD': 2,\n",
    "            'FWD': 1\n",
    "        }\n",
    "        df['drive_weight'] = df['구동방식'].map(drive_weight_map)\n",
    "        \n",
    "        # 브랜드-구동방식 조합 특성\n",
    "        df['brand_drive_combined'] = df['brand_tier'] * df['drive_weight']\n",
    "        \n",
    "        # 주요 특성 선택 및 가중치 반영\n",
    "        features = pd.DataFrame({\n",
    "            'brand_tier': df['brand_tier'] * 2,  # 브랜드 중요도 2배\n",
    "            'drive_weight': df['drive_weight'] * 2,  # 구동방식 중요도 2배\n",
    "            'brand_drive_combined': df['brand_drive_combined'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'battery_capacity': df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean')),\n",
    "            'log_distance': np.log1p(df['주행거리(km)']),\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'age': df['연식(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int)\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        # 특성 중요도 출력\n",
    "        importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "        print(\"\\n=== 특성 중요도 ===\")\n",
    "        print(importance.sort_values('importance', ascending=False))\n",
    "        \n",
    "        # 학습 성능 평가\n",
    "        train_pred = self.model.predict(X)\n",
    "        rmse = np.sqrt(((y - train_pred) ** 2).mean())\n",
    "        print(f\"\\n학습 데이터 RMSE: {rmse:.4f}\")\n",
    "        \n",
    "    def predict(self, test_df):\n",
    "        X = self.create_features(test_df)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = WeightedPricePredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "submission.to_csv('weighted_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.6264, R2: 0.9981\n",
      "Fold 2 - RMSE: 2.0375, R2: 0.9970\n",
      "Fold 3 - RMSE: 1.4646, R2: 0.9984\n",
      "Fold 4 - RMSE: 1.3770, R2: 0.9986\n",
      "Fold 5 - RMSE: 1.4848, R2: 0.9982\n",
      "\n",
      "평균 RMSE: 1.5981 (+/- 0.4677)\n",
      "\n",
      "=== 특성 중요도 ===\n",
      "                feature  importance\n",
      "0  brand_drive_combined    0.431343\n",
      "1            brand_tier    0.357823\n",
      "2      battery_capacity    0.104601\n",
      "3         model_encoded    0.097673\n",
      "4          log_distance    0.004148\n",
      "5              warranty    0.002511\n",
      "6     condition_encoded    0.001491\n",
      "7          drive_weight    0.000279\n",
      "8                   age    0.000126\n",
      "9              accident    0.000005\n",
      "\n",
      "=== 예측 오차 분석 ===\n",
      "          실제가격     예측가격       오차\n",
      "count  7497.00  7497.00  7497.00\n",
      "mean     62.33    62.33     0.85\n",
      "std      36.65    36.52     1.37\n",
      "min       9.00    13.45     0.00\n",
      "25%      34.39    34.34     0.22\n",
      "50%      56.00    56.32     0.49\n",
      "75%      80.05    79.96     0.89\n",
      "max     161.09   160.46    21.81\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class CVWeightedPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            n_estimators=700,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        # 기존의 feature creation 코드\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(df[col])\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        brand_tier_map = {\n",
    "            'P사': 3,\n",
    "            'A사': 2, 'T사': 2, 'B사': 2,\n",
    "            'V사': 1, 'H사': 1, 'K사': 1\n",
    "        }\n",
    "        df['brand_tier'] = df['제조사'].map(brand_tier_map)\n",
    "        \n",
    "        drive_weight_map = {\n",
    "            'AWD': 3,\n",
    "            'RWD': 2,\n",
    "            'FWD': 1\n",
    "        }\n",
    "        df['drive_weight'] = df['구동방식'].map(drive_weight_map)\n",
    "        \n",
    "        df['brand_drive_combined'] = df['brand_tier'] * df['drive_weight']\n",
    "        \n",
    "        features = pd.DataFrame({\n",
    "            'brand_drive_combined': df['brand_drive_combined'],\n",
    "            'brand_tier': df['brand_tier'] * 2,\n",
    "            'battery_capacity': df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean')),\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'log_distance': np.log1p(df['주행거리(km)']),\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_weight': df['drive_weight'] * 2,\n",
    "            'age': df['연식(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int)\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def cv_evaluate(self, X, y):\n",
    "        cv_scores = []\n",
    "        cv_predictions = np.zeros_like(y)\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # 모델 학습\n",
    "            self.model.fit(X_train, y_train)\n",
    "            \n",
    "            # 검증 세트 예측\n",
    "            val_pred = self.model.predict(X_val)\n",
    "            cv_predictions[val_idx] = val_pred\n",
    "            \n",
    "            # 성능 평가\n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            fold_r2 = r2_score(y_val, val_pred)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        return cv_scores, cv_predictions\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        # 교차 검증 수행\n",
    "        cv_scores, cv_predictions = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 전체 데이터로 최종 모델 학습\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        # 특성 중요도 출력\n",
    "        importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "        print(\"\\n=== 특성 중요도 ===\")\n",
    "        print(importance.sort_values('importance', ascending=False))\n",
    "        \n",
    "        # 예측 vs 실제 분석\n",
    "        prediction_analysis = pd.DataFrame({\n",
    "            '실제가격': y,\n",
    "            '예측가격': cv_predictions,\n",
    "            '오차': np.abs(y - cv_predictions)\n",
    "        })\n",
    "        \n",
    "        print(\"\\n=== 예측 오차 분석 ===\")\n",
    "        print(prediction_analysis.describe().round(2))\n",
    "        \n",
    "    def predict(self, test_df):\n",
    "        X = self.create_features(test_df)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = CVWeightedPricePredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "submission.to_csv('cv_weighted_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\119116312.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['battery_efficiency'].fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.6313, R2: 0.9981\n",
      "Fold 2 - RMSE: 2.1091, R2: 0.9968\n",
      "Fold 3 - RMSE: 1.5212, R2: 0.9983\n",
      "Fold 4 - RMSE: 1.4768, R2: 0.9984\n",
      "Fold 5 - RMSE: 1.4917, R2: 0.9982\n",
      "\n",
      "평균 RMSE: 1.6460 (+/- 0.4756)\n",
      "\n",
      "=== 특성 중요도 ===\n",
      "                      feature  importance\n",
      "0        brand_drive_combined    0.431179\n",
      "1                  brand_tier    0.357903\n",
      "2            battery_capacity    0.099304\n",
      "7               model_encoded    0.094548\n",
      "6          battery_efficiency    0.010204\n",
      "9                    warranty    0.002913\n",
      "8                log_distance    0.001416\n",
      "5   efficiency_drive_combined    0.001139\n",
      "4   efficiency_brand_combined    0.000442\n",
      "11               drive_weight    0.000300\n",
      "3            efficiency_grade    0.000292\n",
      "10          condition_encoded    0.000214\n",
      "12                        age    0.000142\n",
      "13                   accident    0.000004\n",
      "\n",
      "=== 예측 오차 분석 ===\n",
      "          실제가격     예측가격       오차\n",
      "count  7497.00  7497.00  7497.00\n",
      "mean     62.33    62.34     0.87\n",
      "std      36.65    36.52     1.41\n",
      "min       9.00    14.08     0.00\n",
      "25%      34.39    34.38     0.22\n",
      "50%      56.00    56.05     0.51\n",
      "75%      80.05    79.95     0.90\n",
      "max     161.09   160.37    23.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\119116312.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['battery_efficiency'].fillna(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class BatteryEfficiencyPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            n_estimators=700,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def calculate_battery_efficiency(self, df):\n",
    "        \"\"\"배터리 효율 계산 및 등급 부여\"\"\"\n",
    "        # 기본 배터리 효율 = 배터리용량 / 주행거리\n",
    "        df['battery_efficiency'] = df['배터리용량'] / (df['주행거리(km)'] / 1000)  # kWh/km\n",
    "        \n",
    "        # 결측치는 모델별 평균으로 대체\n",
    "        df['battery_efficiency'].fillna(\n",
    "            df.groupby('모델')['battery_efficiency'].transform('mean'), \n",
    "            inplace=True\n",
    "        )\n",
    "        \n",
    "        # 효율 등급 부여 (quantile 기반)\n",
    "        efficiency_quantiles = df['battery_efficiency'].quantile([0.2, 0.4, 0.6, 0.8])\n",
    "        \n",
    "        def get_efficiency_grade(x):\n",
    "            if x <= efficiency_quantiles[0.2]:\n",
    "                return 5  # 가장 효율적\n",
    "            elif x <= efficiency_quantiles[0.4]:\n",
    "                return 4\n",
    "            elif x <= efficiency_quantiles[0.6]:\n",
    "                return 3\n",
    "            elif x <= efficiency_quantiles[0.8]:\n",
    "                return 2\n",
    "            else:\n",
    "                return 1  # 가장 비효율적\n",
    "        \n",
    "        df['efficiency_grade'] = df['battery_efficiency'].apply(get_efficiency_grade)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        # 배터리 효율 계산\n",
    "        df = self.calculate_battery_efficiency(df)\n",
    "        \n",
    "        # 기존 feature engineering\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(df[col])\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        brand_tier_map = {\n",
    "            'P사': 3,\n",
    "            'A사': 2, 'T사': 2, 'B사': 2,\n",
    "            'V사': 1, 'H사': 1, 'K사': 1\n",
    "        }\n",
    "        df['brand_tier'] = df['제조사'].map(brand_tier_map)\n",
    "        \n",
    "        drive_weight_map = {\n",
    "            'AWD': 3,\n",
    "            'RWD': 2,\n",
    "            'FWD': 1\n",
    "        }\n",
    "        df['drive_weight'] = df['구동방식'].map(drive_weight_map)\n",
    "        \n",
    "        df['brand_drive_combined'] = df['brand_tier'] * df['drive_weight']\n",
    "        \n",
    "        # 배터리 효율 관련 새로운 특성\n",
    "        df['efficiency_brand_combined'] = df['efficiency_grade'] * df['brand_tier']\n",
    "        df['efficiency_drive_combined'] = df['efficiency_grade'] * df['drive_weight']\n",
    "        \n",
    "        features = pd.DataFrame({\n",
    "            'brand_drive_combined': df['brand_drive_combined'],\n",
    "            'brand_tier': df['brand_tier'] * 2,\n",
    "            'battery_capacity': df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean')),\n",
    "            'efficiency_grade': df['efficiency_grade'],\n",
    "            'efficiency_brand_combined': df['efficiency_brand_combined'],\n",
    "            'efficiency_drive_combined': df['efficiency_drive_combined'],\n",
    "            'battery_efficiency': df['battery_efficiency'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'log_distance': np.log1p(df['주행거리(km)']),\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_weight': df['drive_weight'] * 2,\n",
    "            'age': df['연식(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int)\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def cv_evaluate(self, X, y):\n",
    "        cv_scores = []\n",
    "        cv_predictions = np.zeros_like(y)\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            self.model.fit(X_train, y_train)\n",
    "            val_pred = self.model.predict(X_val)\n",
    "            cv_predictions[val_idx] = val_pred\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            fold_r2 = r2_score(y_val, val_pred)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        return cv_scores, cv_predictions\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores, cv_predictions = self.cv_evaluate(X, y)\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "        print(\"\\n=== 특성 중요도 ===\")\n",
    "        print(importance.sort_values('importance', ascending=False))\n",
    "        \n",
    "        prediction_analysis = pd.DataFrame({\n",
    "            '실제가격': y,\n",
    "            '예측가격': cv_predictions,\n",
    "            '오차': np.abs(y - cv_predictions)\n",
    "        })\n",
    "        \n",
    "        print(\"\\n=== 예측 오차 분석 ===\")\n",
    "        print(prediction_analysis.describe().round(2))\n",
    "        \n",
    "    def predict(self, test_df):\n",
    "        X = self.create_features(test_df)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = BatteryEfficiencyPricePredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "submission.to_csv('battery_efficiency_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.5578, R2: 0.9982\n",
      "Fold 2 - RMSE: 1.6256, R2: 0.9981\n",
      "Fold 3 - RMSE: 1.4170, R2: 0.9985\n",
      "Fold 4 - RMSE: 1.3455, R2: 0.9987\n",
      "Fold 5 - RMSE: 1.4114, R2: 0.9984\n",
      "\n",
      "평균 RMSE: 1.4714 (+/- 0.2071)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.1743\n",
      "세그먼트 2 RMSE: 1.3267\n",
      "세그먼트 3 RMSE: 1.8348\n",
      "세그먼트 4 RMSE: 2.5911\n",
      "\n",
      "=== 특성 중요도 ===\n",
      "                   feature  importance\n",
      "2   segment_brand_combined    0.303496\n",
      "4               brand_tier    0.226917\n",
      "3     brand_drive_combined    0.220434\n",
      "5         battery_capacity    0.098580\n",
      "6            model_encoded    0.084132\n",
      "1   segment_drive_combined    0.045328\n",
      "0            model_segment    0.012243\n",
      "8                 warranty    0.003852\n",
      "7             log_distance    0.003428\n",
      "9        condition_encoded    0.001295\n",
      "10            drive_weight    0.000187\n",
      "11                     age    0.000104\n",
      "12                accident    0.000004\n",
      "\n",
      "=== 예측 오차 분석 ===\n",
      "          실제가격     예측가격       오차\n",
      "count  7497.00  7497.00  7497.00\n",
      "mean     62.33    62.32     0.80\n",
      "std      36.65    36.55     1.24\n",
      "min       9.00    12.83     0.00\n",
      "25%      34.39    34.33     0.21\n",
      "50%      56.00    56.15     0.47\n",
      "75%      80.05    80.01     0.83\n",
      "max     161.09   160.65    12.84\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ModelSegmentPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            n_estimators=700,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def get_model_segment(self, model_name):\n",
    "        \"\"\"모델별 세그먼트 분류\"\"\"\n",
    "        if model_name in ['TayGTS', 'TayCT']:\n",
    "            return 4  # 프리미엄\n",
    "        elif model_name in ['Tay', 'RSeGT', 'MX', 'iX']:\n",
    "            return 3  # 고급\n",
    "        elif model_name in ['MS', 'MY']:\n",
    "            return 2  # 중급\n",
    "        else:\n",
    "            return 1  # 보급형\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        # 모델 세그먼트 추가\n",
    "        df['model_segment'] = df['모델'].apply(self.get_model_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(df[col])\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 브랜드 티어\n",
    "        brand_tier_map = {\n",
    "            'P사': 3,\n",
    "            'A사': 2, 'T사': 2, 'B사': 2,\n",
    "            'V사': 1, 'H사': 1, 'K사': 1\n",
    "        }\n",
    "        df['brand_tier'] = df['제조사'].map(brand_tier_map)\n",
    "        \n",
    "        # 구동방식 가중치\n",
    "        drive_weight_map = {\n",
    "            'AWD': 3,\n",
    "            'RWD': 2,\n",
    "            'FWD': 1\n",
    "        }\n",
    "        df['drive_weight'] = df['구동방식'].map(drive_weight_map)\n",
    "        \n",
    "        # 복합 특성 생성\n",
    "        df['brand_drive_combined'] = df['brand_tier'] * df['drive_weight']\n",
    "        df['segment_drive_combined'] = df['model_segment'] * df['drive_weight']\n",
    "        df['segment_brand_combined'] = df['model_segment'] * df['brand_tier']\n",
    "        \n",
    "        features = pd.DataFrame({\n",
    "            'model_segment': df['model_segment'],\n",
    "            'segment_drive_combined': df['segment_drive_combined'],\n",
    "            'segment_brand_combined': df['segment_brand_combined'],\n",
    "            'brand_drive_combined': df['brand_drive_combined'],\n",
    "            'brand_tier': df['brand_tier'],\n",
    "            'battery_capacity': df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean')),\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'log_distance': np.log1p(df['주행거리(km)']),\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_weight': df['drive_weight'],\n",
    "            'age': df['연식(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int)\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def cv_evaluate(self, X, y):\n",
    "        cv_scores = []\n",
    "        cv_predictions = np.zeros_like(y)\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            self.model.fit(X_train, y_train)\n",
    "            val_pred = self.model.predict(X_val)\n",
    "            cv_predictions[val_idx] = val_pred\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            fold_r2 = r2_score(y_val, val_pred)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        \n",
    "        # 세그먼트별 성능 분석\n",
    "        df_analysis = pd.DataFrame({\n",
    "            '실제가격': y,\n",
    "            '예측가격': cv_predictions,\n",
    "            '오차': np.abs(y - cv_predictions),\n",
    "            '세그먼트': X['model_segment']\n",
    "        })\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 5):\n",
    "            segment_rmse = np.sqrt(mean_squared_error(\n",
    "                df_analysis[df_analysis['세그먼트'] == segment]['실제가격'],\n",
    "                df_analysis[df_analysis['세그먼트'] == segment]['예측가격']\n",
    "            ))\n",
    "            print(f\"세그먼트 {segment} RMSE: {segment_rmse:.4f}\")\n",
    "        \n",
    "        return cv_scores, cv_predictions\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores, cv_predictions = self.cv_evaluate(X, y)\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "        print(\"\\n=== 특성 중요도 ===\")\n",
    "        print(importance.sort_values('importance', ascending=False))\n",
    "        \n",
    "        prediction_analysis = pd.DataFrame({\n",
    "            '실제가격': y,\n",
    "            '예측가격': cv_predictions,\n",
    "            '오차': np.abs(y - cv_predictions)\n",
    "        })\n",
    "        \n",
    "        print(\"\\n=== 예측 오차 분석 ===\")\n",
    "        print(prediction_analysis.describe().round(2))\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        X = self.create_features(test_df)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = ModelSegmentPricePredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "submission.to_csv('model_segment_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4520, R2: 0.9985\n",
      "Fold 2 - RMSE: 1.5175, R2: 0.9983\n",
      "Fold 3 - RMSE: 1.3805, R2: 0.9986\n",
      "Fold 4 - RMSE: 1.2854, R2: 0.9988\n",
      "Fold 5 - RMSE: 1.3627, R2: 0.9985\n",
      "\n",
      "평균 RMSE: 1.3996 (+/- 0.1585)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.7190\n",
      "세그먼트 2 RMSE: 0.5245\n",
      "세그먼트 3 RMSE: 0.5053\n",
      "세그먼트 4 RMSE: 0.8587\n",
      "세그먼트 5 RMSE: 0.6218\n",
      "세그먼트 6 RMSE: 3.3324\n",
      "세그먼트 7 RMSE: 0.3686\n",
      "\n",
      "=== 특성 중요도 ===\n",
      "                   feature  importance\n",
      "1   segment_brand_combined    0.382401\n",
      "3               brand_tier    0.227883\n",
      "0            model_segment    0.176826\n",
      "5            model_encoded    0.103514\n",
      "2   segment_drive_combined    0.095743\n",
      "7                 warranty    0.003919\n",
      "6             log_distance    0.003709\n",
      "4         battery_capacity    0.002611\n",
      "8        condition_encoded    0.001810\n",
      "9             drive_weight    0.001443\n",
      "10                     age    0.000136\n",
      "11                accident    0.000005\n",
      "\n",
      "=== 예측 오차 분석 ===\n",
      "          실제가격     예측가격       오차\n",
      "count  7497.00  7497.00  7497.00\n",
      "mean     62.33    62.32     0.73\n",
      "std      36.65    36.57     1.20\n",
      "min       9.00    13.59     0.00\n",
      "25%      34.39    34.36     0.18\n",
      "50%      56.00    56.04     0.42\n",
      "75%      80.05    80.03     0.76\n",
      "max     161.09   160.85    12.86\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class DetailedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.model = GradientBoostingRegressor(\n",
    "            n_estimators=700,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7  # 프리미엄\n",
    "        elif model_name in semi_premium:\n",
    "            return 6  # 준프리미엄\n",
    "        elif model_name in luxury:\n",
    "            return 5  # 고급\n",
    "        elif model_name in upper_mid:\n",
    "            return 4  # 중상급\n",
    "        elif model_name in mid:\n",
    "            return 3  # 중급\n",
    "        elif model_name in basic:\n",
    "            return 2  # 보급형\n",
    "        else:\n",
    "            return 1  # 엔트리\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        # 세분화된 모델 세그먼트 추가\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(df[col])\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 브랜드 티어\n",
    "        brand_tier_map = {\n",
    "            'P사': 7,\n",
    "            'A사': 6, 'T사': 5, \n",
    "            'B사': 4,\n",
    "            'V사': 3,\n",
    "            'H사': 2,\n",
    "            'K사': 1\n",
    "        }\n",
    "        df['brand_tier'] = df['제조사'].map(brand_tier_map)\n",
    "        \n",
    "        # 구동방식 가중치\n",
    "        drive_weight_map = {\n",
    "            'AWD': 3,\n",
    "            'RWD': 2,\n",
    "            'FWD': 1\n",
    "        }\n",
    "        df['drive_weight'] = df['구동방식'].map(drive_weight_map)\n",
    "        \n",
    "        # 복합 특성 생성\n",
    "        df['segment_brand_combined'] = df['model_segment'] * df['brand_tier']\n",
    "        df['segment_drive_combined'] = df['model_segment'] * df['drive_weight']\n",
    "        \n",
    "        features = pd.DataFrame({\n",
    "            'model_segment': df['model_segment'],\n",
    "            'segment_brand_combined': df['segment_brand_combined'],\n",
    "            'segment_drive_combined': df['segment_drive_combined'],\n",
    "            'brand_tier': df['brand_tier'],\n",
    "            'battery_capacity': df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean')),\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'log_distance': np.log1p(df['주행거리(km)']),\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_weight': df['drive_weight'],\n",
    "            'age': df['연식(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int)\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "\n",
    "    \n",
    "    def cv_evaluate(self, X, y):\n",
    "        cv_scores = []\n",
    "        segment_predictions = {}\n",
    "        cv_predictions = np.zeros_like(y)\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            self.model.fit(X_train, y_train)\n",
    "            val_pred = self.model.predict(X_val)\n",
    "            cv_predictions[val_idx] = val_pred\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "            fold_r2 = r2_score(y_val, val_pred)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        \n",
    "        # 세그먼트별 성능 분석\n",
    "        df_analysis = pd.DataFrame({\n",
    "            '실제가격': y,\n",
    "            '예측가격': cv_predictions,\n",
    "            '오차': np.abs(y - cv_predictions),\n",
    "            '세그먼트': X['model_segment']\n",
    "        })\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            segment_mask = df_analysis['세그먼트'] == segment\n",
    "            if segment_mask.any():\n",
    "                segment_rmse = np.sqrt(mean_squared_error(\n",
    "                    df_analysis[segment_mask]['실제가격'],\n",
    "                    df_analysis[segment_mask]['예측가격']\n",
    "                ))\n",
    "                print(f\"세그먼트 {segment} RMSE: {segment_rmse:.4f}\")\n",
    "        \n",
    "        return cv_scores, cv_predictions\n",
    "    \n",
    "    def fit(self, train_df):\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores, cv_predictions = self.cv_evaluate(X, y)\n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.model.feature_importances_\n",
    "        })\n",
    "        print(\"\\n=== 특성 중요도 ===\")\n",
    "        print(importance.sort_values('importance', ascending=False))\n",
    "        \n",
    "        prediction_analysis = pd.DataFrame({\n",
    "            '실제가격': y,\n",
    "            '예측가격': cv_predictions,\n",
    "            '오차': np.abs(y - cv_predictions)\n",
    "        })\n",
    "        \n",
    "        print(\"\\n=== 예측 오차 분석 ===\")\n",
    "        print(prediction_analysis.describe().round(2))\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        X = self.create_features(test_df)\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = DetailedSegmentPredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "submission.to_csv('detailed_segment_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 엔트리 세그먼트(1) 이상치 분석 ===\n",
      "\n",
      "=== RSeTGT 모델 분석 ===\n",
      "전체 데이터 수: 385\n",
      "이상치 데이터 수: 55\n",
      "이상치 비율: 14.29%\n",
      "\n",
      "기본 통계:\n",
      "Q1: 98.02, Q3: 100.10, IQR: 2.08\n",
      "하한 경계: 94.90\n",
      "상한 경계: 103.22\n",
      "\n",
      "차량상태별 이상치 분포:\n",
      "차량상태\n",
      "Pre-Owned    55\n",
      "Name: count, dtype: int64\n",
      "\n",
      "사고이력별 이상치 분포:\n",
      "사고이력\n",
      "No     53\n",
      "Yes     2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "이상치 상세 데이터:\n",
      "      가격(백만원)  주행거리(km)  배터리용량       차량상태 사고이력  연식(년)  보증기간(년)\n",
      "3231    94.89    148828  78.23  Pre-Owned   No      0        0\n",
      "128     94.89    129869  78.23  Pre-Owned  Yes      0        0\n",
      "4508    94.83     53956    NaN  Pre-Owned   No      0        0\n",
      "4906    94.82    140373    NaN  Pre-Owned   No      0        0\n",
      "1655    94.81    129550    NaN  Pre-Owned   No      0        0\n",
      "33      94.79    128546    NaN  Pre-Owned   No      0        0\n",
      "968     94.78    171887    NaN  Pre-Owned   No      0        0\n",
      "2547    94.77     55883    NaN  Pre-Owned   No      0        0\n",
      "3921    94.74    187284    NaN  Pre-Owned   No      0        0\n",
      "7080    94.71    108152    NaN  Pre-Owned   No      0        0\n",
      "5193    94.68     55837    NaN  Pre-Owned   No      0        0\n",
      "6997    94.60     99753    NaN  Pre-Owned   No      0        0\n",
      "4968    94.57     76648    NaN  Pre-Owned   No      0        0\n",
      "2693    94.57    105927  78.23  Pre-Owned   No      0        0\n",
      "5603    94.55    175189    NaN  Pre-Owned   No      0        0\n",
      "4851    94.52    133053    NaN  Pre-Owned   No      0        0\n",
      "193     94.51    130607  78.23  Pre-Owned   No      0        0\n",
      "5232    94.48    124877  78.23  Pre-Owned   No      0        0\n",
      "2235    94.48     66322  78.23  Pre-Owned   No      0        0\n",
      "1595    94.45     52008    NaN  Pre-Owned   No      0        0\n",
      "3213    94.44    134444    NaN  Pre-Owned   No      0        0\n",
      "2386    94.42    187973    NaN  Pre-Owned  Yes      0        0\n",
      "4192    94.32     79386    NaN  Pre-Owned   No      0        0\n",
      "2855    94.23    108315    NaN  Pre-Owned   No      0        0\n",
      "3905    94.19     79908  78.23  Pre-Owned   No      0        0\n",
      "5655    94.19     57125    NaN  Pre-Owned   No      0        0\n",
      "395     94.19     52495    NaN  Pre-Owned   No      0        0\n",
      "6820    94.15     91225    NaN  Pre-Owned   No      0        0\n",
      "7455    94.14    160716    NaN  Pre-Owned   No      0        0\n",
      "2325    94.14     89443    NaN  Pre-Owned   No      0        0\n",
      "5764    94.12     55596    NaN  Pre-Owned   No      0        0\n",
      "6874    94.11    171251    NaN  Pre-Owned   No      0        0\n",
      "4861    94.08    129049    NaN  Pre-Owned   No      0        0\n",
      "2173    94.08    163107  78.23  Pre-Owned   No      0        0\n",
      "6318    94.07    122952    NaN  Pre-Owned   No      0        0\n",
      "6293    94.06     70028    NaN  Pre-Owned   No      0        0\n",
      "2975    94.05    187769  78.23  Pre-Owned   No      0        0\n",
      "3840    94.05     70474    NaN  Pre-Owned   No      0        0\n",
      "2280    94.04    170558    NaN  Pre-Owned   No      0        0\n",
      "6088    94.04     77303    NaN  Pre-Owned   No      0        0\n",
      "4996    94.03    147419  78.23  Pre-Owned   No      0        0\n",
      "293     94.02    188472    NaN  Pre-Owned   No      0        0\n",
      "6924    94.00    197674    NaN  Pre-Owned   No      0        0\n",
      "6811    94.00    149575  78.23  Pre-Owned   No      0        0\n",
      "6688    94.00     90760    NaN  Pre-Owned   No      0        0\n",
      "3779    94.00    121366    NaN  Pre-Owned   No      0        0\n",
      "6285    94.00    156431    NaN  Pre-Owned   No      0        0\n",
      "5739    94.00    105142    NaN  Pre-Owned   No      0        0\n",
      "5431    94.00    139330    NaN  Pre-Owned   No      0        0\n",
      "2364    94.00    192375  78.23  Pre-Owned   No      0        0\n",
      "4725    94.00    114562    NaN  Pre-Owned   No      0        0\n",
      "4258    94.00    132041    NaN  Pre-Owned   No      0        0\n",
      "3040    94.00     77459    NaN  Pre-Owned   No      0        0\n",
      "3247    94.00     95565    NaN  Pre-Owned   No      0        0\n",
      "2005    94.00    191938    NaN  Pre-Owned   No      0        0\n",
      "\n",
      "이상치 데이터 상관관계:\n",
      "가격(백만원)     1.000\n",
      "주행거리(km)   -0.108\n",
      "배터리용량         NaN\n",
      "연식(년)         NaN\n",
      "보증기간(년)       NaN\n",
      "Name: 가격(백만원), dtype: float64\n",
      "\n",
      "=== Soul 모델 분석 ===\n",
      "전체 데이터 수: 397\n",
      "이상치 데이터 수: 41\n",
      "이상치 비율: 10.33%\n",
      "\n",
      "기본 통계:\n",
      "Q1: 21.93, Q3: 23.24, IQR: 1.31\n",
      "하한 경계: 19.97\n",
      "상한 경계: 25.20\n",
      "\n",
      "차량상태별 이상치 분포:\n",
      "차량상태\n",
      "Brand New    41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "사고이력별 이상치 분포:\n",
      "사고이력\n",
      "No     38\n",
      "Yes     3\n",
      "Name: count, dtype: int64\n",
      "\n",
      "이상치 상세 데이터:\n",
      "      가격(백만원)  주행거리(km)  배터리용량       차량상태 사고이력  연식(년)  보증기간(년)\n",
      "7327    19.85      4329    NaN  Brand New   No      0        9\n",
      "1685    19.75      8241   90.0  Brand New   No      0        9\n",
      "1828    19.69      4684    NaN  Brand New   No      0        9\n",
      "3617    19.69      1397   90.0  Brand New   No      0        9\n",
      "4109    19.66      6338   90.0  Brand New   No      0        9\n",
      "1192    19.64      1161    NaN  Brand New   No      0        9\n",
      "2595    19.58      9232    NaN  Brand New   No      0        9\n",
      "1873    19.39      4811    NaN  Brand New   No      0        9\n",
      "5647    18.48      9027    NaN  Brand New  Yes      0       10\n",
      "2536    18.41      3473    NaN  Brand New   No      0       10\n",
      "6419    18.35      5609   90.0  Brand New   No      0       10\n",
      "3966    18.28       658    NaN  Brand New   No      0       10\n",
      "2738    18.22        15    NaN  Brand New   No      0       10\n",
      "6587    18.17      3069    NaN  Brand New   No      0       10\n",
      "7149    18.03      5828    NaN  Brand New  Yes      0       10\n",
      "7142    17.85      9266    NaN  Brand New   No      0       10\n",
      "2107    17.75      9146    NaN  Brand New   No      0       10\n",
      "1880    17.67      1759    NaN  Brand New  Yes      0       10\n",
      "385     17.65      4148    NaN  Brand New   No      0       10\n",
      "3353    17.59       444    NaN  Brand New   No      0       10\n",
      "4915    17.55       659    NaN  Brand New   No      0       10\n",
      "2057    17.48      6892    NaN  Brand New   No      0       10\n",
      "5358    17.45      9829    NaN  Brand New   No      0       10\n",
      "2089    17.43      1323    NaN  Brand New   No      0       10\n",
      "1854    17.43       584   90.0  Brand New   No      0       10\n",
      "4769    17.43      3310    NaN  Brand New   No      0       10\n",
      "6613    17.42      5599    NaN  Brand New   No      0       10\n",
      "7482    17.41      8287    NaN  Brand New   No      0       10\n",
      "7453    17.38      8204    NaN  Brand New   No      0       10\n",
      "4788    17.07      9732   90.0  Brand New   No      0       10\n",
      "4024    17.02       856    NaN  Brand New   No      0       10\n",
      "6351    16.99      9517    NaN  Brand New   No      0       10\n",
      "1684    16.88       420    NaN  Brand New   No      0       10\n",
      "6082    16.87      2808    NaN  Brand New   No      0       10\n",
      "7491    16.75      5966    NaN  Brand New   No      0       10\n",
      "3706    16.74       956    NaN  Brand New   No      0       10\n",
      "7051    16.73      5320    NaN  Brand New   No      0       10\n",
      "4187    16.68      8625   90.0  Brand New   No      0       10\n",
      "1343    16.64      2517    NaN  Brand New   No      0       10\n",
      "1265    16.61      8709    NaN  Brand New   No      0       10\n",
      "4630    16.56      3726    NaN  Brand New   No      0       10\n",
      "\n",
      "이상치 데이터 상관관계:\n",
      "가격(백만원)     1.000\n",
      "주행거리(km)    0.004\n",
      "배터리용량         NaN\n",
      "연식(년)         NaN\n",
      "보증기간(년)    -0.864\n",
      "Name: 가격(백만원), dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47784 (\\N{HANGUL SYLLABLE MO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 45944 (\\N{HANGUL SYLLABLE DEL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44201 (\\N{HANGUL SYLLABLE GYEOG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 48177 (\\N{HANGUL SYLLABLE BAEG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 49464 (\\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47676 (\\N{HANGUL SYLLABLE MEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 53944 (\\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 51452 (\\N{HANGUL SYLLABLE JU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 54665 (\\N{HANGUL SYLLABLE HAENG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44144 (\\N{HANGUL SYLLABLE GEO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44288 (\\N{HANGUL SYLLABLE GWAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44228 (\\N{HANGUL SYLLABLE GYE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 52264 (\\N{HANGUL SYLLABLE CA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47049 (\\N{HANGUL SYLLABLE RYANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 53468 (\\N{HANGUL SYLLABLE TAE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44256 (\\N{HANGUL SYLLABLE GO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47141 (\\N{HANGUL SYLLABLE RYEOG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44201 (\\N{HANGUL SYLLABLE GYEOG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48177 (\\N{HANGUL SYLLABLE BAEG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49464 (\\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47676 (\\N{HANGUL SYLLABLE MEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53944 (\\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47784 (\\N{HANGUL SYLLABLE MO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 45944 (\\N{HANGUL SYLLABLE DEL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51452 (\\N{HANGUL SYLLABLE JU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 54665 (\\N{HANGUL SYLLABLE HAENG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44144 (\\N{HANGUL SYLLABLE GEO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44288 (\\N{HANGUL SYLLABLE GWAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44228 (\\N{HANGUL SYLLABLE GYE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 52264 (\\N{HANGUL SYLLABLE CA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47049 (\\N{HANGUL SYLLABLE RYANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53468 (\\N{HANGUL SYLLABLE TAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44256 (\\N{HANGUL SYLLABLE GO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47141 (\\N{HANGUL SYLLABLE RYEOG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 준프리미엄 세그먼트(6) 이상치 분석 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47784 (\\N{HANGUL SYLLABLE MO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 45944 (\\N{HANGUL SYLLABLE DEL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44201 (\\N{HANGUL SYLLABLE GYEOG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 48177 (\\N{HANGUL SYLLABLE BAEG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 49464 (\\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47676 (\\N{HANGUL SYLLABLE MEON}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 53944 (\\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 51452 (\\N{HANGUL SYLLABLE JU}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 54665 (\\N{HANGUL SYLLABLE HAENG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44144 (\\N{HANGUL SYLLABLE GEO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44288 (\\N{HANGUL SYLLABLE GWAN}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44228 (\\N{HANGUL SYLLABLE GYE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 52264 (\\N{HANGUL SYLLABLE CA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47049 (\\N{HANGUL SYLLABLE RYANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 53468 (\\N{HANGUL SYLLABLE TAE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 44256 (\\N{HANGUL SYLLABLE GO}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\1078995942.py:111: UserWarning: Glyph 47141 (\\N{HANGUL SYLLABLE RYEOG}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44032 (\\N{HANGUL SYLLABLE GA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44201 (\\N{HANGUL SYLLABLE GYEOG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48177 (\\N{HANGUL SYLLABLE BAEG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49464 (\\N{HANGUL SYLLABLE SE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44536 (\\N{HANGUL SYLLABLE GEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47676 (\\N{HANGUL SYLLABLE MEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53944 (\\N{HANGUL SYLLABLE TEU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 48516 (\\N{HANGUL SYLLABLE BUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 54252 (\\N{HANGUL SYLLABLE PO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47784 (\\N{HANGUL SYLLABLE MO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 45944 (\\N{HANGUL SYLLABLE DEL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51452 (\\N{HANGUL SYLLABLE JU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 54665 (\\N{HANGUL SYLLABLE HAENG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44144 (\\N{HANGUL SYLLABLE GEO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47532 (\\N{HANGUL SYLLABLE RI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44288 (\\N{HANGUL SYLLABLE GWAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44228 (\\N{HANGUL SYLLABLE GYE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 52264 (\\N{HANGUL SYLLABLE CA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47049 (\\N{HANGUL SYLLABLE RYANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 53468 (\\N{HANGUL SYLLABLE TAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 49324 (\\N{HANGUL SYLLABLE SA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 44256 (\\N{HANGUL SYLLABLE GO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "c:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\IPython\\core\\pylabtools.py:170: UserWarning: Glyph 47141 (\\N{HANGUL SYLLABLE RYEOG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_detailed_segment(model_name):\n",
    "    \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "    premium = ['TayGTS']\n",
    "    semi_premium = ['TayCT', 'Tay']\n",
    "    luxury = ['RSeGT', 'MX', 'iX']\n",
    "    upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "    mid = ['Q4eT', 'M3', 'i4']\n",
    "    basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "    entry = ['i3', 'Soul', 'IONIQ']\n",
    "    \n",
    "    if model_name in premium:\n",
    "        return 7  # 프리미엄\n",
    "    elif model_name in semi_premium:\n",
    "        return 6  # 준프리미엄\n",
    "    elif model_name in luxury:\n",
    "        return 5  # 고급\n",
    "    elif model_name in upper_mid:\n",
    "        return 4  # 중상급\n",
    "    elif model_name in mid:\n",
    "        return 3  # 중급\n",
    "    elif model_name in basic:\n",
    "        return 2  # 보급형\n",
    "    else:\n",
    "        return 1  # 엔트리\n",
    "\n",
    "def analyze_segment_outliers(df, segment_num):\n",
    "    \"\"\"세그먼트별 이상치 분석\"\"\"\n",
    "    # 세그먼트 할당\n",
    "    df['segment'] = df['모델'].apply(get_detailed_segment)\n",
    "    segment_data = df[df['segment'] == segment_num]\n",
    "    \n",
    "    segment_names = {\n",
    "        1: \"엔트리\",\n",
    "        2: \"보급형\",\n",
    "        3: \"중급\",\n",
    "        4: \"중상급\",\n",
    "        5: \"고급\",\n",
    "        6: \"준프리미엄\",\n",
    "        7: \"프리미엄\"\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n=== {segment_names[segment_num]} 세그먼트({segment_num}) 이상치 분석 ===\")\n",
    "    \n",
    "    for model in segment_data['모델'].unique():\n",
    "        model_data = segment_data[segment_data['모델'] == model]\n",
    "        Q1 = model_data['가격(백만원)'].quantile(0.25)\n",
    "        Q3 = model_data['가격(백만원)'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        outliers = model_data[\n",
    "            (model_data['가격(백만원)'] < (Q1 - 1.5 * IQR)) | \n",
    "            (model_data['가격(백만원)'] > (Q3 + 1.5 * IQR))\n",
    "        ]\n",
    "        \n",
    "        if len(outliers) > 0:\n",
    "            print(f\"\\n=== {model} 모델 분석 ===\")\n",
    "            print(f\"전체 데이터 수: {len(model_data)}\")\n",
    "            print(f\"이상치 데이터 수: {len(outliers)}\")\n",
    "            print(f\"이상치 비율: {(len(outliers)/len(model_data)*100):.2f}%\")\n",
    "            print(f\"\\n기본 통계:\")\n",
    "            print(f\"Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "            print(f\"하한 경계: {(Q1 - 1.5 * IQR):.2f}\")\n",
    "            print(f\"상한 경계: {(Q3 + 1.5 * IQR):.2f}\")\n",
    "            \n",
    "            # 차량상태별 이상치 분포\n",
    "            condition_dist = outliers['차량상태'].value_counts()\n",
    "            print(\"\\n차량상태별 이상치 분포:\")\n",
    "            print(condition_dist)\n",
    "            \n",
    "            # 사고이력별 이상치 분포\n",
    "            accident_dist = outliers['사고이력'].value_counts()\n",
    "            print(\"\\n사고이력별 이상치 분포:\")\n",
    "            print(accident_dist)\n",
    "            \n",
    "            # 이상치 상세 정보\n",
    "            print(\"\\n이상치 상세 데이터:\")\n",
    "            columns = ['가격(백만원)', '주행거리(km)', '배터리용량', '차량상태', \n",
    "                      '사고이력', '연식(년)', '보증기간(년)']\n",
    "            print(outliers[columns].sort_values('가격(백만원)', ascending=False).round(2))\n",
    "            \n",
    "            # 상관관계 분석\n",
    "            print(\"\\n이상치 데이터 상관관계:\")\n",
    "            numeric_cols = ['가격(백만원)', '주행거리(km)', '배터리용량', '연식(년)', '보증기간(년)']\n",
    "            correlations = outliers[numeric_cols].corr()['가격(백만원)'].round(3)\n",
    "            print(correlations)\n",
    "\n",
    "def visualize_outliers(df, segment_num):\n",
    "    \"\"\"이상치 시각화\"\"\"\n",
    "    df['segment'] = df['모델'].apply(get_detailed_segment)\n",
    "    segment_data = df[df['segment'] == segment_num]\n",
    "    \n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # 박스플롯\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.boxplot(x='모델', y='가격(백만원)', data=segment_data)\n",
    "    plt.title(f'세그먼트 {segment_num} 가격 분포')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 산점도\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.scatterplot(data=segment_data, x='주행거리(km)', y='가격(백만원)', \n",
    "                   hue='차량상태', style='사고이력')\n",
    "    plt.title(f'세그먼트 {segment_num} 주행거리-가격 관계')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 데이터 로드 및 분석 실행\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# 엔트리(1)와 준프리미엄(6) 세그먼트 분석\n",
    "for segment_num in [1, 6]:\n",
    "    analyze_segment_outliers(train_data, segment_num)\n",
    "    visualize_outliers(train_data, segment_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.5696, R2: 0.9982\n",
      "Fold 2 - RMSE: 1.5916, R2: 0.9982\n",
      "Fold 3 - RMSE: 1.4493, R2: 0.9985\n",
      "Fold 4 - RMSE: 1.3437, R2: 0.9987\n",
      "Fold 5 - RMSE: 1.3877, R2: 0.9984\n",
      "\n",
      "평균 RMSE: 1.4684 (+/- 0.1957)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.8455\n",
      "세그먼트 2 RMSE: 0.5333\n",
      "세그먼트 3 RMSE: 0.4414\n",
      "세그먼트 4 RMSE: 0.5983\n",
      "세그먼트 5 RMSE: 0.6735\n",
      "세그먼트 6 RMSE: 3.5614\n",
      "세그먼트 7 RMSE: 0.3776\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'price_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price_weight'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 223\u001b[0m\n\u001b[0;32m    220\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ImprovedSegmentPredictor()\n\u001b[0;32m    221\u001b[0m predictor\u001b[38;5;241m.\u001b[39mfit(train_data)\n\u001b[1;32m--> 223\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m    227\u001b[0m })\n\u001b[0;32m    229\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimproved_segment_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[36], line 200\u001b[0m, in \u001b[0;36mImprovedSegmentPredictor.predict\u001b[1;34m(self, test_df)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, test_df):\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"예측\"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(X))\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[36], line 118\u001b[0m, in \u001b[0;36mImprovedSegmentPredictor.create_features\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    104\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_impact\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog1p(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m주행거리(km)\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    105\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarranty_impact\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m보증기간(년)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_segment\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    107\u001b[0m features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_segment\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_segment\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanufacturer_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m제조사_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcondition_weight\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrive_type_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m구동방식_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbattery_capacity\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m배터리용량\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m배터리용량\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_impact\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_impact\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarranty_impact\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwarranty_impact\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m연식(년)\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccident\u001b[39m\u001b[38;5;124m'\u001b[39m: (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m사고이력\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m),\n\u001b[1;32m--> 118\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprice_weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    119\u001b[0m })\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'price_weight'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ImprovedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def get_condition_weight(self, condition, model_segment):\n",
    "        \"\"\"세그먼트별 차량상태 가중치\"\"\"\n",
    "        if model_segment == 1:  # 엔트리\n",
    "            weights = {'Brand New': 3, 'Nearly New': 2, 'Pre-Owned': 1}\n",
    "        elif model_segment == 6:  # 준프리미엄\n",
    "            weights = {'Pre-Owned': 3, 'Nearly New': 2, 'Brand New': 1}\n",
    "        else:\n",
    "            weights = {'Brand New': 1.5, 'Nearly New': 1.2, 'Pre-Owned': 1}\n",
    "        return weights.get(condition, 1)\n",
    "\n",
    "    def handle_outliers(self, df):\n",
    "        \"\"\"이상치 처리 및 가중치 부여\"\"\"\n",
    "        if '가격(백만원)' not in df.columns:\n",
    "            return df  # 가격 정보가 없는 경우 그대로 반환\n",
    "\n",
    "        df['price_weight'] = 1.0\n",
    "        \n",
    "        for segment in df['model_segment'].unique():\n",
    "            segment_data = df[df['model_segment'] == segment]\n",
    "            for model in segment_data['모델'].unique():\n",
    "                model_data = segment_data[segment_data['모델'] == model]\n",
    "                Q1 = model_data['가격(백만원)'].quantile(0.25)\n",
    "                Q3 = model_data['가격(백만원)'].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                \n",
    "                mask = (df['모델'] == model) & (\n",
    "                    (df['가격(백만원)'] < (Q1 - 1.5 * IQR)) | \n",
    "                    (df['가격(백만원)'] > (Q3 + 1.5 * IQR))\n",
    "                )\n",
    "                df.loc[mask, 'price_weight'] = 0.5\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()  # 원본 데이터 복사\n",
    "    \n",
    "        # 필수 컬럼 확인\n",
    "        required_columns = ['모델', '제조사', '구동방식', '차량상태', '배터리용량', \n",
    "                        '주행거리(km)', '보증기간(년)', '연식(년)', '사고이력']\n",
    "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "        if missing_columns:\n",
    "            raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "        \n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(df[col])\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 차량상태 가중치\n",
    "        df['condition_weight'] = df.apply(\n",
    "            lambda x: self.get_condition_weight(x['차량상태'], x['model_segment']), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # 이상치 처리\n",
    "        df = self.handle_outliers(df)\n",
    "        \n",
    "        # 세그먼트별 특화 특성\n",
    "        df['distance_impact'] = np.log1p(df['주행거리(km)']) * df['condition_weight']\n",
    "        df['warranty_impact'] = df['보증기간(년)'] * (df['model_segment'].map(lambda x: 2 if x == 1 else 1))\n",
    "        \n",
    "        features = pd.DataFrame({\n",
    "            'model_segment': df['model_segment'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'condition_weight': df['condition_weight'],\n",
    "            'drive_type_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean')),\n",
    "            'distance_impact': df['distance_impact'],\n",
    "            'warranty_impact': df['warranty_impact'],\n",
    "            'age': df['연식(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'price_weight': df['price_weight']\n",
    "        })\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        model = GradientBoostingRegressor(\n",
    "            n_estimators=700,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=6,\n",
    "            subsample=0.9,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        mask = X['model_segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            segment_X = X[mask]\n",
    "            segment_y = y[mask]\n",
    "            weights = segment_X['price_weight']\n",
    "            model.fit(segment_X, segment_y, sample_weight=weights)\n",
    "            return model\n",
    "        return None\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        cv_predictions = np.zeros_like(y)\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            # 세그먼트별 학습 및 예측\n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['model_segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        segment_pred = model.predict(X_val[mask])\n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        \n",
    "                        # 세그먼트별 성능 계산\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            cv_predictions[val_idx] = fold_predictions\n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores, cv_predictions\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores, cv_predictions = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "    \n",
    "        try:\n",
    "            for segment, model in self.segment_models.items():\n",
    "                if model is not None:\n",
    "                    mask = X['model_segment'] == segment    \n",
    "                    if sum(mask) > 0:\n",
    "                        predictions[mask] = model.predict(X[mask])\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError 발생: {e}\")\n",
    "            print(\"해당 키가 없는 데이터:\", test_df.columns)\n",
    "            raise\n",
    "    \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = ImprovedSegmentPredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('improved_segment_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4673, R2: 0.9984\n",
      "Fold 2 - RMSE: 1.5044, R2: 0.9984\n",
      "Fold 3 - RMSE: 1.4075, R2: 0.9986\n",
      "Fold 4 - RMSE: 1.3624, R2: 0.9986\n",
      "Fold 5 - RMSE: 1.4080, R2: 0.9984\n",
      "\n",
      "평균 RMSE: 1.4299 (+/- 0.0999)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.8581\n",
      "세그먼트 2 RMSE: 0.5265\n",
      "세그먼트 3 RMSE: 0.4511\n",
      "세그먼트 4 RMSE: 0.5811\n",
      "세그먼트 5 RMSE: 0.6359\n",
      "세그먼트 6 RMSE: 3.3955\n",
      "세그먼트 7 RMSE: 0.3541\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ImprovedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def get_condition_weight(self, condition, model_segment):\n",
    "        \"\"\"세그먼트별 차량상태 가중치\"\"\"\n",
    "        if model_segment == 1:  # 엔트리\n",
    "            weights = {'Brand New': 3, 'Nearly New': 2, 'Pre-Owned': 1}\n",
    "        elif model_segment == 6:  # 준프리미엄\n",
    "            weights = {'Brand New': 1.2, 'Nearly New': 1.1, 'Pre-Owned': 1}\n",
    "        elif model_segment == 7:  # 프리미엄\n",
    "            weights = {'Brand New': 1.3, 'Nearly New': 1.2, 'Pre-Owned': 1}\n",
    "        else:\n",
    "            weights = {'Brand New': 1.5, 'Nearly New': 1.2, 'Pre-Owned': 1}\n",
    "        return weights.get(condition, 1)\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['price_weight'] = 1.0\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                # fit은 학습 데이터의 고유값만 사용\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:  # 테스트 데이터인 경우\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 특성 생성\n",
    "        df['condition_weight'] = df.apply(\n",
    "            lambda x: self.get_condition_weight(x['차량상태'], x['model_segment']), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        df['km_per_year'] = df['주행거리(km)'] / np.maximum(df['연식(년)'], 1)\n",
    "        df['battery_efficiency'] = df['배터리용량'] / np.maximum(df['주행거리(km)'], 1) * 1000\n",
    "        df['warranty_impact'] = df['보증기간(년)'] * df['condition_weight']\n",
    "        \n",
    "        features = pd.DataFrame({\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'km_per_year': df['km_per_year'],\n",
    "            'battery_efficiency': df['battery_efficiency'],\n",
    "            'warranty_impact': df['warranty_impact'],\n",
    "            'age': df['연식(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'price_weight': df['price_weight']\n",
    "        })\n",
    "        \n",
    "        return features.fillna(0)  # 안전을 위한 최종 결측치 처리\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['model_segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            # HistGradientBoostingRegressor는 결측치를 자동으로 처리\n",
    "            model = HistGradientBoostingRegressor(\n",
    "                max_iter=1000,\n",
    "                learning_rate=0.01,\n",
    "                max_depth=6,\n",
    "                min_samples_leaf=5,\n",
    "                random_state=42,\n",
    "                validation_fraction=0.1,\n",
    "                early_stopping=True,\n",
    "                n_iter_no_change=50\n",
    "            )\n",
    "            \n",
    "            segment_X = X[mask]\n",
    "            segment_y = y[mask]\n",
    "            model.fit(segment_X, segment_y)\n",
    "            return model\n",
    "        return None\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            # 세그먼트별 학습 및 예측\n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['model_segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        segment_pred = model.predict(X_val[mask])\n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        \n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, model in self.segment_models.items():\n",
    "            if model is not None:\n",
    "                mask = X['model_segment'] == segment\n",
    "                if sum(mask) > 0:\n",
    "                    predictions[mask] = model.predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = ImprovedSegmentPredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('improved_segment_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.7623, R2: 0.9977\n",
      "Fold 2 - RMSE: 1.8967, R2: 0.9974\n",
      "Fold 3 - RMSE: 1.7757, R2: 0.9977\n",
      "Fold 4 - RMSE: 1.7893, R2: 0.9976\n",
      "Fold 5 - RMSE: 1.9154, R2: 0.9970\n",
      "\n",
      "평균 RMSE: 1.8279 (+/- 0.1293)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.7276\n",
      "세그먼트 2 RMSE: 1.3568\n",
      "세그먼트 3 RMSE: 1.9685\n",
      "세그먼트 4 RMSE: 2.0420\n",
      "세그먼트 5 RMSE: 0.6319\n",
      "세그먼트 6 RMSE: 3.2959\n",
      "세그먼트 7 RMSE: 0.3465\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ImprovedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def get_condition_weight(self, condition, model_segment, warranty_years=0, distance_km=0):\n",
    "        \"\"\"세분화된 차량상태 가중치\"\"\"\n",
    "        if model_segment == 1:  # 엔트리\n",
    "            warranty_factor = min(warranty_years / 5, 2)  # 보증기간 가중치\n",
    "            distance_factor = np.exp(-distance_km / 50000)  # 주행거리 가중치\n",
    "            base_weights = {'Brand New': 2.5, 'Nearly New': 1.5, 'Pre-Owned': 1}\n",
    "            return base_weights.get(condition, 1) * warranty_factor * distance_factor\n",
    "        elif model_segment == 6:  # 준프리미엄\n",
    "            distance_factor = np.exp(-distance_km / 100000)  # 주행거리 가중치\n",
    "            base_weights = {'Brand New': 1.3, 'Nearly New': 1.2, 'Pre-Owned': 1}\n",
    "            return base_weights.get(condition, 1) * distance_factor\n",
    "        elif model_segment == 7:  # 프리미엄\n",
    "            base_weights = {'Brand New': 1.3, 'Nearly New': 1.2, 'Pre-Owned': 1}\n",
    "            return base_weights.get(condition, 1)\n",
    "        else:\n",
    "            base_weights = {'Brand New': 1.5, 'Nearly New': 1.2, 'Pre-Owned': 1}\n",
    "            return base_weights.get(condition, 1)\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['price_weight'] = 1.0\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:  # 테스트 데이터인 경우\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 차량상태 가중치 계산\n",
    "        df['condition_weight'] = df.apply(\n",
    "            lambda x: self.get_condition_weight(\n",
    "                x['차량상태'], \n",
    "                x['model_segment'],\n",
    "                x['보증기간(년)'],\n",
    "                x['주행거리(km)']\n",
    "            ), \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # 세그먼트별 특화 처리\n",
    "        # 세그먼트 1 (엔트리) 특화 처리\n",
    "        mask_seg1 = (df['model_segment'] == 1)\n",
    "        if sum(mask_seg1) > 0:\n",
    "            # 보증기간과 주행거리의 영향을 강화\n",
    "            df.loc[mask_seg1, 'warranty_impact'] = df.loc[mask_seg1, '보증기간(년)'] * df.loc[mask_seg1, 'condition_weight']\n",
    "            df.loc[mask_seg1, 'distance_impact'] = np.exp(-df.loc[mask_seg1, '주행거리(km)'] / 30000)\n",
    "        \n",
    "        # 세그먼트 6 (준프리미엄) 특화 처리\n",
    "        mask_seg6 = (df['model_segment'] == 6)\n",
    "        if sum(mask_seg6) > 0:\n",
    "            # 주행거리 기반 가중치 조정\n",
    "            df.loc[mask_seg6, 'price_weight'] = np.where(\n",
    "                df.loc[mask_seg6, '주행거리(km)'] > 150000,\n",
    "                0.7,  # 고주행 차량\n",
    "                np.where(\n",
    "                    df.loc[mask_seg6, '주행거리(km)'] < 50000,\n",
    "                    1.3,  # 저주행 차량\n",
    "                    1.0   # 일반 차량\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # 공통 특성 생성\n",
    "        df['km_per_year'] = df['주행거리(km)'] / np.maximum(df['연식(년)'], 1)\n",
    "        df['battery_efficiency'] = df['배터리용량'] / np.maximum(df['주행거리(km)'], 1) * 1000\n",
    "        df['battery_age_impact'] = df['배터리용량'] * np.exp(-df['연식(년)'] * 0.1)\n",
    "        \n",
    "        features = pd.DataFrame({\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'km_per_year': df['km_per_year'],\n",
    "            'battery_efficiency': df['battery_efficiency'],\n",
    "            'battery_age_impact': df['battery_age_impact'],\n",
    "            'warranty_impact': df.get('warranty_impact', df['보증기간(년)']),\n",
    "            'distance_impact': df.get('distance_impact', np.exp(-df['주행거리(km)'] / 50000)),\n",
    "            'age': df['연식(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'price_weight': df['price_weight']\n",
    "        })\n",
    "        \n",
    "        return features.fillna(0)\n",
    "\n",
    "    def get_segment_params(self, segment):\n",
    "        \"\"\"세그먼트별 최적 하이퍼파라미터\"\"\"\n",
    "        if segment == 1:  # 엔트리\n",
    "            return {\n",
    "                'max_iter': 1000,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 4,\n",
    "                'min_samples_leaf': 10,\n",
    "                'l2_regularization': 2.0,\n",
    "                'early_stopping': True,\n",
    "                'n_iter_no_change': 50\n",
    "            }\n",
    "        elif segment == 6:  # 준프리미엄\n",
    "            return {\n",
    "                'max_iter': 1200,\n",
    "                'learning_rate': 0.008,\n",
    "                'max_depth': 5,\n",
    "                'min_samples_leaf': 8,\n",
    "                'l2_regularization': 1.5,\n",
    "                'early_stopping': True,\n",
    "                'n_iter_no_change': 50\n",
    "            }\n",
    "        else:  # 기본 파라미터\n",
    "            return {\n",
    "                'max_iter': 1000,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 6,\n",
    "                'min_samples_leaf': 5,\n",
    "                'l2_regularization': 1.0,\n",
    "                'early_stopping': True,\n",
    "                'n_iter_no_change': 50\n",
    "            }\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['model_segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            params = self.get_segment_params(segment)\n",
    "            model = HistGradientBoostingRegressor(\n",
    "                random_state=42,\n",
    "                **params\n",
    "            )\n",
    "            \n",
    "            segment_X = X[mask]\n",
    "            segment_y = y[mask]\n",
    "            model.fit(segment_X, segment_y)\n",
    "            return model\n",
    "        return None\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['model_segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        segment_pred = model.predict(X_val[mask])\n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        \n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, model in self.segment_models.items():\n",
    "            if model is not None:\n",
    "                mask = X['model_segment'] == segment\n",
    "                if sum(mask) > 0:\n",
    "                    predictions[mask] = model.predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = ImprovedSegmentPredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('improved_segment_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4118, R2: 0.9985\n",
      "Fold 2 - RMSE: 1.4307, R2: 0.9985\n",
      "Fold 3 - RMSE: 1.3346, R2: 0.9987\n",
      "Fold 4 - RMSE: 1.2028, R2: 0.9989\n",
      "Fold 5 - RMSE: 1.2924, R2: 0.9987\n",
      "\n",
      "평균 RMSE: 1.3345 (+/- 0.1658)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.6854\n",
      "세그먼트 2 RMSE: 0.5268\n",
      "세그먼트 3 RMSE: 0.4092\n",
      "세그먼트 4 RMSE: 0.6297\n",
      "세그먼트 5 RMSE: 0.6116\n",
      "세그먼트 6 RMSE: 3.1793\n",
      "세그먼트 7 RMSE: 0.3299\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- TayCT_price_ratio\n- Tay_price_ratio\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 297\u001b[0m\n\u001b[0;32m    294\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ImprovedSegmentPredictor()\n\u001b[0;32m    295\u001b[0m predictor\u001b[38;5;241m.\u001b[39mfit(train_data)\n\u001b[1;32m--> 297\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    298\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m    301\u001b[0m })\n\u001b[0;32m    303\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimproved_segment_submission2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[45], line 286\u001b[0m, in \u001b[0;36mImprovedSegmentPredictor.predict\u001b[1;34m(self, test_df)\u001b[0m\n\u001b[0;32m    284\u001b[0m             predictions[mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_segment_6(X[mask], model)\n\u001b[0;32m    285\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m             predictions[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1769\u001b[0m, in \u001b[0;36mHistGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1766\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# Return inverse link of raw predictions after converting\u001b[39;00m\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;66;03m# shape (n_samples, 1) to (n_samples,)\u001b[39;00m\n\u001b[1;32m-> 1769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mlink\u001b[38;5;241m.\u001b[39minverse(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1278\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._raw_predict\u001b[1;34m(self, X, n_threads)\u001b[0m\n\u001b[0;32m   1276\u001b[0m is_binned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_in_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_binned:\n\u001b[1;32m-> 1278\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1280\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1281\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m   1282\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iteration_),\n\u001b[0;32m   1283\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_baseline_prediction\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1284\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1285\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:268\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._preprocess_X\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reset:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_X_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocessor\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# At this point, reset is False, which runs during `fit`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- TayCT_price_ratio\n- Tay_price_ratio\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ImprovedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.premium_models = {}  # 세그먼트 6의 모델별 예측기\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def get_model_specific_features(self, df, model_name):\n",
    "        \"\"\"모델별 특화 특성 생성\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        if model_name == 'Tay':\n",
    "            # 주행거리 구간: 0-50000, 50000-100000, 100000-150000, 150000+\n",
    "            distance_ranges = [0, 50000, 100000, 150000]\n",
    "            labels = ['low', 'medium', 'high', 'very_high']\n",
    "        elif model_name == 'TayCT':\n",
    "            # 주행거리 구간: 0-40000, 40000-80000, 80000-120000, 120000+\n",
    "            distance_ranges = [0, 40000, 80000, 120000]\n",
    "            labels = ['low', 'medium', 'high', 'very_high']\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # 주행거리 구간화\n",
    "        features['distance_level'] = pd.cut(\n",
    "            df['주행거리(km)'],\n",
    "            bins=distance_ranges + [float('inf')],\n",
    "            labels=labels,\n",
    "            include_lowest=True\n",
    "        ).astype(str)\n",
    "        \n",
    "        # 차량상태 점수화\n",
    "        condition_map = {'Brand New': 3, 'Nearly New': 2, 'Pre-Owned': 1}\n",
    "        features['condition_score'] = df['차량상태'].map(condition_map)\n",
    "        \n",
    "        # 배터리 효율성 점수\n",
    "        features['battery_score'] = np.where(\n",
    "            df['배터리용량'].isna(),\n",
    "            0,\n",
    "            df['배터리용량'] / df['배터리용량'].mean()\n",
    "        )\n",
    "        \n",
    "        # 가격 기대값 (제조사 평균 기준)\n",
    "        if '가격(백만원)' in df.columns:\n",
    "            features['price_ratio'] = df['가격(백만원)'] / df['가격(백만원)'].mean()\n",
    "        \n",
    "        # 주행거리 영향도\n",
    "        features['distance_impact'] = np.exp(-df['주행거리(km)'] / 100000)\n",
    "        \n",
    "        # 모든 특성을 DataFrame으로 변환\n",
    "        features_df = pd.DataFrame(features)\n",
    "        \n",
    "        # distance_level을 one-hot 인코딩\n",
    "        distance_dummies = pd.get_dummies(\n",
    "            features_df['distance_level'], \n",
    "            prefix='distance'\n",
    "        )\n",
    "        \n",
    "        # 기존 특성과 one-hot 인코딩 결과 결합\n",
    "        result = pd.concat([features_df, distance_dummies], axis=1)\n",
    "        \n",
    "        # distance_level 컬럼 제거 (이미 one-hot으로 변환됨)\n",
    "        result.drop('distance_level', axis=1, inplace=True)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 기본 특성 생성\n",
    "        features = {\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'distance': df['주행거리(km)']\n",
    "        }\n",
    "        \n",
    "        # 세그먼트 6 (준프리미엄) 특화 처리\n",
    "        segment_6_features = {}\n",
    "        if '모델' in df.columns:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = (df['모델'] == model)\n",
    "                if sum(model_mask) > 0:\n",
    "                    model_features = self.get_model_specific_features(df[model_mask], model)\n",
    "                    if not model_features.empty:\n",
    "                        for col in model_features.columns:\n",
    "                            features[f'{model}_{col}'] = np.zeros(len(df))\n",
    "                    features[f'{model}_{col}'][model_mask] = model_features[col].values\n",
    "\n",
    "        features_df = pd.DataFrame(features).fillna(0)\n",
    "        return features_df\n",
    "\n",
    "    def train_premium_model(self, X, y, model_name):\n",
    "        \"\"\"준프리미엄 모델별 학습\"\"\"\n",
    "        model_params = {\n",
    "            'Tay': {\n",
    "                'max_iter': 500,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 5,\n",
    "                'l2_regularization': 1.5\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'max_iter': 500,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 4,\n",
    "                'l2_regularization': 2.0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 해당 모델의 데이터만 선택\n",
    "        mask = X['model_encoded'] == self.label_encoders['모델'].transform([model_name])[0]\n",
    "        if sum(mask) > 0:\n",
    "            model = HistGradientBoostingRegressor(\n",
    "                random_state=42,\n",
    "                **model_params.get(model_name, model_params['Tay'])\n",
    "            )\n",
    "            features_to_use = [col for col in X.columns if model_name in col or col in [\n",
    "                'distance', 'battery_capacity', 'age', 'warranty', \n",
    "                'accident', 'condition_encoded', 'drive_encoded'\n",
    "            ]]\n",
    "            model.fit(X[mask][features_to_use], y[mask])\n",
    "            return model, features_to_use\n",
    "        return None, None\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['model_segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            if segment == 6:  # 준프리미엄 세그먼트\n",
    "                models = {}\n",
    "                for model in ['Tay', 'TayCT']:\n",
    "                    model_obj, features = self.train_premium_model(X, y, model)\n",
    "                    if model_obj is not None:\n",
    "                        models[model] = (model_obj, features)\n",
    "                return models\n",
    "            else:  # 다른 세그먼트\n",
    "                params = {\n",
    "                    'max_iter': 1000,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 1.0,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "                # 세그먼트별 파라미터 조정\n",
    "                if segment == 1:  # 엔트리\n",
    "                    params.update({\n",
    "                        'max_depth': 4,\n",
    "                        'l2_regularization': 2.0\n",
    "                    })\n",
    "                model = HistGradientBoostingRegressor(**params)\n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                model.fit(segment_X, segment_y)\n",
    "                return model\n",
    "        return None\n",
    "\n",
    "    def predict_segment_6(self, X, models):\n",
    "        \"\"\"준프리미엄 세그먼트 예측\"\"\"\n",
    "        predictions = np.zeros(len(X))\n",
    "        for model_name, (model, features) in models.items():\n",
    "            mask = X['model_encoded'] == self.label_encoders['모델'].transform([model_name])[0]\n",
    "            if sum(mask) > 0:\n",
    "                predictions[mask] = model.predict(X[mask][features])\n",
    "        return predictions\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['model_segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        if segment == 6:\n",
    "                            segment_pred = self.predict_segment_6(X_val[mask], model)\n",
    "                        else:\n",
    "                            segment_pred = model.predict(X_val[mask])\n",
    "                            \n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, model in self.segment_models.items():\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                if segment == 6:\n",
    "                    predictions[mask] = self.predict_segment_6(X[mask], model)\n",
    "                elif model is not None:\n",
    "                    predictions[mask] = model.predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = ImprovedSegmentPredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('improved_segment_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4042, R2: 0.9986\n",
      "Fold 2 - RMSE: 1.4293, R2: 0.9985\n",
      "Fold 3 - RMSE: 1.3482, R2: 0.9987\n",
      "Fold 4 - RMSE: 1.2253, R2: 0.9989\n",
      "Fold 5 - RMSE: 1.3232, R2: 0.9986\n",
      "\n",
      "평균 RMSE: 1.3461 (+/- 0.1426)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.6888\n",
      "세그먼트 2 RMSE: 0.5266\n",
      "세그먼트 3 RMSE: 0.4090\n",
      "세그먼트 4 RMSE: 0.6297\n",
      "세그먼트 5 RMSE: 0.6114\n",
      "세그먼트 6 RMSE: 3.2278\n",
      "세그먼트 7 RMSE: 0.3265\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ImprovedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.premium_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def get_model_specific_features(self, df, model_name):\n",
    "        \"\"\"모델별 특화 특성 생성\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        if model_name == 'Tay':\n",
    "            distance_ranges = [0, 50000, 100000, 150000]\n",
    "            labels = ['low', 'medium', 'high', 'very_high']\n",
    "        elif model_name == 'TayCT':\n",
    "            distance_ranges = [0, 40000, 80000, 120000]\n",
    "            labels = ['low', 'medium', 'high', 'very_high']\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # 주행거리 구간화\n",
    "        features['distance_level'] = pd.cut(\n",
    "            df['주행거리(km)'],\n",
    "            bins=distance_ranges + [float('inf')],\n",
    "            labels=labels,\n",
    "            include_lowest=True\n",
    "        ).astype(str)\n",
    "        \n",
    "        # 차량상태 점수화\n",
    "        condition_map = {'Brand New': 3, 'Nearly New': 2, 'Pre-Owned': 1}\n",
    "        features['condition_score'] = df['차량상태'].map(condition_map)\n",
    "        \n",
    "        # 배터리 효율성 점수\n",
    "        features['battery_score'] = np.where(\n",
    "            df['배터리용량'].isna(),\n",
    "            0,\n",
    "            df['배터리용량'] / df['배터리용량'].mean()\n",
    "        )\n",
    "        \n",
    "        # 주행거리 영향도\n",
    "        features['distance_impact'] = np.exp(-df['주행거리(km)'] / 100000)\n",
    "        \n",
    "        # condition과 distance의 상호작용\n",
    "        features['condition_distance'] = features['condition_score'] * features['distance_impact']\n",
    "        \n",
    "        # 배터리와 주행거리의 상호작용\n",
    "        features['battery_distance'] = features['battery_score'] * features['distance_impact']\n",
    "        \n",
    "        # 모든 특성을 DataFrame으로 변환\n",
    "        features_df = pd.DataFrame(features)\n",
    "        \n",
    "        # distance_level을 one-hot 인코딩\n",
    "        distance_dummies = pd.get_dummies(\n",
    "            features_df['distance_level'], \n",
    "            prefix='distance'\n",
    "        )\n",
    "        \n",
    "        # 기존 특성과 one-hot 인코딩 결과 결합\n",
    "        result = pd.concat([features_df, distance_dummies], axis=1)\n",
    "        \n",
    "        # distance_level 컬럼 제거\n",
    "        result.drop('distance_level', axis=1, inplace=True)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 기본 특성 생성\n",
    "        features = {\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'distance': df['주행거리(km)'],\n",
    "            'distance_impact': np.exp(-df['주행거리(km)'] / 100000)\n",
    "        }\n",
    "        \n",
    "        # 세그먼트 6 (준프리미엄) 특화 처리\n",
    "        if '모델' in df.columns:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = (df['모델'] == model)\n",
    "                if sum(model_mask) > 0:\n",
    "                    model_features = self.get_model_specific_features(df[model_mask], model)\n",
    "                    if not model_features.empty:\n",
    "                        for col in model_features.columns:\n",
    "                            features[f'{model}_{col}'] = np.zeros(len(df))\n",
    "                            features[f'{model}_{col}'][model_mask] = model_features[col].values\n",
    "        \n",
    "        features_df = pd.DataFrame(features).fillna(0)\n",
    "        return features_df\n",
    "\n",
    "    def train_premium_model(self, X, y, model_name):\n",
    "        \"\"\"준프리미엄 모델별 학습\"\"\"\n",
    "        model_params = {\n",
    "            'Tay': {\n",
    "                'max_iter': 500,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 5,\n",
    "                'l2_regularization': 1.5\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'max_iter': 500,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 4,\n",
    "                'l2_regularization': 2.0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 해당 모델의 데이터만 선택\n",
    "        mask = X['model_encoded'] == self.label_encoders['모델'].transform([model_name])[0]\n",
    "        if sum(mask) > 0:\n",
    "            model = HistGradientBoostingRegressor(\n",
    "                random_state=42,\n",
    "                **model_params.get(model_name, model_params['Tay'])\n",
    "            )\n",
    "            # 모델별 관련 특성만 선택\n",
    "            features_to_use = [col for col in X.columns if model_name in col or col in [\n",
    "                'distance', 'battery_capacity', 'age', 'warranty', \n",
    "                'accident', 'condition_encoded', 'drive_encoded', 'distance_impact'\n",
    "            ]]\n",
    "            model.fit(X[mask][features_to_use], y[mask])\n",
    "            return model, features_to_use\n",
    "        return None, None\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['model_segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            if segment == 6:  # 준프리미엄 세그먼트\n",
    "                models = {}\n",
    "                for model in ['Tay', 'TayCT']:\n",
    "                    model_obj, features = self.train_premium_model(X, y, model)\n",
    "                    if model_obj is not None:\n",
    "                        models[model] = (model_obj, features)\n",
    "                return models\n",
    "            else:  # 다른 세그먼트\n",
    "                model_params = {\n",
    "                    1: {  # 엔트리\n",
    "                        'max_iter': 1000,\n",
    "                        'learning_rate': 0.01,\n",
    "                        'max_depth': 4,\n",
    "                        'l2_regularization': 2.0,\n",
    "                    },\n",
    "                    7: {  # 프리미엄\n",
    "                        'max_iter': 800,\n",
    "                        'learning_rate': 0.01,\n",
    "                        'max_depth': 3,\n",
    "                        'l2_regularization': 1.5,\n",
    "                    }\n",
    "                }.get(segment, {\n",
    "                    'max_iter': 1000,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 1.0,\n",
    "                })\n",
    "                \n",
    "                model = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    **model_params\n",
    "                )\n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                model.fit(segment_X, segment_y)\n",
    "                return model\n",
    "        return None\n",
    "\n",
    "    def predict_segment_6(self, X, models):\n",
    "        \"\"\"준프리미엄 세그먼트 예측\"\"\"\n",
    "        predictions = np.zeros(len(X))\n",
    "        for model_name, (model, features) in models.items():\n",
    "            mask = X['model_encoded'] == self.label_encoders['모델'].transform([model_name])[0]\n",
    "            if sum(mask) > 0:\n",
    "                predictions[mask] = model.predict(X[mask][features])\n",
    "        return predictions\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['model_segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        if segment == 6:\n",
    "                            segment_pred = self.predict_segment_6(X_val[mask], model)\n",
    "                        else:\n",
    "                            segment_pred = model.predict(X_val[mask])\n",
    "                            \n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, model in self.segment_models.items():\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                if segment == 6:\n",
    "                    predictions[mask] = self.predict_segment_6(X[mask], model)\n",
    "                elif model is not None:\n",
    "                    predictions[mask] = model.predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = ImprovedSegmentPredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('improved_segment_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.3933, R2: 0.9986\n",
      "Fold 2 - RMSE: 1.4280, R2: 0.9985\n",
      "Fold 3 - RMSE: 1.3493, R2: 0.9987\n",
      "Fold 4 - RMSE: 1.2280, R2: 0.9989\n",
      "Fold 5 - RMSE: 1.3270, R2: 0.9986\n",
      "\n",
      "평균 RMSE: 1.3451 (+/- 0.1364)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.6780\n",
      "세그먼트 2 RMSE: 0.5268\n",
      "세그먼트 3 RMSE: 0.4092\n",
      "세그먼트 4 RMSE: 0.6297\n",
      "세그먼트 5 RMSE: 0.6116\n",
      "세그먼트 6 RMSE: 3.2380\n",
      "세그먼트 7 RMSE: 0.3261\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ImprovedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.premium_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        self.model_stats = {}\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def handle_premium_outliers(self, df, model_name):\n",
    "        \"\"\"준프리미엄 세그먼트 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        if model_name == 'Tay':\n",
    "            # 15만km 이상 주행한 Pre-Owned 차량 가중치 조정\n",
    "            high_mileage_mask = (df['주행거리(km)'] > 150000) & (df['차량상태'] == 'Pre-Owned')\n",
    "            df.loc[high_mileage_mask, 'price_weight'] *= 0.7\n",
    "            \n",
    "            # 주행거리 대비 가격이 비정상적으로 높은 경우\n",
    "            if '가격(백만원)' in df.columns:\n",
    "                expected_price = 122 - (df['주행거리(km)'] / 20000)\n",
    "                price_diff = np.abs(df['가격(백만원)'] - expected_price)\n",
    "                df.loc[price_diff > 15, 'price_weight'] *= 0.8\n",
    "                \n",
    "        elif model_name == 'TayCT':\n",
    "            # 주행거리 구간별 가중치 조정\n",
    "            df.loc[df['주행거리(km)'] > 120000, 'price_weight'] *= 0.7\n",
    "            df.loc[(df['주행거리(km)'] > 80000) & (df['주행거리(km)'] <= 120000), 'price_weight'] *= 0.85\n",
    "            \n",
    "            if '가격(백만원)' in df.columns:\n",
    "                brand_new_mask = df['차량상태'] == 'Brand New'\n",
    "                brand_new_mean = df.loc[brand_new_mask, '가격(백만원)'].mean()\n",
    "                brand_new_std = df.loc[brand_new_mask, '가격(백만원)'].std()\n",
    "                price_outlier_mask = np.abs(df['가격(백만원)'] - brand_new_mean) > 2 * brand_new_std\n",
    "                df.loc[brand_new_mask & price_outlier_mask, 'price_weight'] *= 0.8\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def handle_entry_outliers(self, df):\n",
    "        \"\"\"엔트리 세그먼트 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        # IONIQ 특별 처리\n",
    "        ioniq_mask = df['모델'] == 'IONIQ'\n",
    "        if sum(ioniq_mask) > 0 and '가격(백만원)' in df.columns:\n",
    "            ioniq_mean = df[ioniq_mask]['가격(백만원)'].mean()\n",
    "            ioniq_std = df[ioniq_mask]['가격(백만원)'].std()\n",
    "            outlier_mask = np.abs(df[ioniq_mask]['가격(백만원)'] - ioniq_mean) > 2 * ioniq_std\n",
    "            df.loc[ioniq_mask & outlier_mask, 'price_weight'] *= 0.7\n",
    "        \n",
    "        # Soul의 고보증기간 차량 처리\n",
    "        soul_mask = (df['모델'] == 'Soul') & (df['보증기간(년)'] >= 9)\n",
    "        df.loc[soul_mask, 'warranty_factor'] = 1.2\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_model_specific_features(self, df, model_name):\n",
    "        \"\"\"모델별 특화 특성 생성\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        if model_name == 'Tay':\n",
    "            distance_ranges = [0, 50000, 100000, 150000]\n",
    "            labels = ['low', 'medium', 'high', 'very_high']\n",
    "            # Tay 모델별 파라미터\n",
    "            decay_factor = 80000\n",
    "            condition_weights = {'Brand New': 3.5, 'Nearly New': 2.5, 'Pre-Owned': 1}\n",
    "        elif model_name == 'TayCT':\n",
    "            distance_ranges = [0, 40000, 80000, 120000]\n",
    "            labels = ['low', 'medium', 'high', 'very_high']\n",
    "            # TayCT 모델별 파라미터\n",
    "            decay_factor = 60000\n",
    "            condition_weights = {'Brand New': 3, 'Nearly New': 2, 'Pre-Owned': 1}\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # 주행거리 구간화\n",
    "        features['distance_level'] = pd.cut(\n",
    "            df['주행거리(km)'],\n",
    "            bins=distance_ranges + [float('inf')],\n",
    "            labels=labels,\n",
    "            include_lowest=True\n",
    "        ).astype(str)\n",
    "        \n",
    "        # 차량상태 점수화\n",
    "        features['condition_score'] = df['차량상태'].map(condition_weights)\n",
    "        \n",
    "        # 배터리 효율성 점수\n",
    "        features['battery_score'] = np.where(\n",
    "            df['배터리용량'].isna(),\n",
    "            0,\n",
    "            df['배터리용량'] / df['배터리용량'].mean()\n",
    "        )\n",
    "        \n",
    "        # 주행거리 영향도\n",
    "        features['distance_impact'] = np.exp(-df['주행거리(km)'] / decay_factor)\n",
    "        \n",
    "        # 보증기간과 연식의 상호작용\n",
    "        features['warranty_age_ratio'] = df['보증기간(년)'] / np.maximum(df['연식(년)'], 1)\n",
    "        \n",
    "        # 배터리와 주행거리의 상호작용\n",
    "        features['battery_efficiency'] = features['battery_score'] * features['distance_impact']\n",
    "        \n",
    "        # 차량상태와 주행거리의 상호작용\n",
    "        features['condition_distance'] = features['condition_score'] * features['distance_impact']\n",
    "        \n",
    "        # 모든 특성을 DataFrame으로 변환\n",
    "        features_df = pd.DataFrame(features)\n",
    "        \n",
    "        # distance_level을 one-hot 인코딩\n",
    "        distance_dummies = pd.get_dummies(\n",
    "            features_df['distance_level'], \n",
    "            prefix='distance'\n",
    "        )\n",
    "        \n",
    "        # 기존 특성과 one-hot 인코딩 결과 결합\n",
    "        result = pd.concat([features_df, distance_dummies], axis=1)\n",
    "        result.drop('distance_level', axis=1, inplace=True)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 가중치 초기화\n",
    "        df['price_weight'] = 1.0\n",
    "        df['warranty_factor'] = 1.0\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 이상치 처리\n",
    "        premium_mask = df['model_segment'] == 6\n",
    "        entry_mask = df['model_segment'] == 1\n",
    "        \n",
    "        if sum(premium_mask) > 0:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = df['모델'] == model\n",
    "                if sum(model_mask) > 0:\n",
    "                    df.loc[model_mask] = self.handle_premium_outliers(df[model_mask], model)\n",
    "        \n",
    "        if sum(entry_mask) > 0:\n",
    "            df.loc[entry_mask] = self.handle_entry_outliers(df[entry_mask])\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "\n",
    "        # 기본 특성 생성\n",
    "        features = {\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'] * df['warranty_factor'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'distance': df['주행거리(km)'],\n",
    "            'price_weight': df['price_weight']\n",
    "        }\n",
    "\n",
    "    # create_features 메소드의 마지막 부분부터 이어서...\n",
    "        \n",
    "        # 세그먼트별 특화 특성\n",
    "        if '모델' in df.columns:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = (df['모델'] == model)\n",
    "                if sum(model_mask) > 0:\n",
    "                    model_features = self.get_model_specific_features(df[model_mask], model)\n",
    "                    if not model_features.empty:\n",
    "                        for col in model_features.columns:\n",
    "                            features[f'{model}_{col}'] = np.zeros(len(df))\n",
    "                            features[f'{model}_{col}'][model_mask] = model_features[col].values\n",
    "        \n",
    "        features_df = pd.DataFrame(features).fillna(0)\n",
    "        return features_df\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['model_segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            if segment == 6:  # 준프리미엄 세그먼트\n",
    "                models = {}\n",
    "                for model in ['Tay', 'TayCT']:\n",
    "                    mask = X['model_encoded'] == self.label_encoders['모델'].transform([model])[0]\n",
    "                    if sum(mask) > 0:\n",
    "                        params = {\n",
    "                            'Tay': {\n",
    "                                'max_iter': 800,\n",
    "                                'learning_rate': 0.008,\n",
    "                                'max_depth': 5,\n",
    "                                'l2_regularization': 1.8\n",
    "                            },\n",
    "                            'TayCT': {\n",
    "                                'max_iter': 600,\n",
    "                                'learning_rate': 0.01,\n",
    "                                'max_depth': 4,\n",
    "                                'l2_regularization': 2.0\n",
    "                            }\n",
    "                        }[model]\n",
    "                        \n",
    "                        model_cols = [col for col in X.columns if model in col or col in [\n",
    "                            'distance', 'battery_capacity', 'age', 'warranty', \n",
    "                            'accident', 'condition_encoded', 'drive_encoded',\n",
    "                            'price_weight'\n",
    "                        ]]\n",
    "                        \n",
    "                        regressor = HistGradientBoostingRegressor(\n",
    "                            random_state=42,\n",
    "                            **params\n",
    "                        )\n",
    "                        \n",
    "                        model_X = X[mask][model_cols]\n",
    "                        model_y = y[mask]\n",
    "                        weights = X[mask]['price_weight'] if 'price_weight' in X.columns else None\n",
    "                        \n",
    "                        regressor.fit(model_X, model_y, sample_weight=weights)\n",
    "                        models[model] = (regressor, model_cols)\n",
    "                return models\n",
    "            else:\n",
    "                params = {\n",
    "                    1: {  # 엔트리\n",
    "                        'max_iter': 1200,\n",
    "                        'learning_rate': 0.008,\n",
    "                        'max_depth': 4,\n",
    "                        'l2_regularization': 2.0,\n",
    "                    },\n",
    "                    7: {  # 프리미엄\n",
    "                        'max_iter': 800,\n",
    "                        'learning_rate': 0.01,\n",
    "                        'max_depth': 3,\n",
    "                        'l2_regularization': 1.5,\n",
    "                    }\n",
    "                }.get(segment, {\n",
    "                    'max_iter': 1000,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 1.0,\n",
    "                })\n",
    "                \n",
    "                model = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    **params\n",
    "                )\n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                weights = X[mask]['price_weight'] if 'price_weight' in X.columns else None\n",
    "                \n",
    "                model.fit(segment_X, segment_y, sample_weight=weights)\n",
    "                return model\n",
    "        return None\n",
    "\n",
    "    def predict_segment_6(self, X, models):\n",
    "        \"\"\"준프리미엄 세그먼트 예측\"\"\"\n",
    "        predictions = np.zeros(len(X))\n",
    "        for model_name, (model, cols) in models.items():\n",
    "            mask = X['model_encoded'] == self.label_encoders['모델'].transform([model_name])[0]\n",
    "            if sum(mask) > 0:\n",
    "                predictions[mask] = model.predict(X[mask][cols])\n",
    "        return predictions\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['model_segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        if segment == 6:\n",
    "                            segment_pred = self.predict_segment_6(X_val[mask], model)\n",
    "                        else:\n",
    "                            segment_pred = model.predict(X_val[mask])\n",
    "                            \n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, model in self.segment_models.items():\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                if segment == 6:\n",
    "                    predictions[mask] = self.predict_segment_6(X[mask], model)\n",
    "                elif model is not None:\n",
    "                    predictions[mask] = model.predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "predictor = ImprovedSegmentPredictor()\n",
    "predictor.fit(train_data)\n",
    "\n",
    "predictions = predictor.predict(test_data)\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_data['ID'],\n",
    "    '가격(백만원)': predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('improved_segment_submission3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.3907, R2: 0.9986\n",
      "Fold 2 - RMSE: 1.4466, R2: 0.9985\n",
      "Fold 3 - RMSE: 1.3365, R2: 0.9987\n",
      "Fold 4 - RMSE: 1.2418, R2: 0.9989\n",
      "Fold 5 - RMSE: 1.3218, R2: 0.9986\n",
      "\n",
      "평균 RMSE: 1.3475 (+/- 0.1375)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.6922\n",
      "세그먼트 2 RMSE: 0.5268\n",
      "세그먼트 3 RMSE: 0.4092\n",
      "세그먼트 4 RMSE: 0.6297\n",
      "세그먼트 5 RMSE: 0.6116\n",
      "세그먼트 6 RMSE: 3.2319\n",
      "세그먼트 7 RMSE: 0.3261\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Tay_distance_very_high\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 443\u001b[0m\n\u001b[0;32m    440\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ImprovedSegmentPredictor()\n\u001b[0;32m    441\u001b[0m predictor\u001b[38;5;241m.\u001b[39mfit(train_data)\n\u001b[1;32m--> 443\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m    447\u001b[0m })\n\u001b[0;32m    449\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimproved_segment_submission4.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[59], line 431\u001b[0m, in \u001b[0;36mImprovedSegmentPredictor.predict\u001b[1;34m(self, test_df)\u001b[0m\n\u001b[0;32m    429\u001b[0m             predictions[mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_segment_6(X[mask], model)\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 431\u001b[0m             predictions[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1769\u001b[0m, in \u001b[0;36mHistGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1766\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# Return inverse link of raw predictions after converting\u001b[39;00m\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;66;03m# shape (n_samples, 1) to (n_samples,)\u001b[39;00m\n\u001b[1;32m-> 1769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mlink\u001b[38;5;241m.\u001b[39minverse(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1278\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._raw_predict\u001b[1;34m(self, X, n_threads)\u001b[0m\n\u001b[0;32m   1276\u001b[0m is_binned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_in_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_binned:\n\u001b[1;32m-> 1278\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1280\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1281\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m   1282\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iteration_),\n\u001b[0;32m   1283\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_baseline_prediction\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1284\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1285\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:268\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._preprocess_X\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reset:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_X_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocessor\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# At this point, reset is False, which runs during `fit`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- Tay_distance_very_high\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ImprovedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.premium_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        self.model_stats = {}\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "    def handle_premium_outliers(self, df, model_name):\n",
    "        \"\"\"준프리미엄 세그먼트 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        if model_name == 'Tay':\n",
    "            # 주행거리 구간별 가중치\n",
    "            high_mileage_mask = (df['주행거리(km)'] > 150000) & (df['차량상태'] == 'Pre-Owned')\n",
    "            medium_mileage_mask = (df['주행거리(km)'] > 100000) & (df['주행거리(km)'] <= 150000)\n",
    "            df.loc[high_mileage_mask, 'price_weight'] *= 0.65\n",
    "            df.loc[medium_mileage_mask, 'price_weight'] *= 0.8\n",
    "            \n",
    "            # 차량상태와 연식 복합 가중치\n",
    "            if '가격(백만원)' in df.columns:\n",
    "                age_factor = np.exp(-0.15 * df['연식(년)'])\n",
    "                df['price_weight'] *= age_factor\n",
    "                \n",
    "                # 배터리 효율성 고려\n",
    "                battery_efficiency = df['배터리용량'] / (df['주행거리(km)'] + 5000)\n",
    "                df.loc[battery_efficiency < battery_efficiency.quantile(0.25), 'price_weight'] *= 0.9\n",
    "                \n",
    "        elif model_name == 'TayCT':\n",
    "            # 개선된 주행거리 구간별 가중치\n",
    "            df.loc[df['주행거리(km)'] > 120000, 'price_weight'] *= 0.65\n",
    "            df.loc[(df['주행거리(km)'] > 80000) & (df['주행거리(km)'] <= 120000), 'price_weight'] *= 0.8\n",
    "            df.loc[(df['주행거리(km)'] > 40000) & (df['주행거리(km)'] <= 80000), 'price_weight'] *= 0.9\n",
    "            \n",
    "            # 차량상태별 세분화된 가중치\n",
    "            if '가격(백만원)' in df.columns:\n",
    "                condition_weights = {\n",
    "                    'Brand New': 1.1,\n",
    "                    'Nearly New': 1.0,\n",
    "                    'Pre-Owned': 0.85\n",
    "                }\n",
    "                df['price_weight'] *= df['차량상태'].map(condition_weights)\n",
    "                \n",
    "                # 배터리 용량과 주행거리 관계 고려\n",
    "                battery_distance_ratio = df['배터리용량'] / np.log1p(df['주행거리(km)'])\n",
    "                df.loc[battery_distance_ratio < battery_distance_ratio.median(), 'price_weight'] *= 0.9\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def handle_entry_outliers(self, df):\n",
    "        \"\"\"엔트리 세그먼트 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # IONIQ 특별 처리 개선\n",
    "        ioniq_mask = df['모델'] == 'IONIQ'\n",
    "        if sum(ioniq_mask) > 0 and '가격(백만원)' in df.columns:\n",
    "            # 연식 기반 가격 조정\n",
    "            df.loc[ioniq_mask, 'price_weight'] *= np.exp(-0.1 * df.loc[ioniq_mask, '연식(년)'])\n",
    "            \n",
    "            # 주행거리 기반 가격 조정\n",
    "            distance_factor = 1 - (df.loc[ioniq_mask, '주행거리(km)'] / 200000)\n",
    "            df.loc[ioniq_mask, 'price_weight'] *= np.maximum(0.7, distance_factor)\n",
    "            \n",
    "            # 배터리 상태 고려\n",
    "            battery_factor = df.loc[ioniq_mask, '배터리용량'] / df.loc[ioniq_mask, '배터리용량'].mean()\n",
    "            df.loc[ioniq_mask, 'price_weight'] *= np.minimum(1.2, np.maximum(0.8, battery_factor))\n",
    "        \n",
    "        # Soul 모델 특화 처리\n",
    "        soul_mask = df['모델'] == 'Soul'\n",
    "        if sum(soul_mask) > 0:\n",
    "            # 배터리 상태에 따른 보증 가중치 조정\n",
    "            df.loc[soul_mask, 'warranty_factor'] = np.where(\n",
    "                df.loc[soul_mask, '배터리용량'] > df.loc[soul_mask, '배터리용량'].mean(),\n",
    "                1.3,  # 배터리 용량이 평균 이상인 경우\n",
    "                1.1   # 배터리 용량이 평균 미만인 경우\n",
    "            )\n",
    "            \n",
    "            # 주행거리와 연식의 복합 가중치\n",
    "            age_distance_factor = 1 - (\n",
    "                0.3 * df.loc[soul_mask, '연식(년)'] / 10 +\n",
    "                0.7 * df.loc[soul_mask, '주행거리(km)'] / 150000\n",
    "            )\n",
    "            df.loc[soul_mask, 'price_weight'] *= np.maximum(0.75, age_distance_factor)\n",
    "            \n",
    "            # 사고이력 고려\n",
    "            df.loc[soul_mask & (df['사고이력'] == 'Yes'), 'price_weight'] *= 0.9\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_model_specific_features(self, df, model_name):\n",
    "        \"\"\"모델별 특화 특성 생성\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        if model_name == 'Tay':\n",
    "            # 주행거리 구간을 더 세분화\n",
    "            distance_ranges = [0, 30000, 60000, 90000, 120000, 150000]\n",
    "            labels = ['very_low', 'low', 'medium', 'high', 'very_high', 'extreme']\n",
    "            \n",
    "            # 차량상태별 가중치 조정\n",
    "            condition_weights = {\n",
    "                'Brand New': 4.0,    # 증가\n",
    "                'Nearly New': 2.8,   # 증가\n",
    "                'Pre-Owned': 1.0\n",
    "            }\n",
    "            \n",
    "            # 추가: 연식과 주행거리의 비율\n",
    "            features['age_distance_ratio'] = df['연식(년)'] / (df['주행거리(km)'] + 1000)\n",
    "            \n",
    "            # 추가: 보증기간과 배터리용량의 상호작용\n",
    "            features['warranty_battery_score'] = (df['보증기간(년)'] + 1) * (df['배터리용량'] / df['배터리용량'].mean())\n",
    "            \n",
    "            # 배터리 효율성 개선\n",
    "            features['battery_efficiency'] = df['배터리용량'] / np.log1p(df['주행거리(km)'])\n",
    "            \n",
    "        elif model_name == 'TayCT':\n",
    "            # TayCT만의 특별한 구간화\n",
    "            distance_ranges = [0, 25000, 50000, 75000, 100000]\n",
    "            labels = ['very_low', 'low', 'medium', 'high', 'very_high']\n",
    "            \n",
    "            # TayCT 특화 가중치\n",
    "            condition_weights = {\n",
    "                'Brand New': 3.5,\n",
    "                'Nearly New': 2.5,\n",
    "                'Pre-Owned': 1.0\n",
    "            }\n",
    "            \n",
    "            # 추가: 배터리 성능 지수\n",
    "            features['battery_performance_index'] = (\n",
    "                df['배터리용량'] * 0.7 + \n",
    "                (150000 - df['주행거리(km)']) / 150000 * 0.3\n",
    "            )\n",
    "            \n",
    "            # 추가: 보증-연식-주행거리 복합 지수\n",
    "            features['warranty_age_distance'] = (\n",
    "                df['보증기간(년)'] * 0.4 +\n",
    "                (10 - df['연식(년)']) * 0.3 +\n",
    "                (100000 - df['주행거리(km)']) / 100000 * 0.3\n",
    "            )\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # 주행거리 구간화\n",
    "        features['distance_level'] = pd.cut(\n",
    "            df['주행거리(km)'],\n",
    "            bins=distance_ranges + [float('inf')],\n",
    "            labels=labels,\n",
    "            include_lowest=True\n",
    "        ).astype(str)\n",
    "        \n",
    "        # 차량상태 점수화\n",
    "        features['condition_score'] = df['차량상태'].map(condition_weights)\n",
    "        \n",
    "        # 배터리 상태 점수\n",
    "        features['battery_score'] = np.where(\n",
    "            df['배터리용량'].isna(),\n",
    "            0,\n",
    "            df['배터리용량'] / df['배터리용량'].mean()\n",
    "        )\n",
    "        \n",
    "        # 주행거리 영향도 개선\n",
    "        features['distance_impact'] = 1 / (1 + np.exp((df['주행거리(km)'] - 75000) / 25000))\n",
    "        \n",
    "        # 보증기간과 연식의 상호작용\n",
    "        features['warranty_age_ratio'] = df['보증기간(년)'] / np.maximum(df['연식(년)'], 1)\n",
    "        \n",
    "        # 차량상태와 주행거리의 상호작용\n",
    "        features['condition_distance'] = features['condition_score'] * features['distance_impact']\n",
    "        \n",
    "        # 모든 특성을 DataFrame으로 변환\n",
    "        features_df = pd.DataFrame(features)\n",
    "        \n",
    "        # distance_level을 one-hot 인코딩\n",
    "        distance_dummies = pd.get_dummies(\n",
    "            features_df['distance_level'], \n",
    "            prefix='distance'\n",
    "        )\n",
    "        \n",
    "        # 기존 특성과 one-hot 인코딩 결과 결합\n",
    "        result = pd.concat([features_df, distance_dummies], axis=1)\n",
    "        result.drop('distance_level', axis=1, inplace=True)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 가중치 초기화\n",
    "        df['price_weight'] = 1.0\n",
    "        df['warranty_factor'] = 1.0\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 이상치 처리\n",
    "        premium_mask = df['model_segment'] == 6\n",
    "        entry_mask = df['model_segment'] == 1\n",
    "        \n",
    "        if sum(premium_mask) > 0:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = df['모델'] == model\n",
    "                if sum(model_mask) > 0:\n",
    "                    df.loc[model_mask] = self.handle_premium_outliers(df[model_mask], model)\n",
    "        \n",
    "        if sum(entry_mask) > 0:\n",
    "            df.loc[entry_mask] = self.handle_entry_outliers(df[entry_mask])\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "\n",
    "        # 기본 특성 생성\n",
    "        features = {\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'] * df['warranty_factor'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'distance': df['주행거리(km)'],\n",
    "            'price_weight': df['price_weight']\n",
    "        }\n",
    "        \n",
    "        # 세그먼트별 특화 특성\n",
    "        if '모델' in df.columns:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = (df['모델'] == model)\n",
    "                if sum(model_mask) > 0:\n",
    "                    model_features = self.get_model_specific_features(df[model_mask], model)\n",
    "                    if not model_features.empty:\n",
    "                        for col in model_features.columns:\n",
    "                            features[f'{model}_{col}'] = np.zeros(len(df))\n",
    "                            features[f'{model}_{col}'][model_mask] = model_features[col].values\n",
    "        \n",
    "        features_df = pd.DataFrame(features).fillna(0)\n",
    "        return features_df\n",
    "    \n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['model_segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            if segment == 6:  # 준프리미엄 세그먼트\n",
    "                models = {}\n",
    "                for model in ['Tay', 'TayCT']:\n",
    "                    mask = X['model_encoded'] == self.label_encoders['모델'].transform([model])[0]\n",
    "                    if sum(mask) > 0:\n",
    "                        params = {\n",
    "                            'Tay': {\n",
    "                                'max_iter': 1000,       # 증가\n",
    "                                'learning_rate': 0.006, # 감소\n",
    "                                'max_depth': 6,         # 증가\n",
    "                                'l2_regularization': 2.0# 증가\n",
    "                            },\n",
    "                            'TayCT': {\n",
    "                                'max_iter': 800,\n",
    "                                'learning_rate': 0.008,\n",
    "                                'max_depth': 5,\n",
    "                                'l2_regularization': 2.2\n",
    "                            }\n",
    "                        }[model]\n",
    "                        \n",
    "                        model_cols = [col for col in X.columns if model in col or col in [\n",
    "                            'distance', 'battery_capacity', 'age', 'warranty', \n",
    "                            'accident', 'condition_encoded', 'drive_encoded',\n",
    "                            'price_weight'\n",
    "                        ]]\n",
    "                        \n",
    "                        regressor = HistGradientBoostingRegressor(\n",
    "                            random_state=42,\n",
    "                            **params\n",
    "                        )\n",
    "                        \n",
    "                        model_X = X[mask][model_cols]\n",
    "                        model_y = y[mask]\n",
    "                        weights = X[mask]['price_weight'] if 'price_weight' in X.columns else None\n",
    "                        \n",
    "                        regressor.fit(model_X, model_y, sample_weight=weights)\n",
    "                        models[model] = (regressor, model_cols)\n",
    "                return models\n",
    "            else:\n",
    "                params = {\n",
    "                    1: {  # 엔트리\n",
    "                        'max_iter': 1500,           # 증가\n",
    "                        'learning_rate': 0.006,     # 감소\n",
    "                        'max_depth': 5,             # 증가\n",
    "                        'l2_regularization': 2.5    # 증가\n",
    "                    },\n",
    "                    7: {  # 프리미엄\n",
    "                        'max_iter': 800,\n",
    "                        'learning_rate': 0.01,\n",
    "                        'max_depth': 3,\n",
    "                        'l2_regularization': 1.5,\n",
    "                    }\n",
    "                }.get(segment, {\n",
    "                    'max_iter': 1000,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 1.0,\n",
    "                })\n",
    "                \n",
    "                model = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    **params\n",
    "                )\n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                weights = X[mask]['price_weight'] if 'price_weight' in X.columns else None\n",
    "                \n",
    "                model.fit(segment_X, segment_y, sample_weight=weights)\n",
    "                return model\n",
    "        return None\n",
    "\n",
    "    def predict_segment_6(self, X, models):\n",
    "        \"\"\"준프리미엄 세그먼트 예측\"\"\"\n",
    "        predictions = np.zeros(len(X))\n",
    "        for model_name, (model, cols) in models.items():\n",
    "            mask = X['model_encoded'] == self.label_encoders['모델'].transform([model_name])[0]\n",
    "            if sum(mask) > 0:\n",
    "                predictions[mask] = model.predict(X[mask][cols])\n",
    "        return predictions\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['model_segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        if segment == 6:\n",
    "                            segment_pred = self.predict_segment_6(X_val[mask], model)\n",
    "                        else:\n",
    "                            segment_pred = model.predict(X_val[mask])\n",
    "                            \n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, model in self.segment_models.items():\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                if segment == 6:\n",
    "                    predictions[mask] = self.predict_segment_6(X[mask], model)\n",
    "                elif model is not None:\n",
    "                    predictions[mask] = model.predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = ImprovedSegmentPredictor()\n",
    "    predictor.fit(train_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('improved_segment_submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.3915, R2: 0.9986\n",
      "Fold 2 - RMSE: 1.4722, R2: 0.9984\n",
      "Fold 3 - RMSE: 1.4566, R2: 0.9984\n",
      "Fold 4 - RMSE: 1.2231, R2: 0.9989\n",
      "Fold 5 - RMSE: 1.3473, R2: 0.9985\n",
      "\n",
      "평균 RMSE: 1.3781 (+/- 0.1793)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.6725\n",
      "세그먼트 2 RMSE: 0.5268\n",
      "세그먼트 3 RMSE: 0.4268\n",
      "세그먼트 4 RMSE: 0.6281\n",
      "세그먼트 5 RMSE: 0.6280\n",
      "세그먼트 6 RMSE: 3.3879\n",
      "세그먼트 7 RMSE: 0.3319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class DepreciationBasedPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "            \n",
    "    def get_premium_features(self, df):\n",
    "        \"\"\"준프리미엄 세그먼트 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 기준가격 설정\n",
    "        base_prices = {\n",
    "            'Tay': 125,    # 1억 2500만원\n",
    "            'TayCT': 95    # 9500만원\n",
    "        }\n",
    "        \n",
    "        features.loc[:, 'base_price'] = features['모델'].map(base_prices).fillna(0)\n",
    "        features.loc[:, 'age_depreciation'] = -0.2 * (features['연식(년)'] / 5)\n",
    "        features.loc[:, 'distance_depreciation'] = -0.3 * (features['주행거리(km)'] / 100000)\n",
    "        features.loc[:, 'battery_depreciation'] = -0.15 * (1 - features['배터리용량'] / features['배터리용량'].max())\n",
    "        \n",
    "        # 차량상태 보정계수\n",
    "        condition_factor = {\n",
    "            'Brand New': 1.0,\n",
    "            'Nearly New': 0.95,\n",
    "            'Pre-Owned': 0.85\n",
    "        }\n",
    "        features.loc[:, 'condition_factor'] = features['차량상태'].map(condition_factor)\n",
    "        \n",
    "        # 배터리 효율성\n",
    "        features.loc[:, 'battery_efficiency'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "        \n",
    "        # 총 감가상각률\n",
    "        features.loc[:, 'total_depreciation'] = (\n",
    "            features['age_depreciation'] + \n",
    "            features['distance_depreciation'] + \n",
    "            features['battery_depreciation']\n",
    "        ) * features['condition_factor']\n",
    "        \n",
    "        # 예상 가격\n",
    "        features.loc[:, 'expected_price'] = features['base_price'] * (1 + features['total_depreciation'])\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    def get_entry_features(self, df):\n",
    "        \"\"\"엔트리 세그먼트 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 모델별 기준가격\n",
    "        model_base = {\n",
    "            'IONIQ': 45,  # 4500만원\n",
    "            'Soul': 42,   # 4200만원\n",
    "            'i3': 48      # 4800만원\n",
    "        }\n",
    "        features.loc[:, 'base_price'] = features['모델'].map(model_base).fillna(0)\n",
    "        \n",
    "        # 연식별 감가율 (비선형)\n",
    "        features.loc[:, 'age_depreciation'] = np.where(\n",
    "            features['연식(년)'] <= 2,\n",
    "            -0.1 * features['연식(년)'],\n",
    "            -0.2 * features['연식(년)']\n",
    "        )\n",
    "        \n",
    "        # 주행거리 기반 가격조정\n",
    "        features.loc[:, 'distance_factor'] = np.clip(\n",
    "            1 - (features['주행거리(km)'] / 150000) ** 0.7,\n",
    "            0.6,\n",
    "            1.0\n",
    "        )\n",
    "        \n",
    "        # 배터리 상태 점수\n",
    "        features.loc[:, 'battery_score'] = np.clip(\n",
    "            features['배터리용량'] / features['배터리용량'].mean(),\n",
    "            0.8,\n",
    "            1.2\n",
    "        )\n",
    "        \n",
    "        # 사고이력 가중치\n",
    "        features.loc[:, 'accident_factor'] = np.where(features['사고이력'] == 'Yes', 0.9, 1.0)\n",
    "        \n",
    "        # 예상 가격\n",
    "        features.loc[:, 'expected_price'] = (\n",
    "            features['base_price'] * \n",
    "            (1 + features['age_depreciation']) * \n",
    "            features['distance_factor'] * \n",
    "            features['battery_score'] * \n",
    "            features['accident_factor']\n",
    "        )\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"전체 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        features['segment'] = features['모델'].apply(self.get_segment)\n",
    "        \n",
    "        # 세그먼트별 특성 생성\n",
    "        premium_mask = features['segment'] == 6\n",
    "        entry_mask = features['segment'] == 1\n",
    "        \n",
    "        if sum(premium_mask) > 0:\n",
    "            premium_features = self.get_premium_features(features[premium_mask])\n",
    "            for col in premium_features.columns:\n",
    "                if col not in features.columns:\n",
    "                    features.loc[premium_mask, col] = premium_features[col]\n",
    "        \n",
    "        if sum(entry_mask) > 0:\n",
    "            entry_features = self.get_entry_features(features[entry_mask])\n",
    "            for col in entry_features.columns:\n",
    "                if col not in features.columns:\n",
    "                    features.loc[entry_mask, col] = entry_features[col]\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(features[col].unique())\n",
    "                if '가격(백만원)' not in features.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "        \n",
    "        # 최종 특성 선택\n",
    "        feature_cols = [\n",
    "            'segment', '제조사_encoded', '모델_encoded', '구동방식_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)'\n",
    "        ]\n",
    "        \n",
    "        if 'base_price' in features.columns:\n",
    "            feature_cols.extend(['base_price', 'expected_price'])\n",
    "            \n",
    "        if 'total_depreciation' in features.columns:\n",
    "            feature_cols.extend(['total_depreciation'])\n",
    "            \n",
    "        if 'battery_efficiency' in features.columns:\n",
    "            feature_cols.extend(['battery_efficiency'])\n",
    "            \n",
    "        if 'distance_factor' in features.columns:\n",
    "            feature_cols.extend(['distance_factor'])\n",
    "        \n",
    "        return features[feature_cols].fillna(0)\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            if segment == 6:  # 준프리미엄 세그먼트\n",
    "                params = {\n",
    "                    'max_iter': 1000,\n",
    "                    'learning_rate': 0.005,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 2.5\n",
    "                }\n",
    "            elif segment == 1:  # 엔트리 세그먼트\n",
    "                params = {\n",
    "                    'max_iter': 1200,\n",
    "                    'learning_rate': 0.005,\n",
    "                    'max_depth': 4,\n",
    "                    'l2_regularization': 3.0\n",
    "                }\n",
    "            else:\n",
    "                params = {\n",
    "                    'max_iter': 1000,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 1.0\n",
    "                }\n",
    "            \n",
    "            model = HistGradientBoostingRegressor(random_state=42, **params)\n",
    "            segment_X = X[mask]\n",
    "            segment_y = y[mask]\n",
    "            \n",
    "            model.fit(segment_X, segment_y)\n",
    "            return model\n",
    "            \n",
    "        return None\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        segment_pred = model.predict(X_val[mask])\n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, model in self.segment_models.items():\n",
    "            mask = X['segment'] == segment\n",
    "            if sum(mask) > 0 and model is not None:\n",
    "                predictions[mask] = model.predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = DepreciationBasedPredictor()\n",
    "    predictor.fit(train_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('depreciation_based_submission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 세그먼트 1 튜닝 시작 ===\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "\n",
      "=== 세그먼트 1 최적 파라미터 ===\n",
      "Best parameters: {'l2_regularization': 1.5, 'learning_rate': 0.01, 'max_depth': 7, 'max_iter': 2000}\n",
      "Best RMSE: -1.8309\n",
      "\n",
      "=== 세그먼트 2 튜닝 시작 ===\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "\n",
      "=== 세그먼트 2 최적 파라미터 ===\n",
      "Best parameters: {'l2_regularization': 0.8, 'learning_rate': 0.012, 'max_depth': 7, 'max_iter': 1200}\n",
      "Best RMSE: -0.5398\n",
      "\n",
      "=== 세그먼트 3 튜닝 시작 ===\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "\n",
      "=== 세그먼트 3 최적 파라미터 ===\n",
      "Best parameters: {'l2_regularization': 0.8, 'learning_rate': 0.012, 'max_depth': 7, 'max_iter': 1200}\n",
      "Best RMSE: -0.4296\n",
      "\n",
      "=== 세그먼트 4 튜닝 시작 ===\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "\n",
      "=== 세그먼트 4 최적 파라미터 ===\n",
      "Best parameters: {'l2_regularization': 1.2, 'learning_rate': 0.012, 'max_depth': 5, 'max_iter': 1200}\n",
      "Best RMSE: -0.6338\n",
      "\n",
      "=== 세그먼트 5 튜닝 시작 ===\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "\n",
      "=== 세그먼트 5 최적 파라미터 ===\n",
      "Best parameters: {'l2_regularization': 1.2, 'learning_rate': 0.012, 'max_depth': 7, 'max_iter': 1200}\n",
      "Best RMSE: -0.6097\n",
      "\n",
      "=== 세그먼트 6 튜닝 시작 ===\n",
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "\n",
      "=== 세그먼트 6 최적 파라미터 ===\n",
      "Best parameters: {'l2_regularization': 1.5, 'learning_rate': 0.015, 'max_depth': 8, 'max_iter': 2000}\n",
      "Best RMSE: -3.5059\n",
      "\n",
      "=== 세그먼트 7 튜닝 시작 ===\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "\n",
      "=== 세그먼트 7 최적 파라미터 ===\n",
      "Best parameters: {'l2_regularization': 1.2, 'learning_rate': 0.012, 'max_depth': 7, 'max_iter': 1200}\n",
      "Best RMSE: -0.3384\n",
      "\n",
      "=== 전체 결과 ===\n",
      "   segment  l2_regularization  learning_rate  max_depth  max_iter      rmse\n",
      "0        1                1.5          0.010          7      2000 -1.830947\n",
      "1        2                0.8          0.012          7      1200 -0.539821\n",
      "2        3                0.8          0.012          7      1200 -0.429581\n",
      "3        4                1.2          0.012          5      1200 -0.633791\n",
      "4        5                1.2          0.012          7      1200 -0.609678\n",
      "5        6                1.5          0.015          8      2000 -3.505917\n",
      "6        7                1.2          0.012          7      1200 -0.338421\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "def tune_segment_hyperparameters(X, y, segment_id):\n",
    "    \"\"\"세그먼트별 하이퍼파라미터 튜닝\"\"\"\n",
    "    \n",
    "    # 세그먼트별 파라미터 그리드 설정\n",
    "    if segment_id == 6:  # 준프리미엄\n",
    "        param_grid = {\n",
    "            'max_iter': [1000, 1500, 2000],\n",
    "            'learning_rate': [0.005, 0.007, 0.01, 0.015],\n",
    "            'max_depth': [5, 6, 7, 8],\n",
    "            'l2_regularization': [1.0, 1.5, 2.0, 2.5]\n",
    "        }\n",
    "    elif segment_id == 1:  # 엔트리\n",
    "        param_grid = {\n",
    "            'max_iter': [1200, 1500, 2000],\n",
    "            'learning_rate': [0.005, 0.007, 0.01],\n",
    "            'max_depth': [4, 5, 6, 7],\n",
    "            'l2_regularization': [1.5, 2.0, 2.5, 3.0]\n",
    "        }\n",
    "    else:  # 다른 세그먼트\n",
    "        param_grid = {\n",
    "            'max_iter': [800, 1000, 1200],\n",
    "            'learning_rate': [0.008, 0.01, 0.012],\n",
    "            'max_depth': [5, 6, 7],\n",
    "            'l2_regularization': [0.8, 1.0, 1.2]\n",
    "        }\n",
    "    \n",
    "    # 기본 모델 설정\n",
    "    base_model = HistGradientBoostingRegressor(random_state=42)\n",
    "    \n",
    "    # RMSE 스코어러 생성\n",
    "    rmse_scorer = make_scorer(\n",
    "        lambda y_true, y_pred: -np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        greater_is_better=False\n",
    "    )\n",
    "    \n",
    "    # GridSearchCV 설정\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=base_model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=rmse_scorer,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 그리드 서치 수행\n",
    "    grid_search.fit(X, y)\n",
    "    \n",
    "    # 결과 출력\n",
    "    print(f\"\\n=== 세그먼트 {segment_id} 최적 파라미터 ===\")\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best RMSE: {-grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return grid_search.best_params_, -grid_search.best_score_\n",
    "\n",
    "def prepare_segment_data(train_df, segment_id):\n",
    "    \"\"\"세그먼트별 데이터 준비\"\"\"\n",
    "    # 라벨 인코더 준비\n",
    "    label_encoders = {}\n",
    "    for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        label_encoders[col].fit(train_df[col])\n",
    "        \n",
    "    # 세그먼트 필터링\n",
    "    segment_mask = train_df['segment'] == segment_id\n",
    "    segment_data = train_df[segment_mask].copy()\n",
    "    \n",
    "    # 특성 생성\n",
    "    for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "        segment_data[f'{col}_encoded'] = label_encoders[col].transform(segment_data[col])\n",
    "    \n",
    "    # 수치형 특성 선택\n",
    "    feature_cols = [\n",
    "        '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)',\n",
    "        '제조사_encoded', '모델_encoded', '구동방식_encoded', '차량상태_encoded'\n",
    "    ]\n",
    "    \n",
    "    X = segment_data[feature_cols]\n",
    "    y = segment_data['가격(백만원)']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# 메인 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    \n",
    "    # 세그먼트 할당\n",
    "    def get_segment(model_name):\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    train_data['segment'] = train_data['모델'].apply(get_segment)\n",
    "    \n",
    "    # 결측치 처리\n",
    "    train_data['배터리용량'] = train_data.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    # 세그먼트별 하이퍼파라미터 튜닝\n",
    "    all_results = {}\n",
    "    for segment in range(1, 8):\n",
    "        print(f\"\\n=== 세그먼트 {segment} 튜닝 시작 ===\")\n",
    "        X, y = prepare_segment_data(train_data, segment)\n",
    "        best_params, best_rmse = tune_segment_hyperparameters(X, y, segment)\n",
    "        all_results[segment] = {\n",
    "            'params': best_params,\n",
    "            'rmse': best_rmse\n",
    "        }\n",
    "    \n",
    "    # 결과 정리 및 저장\n",
    "    results_df = pd.DataFrame([\n",
    "        {\n",
    "            'segment': segment,\n",
    "            **results['params'],\n",
    "            'rmse': results['rmse']\n",
    "        }\n",
    "        for segment, results in all_results.items()\n",
    "    ])\n",
    "    \n",
    "    results_df.to_csv('hyperparameter_tuning_results.csv', index=False)\n",
    "    print(\"\\n=== 전체 결과 ===\")\n",
    "    print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.5081, R2: 0.9983\n",
      "Fold 2 - RMSE: 1.5496, R2: 0.9983\n",
      "Fold 3 - RMSE: 1.4168, R2: 0.9985\n",
      "Fold 4 - RMSE: 1.2688, R2: 0.9988\n",
      "Fold 5 - RMSE: 1.4306, R2: 0.9984\n",
      "\n",
      "평균 RMSE: 1.4348 (+/- 0.1928)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.8322\n",
      "세그먼트 2 RMSE: 0.5319\n",
      "세그먼트 3 RMSE: 0.4231\n",
      "세그먼트 4 RMSE: 0.6694\n",
      "세그먼트 5 RMSE: 0.6204\n",
      "세그먼트 6 RMSE: 3.4110\n",
      "세그먼트 7 RMSE: 0.3365\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class OptimizedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 세그먼트별 최적 하이퍼파라미터\n",
    "        self.segment_params = {\n",
    "            1: {\n",
    "                'max_iter': 2000,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 7,\n",
    "                'l2_regularization': 1.5\n",
    "            },\n",
    "            2: {\n",
    "                'max_iter': 1200,\n",
    "                'learning_rate': 0.012,\n",
    "                'max_depth': 7,\n",
    "                'l2_regularization': 0.8\n",
    "            },\n",
    "            3: {\n",
    "                'max_iter': 1200,\n",
    "                'learning_rate': 0.012,\n",
    "                'max_depth': 7,\n",
    "                'l2_regularization': 0.8\n",
    "            },\n",
    "            4: {\n",
    "                'max_iter': 1200,\n",
    "                'learning_rate': 0.012,\n",
    "                'max_depth': 5,\n",
    "                'l2_regularization': 1.2\n",
    "            },\n",
    "            5: {\n",
    "                'max_iter': 1200,\n",
    "                'learning_rate': 0.012,\n",
    "                'max_depth': 7,\n",
    "                'l2_regularization': 1.2\n",
    "            },\n",
    "            6: {\n",
    "                'max_iter': 2000,\n",
    "                'learning_rate': 0.015,\n",
    "                'max_depth': 8,\n",
    "                'l2_regularization': 1.5\n",
    "            },\n",
    "            7: {\n",
    "                'max_iter': 1200,\n",
    "                'learning_rate': 0.012,\n",
    "                'max_depth': 7,\n",
    "                'l2_regularization': 1.2\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        features['segment'] = features['모델'].apply(self.get_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(features[col].unique())\n",
    "                if '가격(백만원)' not in features.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "\n",
    "        # 특성 선택\n",
    "        feature_cols = [\n",
    "            'segment',\n",
    "            '제조사_encoded',\n",
    "            '모델_encoded',\n",
    "            '구동방식_encoded',\n",
    "            '차량상태_encoded',\n",
    "            '배터리용량',\n",
    "            '주행거리(km)',\n",
    "            '보증기간(년)',\n",
    "            '연식(년)'\n",
    "        ]\n",
    "\n",
    "        # 세그먼트 6 (준프리미엄)을 위한 추가 특성\n",
    "        premium_mask = features['segment'] == 6\n",
    "        if sum(premium_mask) > 0:\n",
    "            # 배터리 효율성\n",
    "            features.loc[:, 'battery_efficiency'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "            # 연식-주행거리 상호작용\n",
    "            features.loc[:, 'age_distance_ratio'] = features['연식(년)'] / np.log1p(features['주행거리(km)'])\n",
    "            feature_cols.extend(['battery_efficiency', 'age_distance_ratio'])\n",
    "        \n",
    "        return features[feature_cols]\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            params = self.segment_params[segment]\n",
    "            model = HistGradientBoostingRegressor(\n",
    "                random_state=42,\n",
    "                **params\n",
    "            )\n",
    "            segment_X = X[mask]\n",
    "            segment_y = y[mask]\n",
    "            \n",
    "            model.fit(segment_X, segment_y)\n",
    "            return model\n",
    "            \n",
    "        return None\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        segment_pred = model.predict(X_val[mask])\n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, model in self.segment_models.items():\n",
    "            mask = X['segment'] == segment\n",
    "            if sum(mask) > 0 and model is not None:\n",
    "                predictions[mask] = model.predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = OptimizedSegmentPredictor()\n",
    "    predictor.fit(train_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('optimized_segment_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4666, R2: 0.9984\n",
      "Fold 2 - RMSE: 1.5089, R2: 0.9984\n",
      "Fold 3 - RMSE: 1.3637, R2: 0.9986\n",
      "Fold 4 - RMSE: 1.2763, R2: 0.9988\n",
      "Fold 5 - RMSE: 1.3589, R2: 0.9985\n",
      "\n",
      "평균 RMSE: 1.3949 (+/- 0.1660)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.7378\n",
      "세그먼트 2 RMSE: 0.5310\n",
      "세그먼트 3 RMSE: 0.4215\n",
      "세그먼트 4 RMSE: 0.7128\n",
      "세그먼트 5 RMSE: 0.6222\n",
      "세그먼트 6 RMSE: 3.3353\n",
      "세그먼트 7 RMSE: 0.3375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class EnsembleSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.rf_models = {}  # Random Forest 모델\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Random Forest 파라미터\n",
    "        self.rf_params = {\n",
    "            6: {  # 준프리미엄\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 12,\n",
    "                'min_samples_split': 10,\n",
    "                'min_samples_leaf': 4,\n",
    "                'random_state': 42\n",
    "            },\n",
    "            1: {  # 엔트리\n",
    "                'n_estimators': 150,\n",
    "                'max_depth': 10,\n",
    "                'min_samples_split': 8,\n",
    "                'min_samples_leaf': 3,\n",
    "                'random_state': 42\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # HGBR 파라미터\n",
    "        self.hgb_params = {\n",
    "            6: {\n",
    "                'max_iter': 2000,\n",
    "                'learning_rate': 0.015,\n",
    "                'max_depth': 8,\n",
    "                'l2_regularization': 1.5\n",
    "            },\n",
    "            1: {\n",
    "                'max_iter': 2000,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 7,\n",
    "                'l2_regularization': 1.5\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 앙상블 가중치\n",
    "        self.ensemble_weights = {\n",
    "            6: {'hgb': 0.3, 'rf': 0.7},  # 준프리미엄\n",
    "            1: {'hgb': 0.4, 'rf': 0.6}   # 엔트리\n",
    "        }\n",
    "\n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        features['segment'] = features['모델'].apply(self.get_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(features[col].unique())\n",
    "                if '가격(백만원)' not in features.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "\n",
    "        # 기본 특성\n",
    "        feature_cols = [\n",
    "            'segment',\n",
    "            '제조사_encoded',\n",
    "            '모델_encoded',\n",
    "            '구동방식_encoded',\n",
    "            '차량상태_encoded',\n",
    "            '배터리용량',\n",
    "            '주행거리(km)',\n",
    "            '보증기간(년)',\n",
    "            '연식(년)'\n",
    "        ]\n",
    "        \n",
    "        # 세그먼트별 특화 특성\n",
    "        for segment in [1, 6]:\n",
    "            segment_mask = features['segment'] == segment\n",
    "            if sum(segment_mask) > 0:\n",
    "                # 배터리 효율성\n",
    "                features.loc[:, 'battery_efficiency'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "                # 연식-주행거리 상호작용\n",
    "                features.loc[:, 'age_distance_ratio'] = features['연식(년)'] / np.log1p(features['주행거리(km)'])\n",
    "                # 배터리-보증 상호작용\n",
    "                features.loc[:, 'battery_warranty'] = features['배터리용량'] * features['보증기간(년)']\n",
    "                # 주행거리 구간화\n",
    "                features.loc[:, 'distance_group'] = pd.qcut(features['주행거리(km)'], q=5, labels=False, duplicates='drop')\n",
    "                \n",
    "                feature_cols.extend([\n",
    "                    'battery_efficiency',\n",
    "                    'age_distance_ratio',\n",
    "                    'battery_warranty',\n",
    "                    'distance_group'\n",
    "                ])\n",
    "\n",
    "        return features[feature_cols]\n",
    "\n",
    "    def train_models(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            if segment in [1, 6]:  # 앙상블 적용 세그먼트\n",
    "                # HGBR 모델\n",
    "                hgb = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    **self.hgb_params[segment]\n",
    "                )\n",
    "                \n",
    "                # Random Forest 모델\n",
    "                rf = RandomForestRegressor(\n",
    "                    **self.rf_params[segment]\n",
    "                )\n",
    "                \n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                \n",
    "                hgb.fit(segment_X, segment_y)\n",
    "                rf.fit(segment_X, segment_y)\n",
    "                \n",
    "                return {'hgb': hgb, 'rf': rf}\n",
    "            else:  # 기본 HGBR 모델\n",
    "                model = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    max_iter=1200,\n",
    "                    learning_rate=0.012,\n",
    "                    max_depth=7,\n",
    "                    l2_regularization=1.2\n",
    "                )\n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                model.fit(segment_X, segment_y)\n",
    "                return model\n",
    "        return None\n",
    "\n",
    "    def predict_segment(self, X, models, segment):\n",
    "        \"\"\"세그먼트별 예측\"\"\"\n",
    "        if segment in [1, 6]:  # 앙상블 적용 세그먼트\n",
    "            hgb_pred = models['hgb'].predict(X)\n",
    "            rf_pred = models['rf'].predict(X)\n",
    "            weights = self.ensemble_weights[segment]\n",
    "            return weights['hgb'] * hgb_pred + weights['rf'] * rf_pred\n",
    "        else:\n",
    "            return models.predict(X)\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                models = self.train_models(X_train, y_train, segment)\n",
    "                if models is not None:\n",
    "                    mask = X_val['segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        segment_pred = self.predict_segment(X_val[mask], models, segment)\n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_models(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, models in self.segment_models.items():\n",
    "            mask = X['segment'] == segment\n",
    "            if sum(mask) > 0 and models is not None:\n",
    "                predictions[mask] = self.predict_segment(X[mask], models, segment)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = EnsembleSegmentPredictor()\n",
    "    predictor.fit(train_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('ensemble_segment_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4600, R2: 0.9984\n",
      "Fold 2 - RMSE: 1.5314, R2: 0.9983\n",
      "Fold 3 - RMSE: 1.3601, R2: 0.9986\n",
      "Fold 4 - RMSE: 1.2871, R2: 0.9988\n",
      "Fold 5 - RMSE: 1.3625, R2: 0.9985\n",
      "\n",
      "평균 RMSE: 1.4002 (+/- 0.1712)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.7365\n",
      "세그먼트 2 RMSE: 0.5318\n",
      "세그먼트 3 RMSE: 0.4198\n",
      "세그먼트 4 RMSE: 0.7043\n",
      "세그먼트 5 RMSE: 0.6347\n",
      "세그먼트 6 RMSE: 2.9119\n",
      "세그먼트 7 RMSE: 0.3438\n",
      "세그먼트 8 RMSE: 3.7826\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class RefinedEnsemblePredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.rf_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Random Forest 파라미터\n",
    "        self.rf_params = {\n",
    "            8: {  # Premium Sport (TayCT)\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 10,\n",
    "                'min_samples_split': 8,\n",
    "                'min_samples_leaf': 3,\n",
    "                'random_state': 42\n",
    "            },\n",
    "            6: {  # Premium Sedan (Tay)\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 12,\n",
    "                'min_samples_split': 10,\n",
    "                'min_samples_leaf': 4,\n",
    "                'random_state': 42\n",
    "            },\n",
    "            1: {  # 엔트리\n",
    "                'n_estimators': 150,\n",
    "                'max_depth': 10,\n",
    "                'min_samples_split': 8,\n",
    "                'min_samples_leaf': 3,\n",
    "                'random_state': 42\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # HGBR 파라미터\n",
    "        self.hgb_params = {\n",
    "            8: {  # Premium Sport\n",
    "                'max_iter': 2000,\n",
    "                'learning_rate': 0.012,\n",
    "                'max_depth': 7,\n",
    "                'l2_regularization': 1.2\n",
    "            },\n",
    "            6: {  # Premium Sedan\n",
    "                'max_iter': 2000,\n",
    "                'learning_rate': 0.015,\n",
    "                'max_depth': 8,\n",
    "                'l2_regularization': 1.5\n",
    "            },\n",
    "            1: {  # 엔트리\n",
    "                'max_iter': 2000,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 7,\n",
    "                'l2_regularization': 1.5\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 앙상블 가중치\n",
    "        self.ensemble_weights = {\n",
    "            8: {'hgb': 0.4, 'rf': 0.6},  # Premium Sport\n",
    "            6: {'hgb': 0.3, 'rf': 0.7},  # Premium Sedan\n",
    "            1: {'hgb': 0.4, 'rf': 0.6}   # 엔트리\n",
    "        }\n",
    "\n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        premium_sport = ['TayCT']    # 새로운 세그먼트 (8)\n",
    "        premium_sedan = ['Tay']      # 새로운 세그먼트 (6)\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in premium_sport:\n",
    "            return 8\n",
    "        elif model_name in premium_sedan:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        features['segment'] = features['모델'].apply(self.get_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(features[col].unique())\n",
    "                if '가격(백만원)' not in features.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "\n",
    "        # 기본 특성\n",
    "        feature_cols = [\n",
    "            'segment',\n",
    "            '제조사_encoded',\n",
    "            '모델_encoded',\n",
    "            '구동방식_encoded',\n",
    "            '차량상태_encoded',\n",
    "            '배터리용량',\n",
    "            '주행거리(km)',\n",
    "            '보증기간(년)',\n",
    "            '연식(년)'\n",
    "        ]\n",
    "        \n",
    "        # 세그먼트별 특화 특성\n",
    "        for segment in [1, 6, 8]:\n",
    "            segment_mask = features['segment'] == segment\n",
    "            if sum(segment_mask) > 0:\n",
    "                # 배터리 효율성\n",
    "                features.loc[:, 'battery_efficiency'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "                # 연식-주행거리 상호작용\n",
    "                features.loc[:, 'age_distance_ratio'] = features['연식(년)'] / np.log1p(features['주행거리(km)'])\n",
    "                # 배터리-보증 상호작용\n",
    "                features.loc[:, 'battery_warranty'] = features['배터리용량'] * features['보증기간(년)']\n",
    "                # 주행거리 구간화\n",
    "                features.loc[:, 'distance_group'] = pd.qcut(features['주행거리(km)'], q=5, labels=False, duplicates='drop')\n",
    "                \n",
    "                # Premium Sport (TayCT) 특화 특성\n",
    "                if segment == 8:\n",
    "                    features.loc[:, 'performance_score'] = (\n",
    "                        features['배터리용량'] * 0.4 +\n",
    "                        (100000 - features['주행거리(km)'])/100000 * 0.3 +\n",
    "                        (10 - features['연식(년)'])/10 * 0.3\n",
    "                    )\n",
    "                \n",
    "                # Premium Sedan (Tay) 특화 특성\n",
    "                if segment == 6:\n",
    "                    features.loc[:, 'luxury_score'] = (\n",
    "                        features['배터리용량'] * 0.3 +\n",
    "                        (150000 - features['주행거리(km)'])/150000 * 0.4 +\n",
    "                        (10 - features['연식(년)'])/10 * 0.3\n",
    "                    )\n",
    "                \n",
    "                feature_cols.extend([\n",
    "                    'battery_efficiency',\n",
    "                    'age_distance_ratio',\n",
    "                    'battery_warranty',\n",
    "                    'distance_group'\n",
    "                ])\n",
    "                \n",
    "                if segment == 8:\n",
    "                    feature_cols.append('performance_score')\n",
    "                if segment == 6:\n",
    "                    feature_cols.append('luxury_score')\n",
    "\n",
    "        return features[feature_cols]\n",
    "\n",
    "    def train_models(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            if segment in [1, 6, 8]:  # 앙상블 적용 세그먼트\n",
    "                # HGBR 모델\n",
    "                hgb = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    **self.hgb_params[segment]\n",
    "                )\n",
    "                \n",
    "                # Random Forest 모델\n",
    "                rf = RandomForestRegressor(\n",
    "                    **self.rf_params[segment]\n",
    "                )\n",
    "                \n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                \n",
    "                hgb.fit(segment_X, segment_y)\n",
    "                rf.fit(segment_X, segment_y)\n",
    "                \n",
    "                return {'hgb': hgb, 'rf': rf}\n",
    "            else:  # 기본 HGBR 모델\n",
    "                model = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    max_iter=1200,\n",
    "                    learning_rate=0.012,\n",
    "                    max_depth=7,\n",
    "                    l2_regularization=1.2\n",
    "                )\n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                model.fit(segment_X, segment_y)\n",
    "                return model\n",
    "        return None\n",
    "\n",
    "    def predict_segment(self, X, models, segment):\n",
    "        \"\"\"세그먼트별 예측\"\"\"\n",
    "        if segment in [1, 6, 8]:  # 앙상블 적용 세그먼트\n",
    "            hgb_pred = models['hgb'].predict(X)\n",
    "            rf_pred = models['rf'].predict(X)\n",
    "            weights = self.ensemble_weights[segment]\n",
    "            return weights['hgb'] * hgb_pred + weights['rf'] * rf_pred\n",
    "        else:\n",
    "            return models.predict(X)\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 9)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 9):\n",
    "                models = self.train_models(X_train, y_train, segment)\n",
    "                if models is not None:\n",
    "                    mask = X_val['segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        segment_pred = self.predict_segment(X_val[mask], models, segment)\n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 9):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 9):\n",
    "            self.segment_models[segment] = self.train_models(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, models in self.segment_models.items():\n",
    "            mask = X['segment'] == segment\n",
    "            if sum(mask) > 0 and models is not None:\n",
    "                predictions[mask] = self.predict_segment(X[mask], models, segment)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = RefinedEnsemblePredictor()\n",
    "    predictor.fit(train_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('refined_ensemble_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4595, R2: 0.9984\n",
      "Fold 2 - RMSE: 1.5222, R2: 0.9983\n",
      "Fold 3 - RMSE: 1.3589, R2: 0.9986\n",
      "Fold 4 - RMSE: 1.2858, R2: 0.9988\n",
      "Fold 5 - RMSE: 1.3610, R2: 0.9985\n",
      "\n",
      "평균 RMSE: 1.3975 (+/- 0.1666)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1 RMSE: 1.7380\n",
      "세그먼트 2 RMSE: 0.5327\n",
      "세그먼트 3 RMSE: 0.4195\n",
      "세그먼트 4 RMSE: 0.7056\n",
      "세그먼트 5 RMSE: 0.6349\n",
      "세그먼트 6 RMSE: 2.9198\n",
      "세그먼트 7 RMSE: 0.3441\n",
      "세그먼트 8 RMSE: 3.7514\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class RefinedEnsemblePredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.rf_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # Random Forest 파라미터\n",
    "        self.rf_params = {\n",
    "            8: {  # TayCT\n",
    "                'n_estimators': 300,\n",
    "                'max_depth': 8,\n",
    "                'min_samples_split': 5,\n",
    "                'min_samples_leaf': 4,\n",
    "                'random_state': 42\n",
    "            },\n",
    "            6: {  # Premium Sedan (Tay)\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 12,\n",
    "                'min_samples_split': 10,\n",
    "                'min_samples_leaf': 4,\n",
    "                'random_state': 42\n",
    "            },\n",
    "            1: {  # 엔트리\n",
    "                'n_estimators': 150,\n",
    "                'max_depth': 10,\n",
    "                'min_samples_split': 8,\n",
    "                'min_samples_leaf': 3,\n",
    "                'random_state': 42\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # HGBR 파라미터\n",
    "        self.hgb_params = {\n",
    "            8: {  # TayCT\n",
    "                'max_iter': 2500,\n",
    "                'learning_rate': 0.008,\n",
    "                'max_depth': 6,\n",
    "                'l2_regularization': 2.0\n",
    "            },\n",
    "            6: {  # Tay\n",
    "                'max_iter': 2000,\n",
    "                'learning_rate': 0.015,\n",
    "                'max_depth': 8,\n",
    "                'l2_regularization': 1.5\n",
    "            },\n",
    "            1: {  # 엔트리\n",
    "                'max_iter': 2000,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 7,\n",
    "                'l2_regularization': 1.5\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 앙상블 가중치\n",
    "        self.ensemble_weights = {\n",
    "            8: {'hgb': 0.2, 'rf': 0.8},  # TayCT - RF 가중치 증가\n",
    "            6: {'hgb': 0.3, 'rf': 0.7},  # Tay\n",
    "            1: {'hgb': 0.4, 'rf': 0.6}   # 엔트리\n",
    "        }\n",
    "\n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        premium_sport = ['TayCT']\n",
    "        premium_sedan = ['Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in premium_sport:\n",
    "            return 8\n",
    "        elif model_name in premium_sedan:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        features['segment'] = features['모델'].apply(self.get_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(features[col].unique())\n",
    "                if '가격(백만원)' not in features.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "\n",
    "        # 기본 특성\n",
    "        feature_cols = [\n",
    "            'segment',\n",
    "            '제조사_encoded',\n",
    "            '모델_encoded',\n",
    "            '구동방식_encoded',\n",
    "            '차량상태_encoded',\n",
    "            '배터리용량',\n",
    "            '주행거리(km)',\n",
    "            '보증기간(년)',\n",
    "            '연식(년)'\n",
    "        ]\n",
    "        \n",
    "        # 세그먼트별 특화 특성\n",
    "        for segment in [1, 6, 8]:\n",
    "            segment_mask = features['segment'] == segment\n",
    "            if sum(segment_mask) > 0:\n",
    "                # 배터리 효율성\n",
    "                features.loc[:, 'battery_efficiency'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "                # 연식-주행거리 상호작용\n",
    "                features.loc[:, 'age_distance_ratio'] = features['연식(년)'] / np.log1p(features['주행거리(km)'])\n",
    "                # 배터리-보증 상호작용\n",
    "                features.loc[:, 'battery_warranty'] = features['배터리용량'] * features['보증기간(년)']\n",
    "                \n",
    "                feature_cols.extend([\n",
    "                    'battery_efficiency',\n",
    "                    'age_distance_ratio',\n",
    "                    'battery_warranty'\n",
    "                ])\n",
    "                \n",
    "                # TayCT 특화 특성\n",
    "                if segment == 8:\n",
    "                    # 차량상태별 기본가격 설정\n",
    "                    base_price = {\n",
    "                        'Brand New': 120,\n",
    "                        'Nearly New': 100,\n",
    "                        'Pre-Owned': 85\n",
    "                    }\n",
    "                    features.loc[segment_mask, 'base_price'] = features.loc[segment_mask, '차량상태'].map(base_price)\n",
    "                    \n",
    "                    # 주행거리 감가율 (더 급격한 감소)\n",
    "                    features.loc[segment_mask, 'mileage_factor'] = np.exp(-features.loc[segment_mask, '주행거리(km)'] / 50000)\n",
    "                    \n",
    "                    # 연식 감가율\n",
    "                    features.loc[segment_mask, 'age_factor'] = np.exp(-0.2 * features.loc[segment_mask, '연식(년)'])\n",
    "                    \n",
    "                    # 최종 성능 점수\n",
    "                    features.loc[segment_mask, 'performance_score'] = (\n",
    "                        features.loc[segment_mask, 'base_price'] * \n",
    "                        features.loc[segment_mask, 'mileage_factor'] * \n",
    "                        features.loc[segment_mask, 'age_factor']\n",
    "                    )\n",
    "                    \n",
    "                    feature_cols.extend(['base_price', 'mileage_factor', 'age_factor', 'performance_score'])\n",
    "                \n",
    "                # Tay 특화 특성\n",
    "                if segment == 6:\n",
    "                    features.loc[:, 'luxury_score'] = (\n",
    "                        features['배터리용량'] * 0.3 +\n",
    "                        (150000 - features['주행거리(km)'])/150000 * 0.4 +\n",
    "                        (10 - features['연식(년)'])/10 * 0.3\n",
    "                    )\n",
    "                    feature_cols.append('luxury_score')\n",
    "\n",
    "        return features[feature_cols]\n",
    "\n",
    "    def train_models(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            if segment in [1, 6, 8]:  # 앙상블 적용 세그먼트\n",
    "                # HGBR 모델\n",
    "                hgb = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    **self.hgb_params[segment]\n",
    "                )\n",
    "                \n",
    "                # Random Forest 모델\n",
    "                rf = RandomForestRegressor(\n",
    "                    **self.rf_params[segment]\n",
    "                )\n",
    "                \n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                \n",
    "                hgb.fit(segment_X, segment_y)\n",
    "                rf.fit(segment_X, segment_y)\n",
    "                \n",
    "                return {'hgb': hgb, 'rf': rf}\n",
    "            else:  # 기본 HGBR 모델\n",
    "                model = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    max_iter=1200,\n",
    "                    learning_rate=0.012,\n",
    "                    max_depth=7,\n",
    "                    l2_regularization=1.2\n",
    "                )\n",
    "                segment_X = X[mask]\n",
    "                segment_y = y[mask]\n",
    "                model.fit(segment_X, segment_y)\n",
    "                return model\n",
    "        return None\n",
    "\n",
    "    def predict_segment(self, X, models, segment):\n",
    "        \"\"\"세그먼트별 예측\"\"\"\n",
    "        if segment in [1, 6, 8]:  # 앙상블 적용 세그먼트\n",
    "            hgb_pred = models['hgb'].predict(X)\n",
    "            rf_pred = models['rf'].predict(X)\n",
    "            weights = self.ensemble_weights[segment]\n",
    "            return weights['hgb'] * hgb_pred + weights['rf'] * rf_pred\n",
    "        else:\n",
    "            return models.predict(X)\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 9)}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for segment in range(1, 9):\n",
    "                models = self.train_models(X_train, y_train, segment)\n",
    "                if models is not None:\n",
    "                    mask = X_val['segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        segment_pred = self.predict_segment(X_val[mask], models, segment)\n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 9):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment} RMSE: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 9):\n",
    "            self.segment_models[segment] = self.train_models(X, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for segment, models in self.segment_models.items():\n",
    "            mask = X['segment'] == segment\n",
    "            if sum(mask) > 0 and models is not None:\n",
    "                predictions[mask] = self.predict_segment(X[mask], models, segment)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = RefinedEnsemblePredictor()\n",
    "    predictor.fit(train_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('refined_ensemble_submission_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 2.2406, R2: 0.9963\n",
      "Fold 2 - RMSE: 3.4030, R2: 0.9916\n",
      "Fold 3 - RMSE: 1.8504, R2: 0.9975\n",
      "Fold 4 - RMSE: 2.1617, R2: 0.9965\n",
      "Fold 5 - RMSE: 2.2554, R2: 0.9959\n",
      "\n",
      "평균 RMSE: 2.3822 (+/- 1.0620)\n",
      "\n",
      "=== 차량상태별 RMSE ===\n",
      "Nearly New: 2.1350\n",
      "Brand New: 2.8347\n",
      "Pre-Owned: 1.5042\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class PriceBasedPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.condition_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 차량상태별 모델 파라미터\n",
    "        self.model_params = {\n",
    "            'Brand New': {\n",
    "                'rf': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 4,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb': {\n",
    "                    'max_iter': 2500,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            'Nearly New': {\n",
    "                'rf': {\n",
    "                    'n_estimators': 250,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 6,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 1.8,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            'Pre-Owned': {\n",
    "                'rf': {\n",
    "                    'n_estimators': 200,\n",
    "                    'max_depth': 6,\n",
    "                    'min_samples_split': 8,\n",
    "                    'min_samples_leaf': 5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb': {\n",
    "                    'max_iter': 1800,\n",
    "                    'learning_rate': 0.012,\n",
    "                    'max_depth': 4,\n",
    "                    'l2_regularization': 1.5,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 앙상블 가중치\n",
    "        self.ensemble_weights = {\n",
    "            'Brand New': {'hgb': 0.3, 'rf': 0.7},\n",
    "            'Nearly New': {'hgb': 0.4, 'rf': 0.6},\n",
    "            'Pre-Owned': {'hgb': 0.5, 'rf': 0.5}\n",
    "        }\n",
    "\n",
    "    def handle_outliers(self, df):\n",
    "        \"\"\"이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        df['price_weight'] = 1.0\n",
    "        \n",
    "        # TayCT 모델 특별 처리\n",
    "        tayct_mask = df['모델'] == 'TayCT'\n",
    "        if sum(tayct_mask) > 0:\n",
    "            # 주행거리 기반 이상치 처리\n",
    "            distance_data = df.loc[tayct_mask, '주행거리(km)']\n",
    "            q1 = distance_data.quantile(0.25)\n",
    "            q3 = distance_data.quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            \n",
    "            distance_outlier_mask = (distance_data < lower_bound) | (distance_data > upper_bound)\n",
    "            df.loc[tayct_mask & distance_outlier_mask, 'price_weight'] *= 0.8\n",
    "            \n",
    "            # 연식 기반 이상치 처리\n",
    "            age_data = df.loc[tayct_mask, '연식(년)']\n",
    "            age_q3 = age_data.quantile(0.75)\n",
    "            df.loc[tayct_mask & (age_data > age_q3), 'price_weight'] *= 0.9\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def get_price_segment(self, price):\n",
    "        \"\"\"가격대 기반 세그먼트 분류\"\"\"\n",
    "        if price >= 90:\n",
    "            return 'high'\n",
    "        elif price >= 60:\n",
    "            return 'mid'\n",
    "        else:\n",
    "            return 'low'\n",
    "\n",
    "    def create_nonlinear_features(self, df):\n",
    "        \"\"\"비선형 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 거리 기반 비선형 특성\n",
    "        features['distance_exp'] = np.exp(-features['주행거리(km)'] / 50000)\n",
    "        features['distance_log'] = np.log1p(features['주행거리(km)'])\n",
    "        features['distance_sqrt'] = np.sqrt(features['주행거리(km)'])\n",
    "        \n",
    "        # 연식 기반 비선형 특성\n",
    "        features['age_exp'] = np.exp(-features['연식(년)'] / 2)\n",
    "        features['age_squared'] = features['연식(년)'] ** 2\n",
    "        \n",
    "        # 배터리 효율성 특성\n",
    "        features['battery_efficiency'] = features['배터리용량'] / features['distance_log']\n",
    "        \n",
    "        # 복합 특성\n",
    "        features['age_distance_interaction'] = features['age_exp'] * features['distance_exp']\n",
    "        features['battery_age_interaction'] = features['배터리용량'] * features['age_exp']\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 이상치 처리\n",
    "        features = self.handle_outliers(features)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(features[col].unique())\n",
    "                if '가격(백만원)' not in features.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "\n",
    "        # 비선형 특성 생성\n",
    "        features = self.create_nonlinear_features(features)\n",
    "        \n",
    "        # 최종 특성 선택\n",
    "        feature_cols = [\n",
    "            '제조사_encoded', '모델_encoded', '구동방식_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)',\n",
    "            'distance_exp', 'distance_log', 'distance_sqrt',\n",
    "            'age_exp', 'age_squared',\n",
    "            'battery_efficiency',\n",
    "            'age_distance_interaction', 'battery_age_interaction',\n",
    "            'price_weight'\n",
    "        ]\n",
    "        \n",
    "        return features[feature_cols]\n",
    "\n",
    "    def train_condition_model(self, X, y, condition):\n",
    "        \"\"\"차량상태별 모델 학습\"\"\"\n",
    "        # Random Forest 모델\n",
    "        rf = RandomForestRegressor(**self.model_params[condition]['rf'])\n",
    "        \n",
    "        # HGBR 모델\n",
    "        hgb = HistGradientBoostingRegressor(**self.model_params[condition]['hgb'])\n",
    "        \n",
    "        # 가중치 적용\n",
    "        weights = X['price_weight'] if 'price_weight' in X.columns else None\n",
    "        \n",
    "        # 모델 학습\n",
    "        rf.fit(X, y, sample_weight=weights)\n",
    "        hgb.fit(X, y, sample_weight=weights)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb}\n",
    "\n",
    "    def predict_condition(self, X, models, condition):\n",
    "        \"\"\"차량상태별 예측\"\"\"\n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        \n",
    "        weights = self.ensemble_weights[condition]\n",
    "        return weights['rf'] * rf_pred + weights['hgb'] * hgb_pred\n",
    "\n",
    "    def cv_evaluate(self, X, y, conditions):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        condition_scores = {condition: [] for condition in conditions}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            conditions_train = conditions.iloc[train_idx]\n",
    "            conditions_val = conditions.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "            \n",
    "            for condition in self.model_params.keys():\n",
    "                condition_mask_train = conditions_train == condition\n",
    "                condition_mask_val = conditions_val == condition\n",
    "                \n",
    "                if sum(condition_mask_train) > 0 and sum(condition_mask_val) > 0:\n",
    "                    models = self.train_condition_model(\n",
    "                        X_train[condition_mask_train],\n",
    "                        y_train[condition_mask_train],\n",
    "                        condition\n",
    "                    )\n",
    "                    \n",
    "                    predictions = self.predict_condition(\n",
    "                        X_val[condition_mask_val],\n",
    "                        models,\n",
    "                        condition\n",
    "                    )\n",
    "                    \n",
    "                    fold_predictions[condition_mask_val] = predictions\n",
    "                    \n",
    "                    condition_rmse = np.sqrt(mean_squared_error(\n",
    "                        y_val[condition_mask_val],\n",
    "                        predictions\n",
    "                    ))\n",
    "                    condition_scores[condition].append(condition_rmse)\n",
    "            \n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 차량상태별 RMSE ===\")\n",
    "        for condition in condition_scores:\n",
    "            if condition_scores[condition]:\n",
    "                mean_score = np.mean(condition_scores[condition])\n",
    "                print(f\"{condition}: {mean_score:.4f}\")\n",
    "        \n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        conditions = train_df['차량상태']\n",
    "        \n",
    "        cv_scores = self.cv_evaluate(X, y, conditions)\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        for condition in self.model_params.keys():\n",
    "            condition_mask = conditions == condition\n",
    "            if sum(condition_mask) > 0:\n",
    "                self.condition_models[condition] = self.train_condition_model(\n",
    "                    X[condition_mask],\n",
    "                    y[condition_mask],\n",
    "                    condition\n",
    "                )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "        \n",
    "        for condition, models in self.condition_models.items():\n",
    "            condition_mask = test_df['차량상태'] == condition\n",
    "            if sum(condition_mask) > 0:\n",
    "                predictions[condition_mask] = self.predict_condition(\n",
    "                    X[condition_mask],\n",
    "                    models,\n",
    "                    condition\n",
    "                )\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = PriceBasedPredictor()\n",
    "    predictor.fit(train_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('price_based_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'A사'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'A사'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 361\u001b[0m\n\u001b[0;32m    358\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    360\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ModelSpecificPredictor()\n\u001b[1;32m--> 361\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    363\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(test_data)\n\u001b[0;32m    364\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m    367\u001b[0m })\n",
      "Cell \u001b[1;32mIn[75], line 324\u001b[0m, in \u001b[0;36mModelSpecificPredictor.fit\u001b[1;34m(self, train_df)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"전체 모델 학습\"\"\"\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;66;03m# 교차 검증 수행\u001b[39;00m\n\u001b[1;32m--> 324\u001b[0m cv_scores, model_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# 각 모델별 최종 모델 학습\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique():\n",
      "Cell \u001b[1;32mIn[75], line 288\u001b[0m, in \u001b[0;36mModelSpecificPredictor.cv_evaluate\u001b[1;34m(self, train_df)\u001b[0m\n\u001b[0;32m    285\u001b[0m model_mask_val \u001b[38;5;241m=\u001b[39m val_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m model_name\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(model_mask_train) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28msum\u001b[39m(model_mask_val) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 288\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_mask_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m train_data[model_mask_train][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    291\u001b[0m     X_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_features(val_data[model_mask_val], model_name)\n",
      "Cell \u001b[1;32mIn[75], line 213\u001b[0m, in \u001b[0;36mModelSpecificPredictor.prepare_features\u001b[1;34m(self, df, model_name)\u001b[0m\n\u001b[0;32m    211\u001b[0m             unique_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_encoders[col]\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(unique_values))))\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_encoders[col]\u001b[38;5;241m.\u001b[39mfit(unique_values)\n\u001b[1;32m--> 213\u001b[0m     features[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_encoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;66;03m# 모델별 특화 특성 생성\u001b[39;00m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'A사'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ModelSpecificPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.model_specific_predictors = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 모델별 하이퍼파라미터\n",
    "        self.model_params = {\n",
    "            'RSeTGT': {\n",
    "                'rf': {\n",
    "                    'n_estimators': 200,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb': {\n",
    "                    'max_iter': 1500,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 1.5,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            'Soul': {\n",
    "                'rf': {\n",
    "                    'n_estimators': 150,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 6,\n",
    "                    'min_samples_leaf': 4,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb': {\n",
    "                    'max_iter': 1200,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'rf': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 4,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 기본 하이퍼파라미터\n",
    "        self.default_params = {\n",
    "            'rf': {\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 7,\n",
    "                'min_samples_split': 6,\n",
    "                'min_samples_leaf': 3,\n",
    "                'random_state': 42\n",
    "            },\n",
    "            'hgb': {\n",
    "                'max_iter': 1500,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 6,\n",
    "                'l2_regularization': 1.5,\n",
    "                'random_state': 42\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 앙상블 가중치\n",
    "        self.ensemble_weights = {\n",
    "            'RSeTGT': {'hgb': 0.4, 'rf': 0.6},\n",
    "            'Soul': {'hgb': 0.3, 'rf': 0.7},\n",
    "            'TayCT': {'hgb': 0.2, 'rf': 0.8},\n",
    "            'default': {'hgb': 0.4, 'rf': 0.6}\n",
    "        }\n",
    "\n",
    "    def handle_outliers_by_model(self, df, model_name):\n",
    "        \"\"\"모델별 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        df['price_weight'] = 1.0\n",
    "        df['warranty_factor'] = 1.0\n",
    "        \n",
    "        if model_name == 'RSeTGT':\n",
    "            # Pre-Owned 차량의 가격 조정\n",
    "            mask = (df['차량상태'] == 'Pre-Owned') & (df['가격(백만원)'] < 95)\n",
    "            df.loc[mask, 'price_weight'] = 0.9\n",
    "            \n",
    "            # 결측된 배터리용량 처리\n",
    "            df['배터리용량'] = df['배터리용량'].fillna(78.23)\n",
    "            \n",
    "            # 주행거리 기반 가중치\n",
    "            df['distance_factor'] = np.exp(-df['주행거리(km)'] / 150000)\n",
    "            df['price_weight'] *= df['distance_factor']\n",
    "            \n",
    "        elif model_name == 'Soul':\n",
    "            # Brand New + 높은 보증기간 차량 처리\n",
    "            mask = (df['차량상태'] == 'Brand New') & (df['보증기간(년)'] >= 9)\n",
    "            df.loc[mask, 'price_weight'] = 1.1\n",
    "            \n",
    "            # 보증기간 영향력 반영\n",
    "            df['warranty_factor'] = np.exp(-0.1 * df['보증기간(년)'])\n",
    "            \n",
    "            # 주행거리 영향 감소\n",
    "            df['distance_factor'] = np.exp(-df['주행거리(km)'] / 200000)\n",
    "            df['price_weight'] *= df['distance_factor']\n",
    "            \n",
    "        elif model_name == 'TayCT':\n",
    "            # 차량상태별 기본가격 조정\n",
    "            condition_factor = {\n",
    "                'Brand New': 1.1,\n",
    "                'Nearly New': 1.0,\n",
    "                'Pre-Owned': 0.85\n",
    "            }\n",
    "            df['condition_factor'] = df['차량상태'].map(condition_factor)\n",
    "            df['price_weight'] *= df['condition_factor']\n",
    "            \n",
    "            # 주행거리 기반 가중치 (더 급격한 감소)\n",
    "            df['distance_factor'] = np.exp(-df['주행거리(km)'] / 50000)\n",
    "            df['price_weight'] *= df['distance_factor']\n",
    "            \n",
    "            # 연식 기반 가중치\n",
    "            df['age_factor'] = np.exp(-0.2 * df['연식(년)'])\n",
    "            df['price_weight'] *= df['age_factor']\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_model_features(self, df, model_name):\n",
    "        \"\"\"모델별 특화 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 기본 특성\n",
    "        features['distance_norm'] = features['주행거리(km)'] / 100000\n",
    "        features['battery_efficiency'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "        \n",
    "        if model_name == 'RSeTGT':\n",
    "            # 주행거리 구간화\n",
    "            features['distance_group'] = pd.qcut(\n",
    "                features['주행거리(km)'],\n",
    "                q=5,\n",
    "                labels=['very_low', 'low', 'medium', 'high', 'very_high'],\n",
    "                duplicates='drop'\n",
    "            )\n",
    "            \n",
    "            # 배터리 효율성 점수\n",
    "            features['battery_score'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            \n",
    "        elif model_name == 'Soul':\n",
    "            # 보증기간-연식 상호작용\n",
    "            features['warranty_age_ratio'] = features['보증기간(년)'] / np.maximum(features['연식(년)'], 1)\n",
    "            \n",
    "            # 배터리 상태 점수\n",
    "            features['battery_score'] = np.clip(\n",
    "                features['배터리용량'] / features['배터리용량'].mean(),\n",
    "                0.8,\n",
    "                1.2\n",
    "            )\n",
    "            \n",
    "        elif model_name == 'TayCT':\n",
    "            # 성능 점수\n",
    "            features['performance_score'] = (\n",
    "                features['배터리용량'] * 0.4 +\n",
    "                (100000 - features['주행거리(km)'])/100000 * 0.3 +\n",
    "                (10 - features['연식(년)'])/10 * 0.3\n",
    "            )\n",
    "            \n",
    "            # 주행거리 구간별 감가율\n",
    "            features['distance_depreciation'] = np.where(\n",
    "                features['주행거리(km)'] <= 50000,\n",
    "                0.95,\n",
    "                np.where(\n",
    "                    features['주행거리(km)'] <= 100000,\n",
    "                    0.85,\n",
    "                    0.75\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def prepare_features(self, df, model_name=None):\n",
    "        \"\"\"특성 준비\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 이상치 처리\n",
    "        if model_name is not None:\n",
    "            features = self.handle_outliers_by_model(features, model_name)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(features[col].unique())\n",
    "                if '가격(백만원)' not in features.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "        \n",
    "        # 모델별 특화 특성 생성\n",
    "        if model_name is not None:\n",
    "            features = self.create_model_features(features, model_name)\n",
    "        \n",
    "        # 기본 특성 선택\n",
    "        feature_cols = [\n",
    "            '제조사_encoded', '모델_encoded', '구동방식_encoded', '차량상태_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)',\n",
    "            'price_weight'\n",
    "        ]\n",
    "        \n",
    "        # 모델별 추가 특성\n",
    "        if model_name == 'RSeTGT':\n",
    "            feature_cols.extend(['battery_score', 'distance_norm'])\n",
    "        elif model_name == 'Soul':\n",
    "            feature_cols.extend(['warranty_age_ratio', 'battery_score', 'warranty_factor'])\n",
    "        elif model_name == 'TayCT':\n",
    "            feature_cols.extend(['performance_score', 'distance_depreciation'])\n",
    "        \n",
    "        return features[feature_cols]\n",
    "\n",
    "    def train_model(self, X, y, model_name=None):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        if model_name in self.model_params:\n",
    "            params = self.model_params[model_name]\n",
    "        else:\n",
    "            params = self.default_params\n",
    "        \n",
    "        # Random Forest 모델\n",
    "        rf = RandomForestRegressor(**params['rf'])\n",
    "        \n",
    "        # HGBR 모델\n",
    "        hgb = HistGradientBoostingRegressor(**params['hgb'])\n",
    "        \n",
    "        # 가중치 적용\n",
    "        weights = X['price_weight'] if 'price_weight' in X.columns else None\n",
    "        \n",
    "        # 모델 학습\n",
    "        rf.fit(X, y, sample_weight=weights)\n",
    "        hgb.fit(X, y, sample_weight=weights)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb}\n",
    "\n",
    "    def predict_model(self, X, models, model_name=None):\n",
    "        \"\"\"모델 예측\"\"\"\n",
    "        if model_name in self.ensemble_weights:\n",
    "            weights = self.ensemble_weights[model_name]\n",
    "        else:\n",
    "            weights = self.ensemble_weights['default']\n",
    "        \n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        \n",
    "        return weights['rf'] * rf_pred + weights['hgb'] * hgb_pred\n",
    "\n",
    "    def cv_evaluate(self, train_df):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        model_scores = {}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(train_df), 1):\n",
    "            train_data = train_df.iloc[train_idx]\n",
    "            val_data = train_df.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros(len(val_data))\n",
    "            \n",
    "            for model_name in train_data['모델'].unique():\n",
    "                # 모델별 데이터 준비\n",
    "                model_mask_train = train_data['모델'] == model_name\n",
    "                model_mask_val = val_data['모델'] == model_name\n",
    "                \n",
    "                if sum(model_mask_train) > 0 and sum(model_mask_val) > 0:\n",
    "                    X_train = self.prepare_features(train_data[model_mask_train], model_name)\n",
    "                    y_train = train_data[model_mask_train]['가격(백만원)']\n",
    "                    \n",
    "                    X_val = self.prepare_features(val_data[model_mask_val], model_name)\n",
    "                    y_val = val_data[model_mask_val]['가격(백만원)']\n",
    "                    \n",
    "                    # 모델 학습 및 예측\n",
    "                    models = self.train_model(X_train, y_train, model_name)\n",
    "                    predictions = self.predict_model(X_val, models, model_name)\n",
    "                    \n",
    "                    # 예측값 저장\n",
    "                    fold_predictions[model_mask_val] = predictions\n",
    "                    \n",
    "                    # 모델별 성능 기록\n",
    "                    model_rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                    if model_name not in model_scores:\n",
    "                        model_scores[model_name] = []\n",
    "                    model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 전체 폴드 성능 계산\n",
    "            fold_rmse = np.sqrt(mean_squared_error(val_data['가격(백만원)'], fold_predictions))\n",
    "            fold_r2 = r2_score(val_data['가격(백만원)'], fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 모델별 RMSE ===\")\n",
    "        for model_name, scores in model_scores.items():\n",
    "            print(f\"{model_name}: {np.mean(scores):.4f}\")\n",
    "        \n",
    "        return cv_scores, model_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"전체 모델 학습\"\"\"\n",
    "        # 교차 검증 수행\n",
    "        cv_scores, model_scores = self.cv_evaluate(train_df)\n",
    "        \n",
    "        # 각 모델별 최종 모델 학습\n",
    "        for model_name in train_df['모델'].unique():\n",
    "            model_data = train_df[train_df['모델'] == model_name]\n",
    "            \n",
    "            if len(model_data) > 0:\n",
    "                X = self.prepare_features(model_data, model_name)\n",
    "                y = model_data['가격(백만원)']\n",
    "                \n",
    "                self.model_specific_predictors[model_name] = self.train_model(X, y, model_name)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        for model_name in test_df['모델'].unique():\n",
    "            model_mask = test_df['모델'] == model_name\n",
    "            \n",
    "            if sum(model_mask) > 0 and model_name in self.model_specific_predictors:\n",
    "                X = self.prepare_features(test_df[model_mask], model_name)\n",
    "                predictions[model_mask] = self.predict_model(\n",
    "                    X,\n",
    "                    self.model_specific_predictors[model_name],\n",
    "                    model_name\n",
    "                )\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = ModelSpecificPredictor()\n",
    "    predictor.fit(train_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('model_specific_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4127, R2: 0.9985\n",
      "Fold 2 - RMSE: 1.5839, R2: 0.9982\n",
      "Fold 3 - RMSE: 1.4019, R2: 0.9986\n",
      "Fold 4 - RMSE: 1.2946, R2: 0.9988\n",
      "Fold 5 - RMSE: 1.3128, R2: 0.9986\n",
      "\n",
      "평균 RMSE: 1.4012 (+/- 0.2054)\n",
      "\n",
      "=== 모델별 RMSE ===\n",
      "Niro: 0.6083\n",
      "eT: 0.4876\n",
      "RSeTGT: 0.3493\n",
      "i5: 0.6109\n",
      "ION6: 0.3357\n",
      "MS: 0.9163\n",
      "Q4eT: 0.3914\n",
      "ID4: 0.6357\n",
      "TayCT: 3.6276\n",
      "MY: 1.0337\n",
      "iX: 0.5911\n",
      "MX: 1.0071\n",
      "Soul: 0.6103\n",
      "IONIQ: 5.8709\n",
      "EV6: 0.5989\n",
      "KNE: 0.6476\n",
      "M3: 0.4506\n",
      "TayGTS: 0.3390\n",
      "i3: 0.3410\n",
      "ION5: 0.3408\n",
      "Tay: 2.8359\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ModelSpecificPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.model_specific_predictors = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 모델별 하이퍼파라미터\n",
    "        self.model_params = {\n",
    "            'RSeTGT': {\n",
    "                'rf': {\n",
    "                    'n_estimators': 200,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb': {\n",
    "                    'max_iter': 1500,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 1.5,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            'Soul': {\n",
    "                'rf': {\n",
    "                    'n_estimators': 150,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 6,\n",
    "                    'min_samples_leaf': 4,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb': {\n",
    "                    'max_iter': 1200,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'rf': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 4,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 기본 하이퍼파라미터\n",
    "        self.default_params = {\n",
    "            'rf': {\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 7,\n",
    "                'min_samples_split': 6,\n",
    "                'min_samples_leaf': 3,\n",
    "                'random_state': 42\n",
    "            },\n",
    "            'hgb': {\n",
    "                'max_iter': 1500,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 6,\n",
    "                'l2_regularization': 1.5,\n",
    "                'random_state': 42\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 앙상블 가중치\n",
    "        self.ensemble_weights = {\n",
    "            'RSeTGT': {'hgb': 0.4, 'rf': 0.6},\n",
    "            'Soul': {'hgb': 0.3, 'rf': 0.7},\n",
    "            'TayCT': {'hgb': 0.2, 'rf': 0.8},\n",
    "            'default': {'hgb': 0.4, 'rf': 0.6}\n",
    "        }\n",
    "\n",
    "    def initialize_label_encoders(self, train_df, test_df=None):\n",
    "        \"\"\"레이블 인코더 초기화\"\"\"\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            self.label_encoders[col] = LabelEncoder()\n",
    "            \n",
    "            # 학습 데이터의 unique 값\n",
    "            unique_values = set(train_df[col].unique())\n",
    "            \n",
    "            # 테스트 데이터가 있으면 해당 값들도 포함\n",
    "            if test_df is not None:\n",
    "                unique_values.update(test_df[col].unique())\n",
    "            \n",
    "            # 정렬된 리스트로 변환하여 fit\n",
    "            self.label_encoders[col].fit(sorted(list(unique_values)))\n",
    "\n",
    "    def handle_outliers_by_model(self, df, model_name):\n",
    "        \"\"\"모델별 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        df['price_weight'] = 1.0\n",
    "        df['warranty_factor'] = 1.0\n",
    "        \n",
    "        if model_name == 'RSeTGT':\n",
    "            # Pre-Owned 차량의 가격 조정\n",
    "            mask = (df['차량상태'] == 'Pre-Owned')\n",
    "            df.loc[mask, 'price_weight'] = 0.9\n",
    "            \n",
    "            # 결측된 배터리용량 처리\n",
    "            df['배터리용량'] = df['배터리용량'].fillna(78.23)\n",
    "            \n",
    "            # 주행거리 기반 가중치\n",
    "            df['distance_factor'] = np.exp(-df['주행거리(km)'] / 150000)\n",
    "            df['price_weight'] *= df['distance_factor']\n",
    "            \n",
    "        elif model_name == 'Soul':\n",
    "            # Brand New + 높은 보증기간 차량 처리\n",
    "            mask = (df['차량상태'] == 'Brand New') & (df['보증기간(년)'] >= 9)\n",
    "            df.loc[mask, 'price_weight'] = 1.1\n",
    "            \n",
    "            # 보증기간 영향력 반영\n",
    "            df['warranty_factor'] = np.exp(-0.1 * df['보증기간(년)'])\n",
    "            \n",
    "            # 주행거리 영향 감소\n",
    "            df['distance_factor'] = np.exp(-df['주행거리(km)'] / 200000)\n",
    "            df['price_weight'] *= df['distance_factor']\n",
    "            \n",
    "        elif model_name == 'TayCT':\n",
    "            # 차량상태별 기본가격 조정\n",
    "            condition_factor = {\n",
    "                'Brand New': 1.1,\n",
    "                'Nearly New': 1.0,\n",
    "                'Pre-Owned': 0.85\n",
    "            }\n",
    "            df['condition_factor'] = df['차량상태'].map(condition_factor)\n",
    "            df['price_weight'] *= df['condition_factor']\n",
    "            \n",
    "            # 주행거리 기반 가중치\n",
    "            df['distance_factor'] = np.exp(-df['주행거리(km)'] / 50000)\n",
    "            df['price_weight'] *= df['distance_factor']\n",
    "            \n",
    "            # 연식 기반 가중치\n",
    "            df['age_factor'] = np.exp(-0.2 * df['연식(년)'])\n",
    "            df['price_weight'] *= df['age_factor']\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_model_features(self, df, model_name):\n",
    "        \"\"\"모델별 특화 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 기본 특성\n",
    "        features['distance_norm'] = features['주행거리(km)'] / 100000\n",
    "        features['battery_efficiency'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "        \n",
    "        if model_name == 'RSeTGT':\n",
    "            # 배터리 효율성 점수\n",
    "            features['battery_score'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            \n",
    "        elif model_name == 'Soul':\n",
    "            # 보증기간-연식 상호작용\n",
    "            features['warranty_age_ratio'] = features['보증기간(년)'] / np.maximum(features['연식(년)'], 1)\n",
    "            \n",
    "            # 배터리 상태 점수\n",
    "            features['battery_score'] = np.clip(\n",
    "                features['배터리용량'] / features['배터리용량'].mean(),\n",
    "                0.8,\n",
    "                1.2\n",
    "            )\n",
    "            \n",
    "        elif model_name == 'TayCT':\n",
    "            # 성능 점수\n",
    "            features['performance_score'] = (\n",
    "                features['배터리용량'] * 0.4 +\n",
    "                (100000 - features['주행거리(km)'])/100000 * 0.3 +\n",
    "                (10 - features['연식(년)'])/10 * 0.3\n",
    "            )\n",
    "            \n",
    "            # 주행거리 구간별 감가율\n",
    "            features['distance_depreciation'] = np.where(\n",
    "                features['주행거리(km)'] <= 50000,\n",
    "                0.95,\n",
    "                np.where(\n",
    "                    features['주행거리(km)'] <= 100000,\n",
    "                    0.85,\n",
    "                    0.75\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def prepare_features(self, df, model_name=None):\n",
    "        \"\"\"특성 준비\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 이상치 처리\n",
    "        if model_name is not None:\n",
    "            features = self.handle_outliers_by_model(features, model_name)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "        \n",
    "        # 모델별 특화 특성 생성\n",
    "        if model_name is not None:\n",
    "            features = self.create_model_features(features, model_name)\n",
    "        \n",
    "        # 기본 특성 선택\n",
    "        feature_cols = [\n",
    "            '제조사_encoded', '모델_encoded', '구동방식_encoded', '차량상태_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)',\n",
    "            'price_weight'\n",
    "        ]\n",
    "        \n",
    "        # 모델별 추가 특성\n",
    "        if model_name == 'RSeTGT':\n",
    "            feature_cols.extend(['battery_score', 'distance_norm'])\n",
    "        elif model_name == 'Soul':\n",
    "            feature_cols.extend(['warranty_age_ratio', 'battery_score', 'warranty_factor'])\n",
    "        elif model_name == 'TayCT':\n",
    "            feature_cols.extend(['performance_score', 'distance_depreciation'])\n",
    "        \n",
    "        return features[feature_cols]\n",
    "\n",
    "    def train_model(self, X, y, model_name=None):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        if model_name in self.model_params:\n",
    "            params = self.model_params[model_name]\n",
    "        else:\n",
    "            params = self.default_params\n",
    "        \n",
    "        # Random Forest 모델\n",
    "        rf = RandomForestRegressor(**params['rf'])\n",
    "        \n",
    "        # HGBR 모델\n",
    "        hgb = HistGradientBoostingRegressor(**params['hgb'])\n",
    "        \n",
    "        # 가중치 적용\n",
    "        weights = X['price_weight'] if 'price_weight' in X.columns else None\n",
    "        \n",
    "        # 모델 학습\n",
    "        rf.fit(X, y, sample_weight=weights)\n",
    "        hgb.fit(X, y, sample_weight=weights)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb}\n",
    "\n",
    "    def predict_model(self, X, models, model_name=None):\n",
    "        \"\"\"모델 예측\"\"\"\n",
    "        if model_name in self.ensemble_weights:\n",
    "            weights = self.ensemble_weights[model_name]\n",
    "        else:\n",
    "            weights = self.ensemble_weights['default']\n",
    "        \n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        \n",
    "        return weights['rf'] * rf_pred + weights['hgb'] * hgb_pred\n",
    "\n",
    "    def cv_evaluate(self, train_df):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        model_scores = {}\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(train_df), 1):\n",
    "            train_data = train_df.iloc[train_idx]\n",
    "            val_data = train_df.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros(len(val_data))\n",
    "            \n",
    "            for model_name in train_data['모델'].unique():\n",
    "                # 모델별 데이터 준비\n",
    "                model_mask_train = train_data['모델'] == model_name\n",
    "                model_mask_val = val_data['모델'] == model_name\n",
    "                \n",
    "                if sum(model_mask_train) > 0 and sum(model_mask_val) > 0:\n",
    "                    X_train = self.prepare_features(train_data[model_mask_train], model_name)\n",
    "                    y_train = train_data[model_mask_train]['가격(백만원)']\n",
    "                    \n",
    "                    X_val = self.prepare_features(val_data[model_mask_val], model_name)\n",
    "                    y_val = val_data[model_mask_val]['가격(백만원)']\n",
    "                    \n",
    "                    # 모델 학습 및 예측\n",
    "                    models = self.train_model(X_train, y_train, model_name)\n",
    "                    predictions = self.predict_model(X_val, models, model_name)\n",
    "                    \n",
    "                    # 예측값 저장\n",
    "                    fold_predictions[model_mask_val] = predictions\n",
    "                    \n",
    "                    # 모델별 성능 기록\n",
    "                    model_rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                    if model_name not in model_scores:\n",
    "                        model_scores[model_name] = []\n",
    "                    model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 전체 폴드 성능 계산\n",
    "            fold_rmse = np.sqrt(mean_squared_error(val_data['가격(백만원)'], fold_predictions))\n",
    "            fold_r2 = r2_score(val_data['가격(백만원)'], fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 모델별 RMSE ===\")\n",
    "        for model_name, scores in model_scores.items():\n",
    "            print(f\"{model_name}: {np.mean(scores):.4f}\")\n",
    "        \n",
    "        return cv_scores, model_scores\n",
    "\n",
    "    def fit(self, train_df, test_df=None):\n",
    "        \"\"\"전체 모델 학습\"\"\"\n",
    "        # 레이블 인코더 초기화\n",
    "        self.initialize_label_encoders(train_df, test_df)\n",
    "        \n",
    "        # 교차 검증 수행\n",
    "        cv_scores, model_scores = self.cv_evaluate(train_df)\n",
    "        \n",
    "        # 각 모델별 최종 모델 학습\n",
    "        for model_name in train_df['모델'].unique():\n",
    "            model_data = train_df[train_df['모델'] == model_name]\n",
    "            \n",
    "            if len(model_data) > 0:\n",
    "                X = self.prepare_features(model_data, model_name)\n",
    "                y = model_data['가격(백만원)']\n",
    "                \n",
    "                self.model_specific_predictors[model_name] = self.train_model(X, y, model_name)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        for model_name in test_df['모델'].unique():\n",
    "            model_mask = test_df['모델'] == model_name\n",
    "            \n",
    "            if sum(model_mask) > 0 and model_name in self.model_specific_predictors:\n",
    "                X = self.prepare_features(test_df[model_mask], model_name)\n",
    "                predictions[model_mask] = self.predict_model(\n",
    "                    X,\n",
    "                    self.model_specific_predictors[model_name],\n",
    "                    model_name\n",
    "                )\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = ModelSpecificPredictor()\n",
    "    predictor.fit(train_data, test_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('model_specific_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:291: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - RMSE: 1.3979, R2: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:291: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - RMSE: 1.5373, R2: 0.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:291: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - RMSE: 1.3595, R2: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:291: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - RMSE: 1.3133, R2: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:290: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:291: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - RMSE: 1.3713, R2: 0.9985\n",
      "\n",
      "평균 RMSE: 1.3959 (+/- 0.1517)\n",
      "\n",
      "=== 모델별 RMSE ===\n",
      "EV6: 0.5935\n",
      "ID4: 0.6119\n",
      "ION5: 0.3377\n",
      "ION6: 0.3213\n",
      "IONIQ: 5.7102\n",
      "KNE: 0.5620\n",
      "M3: 0.4363\n",
      "MS: 0.6876\n",
      "MX: 1.8467\n",
      "MY: 0.6655\n",
      "Niro: 0.6028\n",
      "Q4eT: 0.3890\n",
      "RSeTGT: 0.3391\n",
      "Soul: 0.6053\n",
      "Tay: 2.8157\n",
      "TayCT: 3.5734\n",
      "TayGTS: 0.3366\n",
      "eT: 0.5328\n",
      "i3: 0.3384\n",
      "i5: 0.5966\n",
      "iX: 0.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:363: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3308908324.py:398: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class HybridPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.independent_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 독립 모델 설정\n",
    "        self.independent_config = {\n",
    "            'IONIQ': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 6,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.005,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 400,\n",
    "                    'max_depth': 5,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 4,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2500,\n",
    "                    'learning_rate': 0.004,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 3.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.8, 'hgb': 0.2}\n",
    "            },\n",
    "            'Tay': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 350,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.006,\n",
    "                    'max_depth': 7,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 세그먼트별 파라미터\n",
    "        self.segment_params = {\n",
    "            1: {  # 엔트리\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 200,\n",
    "                    'max_depth': 6,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 1500,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.6, 'hgb': 0.4}\n",
    "            },\n",
    "            6: {  # 프리미엄\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def initialize_label_encoders(self, train_df, test_df=None):\n",
    "        \"\"\"레이블 인코더 초기화\"\"\"\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            self.label_encoders[col] = LabelEncoder()\n",
    "            unique_values = set(train_df[col].unique())\n",
    "            \n",
    "            if test_df is not None:\n",
    "                unique_values.update(test_df[col].unique())\n",
    "            \n",
    "            self.label_encoders[col].fit(sorted(list(unique_values)))\n",
    "\n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def create_independent_features(self, df, model_name):\n",
    "        \"\"\"독립 모델을 위한 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # IONIQ 특화 특성\n",
    "        if model_name == 'IONIQ':\n",
    "            features['warranty_score'] = np.exp(-0.1 * features['보증기간(년)'])\n",
    "            features['distance_norm'] = features['주행거리(km)'] / 200000\n",
    "            features['battery_efficiency'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "            \n",
    "            # 가격대별 구분\n",
    "            if '가격(백만원)' in features.columns:\n",
    "                features['price_group'] = pd.qcut(features['가격(백만원)'], q=3, labels=['low', 'mid', 'high'])\n",
    "            \n",
    "        # TayCT 특화 특성\n",
    "        elif model_name == 'TayCT':\n",
    "            condition_prices = {\n",
    "                'Brand New': 130,\n",
    "                'Nearly New': 125,\n",
    "                'Pre-Owned': 120\n",
    "            }\n",
    "            features['base_price'] = features['차량상태'].map(condition_prices)\n",
    "            features['mileage_depreciation'] = np.exp(-features['주행거리(km)'] / 50000)\n",
    "            features['age_depreciation'] = np.exp(-0.2 * features['연식(년)'])\n",
    "            \n",
    "            # 배터리 상태 점수\n",
    "            features['battery_score'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            \n",
    "        # Tay 특화 특성\n",
    "        elif model_name == 'Tay':\n",
    "            features['usage_intensity'] = features['주행거리(km)'] / np.maximum(features['연식(년)'], 1)\n",
    "            features['battery_health'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            features['warranty_age_ratio'] = features['보증기간(년)'] / np.maximum(features['연식(년)'], 1)\n",
    "            \n",
    "            # 차량상태별 가중치\n",
    "            condition_weights = {\n",
    "                'Brand New': 1.1,\n",
    "                'Nearly New': 1.0,\n",
    "                'Pre-Owned': 0.9\n",
    "            }\n",
    "            features['condition_weight'] = features['차량상태'].map(condition_weights)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def prepare_features(self, df, model_name=None, is_independent=False):\n",
    "        \"\"\"특성 준비\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "        \n",
    "        # 기본 특성\n",
    "        feature_cols = [\n",
    "            '제조사_encoded', '모델_encoded', '구동방식_encoded', '차량상태_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)'\n",
    "        ]\n",
    "        \n",
    "        # 독립 모델 특성 추가\n",
    "        if is_independent:\n",
    "            features = self.create_independent_features(features, model_name)\n",
    "            if model_name == 'IONIQ':\n",
    "                feature_cols.extend(['warranty_score', 'distance_norm', 'battery_efficiency'])\n",
    "            elif model_name == 'TayCT':\n",
    "                feature_cols.extend(['base_price', 'mileage_depreciation', 'age_depreciation', 'battery_score'])\n",
    "            elif model_name == 'Tay':\n",
    "                feature_cols.extend(['usage_intensity', 'battery_health', 'warranty_age_ratio', 'condition_weight'])\n",
    "        \n",
    "        return features[feature_cols]\n",
    "\n",
    "    def train_model(self, X, y, model_config):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        rf = RandomForestRegressor(**model_config['rf_params'])\n",
    "        hgb = HistGradientBoostingRegressor(**model_config['hgb_params'])\n",
    "        \n",
    "        rf.fit(X, y)\n",
    "        hgb.fit(X, y)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb}\n",
    "\n",
    "    def predict_model(self, X, models, weights):\n",
    "        \"\"\"모델 예측\"\"\"\n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        \n",
    "        return weights['rf'] * rf_pred + weights['hgb'] * hgb_pred\n",
    "    \n",
    "    def cv_evaluate(self, train_df):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        model_scores = {}\n",
    "        independent_models = set(self.independent_config.keys())\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(train_df), 1):\n",
    "            train_data = train_df.iloc[train_idx]\n",
    "            val_data = train_df.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros(len(val_data))\n",
    "            \n",
    "            # 독립 모델 예측\n",
    "            for model_name in independent_models:\n",
    "                train_mask = train_data['모델'] == model_name\n",
    "                val_mask = val_data['모델'] == model_name\n",
    "                \n",
    "                if sum(train_mask) > 0 and sum(val_mask) > 0:\n",
    "                    X_train = self.prepare_features(\n",
    "                        train_data[train_mask],\n",
    "                        model_name=model_name,\n",
    "                        is_independent=True\n",
    "                    )\n",
    "                    y_train = train_data[train_mask]['가격(백만원)']\n",
    "                    \n",
    "                    X_val = self.prepare_features(\n",
    "                        val_data[val_mask],\n",
    "                        model_name=model_name,\n",
    "                        is_independent=True\n",
    "                    )\n",
    "                    y_val = val_data[val_mask]['가격(백만원)']\n",
    "                    \n",
    "                    model = self.train_model(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        self.independent_config[model_name]\n",
    "                    )\n",
    "                    predictions = self.predict_model(\n",
    "                        X_val,\n",
    "                        model,\n",
    "                        self.independent_config[model_name]['weights']\n",
    "                    )\n",
    "                    \n",
    "                    fold_predictions[val_mask] = predictions\n",
    "                    \n",
    "                    model_rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                    if model_name not in model_scores:\n",
    "                        model_scores[model_name] = []\n",
    "                    model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 세그먼트 모델 예측\n",
    "            segment_data_train = train_data[~train_data['모델'].isin(independent_models)]\n",
    "            segment_data_val = val_data[~val_data['모델'].isin(independent_models)]\n",
    "            \n",
    "            if len(segment_data_train) > 0 and len(segment_data_val) > 0:\n",
    "                segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
    "                segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n",
    "                \n",
    "                for segment in range(1, 8):\n",
    "                    segment_mask_train = segment_data_train['segment'] == segment\n",
    "                    segment_mask_val = segment_data_val['segment'] == segment\n",
    "                    \n",
    "                    if sum(segment_mask_train) > 0 and sum(segment_mask_val) > 0:\n",
    "                        X_train = self.prepare_features(segment_data_train[segment_mask_train])\n",
    "                        y_train = segment_data_train[segment_mask_train]['가격(백만원)']\n",
    "                        \n",
    "                        X_val = self.prepare_features(segment_data_val[segment_mask_val])\n",
    "                        y_val = segment_data_val[segment_mask_val]['가격(백만원)']\n",
    "                        \n",
    "                        segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                        model = self.train_model(X_train, y_train, segment_config)\n",
    "                        predictions = self.predict_model(X_val, model, segment_config['weights'])\n",
    "                        \n",
    "                        # 세그먼트 예측값을 전체 예측값 배열에 할당\n",
    "                        val_indices = val_data.index[~val_data['모델'].isin(independent_models)]\n",
    "                        segment_indices = val_indices[segment_mask_val]\n",
    "                        fold_predictions[val_data.index.get_indexer(segment_indices)] = predictions\n",
    "                        \n",
    "                        # 모델별 성능 기록\n",
    "                        for model_name in segment_data_val[segment_mask_val]['모델'].unique():\n",
    "                            model_mask = segment_data_val[segment_mask_val]['모델'] == model_name\n",
    "                            if sum(model_mask) > 0:\n",
    "                                model_rmse = np.sqrt(mean_squared_error(\n",
    "                                    y_val[model_mask],\n",
    "                                    predictions[model_mask]\n",
    "                                ))\n",
    "                                if model_name not in model_scores:\n",
    "                                    model_scores[model_name] = []\n",
    "                                model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 전체 폴드 성능 계산\n",
    "            fold_rmse = np.sqrt(mean_squared_error(val_data['가격(백만원)'], fold_predictions))\n",
    "            fold_r2 = r2_score(val_data['가격(백만원)'], fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "            \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 모델별 RMSE ===\")\n",
    "        for model_name in sorted(model_scores.keys()):\n",
    "            print(f\"{model_name}: {np.mean(model_scores[model_name]):.4f}\")\n",
    "        \n",
    "        return cv_scores, model_scores\n",
    "    \n",
    "    def fit(self, train_df, test_df=None):\n",
    "        \"\"\"전체 모델 학습\"\"\"\n",
    "        # 레이블 인코더 초기화\n",
    "        self.initialize_label_encoders(train_df, test_df)\n",
    "        \n",
    "        # 교차 검증 수행\n",
    "        cv_scores, model_scores = self.cv_evaluate(train_df)\n",
    "        \n",
    "        # 독립 모델 학습\n",
    "        for model_name in self.independent_config.keys():\n",
    "            model_data = train_df[train_df['모델'] == model_name]\n",
    "            \n",
    "            if len(model_data) > 0:\n",
    "                X = self.prepare_features(model_data, model_name=model_name, is_independent=True)\n",
    "                y = model_data['가격(백만원)']\n",
    "                \n",
    "                self.independent_models[model_name] = self.train_model(\n",
    "                    X, y,\n",
    "                    self.independent_config[model_name]\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 학습\n",
    "        segment_data = train_df[~train_df['모델'].isin(self.independent_config.keys())]\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(segment_data[segment_mask])\n",
    "                    y = segment_data[segment_mask]['가격(백만원)']\n",
    "                    \n",
    "                    segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                    self.segment_models[segment] = self.train_model(X, y, segment_config)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        # 독립 모델 예측\n",
    "        for model_name, model in self.independent_models.items():\n",
    "            model_mask = test_df['모델'] == model_name\n",
    "            if sum(model_mask) > 0:\n",
    "                X = self.prepare_features(\n",
    "                    test_df[model_mask],\n",
    "                    model_name=model_name,\n",
    "                    is_independent=True\n",
    "                )\n",
    "                predictions[model_mask] = self.predict_model(\n",
    "                    X,\n",
    "                    model,\n",
    "                    self.independent_config[model_name]['weights']\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 예측\n",
    "        segment_data = test_df[~test_df['모델'].isin(self.independent_config.keys())]\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment, model in self.segment_models.items():\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(segment_data[segment_mask])\n",
    "                    segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                    \n",
    "                    # 세그먼트 예측값을 전체 예측값 배열에 할당\n",
    "                    test_indices = test_df.index[~test_df['모델'].isin(self.independent_config.keys())]\n",
    "                    segment_indices = test_indices[segment_mask]\n",
    "                    predictions[test_df.index.get_indexer(segment_indices)] = self.predict_model(\n",
    "                        X,\n",
    "                        model,\n",
    "                        segment_config['weights']\n",
    "                    )\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = HybridPredictor()\n",
    "    predictor.fit(train_data, test_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('hybrid_model_submission.csv', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - RMSE: 1.4136, R2: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - RMSE: 1.5374, R2: 0.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - RMSE: 1.3684, R2: 0.9986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - RMSE: 1.3257, R2: 0.9987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:338: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - RMSE: 1.3430, R2: 0.9985\n",
      "\n",
      "평균 RMSE: 1.3976 (+/- 0.1518)\n",
      "\n",
      "=== 모델별 RMSE ===\n",
      "EV6: 0.5935\n",
      "ID4: 0.6119\n",
      "ION5: 0.3377\n",
      "ION6: 0.3213\n",
      "IONIQ: 5.6819\n",
      "KNE: 0.5620\n",
      "M3: 0.4363\n",
      "MS: 0.6876\n",
      "MX: 1.8467\n",
      "MY: 0.6655\n",
      "Niro: 0.6028\n",
      "Q4eT: 0.3890\n",
      "RSeTGT: 0.3391\n",
      "Soul: 0.6053\n",
      "Tay: 2.8144\n",
      "TayCT: 3.6021\n",
      "TayGTS: 0.3366\n",
      "eT: 0.5328\n",
      "i3: 0.3384\n",
      "i5: 0.5966\n",
      "iX: 0.5688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\3335646947.py:410: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'가격(백만원)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '가격(백만원)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 473\u001b[0m\n\u001b[0;32m    470\u001b[0m predictor \u001b[38;5;241m=\u001b[39m HybridPredictor()\n\u001b[0;32m    471\u001b[0m predictor\u001b[38;5;241m.\u001b[39mfit(train_data, test_data)\n\u001b[1;32m--> 473\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m    477\u001b[0m })\n\u001b[0;32m    479\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhybrid_model_submission2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[84], line 431\u001b[0m, in \u001b[0;36mHybridPredictor.predict\u001b[1;34m(self, test_df)\u001b[0m\n\u001b[0;32m    429\u001b[0m     model_mask \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m model_name\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(model_mask) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 431\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_independent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m         predictions[model_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_model(\n\u001b[0;32m    437\u001b[0m             X,\n\u001b[0;32m    438\u001b[0m             model,\n\u001b[0;32m    439\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindependent_config[model_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    440\u001b[0m         )\n\u001b[0;32m    442\u001b[0m \u001b[38;5;66;03m# 세그먼트 모델 예측\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[84], line 238\u001b[0m, in \u001b[0;36mHybridPredictor.prepare_features\u001b[1;34m(self, df, model_name, is_independent)\u001b[0m\n\u001b[0;32m    235\u001b[0m features \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIONIQ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTayCT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTay\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m--> 238\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_battery_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     features[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m배터리용량\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m배터리용량\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mfillna(x\u001b[38;5;241m.\u001b[39mmean()))\n",
      "Cell \u001b[1;32mIn[84], line 141\u001b[0m, in \u001b[0;36mHybridPredictor.handle_battery_missing\u001b[1;34m(self, df, model_name)\u001b[0m\n\u001b[0;32m    138\u001b[0m mask \u001b[38;5;241m=\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTay\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m차량상태\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrand New\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(mask \u001b[38;5;241m&\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m배터리용량\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misnull()) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    140\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[mask, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mqcut(\n\u001b[1;32m--> 141\u001b[0m         \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m가격(백만원)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[0;32m    142\u001b[0m         q\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m    143\u001b[0m         labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    146\u001b[0m         group_mask \u001b[38;5;241m=\u001b[39m mask \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m group)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m-> 1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1186\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1368\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m   1367\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[1;32m-> 1368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1065\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[0;32m   1063\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[1;32m-> 1065\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1067\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[0;32m   1068\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[0;32m   1071\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[0;32m   1072\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1431\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m-> 1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1381\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[1;32m-> 1381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\generic.py:4287\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_level:\n\u001b[1;32m-> 4287\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   4288\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '가격(백만원)'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class HybridPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.independent_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)    \n",
    "        # 독립 모델 설정\n",
    "        self.independent_config = {\n",
    "            'IONIQ': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 6,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.005,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 400,\n",
    "                    'max_depth': 5,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 4,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2500,\n",
    "                    'learning_rate': 0.004,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 3.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.8, 'hgb': 0.2}\n",
    "            },\n",
    "            'Tay': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 350,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.006,\n",
    "                    'max_depth': 7,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 세그먼트별 파라미터\n",
    "        self.segment_params = {\n",
    "            1: {  # 엔트리\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 200,\n",
    "                    'max_depth': 6,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 1500,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.6, 'hgb': 0.4}\n",
    "            },\n",
    "            6: {  # 프리미엄\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def handle_battery_missing(self, df, model_name):\n",
    "        \"\"\"모델별 맞춤형 배터리용량 결측치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "    \n",
    "        if model_name == 'IONIQ':\n",
    "        # IONIQ: 차량상태별 평균으로 대체\n",
    "            for condition in ['Pre-Owned', 'Nearly New']:\n",
    "                mask = (df['모델'] == 'IONIQ') & (df['차량상태'] == condition)\n",
    "                condition_mean = df.loc[mask & df['배터리용량'].notnull(), '배터리용량'].mean()\n",
    "                df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = condition_mean\n",
    "            \n",
    "        elif model_name == 'TayCT':\n",
    "            # TayCT: Brand New의 경우 기본 스펙으로 대체\n",
    "            mask = (df['모델'] == 'TayCT') & (df['차량상태'] == 'Brand New')\n",
    "            df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = 93.4  # TayCT의 공식 배터리 용량\n",
    "        \n",
    "        # 나머지 상태는 주행거리 구간별로 처리\n",
    "            other_mask = (df['모델'] == 'TayCT') & (df['차량상태'] != 'Brand New')\n",
    "            if sum(other_mask & df['배터리용량'].isnull()) > 0:\n",
    "                df.loc[other_mask, 'distance_group'] = pd.qcut(\n",
    "                    df.loc[other_mask, '주행거리(km)'],\n",
    "                    q=3,\n",
    "                    labels=['low', 'medium', 'high']\n",
    "                )\n",
    "                for group in ['low', 'medium', 'high']:\n",
    "                    group_mask = other_mask & (df['distance_group'] == group)\n",
    "                    group_mean = df.loc[group_mask & df['배터리용량'].notnull(), '배터리용량'].mean()\n",
    "                    df.loc[group_mask & df['배터리용량'].isnull(), '배터리용량'] = group_mean\n",
    "            \n",
    "        elif model_name == 'Tay':\n",
    "            # Tay: Brand New는 가격대별로 구분하여 처리\n",
    "            mask = (df['모델'] == 'Tay') & (df['차량상태'] == 'Brand New')\n",
    "            if sum(mask & df['배터리용량'].isnull()) > 0:\n",
    "                df.loc[mask, 'price_group'] = pd.qcut(\n",
    "                    df.loc[mask, '가격(백만원)'],\n",
    "                    q=3,\n",
    "                    labels=['low', 'medium', 'high']\n",
    "                )\n",
    "                for group in ['low', 'medium', 'high']:\n",
    "                    group_mask = mask & (df['price_group'] == group)\n",
    "                    group_mean = df.loc[group_mask & df['배터리용량'].notnull(), '배터리용량'].mean()\n",
    "                    if pd.isna(group_mean):  # 해당 그룹의 non-null 값이 없는 경우\n",
    "                        group_mean = 98.0  # Tay의 기본 배터리 용량\n",
    "                    df.loc[group_mask & df['배터리용량'].isnull(), '배터리용량'] = group_mean\n",
    "        return df\n",
    "    \n",
    "    def initialize_label_encoders(self, train_df, test_df=None):\n",
    "        \"\"\"레이블 인코더 초기화\"\"\"\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            self.label_encoders[col] = LabelEncoder()\n",
    "            unique_values = set(train_df[col].unique())\n",
    "            \n",
    "            if test_df is not None:\n",
    "                unique_values.update(test_df[col].unique())\n",
    "            \n",
    "            self.label_encoders[col].fit(sorted(list(unique_values)))\n",
    "\n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def create_independent_features(self, df, model_name):\n",
    "        \"\"\"독립 모델을 위한 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # IONIQ 특화 특성\n",
    "        if model_name == 'IONIQ':\n",
    "            features['warranty_score'] = np.exp(-0.1 * features['보증기간(년)'])\n",
    "            features['distance_norm'] = features['주행거리(km)'] / 200000\n",
    "            features['battery_efficiency'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "            \n",
    "            # 가격대별 구분\n",
    "            if '가격(백만원)' in features.columns:\n",
    "                features['price_group'] = pd.qcut(features['가격(백만원)'], q=3, labels=['low', 'mid', 'high'])\n",
    "            \n",
    "        # TayCT 특화 특성\n",
    "        elif model_name == 'TayCT':\n",
    "            condition_prices = {\n",
    "                'Brand New': 130,\n",
    "                'Nearly New': 125,\n",
    "                'Pre-Owned': 120\n",
    "            }\n",
    "            features['base_price'] = features['차량상태'].map(condition_prices)\n",
    "            features['mileage_depreciation'] = np.exp(-features['주행거리(km)'] / 50000)\n",
    "            features['age_depreciation'] = np.exp(-0.2 * features['연식(년)'])\n",
    "            \n",
    "            # 배터리 상태 점수\n",
    "            features['battery_score'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            \n",
    "        # Tay 특화 특성\n",
    "        elif model_name == 'Tay':\n",
    "            features['usage_intensity'] = features['주행거리(km)'] / np.maximum(features['연식(년)'], 1)\n",
    "            features['battery_health'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            features['warranty_age_ratio'] = features['보증기간(년)'] / np.maximum(features['연식(년)'], 1)\n",
    "            \n",
    "            # 차량상태별 가중치\n",
    "            condition_weights = {\n",
    "                'Brand New': 1.1,\n",
    "                'Nearly New': 1.0,\n",
    "                'Pre-Owned': 0.9\n",
    "            }\n",
    "            features['condition_weight'] = features['차량상태'].map(condition_weights)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def prepare_features(self, df, model_name=None, is_independent=False):\n",
    "        \"\"\"특성 준비\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        if model_name in ['IONIQ', 'TayCT', 'Tay']:\n",
    "            features = self.handle_battery_missing(features, model_name)\n",
    "        else:\n",
    "            features['배터리용량'] = features.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "        \n",
    "        # 기본 특성\n",
    "        feature_cols = [\n",
    "            '제조사_encoded', '모델_encoded', '구동방식_encoded', '차량상태_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)'\n",
    "        ]\n",
    "        \n",
    "        # 독립 모델 특성 추가\n",
    "        if is_independent:\n",
    "            features = self.create_independent_features(features, model_name)\n",
    "            if model_name == 'IONIQ':\n",
    "                feature_cols.extend(['warranty_score', 'distance_norm', 'battery_efficiency'])\n",
    "            elif model_name == 'TayCT':\n",
    "                feature_cols.extend(['base_price', 'mileage_depreciation', 'age_depreciation', 'battery_score'])\n",
    "            elif model_name == 'Tay':\n",
    "                feature_cols.extend(['usage_intensity', 'battery_health', 'warranty_age_ratio', 'condition_weight'])\n",
    "        \n",
    "        return features[feature_cols]\n",
    "\n",
    "    def train_model(self, X, y, model_config):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        rf = RandomForestRegressor(**model_config['rf_params'])\n",
    "        hgb = HistGradientBoostingRegressor(**model_config['hgb_params'])\n",
    "        \n",
    "        rf.fit(X, y)\n",
    "        hgb.fit(X, y)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb}\n",
    "\n",
    "    def predict_model(self, X, models, weights):\n",
    "        \"\"\"모델 예측\"\"\"\n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        \n",
    "        return weights['rf'] * rf_pred + weights['hgb'] * hgb_pred\n",
    "    \n",
    "    def cv_evaluate(self, train_df):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        model_scores = {}\n",
    "        independent_models = set(self.independent_config.keys())\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(train_df), 1):\n",
    "            train_data = train_df.iloc[train_idx]\n",
    "            val_data = train_df.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros(len(val_data))\n",
    "            \n",
    "            # 독립 모델 예측\n",
    "            for model_name in independent_models:\n",
    "                train_mask = train_data['모델'] == model_name\n",
    "                val_mask = val_data['모델'] == model_name\n",
    "                \n",
    "                if sum(train_mask) > 0 and sum(val_mask) > 0:\n",
    "                    X_train = self.prepare_features(\n",
    "                        train_data[train_mask],\n",
    "                        model_name=model_name,\n",
    "                        is_independent=True\n",
    "                    )\n",
    "                    y_train = train_data[train_mask]['가격(백만원)']\n",
    "                    \n",
    "                    X_val = self.prepare_features(\n",
    "                        val_data[val_mask],\n",
    "                        model_name=model_name,\n",
    "                        is_independent=True\n",
    "                    )\n",
    "                    y_val = val_data[val_mask]['가격(백만원)']\n",
    "                    \n",
    "                    model = self.train_model(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        self.independent_config[model_name]\n",
    "                    )\n",
    "                    predictions = self.predict_model(\n",
    "                        X_val,\n",
    "                        model,\n",
    "                        self.independent_config[model_name]['weights']\n",
    "                    )\n",
    "                    \n",
    "                    fold_predictions[val_mask] = predictions\n",
    "                    \n",
    "                    model_rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                    if model_name not in model_scores:\n",
    "                        model_scores[model_name] = []\n",
    "                    model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 세그먼트 모델 예측\n",
    "            segment_data_train = train_data[~train_data['모델'].isin(independent_models)]\n",
    "            segment_data_val = val_data[~val_data['모델'].isin(independent_models)]\n",
    "            \n",
    "            if len(segment_data_train) > 0 and len(segment_data_val) > 0:\n",
    "                segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
    "                segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n",
    "                \n",
    "                for segment in range(1, 8):\n",
    "                    segment_mask_train = segment_data_train['segment'] == segment\n",
    "                    segment_mask_val = segment_data_val['segment'] == segment\n",
    "                    \n",
    "                    if sum(segment_mask_train) > 0 and sum(segment_mask_val) > 0:\n",
    "                        X_train = self.prepare_features(segment_data_train[segment_mask_train])\n",
    "                        y_train = segment_data_train[segment_mask_train]['가격(백만원)']\n",
    "                        \n",
    "                        X_val = self.prepare_features(segment_data_val[segment_mask_val])\n",
    "                        y_val = segment_data_val[segment_mask_val]['가격(백만원)']\n",
    "                        \n",
    "                        segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                        model = self.train_model(X_train, y_train, segment_config)\n",
    "                        predictions = self.predict_model(X_val, model, segment_config['weights'])\n",
    "                        \n",
    "                        # 세그먼트 예측값을 전체 예측값 배열에 할당\n",
    "                        val_indices = val_data.index[~val_data['모델'].isin(independent_models)]\n",
    "                        segment_indices = val_indices[segment_mask_val]\n",
    "                        fold_predictions[val_data.index.get_indexer(segment_indices)] = predictions\n",
    "                        \n",
    "                        # 모델별 성능 기록\n",
    "                        for model_name in segment_data_val[segment_mask_val]['모델'].unique():\n",
    "                            model_mask = segment_data_val[segment_mask_val]['모델'] == model_name\n",
    "                            if sum(model_mask) > 0:\n",
    "                                model_rmse = np.sqrt(mean_squared_error(\n",
    "                                    y_val[model_mask],\n",
    "                                    predictions[model_mask]\n",
    "                                ))\n",
    "                                if model_name not in model_scores:\n",
    "                                    model_scores[model_name] = []\n",
    "                                model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 전체 폴드 성능 계산\n",
    "            fold_rmse = np.sqrt(mean_squared_error(val_data['가격(백만원)'], fold_predictions))\n",
    "            fold_r2 = r2_score(val_data['가격(백만원)'], fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "            \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 모델별 RMSE ===\")\n",
    "        for model_name in sorted(model_scores.keys()):\n",
    "            print(f\"{model_name}: {np.mean(model_scores[model_name]):.4f}\")\n",
    "        \n",
    "        return cv_scores, model_scores\n",
    "    \n",
    "    def fit(self, train_df, test_df=None):\n",
    "        \"\"\"전체 모델 학습\"\"\"\n",
    "        # 레이블 인코더 초기화\n",
    "        self.initialize_label_encoders(train_df, test_df)\n",
    "        \n",
    "        # 교차 검증 수행\n",
    "        cv_scores, model_scores = self.cv_evaluate(train_df)\n",
    "        \n",
    "        # 독립 모델 학습\n",
    "        for model_name in self.independent_config.keys():\n",
    "            model_data = train_df[train_df['모델'] == model_name]\n",
    "            \n",
    "            if len(model_data) > 0:\n",
    "                X = self.prepare_features(model_data, model_name=model_name, is_independent=True)\n",
    "                y = model_data['가격(백만원)']\n",
    "                \n",
    "                self.independent_models[model_name] = self.train_model(\n",
    "                    X, y,\n",
    "                    self.independent_config[model_name]\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 학습\n",
    "        segment_data = train_df[~train_df['모델'].isin(self.independent_config.keys())]\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(segment_data[segment_mask])\n",
    "                    y = segment_data[segment_mask]['가격(백만원)']\n",
    "                    \n",
    "                    segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                    self.segment_models[segment] = self.train_model(X, y, segment_config)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        # 독립 모델 예측\n",
    "        for model_name, model in self.independent_models.items():\n",
    "            model_mask = test_df['모델'] == model_name\n",
    "            if sum(model_mask) > 0:\n",
    "                X = self.prepare_features(\n",
    "                    test_df[model_mask],\n",
    "                    model_name=model_name,\n",
    "                    is_independent=True\n",
    "                )\n",
    "                predictions[model_mask] = self.predict_model(\n",
    "                    X,\n",
    "                    model,\n",
    "                    self.independent_config[model_name]['weights']\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 예측\n",
    "        segment_data = test_df[~test_df['모델'].isin(self.independent_config.keys())]\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment, model in self.segment_models.items():\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(segment_data[segment_mask])\n",
    "                    segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                    \n",
    "                    # 세그먼트 예측값을 전체 예측값 배열에 할당\n",
    "                    test_indices = test_df.index[~test_df['모델'].isin(self.independent_config.keys())]\n",
    "                    segment_indices = test_indices[segment_mask]\n",
    "                    predictions[test_df.index.get_indexer(segment_indices)] = self.predict_model(\n",
    "                        X,\n",
    "                        model,\n",
    "                        segment_config['weights']\n",
    "                    )\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    predictor = HybridPredictor()\n",
    "    predictor.fit(train_data, test_data)\n",
    "\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "\n",
    "    submission.to_csv('hybrid_model_submission2.csv', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25500\\762036502.py:147: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '10175.5' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[(df[col] < lower_bound) | (df[col] > upper_bound), col] = df[col].median()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Bin edges must be unique: Index([0.0, 0.0, 0.0, 2.0], dtype='float64', name='연식(년)').\nYou can drop duplicate edges by setting the 'duplicates' kwarg",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 556\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;66;03m# 모델 초기화 및 학습\u001b[39;00m\n\u001b[0;32m    555\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ImprovedHybridPredictor()\n\u001b[1;32m--> 556\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;66;03m# 예측 및 저장\u001b[39;00m\n\u001b[0;32m    559\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(test_data)\n",
      "Cell \u001b[1;32mIn[86], line 476\u001b[0m, in \u001b[0;36mImprovedHybridPredictor.fit\u001b[1;34m(self, train_df, test_df)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_label_encoders(train_df, test_df)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;66;03m# 교차 검증 수행\u001b[39;00m\n\u001b[1;32m--> 476\u001b[0m cv_scores, model_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;66;03m# 독립 모델 학습\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindependent_config\u001b[38;5;241m.\u001b[39mkeys():\n",
      "Cell \u001b[1;32mIn[86], line 386\u001b[0m, in \u001b[0;36mImprovedHybridPredictor.cv_evaluate\u001b[1;34m(self, train_df)\u001b[0m\n\u001b[0;32m    383\u001b[0m val_mask \u001b[38;5;241m=\u001b[39m val_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m model_name\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(train_mask) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28msum\u001b[39m(val_mask) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 386\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_improved_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m train_data[train_mask][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    392\u001b[0m     X_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_improved_features(\n\u001b[0;32m    393\u001b[0m         val_data[val_mask],\n\u001b[0;32m    394\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mmodel_name\n\u001b[0;32m    395\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[86], line 317\u001b[0m, in \u001b[0;36mImprovedHybridPredictor.prepare_improved_features\u001b[1;34m(self, df, model_name)\u001b[0m\n\u001b[0;32m    314\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_outliers(df, model_name)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# 결측치 처리\u001b[39;00m\n\u001b[1;32m--> 317\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_battery_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;66;03m# 기본 특성 생성\u001b[39;00m\n\u001b[0;32m    320\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_features(df, model_name, is_independent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[86], line 186\u001b[0m, in \u001b[0;36mImprovedHybridPredictor.handle_battery_missing\u001b[1;34m(self, df, model_name)\u001b[0m\n\u001b[0;32m    182\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_group\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMX\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# MX: 차량상태와 연식 기반 처리\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_group\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqcut\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m모델\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m연식(년)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmedium\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mold\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m age_group \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mold\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m condition \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrand New\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNearly New\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPre-Owned\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\reshape\\tile.py:340\u001b[0m, in \u001b[0;36mqcut\u001b[1;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[0;32m    336\u001b[0m quantiles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, q \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m is_integer(q) \u001b[38;5;28;01melse\u001b[39;00m q\n\u001b[0;32m    338\u001b[0m bins \u001b[38;5;241m=\u001b[39m x_idx\u001b[38;5;241m.\u001b[39mto_series()\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mquantile(quantiles)\n\u001b[1;32m--> 340\u001b[0m fac, bins \u001b[38;5;241m=\u001b[39m \u001b[43m_bins_to_cuts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_lowest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduplicates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mduplicates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _postprocess_for_cut(fac, bins, retbins, original)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\reshape\\tile.py:443\u001b[0m, in \u001b[0;36m_bins_to_cuts\u001b[1;34m(x_idx, bins, right, labels, precision, include_lowest, duplicates, ordered)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_bins) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m duplicates \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 443\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBin edges must be unique: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(bins)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can drop duplicate edges by setting the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduplicates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m kwarg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m         )\n\u001b[0;32m    447\u001b[0m     bins \u001b[38;5;241m=\u001b[39m unique_bins\n\u001b[0;32m    449\u001b[0m side: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Bin edges must be unique: Index([0.0, 0.0, 0.0, 2.0], dtype='float64', name='연식(년)').\nYou can drop duplicate edges by setting the 'duplicates' kwarg"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ImprovedHybridPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.independent_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)    \n",
    "        \n",
    "        # 독립 모델 설정\n",
    "        self.independent_config = {\n",
    "            'IONIQ': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 500,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2500,\n",
    "                    'learning_rate': 0.003,\n",
    "                    'max_depth': 8,\n",
    "                    'l2_regularization': 1.5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.65, 'hgb': 0.35}\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 600,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 3000,\n",
    "                    'learning_rate': 0.002,\n",
    "                    'max_depth': 7,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.75, 'hgb': 0.25}\n",
    "            },\n",
    "            'Tay': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 550,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2800,\n",
    "                    'learning_rate': 0.003,\n",
    "                    'max_depth': 8,\n",
    "                    'l2_regularization': 1.8,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            },\n",
    "            'MX': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 450,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2500,\n",
    "                    'learning_rate': 0.004,\n",
    "                    'max_depth': 7,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 세그먼트별 파라미터\n",
    "        self.segment_params = {\n",
    "            1: {  # 엔트리\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 200,\n",
    "                    'max_depth': 6,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 1500,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.6, 'hgb': 0.4}\n",
    "            },\n",
    "            6: {  # 프리미엄\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def handle_outliers(self, df, model_name):\n",
    "        \"\"\"개선된 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            # IONIQ 모델의 이상치 처리\n",
    "            for col in ['주행거리(km)', '배터리용량', '가격(백만원)']:\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                df.loc[(df[col] < lower_bound) | (df[col] > upper_bound), col] = df[col].median()\n",
    "        \n",
    "        elif model_name in ['TayCT', 'Tay', 'MX']:\n",
    "            # 고가 모델의 이상치 처리 (더 관대한 기준 적용)\n",
    "            for col in ['주행거리(km)', '배터리용량']:\n",
    "                Q1 = df[col].quantile(0.1)\n",
    "                Q3 = df[col].quantile(0.9)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 2 * IQR\n",
    "                upper_bound = Q3 + 2 * IQR\n",
    "                df.loc[(df[col] < lower_bound) | (df[col] > upper_bound), col] = df[col].median()\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def handle_battery_missing(self, df, model_name):\n",
    "        \"\"\"모델별 맞춤형 배터리용량 결측치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            # IONIQ: 차량상태별 평균으로 대체\n",
    "            for condition in ['Pre-Owned', 'Nearly New', 'Brand New']:\n",
    "                mask = (df['모델'] == 'IONIQ') & (df['차량상태'] == condition)\n",
    "                condition_mean = df.loc[mask & df['배터리용량'].notnull(), '배터리용량'].mean()\n",
    "                df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = condition_mean\n",
    "                \n",
    "        elif model_name in ['TayCT', 'Tay']:\n",
    "            # 주행거리 구간별로 처리\n",
    "            df.loc[df['모델'].isin(['TayCT', 'Tay']), 'distance_group'] = pd.qcut(\n",
    "                df.loc[df['모델'].isin(['TayCT', 'Tay']), '주행거리(km)'],\n",
    "                q=4,\n",
    "                labels=['very_low', 'low', 'medium', 'high']\n",
    "            )\n",
    "            \n",
    "            for group in ['very_low', 'low', 'medium', 'high']:\n",
    "                for condition in ['Brand New', 'Nearly New', 'Pre-Owned']:\n",
    "                    mask = (df['모델'].isin(['TayCT', 'Tay'])) & \\\n",
    "                           (df['distance_group'] == group) & \\\n",
    "                           (df['차량상태'] == condition)\n",
    "                    \n",
    "                    group_mean = df.loc[mask & df['배터리용량'].notnull(), '배터리용량'].mean()\n",
    "                    if pd.isna(group_mean):\n",
    "                        group_mean = df.loc[df['모델'].isin(['TayCT', 'Tay']), '배터리용량'].mean()\n",
    "                    \n",
    "                    df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = group_mean\n",
    "            \n",
    "            df = df.drop('distance_group', axis=1)\n",
    "            \n",
    "        elif model_name == 'MX':\n",
    "            # MX: 차량상태와 연식 기반 처리\n",
    "            df.loc[df['모델'] == 'MX', 'age_group'] = pd.qcut(\n",
    "                df.loc[df['모델'] == 'MX', '연식(년)'],\n",
    "                q=3,\n",
    "                labels=['new', 'medium', 'old']\n",
    "            )\n",
    "            \n",
    "            for age_group in ['new', 'medium', 'old']:\n",
    "                for condition in ['Brand New', 'Nearly New', 'Pre-Owned']:\n",
    "                    mask = (df['모델'] == 'MX') & \\\n",
    "                           (df['age_group'] == age_group) & \\\n",
    "                           (df['차량상태'] == condition)\n",
    "                    \n",
    "                    group_mean = df.loc[mask & df['배터리용량'].notnull(), '배터리용량'].mean()\n",
    "                    if pd.isna(group_mean):\n",
    "                        group_mean = df.loc[df['모델'] == 'MX', '배터리용량'].mean()\n",
    "                    \n",
    "                    df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = group_mean\n",
    "            \n",
    "            df = df.drop('age_group', axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def initialize_label_encoders(self, train_df, test_df=None):\n",
    "        \"\"\"레이블 인코더 초기화\"\"\"\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            self.label_encoders[col] = LabelEncoder()\n",
    "            unique_values = set(train_df[col].unique())\n",
    "            \n",
    "            if test_df is not None:\n",
    "                unique_values.update(test_df[col].unique())\n",
    "            \n",
    "            self.label_encoders[col].fit(sorted(list(unique_values)))\n",
    "\n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def create_improved_features(self, df, model_name):\n",
    "        \"\"\"개선된 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 공통 특성\n",
    "        features['age_warranty_ratio'] = features['연식(년)'] / features['보증기간(년)'].replace(0, 0.1)\n",
    "        features['battery_distance_ratio'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            # IONIQ 특화 특성\n",
    "            features['condition_encoded'] = features['차량상태'].map({\n",
    "                'Brand New': 3,\n",
    "                'Nearly New': 2,\n",
    "                'Pre-Owned': 1\n",
    "            })\n",
    "            features['distance_per_year'] = features['주행거리(km)'] / features['연식(년)'].replace(0, 1)\n",
    "            features['battery_age_interaction'] = features['배터리용량'] * np.exp(-0.1 * features['연식(년)'])\n",
    "            features['warranty_value'] = features['보증기간(년)'] * np.exp(-0.2 * features['주행거리(km)'] / 10000)\n",
    "            \n",
    "        elif model_name in ['TayCT', 'Tay']:\n",
    "            # 고가 모델 특화 특성\n",
    "            features['premium_score'] = (\n",
    "                (features['배터리용량'] / features['배터리용량'].mean()) * \n",
    "                np.exp(-0.05 * features['연식(년)']) * \n",
    "                np.exp(-0.1 * features['주행거리(km)'] / 50000)\n",
    "            )\n",
    "            features['condition_value'] = features['차량상태'].map({\n",
    "                'Brand New': 1.2,\n",
    "                'Nearly New': 1.1,\n",
    "                'Pre-Owned': 1.0\n",
    "            })\n",
    "            features['battery_premium'] = (features['배터리용량'] / features['배터리용량'].mean()) ** 2\n",
    "            features['age_penalty'] = np.exp(-0.15 * features['연식(년)'])\n",
    "            \n",
    "        elif model_name == 'MX':\n",
    "            # MX 특화 특성\n",
    "            features['luxury_score'] = (\n",
    "                (features['배터리용량'] / features['배터리용량'].max()) * \n",
    "                np.exp(-0.08 * features['연식(년)']) * \n",
    "                np.exp(-0.15 * features['주행거리(km)'] / 40000)\n",
    "            )\n",
    "            features['condition_multiplier'] = features['차량상태'].map({\n",
    "                'Brand New': 1.3,\n",
    "                'Nearly New': 1.15,\n",
    "                'Pre-Owned': 1.0\n",
    "            })\n",
    "            features['battery_efficiency'] = features['배터리용량'] / (features['주행거리(km)'] + 1000)\n",
    "            features['warranty_modifier'] = np.log1p(features['보증기간(년)']) * features['condition_multiplier']\n",
    "            \n",
    "        return features\n",
    "\n",
    "    def prepare_features(self, df, model_name=None, is_independent=False):\n",
    "        \"\"\"기본 특성 준비\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "        \n",
    "        # 기본 특성\n",
    "        feature_cols = [\n",
    "            '제조사_encoded', '모델_encoded', '구동방식_encoded', '차량상태_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)'\n",
    "        ]\n",
    "        \n",
    "        return features[feature_cols]\n",
    "\n",
    "    def prepare_improved_features(self, df, model_name):\n",
    "        \"\"\"개선된 특성 준비\"\"\"\n",
    "        # 이상치 처리\n",
    "        df = self.handle_outliers(df, model_name)\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df = self.handle_battery_missing(df, model_name)\n",
    "        \n",
    "        # 기본 특성 생성\n",
    "        features = self.prepare_features(df, model_name, is_independent=True)\n",
    "        \n",
    "        # 개선된 특성 추가\n",
    "        improved_features = self.create_improved_features(df, model_name)\n",
    "        \n",
    "        # 모델별 중요 특성 선택\n",
    "        if model_name == 'IONIQ':\n",
    "            additional_cols = [\n",
    "                'condition_encoded', 'distance_per_year', \n",
    "                'battery_age_interaction', 'warranty_value'\n",
    "            ]\n",
    "        elif model_name in ['TayCT', 'Tay']:\n",
    "            additional_cols = [\n",
    "                'premium_score', 'condition_value', \n",
    "                'battery_premium', 'age_penalty'\n",
    "            ]\n",
    "        elif model_name == 'MX':\n",
    "            additional_cols = [\n",
    "                'luxury_score', 'condition_multiplier',\n",
    "                'battery_efficiency', 'warranty_modifier'\n",
    "            ]\n",
    "        else:\n",
    "            additional_cols = []\n",
    "        \n",
    "        # 특성 결합\n",
    "        for col in additional_cols:\n",
    "            features[col] = improved_features[col]\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def train_model(self, X, y, model_config):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        rf = RandomForestRegressor(**model_config['rf_params'])\n",
    "        hgb = HistGradientBoostingRegressor(**model_config['hgb_params'])\n",
    "        \n",
    "        rf.fit(X, y)\n",
    "        hgb.fit(X, y)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb}\n",
    "\n",
    "    def predict_model(self, X, models, weights):\n",
    "        \"\"\"모델 예측\"\"\"\n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        \n",
    "        return weights['rf'] * rf_pred + weights['hgb'] * hgb_pred\n",
    "\n",
    "    def cv_evaluate(self, train_df):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        model_scores = {}\n",
    "        independent_models = set(self.independent_config.keys())\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(train_df), 1):\n",
    "            train_data = train_df.iloc[train_idx]\n",
    "            val_data = train_df.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros(len(val_data))\n",
    "            \n",
    "            # 독립 모델 예측\n",
    "            for model_name in independent_models:\n",
    "                train_mask = train_data['모델'] == model_name\n",
    "                val_mask = val_data['모델'] == model_name\n",
    "                \n",
    "                if sum(train_mask) > 0 and sum(val_mask) > 0:\n",
    "                    X_train = self.prepare_improved_features(\n",
    "                        train_data[train_mask],\n",
    "                        model_name=model_name\n",
    "                    )\n",
    "                    y_train = train_data[train_mask]['가격(백만원)']\n",
    "                    \n",
    "                    X_val = self.prepare_improved_features(\n",
    "                        val_data[val_mask],\n",
    "                        model_name=model_name\n",
    "                    )\n",
    "                    y_val = val_data[val_mask]['가격(백만원)']\n",
    "                    \n",
    "                    model = self.train_model(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        self.independent_config[model_name]\n",
    "                    )\n",
    "                    predictions = self.predict_model(\n",
    "                        X_val,\n",
    "                        model,\n",
    "                        self.independent_config[model_name]['weights']\n",
    "                    )\n",
    "                    \n",
    "                    fold_predictions[val_mask] = predictions\n",
    "                    \n",
    "                    model_rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                    if model_name not in model_scores:\n",
    "                        model_scores[model_name] = []\n",
    "                    model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 세그먼트 모델 예측\n",
    "            segment_data_train = train_data[~train_data['모델'].isin(independent_models)].copy()\n",
    "            segment_data_val = val_data[~val_data['모델'].isin(independent_models)].copy()\n",
    "            \n",
    "            if len(segment_data_train) > 0 and len(segment_data_val) > 0:\n",
    "                segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
    "                segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n",
    "                \n",
    "                for segment in range(1, 8):\n",
    "                    segment_mask_train = segment_data_train['segment'] == segment\n",
    "                    segment_mask_val = segment_data_val['segment'] == segment\n",
    "                    \n",
    "                    if sum(segment_mask_train) > 0 and sum(segment_mask_val) > 0:\n",
    "                        X_train = self.prepare_features(segment_data_train[segment_mask_train])\n",
    "                        y_train = segment_data_train[segment_mask_train]['가격(백만원)']\n",
    "                        \n",
    "                        X_val = self.prepare_features(segment_data_val[segment_mask_val])\n",
    "                        y_val = segment_data_val[segment_mask_val]['가격(백만원)']\n",
    "                        \n",
    "                        segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                        model = self.train_model(X_train, y_train, segment_config)\n",
    "                        predictions = self.predict_model(X_val, model, segment_config['weights'])\n",
    "                        \n",
    "                        # 세그먼트 예측값을 전체 예측값 배열에 할당\n",
    "                        val_indices = val_data.index[~val_data['모델'].isin(independent_models)]\n",
    "                        segment_indices = val_indices[segment_mask_val]\n",
    "                        fold_predictions[val_data.index.get_indexer(segment_indices)] = predictions\n",
    "                        \n",
    "                        # 모델별 성능 기록\n",
    "                        for model_name in segment_data_val[segment_mask_val]['모델'].unique():\n",
    "                            model_mask = segment_data_val[segment_mask_val]['모델'] == model_name\n",
    "                            if sum(model_mask) > 0:\n",
    "                                model_rmse = np.sqrt(mean_squared_error(\n",
    "                                    y_val[model_mask],\n",
    "                                    predictions[model_mask]\n",
    "                                ))\n",
    "                                if model_name not in model_scores:\n",
    "                                    model_scores[model_name] = []\n",
    "                                model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 전체 폴드 성능 계산\n",
    "            fold_rmse = np.sqrt(mean_squared_error(val_data['가격(백만원)'], fold_predictions))\n",
    "            fold_r2 = r2_score(val_data['가격(백만원)'], fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "            \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 모델별 RMSE ===\")\n",
    "        for model_name in sorted(model_scores.keys()):\n",
    "            print(f\"{model_name}: {np.mean(model_scores[model_name]):.4f}\")\n",
    "        \n",
    "        return cv_scores, model_scores\n",
    "\n",
    "    def fit(self, train_df, test_df=None):\n",
    "        \"\"\"전체 모델 학습\"\"\"\n",
    "        # 레이블 인코더 초기화\n",
    "        self.initialize_label_encoders(train_df, test_df)\n",
    "        \n",
    "        # 교차 검증 수행\n",
    "        cv_scores, model_scores = self.cv_evaluate(train_df)\n",
    "        \n",
    "        # 독립 모델 학습\n",
    "        for model_name in self.independent_config.keys():\n",
    "            model_data = train_df[train_df['모델'] == model_name]\n",
    "            \n",
    "            if len(model_data) > 0:\n",
    "                X = self.prepare_improved_features(model_data, model_name=model_name)\n",
    "                y = model_data['가격(백만원)']\n",
    "                \n",
    "                self.independent_models[model_name] = self.train_model(\n",
    "                    X, y,\n",
    "                    self.independent_config[model_name]\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 학습\n",
    "        segment_data = train_df[~train_df['모델'].isin(self.independent_config.keys())].copy()\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(segment_data[segment_mask])\n",
    "                    y = segment_data[segment_mask]['가격(백만원)']\n",
    "                    \n",
    "                    segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                    self.segment_models[segment] = self.train_model(X, y, segment_config)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        # 독립 모델 예측\n",
    "        for model_name, model in self.independent_models.items():\n",
    "            model_mask = test_df['모델'] == model_name\n",
    "            if sum(model_mask) > 0:\n",
    "                X = self.prepare_improved_features(\n",
    "                    test_df[model_mask],\n",
    "                    model_name=model_name\n",
    "                )\n",
    "                predictions[model_mask] = self.predict_model(\n",
    "                    X,\n",
    "                    model,\n",
    "                    self.independent_config[model_name]['weights']\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 예측\n",
    "        segment_data = test_df[~test_df['모델'].isin(self.independent_config.keys())].copy()\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment, model in self.segment_models.items():\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(segment_data[segment_mask])\n",
    "                    segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                    \n",
    "                    # 세그먼트 예측값을 전체 예측값 배열에 할당\n",
    "                    test_indices = test_df.index[~test_df['모델'].isin(self.independent_config.keys())]\n",
    "                    segment_indices = test_indices[segment_mask]\n",
    "                    predictions[test_df.index.get_indexer(segment_indices)] = self.predict_model(\n",
    "                        X,\n",
    "                        model,\n",
    "                        segment_config['weights']\n",
    "                    )\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 모델 초기화 및 학습\n",
    "    predictor = ImprovedHybridPredictor()\n",
    "    predictor.fit(train_data, test_data)\n",
    "    \n",
    "    # 예측 및 저장\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('improved_hybrid_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.3995, R2: 0.9986\n",
      "Fold 2 - RMSE: 1.4611, R2: 0.9985\n",
      "Fold 3 - RMSE: 1.3604, R2: 0.9986\n",
      "Fold 4 - RMSE: 1.2650, R2: 0.9988\n",
      "Fold 5 - RMSE: 1.2730, R2: 0.9987\n",
      "\n",
      "평균 RMSE: 1.3518 (+/- 0.1498)\n",
      "\n",
      "=== 모델별 RMSE ===\n",
      "EV6: 0.5933\n",
      "ID4: 0.6110\n",
      "ION5: 0.3265\n",
      "ION6: 0.3211\n",
      "IONIQ: 5.7835\n",
      "KNE: 0.5622\n",
      "M3: 0.4372\n",
      "MS: 0.6902\n",
      "MX: 0.7226\n",
      "MY: 0.6265\n",
      "Niro: 0.6026\n",
      "Q4eT: 0.3860\n",
      "RSeTGT: 0.3392\n",
      "Soul: 0.6050\n",
      "Tay: 2.9362\n",
      "TayCT: 3.4578\n",
      "TayGTS: 0.3297\n",
      "eT: 0.5251\n",
      "i3: 0.3384\n",
      "i5: 0.5954\n",
      "iX: 0.5870\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'가격(백만원)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '가격(백만원)'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 583\u001b[0m\n\u001b[0;32m    580\u001b[0m predictor\u001b[38;5;241m.\u001b[39mfit(train_data, test_data)\n\u001b[0;32m    582\u001b[0m \u001b[38;5;66;03m# 예측 및 저장\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    584\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m: test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions\n\u001b[0;32m    587\u001b[0m })\n\u001b[0;32m    589\u001b[0m submission\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimproved_hybrid_model_submission2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[110], line 539\u001b[0m, in \u001b[0;36mImprovedHybridPredictor.predict\u001b[1;34m(self, test_df)\u001b[0m\n\u001b[0;32m    537\u001b[0m     model_mask \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m모델\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m model_name\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(model_mask) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 539\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_improved_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m         predictions[model_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_model(\n\u001b[0;32m    544\u001b[0m             X,\n\u001b[0;32m    545\u001b[0m             model,\n\u001b[0;32m    546\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindependent_config[model_name][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    547\u001b[0m         )\n\u001b[0;32m    549\u001b[0m \u001b[38;5;66;03m# 세그먼트 모델 예측\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[110], line 338\u001b[0m, in \u001b[0;36mImprovedHybridPredictor.prepare_improved_features\u001b[1;34m(self, df, model_name)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"개선된 특성 준비\"\"\"\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# 이상치 처리\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_outliers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;66;03m# 결측치 처리\u001b[39;00m\n\u001b[0;32m    341\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_battery_missing(df, model_name)\n",
      "Cell \u001b[1;32mIn[110], line 132\u001b[0m, in \u001b[0;36mImprovedHybridPredictor.handle_outliers\u001b[1;34m(self, df, model_name)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIONIQ\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# IONIQ 모델의 이상치 처리\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m주행거리(km)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m배터리용량\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m--> 132\u001b[0m         Q1 \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.25\u001b[39m)\n\u001b[0;32m    133\u001b[0m         Q3 \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m0.75\u001b[39m)\n\u001b[0;32m    134\u001b[0m         IQR \u001b[38;5;241m=\u001b[39m Q3 \u001b[38;5;241m-\u001b[39m Q1\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: '가격(백만원)'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class ImprovedHybridPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.independent_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 독립 모델 설정\n",
    "        self.independent_config = {\n",
    "            'IONIQ': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 500,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2500,\n",
    "                    'learning_rate': 0.003,\n",
    "                    'max_depth': 8,\n",
    "                    'l2_regularization': 1.5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.65, 'hgb': 0.35}\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 600,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 3000,\n",
    "                    'learning_rate': 0.002,\n",
    "                    'max_depth': 7,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.75, 'hgb': 0.25}\n",
    "            },\n",
    "            'Tay': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 550,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2800,\n",
    "                    'learning_rate': 0.003,\n",
    "                    'max_depth': 8,\n",
    "                    'l2_regularization': 1.8,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            },\n",
    "            'MX': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 450,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2500,\n",
    "                    'learning_rate': 0.004,\n",
    "                    'max_depth': 7,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 세그먼트별 파라미터\n",
    "        self.segment_params = {\n",
    "            1: {  # 엔트리\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 200,\n",
    "                    'max_depth': 6,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 1500,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.6, 'hgb': 0.4}\n",
    "            },\n",
    "            6: {  # 프리미엄\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.7, 'hgb': 0.3}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def handle_outliers(self, df, model_name):\n",
    "        \"\"\"개선된 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            # IONIQ 모델의 이상치 처리\n",
    "            for col in ['주행거리(km)', '배터리용량', '가격(백만원)']:\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                \n",
    "                median_value = df[col].median()\n",
    "                if col == '주행거리(km)':  # 정수형 컬럼\n",
    "                    median_value = int(median_value)\n",
    "                df.loc[(df[col] < lower_bound) | (df[col] > upper_bound), col] = median_value\n",
    "        \n",
    "        elif model_name in ['TayCT', 'Tay', 'MX']:\n",
    "            # 고가 모델의 이상치 처리 (더 관대한 기준 적용)\n",
    "            for col in ['주행거리(km)', '배터리용량']:\n",
    "                Q1 = df[col].quantile(0.1)\n",
    "                Q3 = df[col].quantile(0.9)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 2 * IQR\n",
    "                upper_bound = Q3 + 2 * IQR\n",
    "                \n",
    "                median_value = df[col].median()\n",
    "                if col == '주행거리(km)':  # 정수형 컬럼\n",
    "                    median_value = int(median_value)\n",
    "                df.loc[(df[col] < lower_bound) | (df[col] > upper_bound), col] = median_value\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def handle_battery_missing(self, df, model_name):\n",
    "        \"\"\"모델별 맞춤형 배터리용량 결측치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            # IONIQ: 차량상태별 평균으로 대체\n",
    "            for condition in ['Pre-Owned', 'Nearly New', 'Brand New']:\n",
    "                mask = (df['모델'] == 'IONIQ') & (df['차량상태'] == condition)\n",
    "                condition_mean = df.loc[mask & df['배터리용량'].notnull(), '배터리용량'].mean()\n",
    "                df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = condition_mean\n",
    "                \n",
    "        elif model_name in ['TayCT', 'Tay']:\n",
    "            # 주행거리 구간별로 처리\n",
    "            df.loc[df['모델'].isin(['TayCT', 'Tay']), 'distance_group'] = pd.qcut(\n",
    "                df.loc[df['모델'].isin(['TayCT', 'Tay']), '주행거리(km)'],\n",
    "                q=4,\n",
    "                labels=['very_low', 'low', 'medium', 'high']\n",
    "            )\n",
    "            \n",
    "            for group in ['very_low', 'low', 'medium', 'high']:\n",
    "                for condition in ['Brand New', 'Nearly New', 'Pre-Owned']:\n",
    "                    mask = (df['모델'].isin(['TayCT', 'Tay'])) & \\\n",
    "                           (df['distance_group'] == group) & \\\n",
    "                           (df['차량상태'] == condition)\n",
    "                    \n",
    "                    group_mean = df.loc[mask & df['배터리용량'].notnull(), '배터리용량'].mean()\n",
    "                    if pd.isna(group_mean):\n",
    "                        group_mean = df.loc[df['모델'].isin(['TayCT', 'Tay']), '배터리용량'].mean()\n",
    "                    \n",
    "                    df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = group_mean\n",
    "            \n",
    "            df = df.drop('distance_group', axis=1)\n",
    "            \n",
    "        elif model_name == 'MX':\n",
    "            # MX: 차량상태와 연식 기반 처리\n",
    "            mx_years = df.loc[df['모델'] == 'MX', '연식(년)']\n",
    "            # 연식의 고유값이 3개 미만인 경우 직접 구간 설정\n",
    "            if len(mx_years.unique()) < 3:\n",
    "                df.loc[df['모델'] == 'MX', 'age_group'] = mx_years.apply(\n",
    "                    lambda x: 'new' if x <= 1 else ('medium' if x <= 3 else 'old')\n",
    "                )\n",
    "            else:\n",
    "                try:\n",
    "                    df.loc[df['모델'] == 'MX', 'age_group'] = pd.qcut(\n",
    "                        mx_years,\n",
    "                        q=3,\n",
    "                        labels=['new', 'medium', 'old'],\n",
    "                        duplicates='drop'\n",
    "                    )\n",
    "                except ValueError:\n",
    "                    # qcut이 실패하면 cut 사용\n",
    "                    df.loc[df['모델'] == 'MX', 'age_group'] = pd.cut(\n",
    "                        mx_years,\n",
    "                        bins=3,\n",
    "                        labels=['new', 'medium', 'old']\n",
    "                    )\n",
    "            \n",
    "            for age_group in ['new', 'medium', 'old']:\n",
    "                for condition in ['Brand New', 'Nearly New', 'Pre-Owned']:\n",
    "                    mask = (df['모델'] == 'MX') & \\\n",
    "                           (df['age_group'] == age_group) & \\\n",
    "                           (df['차량상태'] == condition)\n",
    "                    \n",
    "                    group_mean = df.loc[mask & df['배터리용량'].notnull(), '배터리용량'].mean()\n",
    "                    if pd.isna(group_mean):\n",
    "                        group_mean = df.loc[df['모델'] == 'MX', '배터리용량'].mean()\n",
    "                    \n",
    "                    df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = group_mean\n",
    "            \n",
    "            df = df.drop('age_group', axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def initialize_label_encoders(self, train_df, test_df=None):\n",
    "        \"\"\"레이블 인코더 초기화\"\"\"\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            self.label_encoders[col] = LabelEncoder()\n",
    "            unique_values = set(train_df[col].unique())\n",
    "            \n",
    "            if test_df is not None:\n",
    "                unique_values.update(test_df[col].unique())\n",
    "            \n",
    "            self.label_encoders[col].fit(sorted(list(unique_values)))\n",
    "\n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def create_improved_features(self, df, model_name):\n",
    "        \"\"\"개선된 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 공통 특성\n",
    "        features['age_warranty_ratio'] = features['연식(년)'] / features['보증기간(년)'].replace(0, 0.1)\n",
    "        features['battery_distance_ratio'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            # IONIQ 특화 특성\n",
    "            features['condition_encoded'] = features['차량상태'].map({\n",
    "                'Brand New': 3,\n",
    "                'Nearly New': 2,\n",
    "                'Pre-Owned': 1\n",
    "            })\n",
    "            features['distance_per_year'] = features['주행거리(km)'] / features['연식(년)'].replace(0, 1)\n",
    "            features['battery_age_interaction'] = features['배터리용량'] * np.exp(-0.1 * features['연식(년)'])\n",
    "            features['warranty_value'] = features['보증기간(년)'] * np.exp(-0.2 * features['주행거리(km)'] / 10000)\n",
    "            \n",
    "        elif model_name in ['TayCT', 'Tay']:\n",
    "            # 고가 모델 특화 특성\n",
    "            features['premium_score'] = (\n",
    "                (features['배터리용량'] / features['배터리용량'].mean()) * \n",
    "                np.exp(-0.05 * features['연식(년)']) * \n",
    "                np.exp(-0.1 * features['주행거리(km)'] / 50000)\n",
    "            )\n",
    "            features['condition_value'] = features['차량상태'].map({\n",
    "                'Brand New': 1.2,\n",
    "                'Nearly New': 1.1,\n",
    "                'Pre-Owned': 1.0\n",
    "            })\n",
    "            features['battery_premium'] = (features['배터리용량'] / features['배터리용량'].mean()) ** 2\n",
    "            features['age_penalty'] = np.exp(-0.15 * features['연식(년)'])\n",
    "            \n",
    "        elif model_name == 'MX':\n",
    "            # MX 특화 특성\n",
    "            features['luxury_score'] = (\n",
    "                (features['배터리용량'] / features['배터리용량'].max()) * \n",
    "                np.exp(-0.08 * features['연식(년)']) * \n",
    "                np.exp(-0.15 * features['주행거리(km)'] / 40000)\n",
    "            )\n",
    "            features['condition_multiplier'] = features['차량상태'].map({\n",
    "                'Brand New': 1.3,\n",
    "                'Nearly New': 1.15,\n",
    "                'Pre-Owned': 1.0\n",
    "            })\n",
    "            features['battery_efficiency'] = features['배터리용량'] / (features['주행거리(km)'] + 1000)\n",
    "            features['warranty_modifier'] = np.log1p(features['보증기간(년)']) * features['condition_multiplier']\n",
    "            \n",
    "        return features\n",
    "\n",
    "    def prepare_features(self, df, model_name=None, is_independent=False):\n",
    "        \"\"\"기본 특성 준비\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "        \n",
    "        # 기본 특성\n",
    "        feature_cols = [\n",
    "            '제조사_encoded', '모델_encoded', '구동방식_encoded', '차량상태_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)'\n",
    "        ]\n",
    "        \n",
    "        return features[feature_cols]\n",
    "\n",
    "    def prepare_improved_features(self, df, model_name):\n",
    "        \"\"\"개선된 특성 준비\"\"\"\n",
    "        # 이상치 처리\n",
    "        df = self.handle_outliers(df, model_name)\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df = self.handle_battery_missing(df, model_name)\n",
    "        \n",
    "        # 기본 특성 생성\n",
    "        features = self.prepare_features(df, model_name, is_independent=True)\n",
    "        \n",
    "        # 개선된 특성 추가\n",
    "        improved_features = self.create_improved_features(df, model_name)\n",
    "        \n",
    "        # 모델별 중요 특성 선택\n",
    "        if model_name == 'IONIQ':\n",
    "            additional_cols = [\n",
    "                'condition_encoded', 'distance_per_year', \n",
    "                'battery_age_interaction', 'warranty_value'\n",
    "            ]\n",
    "        elif model_name in ['TayCT', 'Tay']:\n",
    "            additional_cols = [\n",
    "                'premium_score', 'condition_value', \n",
    "                'battery_premium', 'age_penalty'\n",
    "            ]\n",
    "        elif model_name == 'MX':\n",
    "            additional_cols = [\n",
    "                'luxury_score', 'condition_multiplier',\n",
    "                'battery_efficiency', 'warranty_modifier'\n",
    "            ]\n",
    "        else:\n",
    "            additional_cols = []\n",
    "        \n",
    "        # 특성 결합\n",
    "        for col in additional_cols:\n",
    "            features[col] = improved_features[col]\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def train_model(self, X, y, model_config):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        rf = RandomForestRegressor(**model_config['rf_params'])\n",
    "        hgb = HistGradientBoostingRegressor(**model_config['hgb_params'])\n",
    "        \n",
    "        rf.fit(X, y)\n",
    "        hgb.fit(X, y)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb}\n",
    "\n",
    "    def predict_model(self, X, models, weights):\n",
    "        \"\"\"모델 예측\"\"\"\n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        \n",
    "        return weights['rf'] * rf_pred + weights['hgb'] * hgb_pred\n",
    "\n",
    "    def cv_evaluate(self, train_df):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        model_scores = {}\n",
    "        independent_models = set(self.independent_config.keys())\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(train_df), 1):\n",
    "            train_data = train_df.iloc[train_idx]\n",
    "            val_data = train_df.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros(len(val_data))\n",
    "            \n",
    "            # 독립 모델 예측\n",
    "            for model_name in independent_models:\n",
    "                train_mask = train_data['모델'] == model_name\n",
    "                val_mask = val_data['모델'] == model_name\n",
    "                \n",
    "                if sum(train_mask) > 0 and sum(val_mask) > 0:\n",
    "                    X_train = self.prepare_improved_features(\n",
    "                        train_data[train_mask],\n",
    "                        model_name=model_name\n",
    "                    )\n",
    "                    y_train = train_data[train_mask]['가격(백만원)']\n",
    "                    \n",
    "                    X_val = self.prepare_improved_features(\n",
    "                        val_data[val_mask],\n",
    "                        model_name=model_name\n",
    "                    )\n",
    "                    y_val = val_data[val_mask]['가격(백만원)']\n",
    "                    \n",
    "                    model = self.train_model(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        self.independent_config[model_name]\n",
    "                    )\n",
    "                    predictions = self.predict_model(\n",
    "                        X_val,\n",
    "                        model,\n",
    "                        self.independent_config[model_name]['weights']\n",
    "                    )\n",
    "                    \n",
    "                    fold_predictions[val_mask] = predictions\n",
    "                    \n",
    "                    model_rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                    if model_name not in model_scores:\n",
    "                        model_scores[model_name] = []\n",
    "                    model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 세그먼트 모델 예측\n",
    "            segment_data_train = train_data[~train_data['모델'].isin(independent_models)].copy()\n",
    "            segment_data_val = val_data[~val_data['모델'].isin(independent_models)].copy()\n",
    "            \n",
    "            if len(segment_data_train) > 0 and len(segment_data_val) > 0:\n",
    "                segment_data_train['segment'] = segment_data_train['모델'].apply(self.get_segment)\n",
    "                segment_data_val['segment'] = segment_data_val['모델'].apply(self.get_segment)\n",
    "                \n",
    "                for segment in range(1, 8):\n",
    "                    segment_mask_train = segment_data_train['segment'] == segment\n",
    "                    segment_mask_val = segment_data_val['segment'] == segment\n",
    "                    \n",
    "                    if sum(segment_mask_train) > 0 and sum(segment_mask_val) > 0:\n",
    "                        X_train = self.prepare_features(segment_data_train[segment_mask_train])\n",
    "                        y_train = segment_data_train[segment_mask_train]['가격(백만원)']\n",
    "                        \n",
    "                        X_val = self.prepare_features(segment_data_val[segment_mask_val])\n",
    "                        y_val = segment_data_val[segment_mask_val]['가격(백만원)']\n",
    "                        \n",
    "                        segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                        model = self.train_model(X_train, y_train, segment_config)\n",
    "                        predictions = self.predict_model(X_val, model, segment_config['weights'])\n",
    "                        \n",
    "                        # 세그먼트 예측값을 전체 예측값 배열에 할당\n",
    "                        val_indices = val_data.index[~val_data['모델'].isin(independent_models)]\n",
    "                        segment_indices = val_indices[segment_mask_val]\n",
    "                        fold_predictions[val_data.index.get_indexer(segment_indices)] = predictions\n",
    "                        \n",
    "                        # 모델별 성능 기록\n",
    "                        for model_name in segment_data_val[segment_mask_val]['모델'].unique():\n",
    "                            model_mask = segment_data_val[segment_mask_val]['모델'] == model_name\n",
    "                            if sum(model_mask) > 0:\n",
    "                                model_rmse = np.sqrt(mean_squared_error(\n",
    "                                    y_val[model_mask],\n",
    "                                    predictions[model_mask]\n",
    "                                ))\n",
    "                                if model_name not in model_scores:\n",
    "                                    model_scores[model_name] = []\n",
    "                                model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 전체 폴드 성능 계산\n",
    "            fold_rmse = np.sqrt(mean_squared_error(val_data['가격(백만원)'], fold_predictions))\n",
    "            fold_r2 = r2_score(val_data['가격(백만원)'], fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "            \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 모델별 RMSE ===\")\n",
    "        for model_name in sorted(model_scores.keys()):\n",
    "            print(f\"{model_name}: {np.mean(model_scores[model_name]):.4f}\")\n",
    "        \n",
    "        return cv_scores, model_scores\n",
    "\n",
    "    def fit(self, train_df, test_df=None):\n",
    "        \"\"\"전체 모델 학습\"\"\"\n",
    "        # 레이블 인코더 초기화\n",
    "        self.initialize_label_encoders(train_df, test_df)\n",
    "        \n",
    "        # 교차 검증 수행\n",
    "        cv_scores, model_scores = self.cv_evaluate(train_df)\n",
    "        \n",
    "        # 독립 모델 학습\n",
    "        for model_name in self.independent_config.keys():\n",
    "            model_data = train_df[train_df['모델'] == model_name]\n",
    "            \n",
    "            if len(model_data) > 0:\n",
    "                X = self.prepare_improved_features(model_data, model_name=model_name)\n",
    "                y = model_data['가격(백만원)']\n",
    "                \n",
    "                self.independent_models[model_name] = self.train_model(\n",
    "                    X, y,\n",
    "                    self.independent_config[model_name]\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 학습\n",
    "        segment_data = train_df[~train_df['모델'].isin(self.independent_config.keys())].copy()\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(segment_data[segment_mask])\n",
    "                    y = segment_data[segment_mask]['가격(백만원)']\n",
    "                    \n",
    "                    segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                    self.segment_models[segment] = self.train_model(X, y, segment_config)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        # 독립 모델 예측\n",
    "        for model_name, model in self.independent_models.items():\n",
    "            model_mask = test_df['모델'] == model_name\n",
    "            if sum(model_mask) > 0:\n",
    "                X = self.prepare_improved_features(\n",
    "                    test_df[model_mask],\n",
    "                    model_name=model_name\n",
    "                )\n",
    "                predictions[model_mask] = self.predict_model(\n",
    "                    X,\n",
    "                    model,\n",
    "                    self.independent_config[model_name]['weights']\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 예측\n",
    "        segment_data = test_df[~test_df['모델'].isin(self.independent_config.keys())].copy()\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment, model in self.segment_models.items():\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(segment_data[segment_mask])\n",
    "                    segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                    \n",
    "                    # 세그먼트 예측값을 전체 예측값 배열에 할당\n",
    "                    test_indices = test_df.index[~test_df['모델'].isin(self.independent_config.keys())]\n",
    "                    segment_indices = test_indices[segment_mask]\n",
    "                    predictions[test_df.index.get_indexer(segment_indices)] = self.predict_model(\n",
    "                        X,\n",
    "                        model,\n",
    "                        segment_config['weights']\n",
    "                    )\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 모델 초기화 및 학습\n",
    "    predictor = ImprovedHybridPredictor()\n",
    "    predictor.fit(train_data, test_data)\n",
    "    \n",
    "    # 예측 및 저장\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('improved_hybrid_model_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중...\n",
      "\n",
      "선택된 모델: ['IONIQ', 'TayCT', 'Tay']\n",
      "학습 데이터 크기: 836\n",
      "테스트 데이터 크기: 95\n",
      "모델 성능 평가 중...\n",
      "\n",
      "=== 교차 검증 결과 ===\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['usage_intensity', 'premium_factor', 'total_value'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 504\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m    503\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ImprovedSpecificPredictor()\n\u001b[1;32m--> 504\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_specific\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_specific\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# 예측\u001b[39;00m\n\u001b[0;32m    507\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(test_specific)\n",
      "Cell \u001b[1;32mIn[97], line 407\u001b[0m, in \u001b[0;36mImprovedSpecificPredictor.fit\u001b[1;34m(self, train_df, test_df)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"모델 학습\"\"\"\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모델 성능 평가 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m전체 데이터로 최종 모델 학습 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_configs\u001b[38;5;241m.\u001b[39mkeys():\n",
      "Cell \u001b[1;32mIn[97], line 352\u001b[0m, in \u001b[0;36mImprovedSpecificPredictor.evaluate\u001b[1;34m(self, train_df)\u001b[0m\n\u001b[0;32m    349\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_data(train_data, model_name)\n\u001b[0;32m    350\u001b[0m val_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_data(val_data, model_name)\n\u001b[1;32m--> 352\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m X_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_features(val_data, model_name)\n\u001b[0;32m    355\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_feature_columns(model_name)\n",
      "Cell \u001b[1;32mIn[97], line 284\u001b[0m, in \u001b[0;36mImprovedSpecificPredictor.create_features\u001b[1;34m(self, df, model_name)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalers:\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalers[model_name] \u001b[38;5;241m=\u001b[39m RobustScaler()\n\u001b[1;32m--> 284\u001b[0m     features[numeric_features] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalers[model_name]\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnumeric_features\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     features[numeric_features] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalers[model_name]\u001b[38;5;241m.\u001b[39mtransform(features[numeric_features])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['usage_intensity', 'premium_factor', 'total_value'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ImprovedSpecificPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scalers = {}\n",
    "        self.models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 모델별 파라미터 설정\n",
    "        self.model_configs = {\n",
    "            'IONIQ': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 1000,\n",
    "                    'max_depth': 12,\n",
    "                    'min_samples_split': 2,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 3500,\n",
    "                    'learning_rate': 0.002,\n",
    "                    'max_depth': 8,\n",
    "                    'l2_regularization': 1.0,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'gbm_params': {\n",
    "                    'n_estimators': 800,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 6,\n",
    "                    'subsample': 0.8,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.5, 'hgb': 0.3, 'gbm': 0.2}\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 1200,\n",
    "                    'max_depth': 14,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 4000,\n",
    "                    'learning_rate': 0.001,\n",
    "                    'max_depth': 10,\n",
    "                    'l2_regularization': 1.5,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'gbm_params': {\n",
    "                    'n_estimators': 1000,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 8,\n",
    "                    'subsample': 0.85,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.45, 'hgb': 0.35, 'gbm': 0.2}\n",
    "            },\n",
    "            'Tay': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 1100,\n",
    "                    'max_depth': 13,\n",
    "                    'min_samples_split': 2,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 3800,\n",
    "                    'learning_rate': 0.0015,\n",
    "                    'max_depth': 9,\n",
    "                    'l2_regularization': 1.2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'gbm_params': {\n",
    "                    'n_estimators': 900,\n",
    "                    'learning_rate': 0.009,\n",
    "                    'max_depth': 7,\n",
    "                    'subsample': 0.82,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.4, 'hgb': 0.4, 'gbm': 0.2}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def handle_outliers(self, df, cols, is_test=False):\n",
    "        \"\"\"이상치 처리 개선 함수\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        for col in cols:\n",
    "            Q1 = df[col].quantile(0.05)\n",
    "            Q3 = df[col].quantile(0.95)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # 이상치를 경계값으로 대체 (중앙값 대신)\n",
    "            df.loc[df[col] < lower_bound, col] = lower_bound\n",
    "            df.loc[df[col] > upper_bound, col] = upper_bound\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df, model_name, is_test=False):\n",
    "        \"\"\"개선된 데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 결측치 처리\n",
    "        numeric_cols = ['주행거리(km)', '배터리용량', '보증기간(년)', '연식(년)']\n",
    "        if not is_test:\n",
    "            numeric_cols.append('가격(백만원)')\n",
    "            \n",
    "        # 각 컬럼의 결측치를 해당 모델의 중앙값으로 채움\n",
    "        for col in numeric_cols:\n",
    "            if df[col].isna().any():\n",
    "                median_val = df[df['모델'] == model_name][col].median()\n",
    "                df[col] = df[col].fillna(median_val)\n",
    "        \n",
    "        # 범주형 변수 결측치 처리\n",
    "        categorical_cols = ['차량상태', '구동방식']\n",
    "        for col in categorical_cols:\n",
    "            if df[col].isna().any():\n",
    "                mode_val = df[df['모델'] == model_name][col].mode()[0]\n",
    "                df[col] = df[col].fillna(mode_val)\n",
    "        \n",
    "        # 모델별 특화 처리\n",
    "        if model_name == 'IONIQ':\n",
    "            df['km_group'] = pd.qcut(\n",
    "                df['주행거리(km)'],\n",
    "                q=6,\n",
    "                labels=['very_low', 'low', 'medium_low', 'medium_high', 'high', 'very_high']\n",
    "            )\n",
    "            \n",
    "            for state in df['차량상태'].unique():\n",
    "                for km_group in df['km_group'].unique():\n",
    "                    mask = (df['차량상태'] == state) & (df['km_group'] == km_group)\n",
    "                    if df.loc[mask, '배터리용량'].isna().any():\n",
    "                        median_val = df.loc[mask, '배터리용량'].median()\n",
    "                        df.loc[mask, '배터리용량'] = df.loc[mask, '배터리용량'].fillna(median_val)\n",
    "            \n",
    "            df = df.drop('km_group', axis=1)\n",
    "            \n",
    "        elif model_name in ['TayCT', 'Tay']:\n",
    "            # 주행거리와 연식의 복합 점수 계산\n",
    "            usage_score = df['주행거리(km)'] * df['연식(년)']\n",
    "            \n",
    "            try:\n",
    "                df['age_km_group'] = pd.qcut(\n",
    "                    usage_score,\n",
    "                    q=5,\n",
    "                    labels=['very_new', 'new', 'medium', 'old', 'very_old'],\n",
    "                    duplicates='drop'\n",
    "                )\n",
    "            except ValueError:\n",
    "                # qcut 실패시 수동으로 그룹 할당\n",
    "                score_median = usage_score.median()\n",
    "                df['age_km_group'] = np.where(\n",
    "                    usage_score <= score_median * 0.5, 'very_new',\n",
    "                    np.where(usage_score <= score_median * 0.8, 'new',\n",
    "                    np.where(usage_score <= score_median * 1.2, 'medium',\n",
    "                    np.where(usage_score <= score_median * 1.5, 'old', 'very_old')))\n",
    "                )\n",
    "            \n",
    "            for state in df['차량상태'].unique():\n",
    "                for group in df['age_km_group'].unique():\n",
    "                    mask = (df['차량상태'] == state) & (df['age_km_group'] == group)\n",
    "                    if df.loc[mask, '배터리용량'].isna().any():\n",
    "                        median_val = df.loc[mask, '배터리용량'].median()\n",
    "                        df.loc[mask, '배터리용량'] = df.loc[mask, '배터리용량'].fillna(median_val)\n",
    "            \n",
    "            df = df.drop('age_km_group', axis=1)\n",
    "\n",
    "        # 이상치 처리\n",
    "        df = self.handle_outliers(df, numeric_cols, is_test)\n",
    "        \n",
    "        # 최종 확인: 남은 NaN이 있다면 전체 중앙값으로 대체\n",
    "        for col in df.columns:\n",
    "            if df[col].isna().any():\n",
    "                if df[col].dtype.kind in 'biufc':  # 숫자형 데이터\n",
    "                    df[col] = df[col].fillna(df[col].median())\n",
    "                else:  # 범주형 데이터\n",
    "                    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_features(self, df, model_name):\n",
    "        \"\"\"개선된 특성 엔지니어링\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 안전한 나눗셈을 위한 함수\n",
    "        def safe_divide(a, b, default=0):\n",
    "            return np.where(b != 0, a / b, default)\n",
    "        \n",
    "        # 공통 특성\n",
    "        features['km_per_battery'] = safe_divide(features['주행거리(km)'], features['배터리용량'], 0)\n",
    "        features['efficiency_score'] = safe_divide(features['배터리용량'], (features['주행거리(km)'] + 1000), 0)\n",
    "        features['age_efficiency'] = safe_divide(features['efficiency_score'], (features['연식(년)'] + 1), 0)\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            # IONIQ 특화 특성\n",
    "            # 주행거리 관련 특성\n",
    "            features['km_per_year'] = safe_divide(features['주행거리(km)'], np.maximum(features['연식(년)'], 1))\n",
    "            features['km_normalized'] = features['주행거리(km)'] / features['주행거리(km)'].mean()\n",
    "            features['km_log'] = np.log1p(features['주행거리(km)'])\n",
    "            \n",
    "            # 배터리 관련 특성\n",
    "            features['battery_normalized'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            features['battery_health'] = features['battery_normalized'] * np.exp(-0.1 * features['연식(년)'])\n",
    "            features['battery_efficiency'] = safe_divide(features['배터리용량'], features['주행거리(km)'] + 1000)\n",
    "            \n",
    "            # 차량 상태 관련 특성\n",
    "            condition_weights = {\n",
    "                'Brand New': 1.3,\n",
    "                'Nearly New': 1.15,\n",
    "                'Pre-Owned': 1.0\n",
    "            }\n",
    "            features['condition_score'] = features['차량상태'].map(condition_weights)\n",
    "            \n",
    "            # 연식 관련 특성\n",
    "            features['age_factor'] = np.exp(-0.15 * features['연식(년)'])\n",
    "            features['age_squared'] = features['연식(년)'] ** 2\n",
    "            \n",
    "            # 보증 관련 특성\n",
    "            features['warranty_ratio'] = safe_divide(features['보증기간(년)'], features['연식(년)'] + 1)\n",
    "            features['warranty_value'] = features['보증기간(년)'] * features['condition_score']\n",
    "            \n",
    "            # 복합 특성\n",
    "            features['value_score'] = (\n",
    "                features['battery_health'] * \n",
    "                (1.5 - features['km_normalized']) * \n",
    "                features['condition_score'] * \n",
    "                features['age_factor'] * \n",
    "                (1 + features['warranty_ratio'])\n",
    "            )\n",
    "            features['premium_index'] = (\n",
    "                features['battery_efficiency'] * \n",
    "                features['condition_score'] * \n",
    "                np.exp(-0.2 * features['km_normalized']) * \n",
    "                features['warranty_value']\n",
    "            )\n",
    "            \n",
    "        elif model_name == 'TayCT':\n",
    "            # TayCT 특화 특성\n",
    "            features['luxury_factor'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            features['age_penalty'] = np.exp(-0.2 * features['연식(년)'])\n",
    "            features['usage_penalty'] = np.exp(-0.15 * features['주행거리(km)'] / 40000)\n",
    "            features['condition_bonus'] = features['차량상태'].map({\n",
    "                'Brand New': 1.3,\n",
    "                'Nearly New': 1.15,\n",
    "                'Pre-Owned': 1.0\n",
    "            })\n",
    "            features['total_score'] = (features['luxury_factor'] * \n",
    "                                     features['age_penalty'] * \n",
    "                                     features['usage_penalty'] * \n",
    "                                     features['condition_bonus'])\n",
    "            \n",
    "        elif model_name == 'Tay':\n",
    "            # Tay 특화 특성\n",
    "            features['battery_premium'] = features['배터리용량'] / features['배터리용량'].max()\n",
    "            features['mileage_factor'] = 1 / (1 + features['주행거리(km)'] / 80000)\n",
    "            features['age_factor'] = np.exp(-0.25 * features['연식(년)'])\n",
    "            features['warranty_value'] = np.log1p(features['보증기간(년)']) * features['age_factor']\n",
    "            features['total_premium'] = (features['battery_premium'] * \n",
    "                                       features['mileage_factor'] * \n",
    "                                       features['warranty_value'])\n",
    "\n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['차량상태', '구동방식']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(features[col])\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "\n",
    "        # 스케일링 적용\n",
    "        numeric_features = self.get_feature_columns(model_name)\n",
    "        if model_name not in self.scalers:\n",
    "            self.scalers[model_name] = RobustScaler()\n",
    "            features[numeric_features] = self.scalers[model_name].fit_transform(features[numeric_features])\n",
    "        else:\n",
    "            features[numeric_features] = self.scalers[model_name].transform(features[numeric_features])\n",
    "\n",
    "        return features\n",
    "\n",
    "    def get_feature_columns(self, model_name):\n",
    "        \"\"\"모델별 특성 컬럼 정의\"\"\"\n",
    "        common_cols = ['배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)', \n",
    "                      '차량상태_encoded', '구동방식_encoded', \n",
    "                      'km_per_battery', 'efficiency_score', 'age_efficiency']\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            return common_cols + ['km_per_year', 'battery_health', 'usage_intensity', \n",
    "                                'premium_factor', 'total_value']\n",
    "        elif model_name == 'TayCT':\n",
    "            return common_cols + ['luxury_factor', 'age_penalty', 'usage_penalty',\n",
    "                                'condition_bonus', 'total_score']\n",
    "        elif model_name == 'Tay':\n",
    "            return common_cols + ['battery_premium', 'mileage_factor', 'age_factor',\n",
    "                                'warranty_value', 'total_premium']\n",
    "        \n",
    "        return common_cols\n",
    "\n",
    "    def train_model(self, X, y, model_config):\n",
    "        \"\"\"개선된 모델 학습\"\"\"\n",
    "        rf = RandomForestRegressor(**model_config['rf_params'])\n",
    "        hgb = HistGradientBoostingRegressor(**model_config['hgb_params'])\n",
    "        gbm = GradientBoostingRegressor(**model_config['gbm_params'])\n",
    "        \n",
    "        rf.fit(X, y)\n",
    "        hgb.fit(X, y)\n",
    "        gbm.fit(X, y)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb, 'gbm': gbm}\n",
    "\n",
    "    def predict_model(self, X, models, weights):\n",
    "        \"\"\"앙상블 예측\"\"\"\n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        gbm_pred = models['gbm'].predict(X)\n",
    "        \n",
    "        return (weights['rf'] * rf_pred + \n",
    "                weights['hgb'] * hgb_pred + \n",
    "                weights['gbm'] * gbm_pred)\n",
    "\n",
    "    def evaluate(self, train_df):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        results = {}\n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        \n",
    "        for model_name in self.model_configs.keys():\n",
    "            model_data = train_df[train_df['모델'] == model_name].copy()\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            fold_scores = []\n",
    "            fold_predictions = []\n",
    "            fold_actuals = []\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(self.kf.split(model_data), 1):\n",
    "                train_data = model_data.iloc[train_idx]\n",
    "                val_data = model_data.iloc[val_idx]\n",
    "                \n",
    "                # 전처리 및 특성 생성\n",
    "                train_data = self.preprocess_data(train_data, model_name)\n",
    "                val_data = self.preprocess_data(val_data, model_name)\n",
    "                \n",
    "                X_train = self.create_features(train_data, model_name)\n",
    "                X_val = self.create_features(val_data, model_name)\n",
    "                \n",
    "                feature_cols = self.get_feature_columns(model_name)\n",
    "                X_train = X_train[feature_cols]\n",
    "                X_val = X_val[feature_cols]\n",
    "                \n",
    "                y_train = train_data['가격(백만원)']\n",
    "                y_val = val_data['가격(백만원)']\n",
    "                \n",
    "                # 모델 학습 및 예측\n",
    "                model = self.train_model(X_train, y_train, self.model_configs[model_name])\n",
    "                predictions = self.predict_model(X_val, model, self.model_configs[model_name]['weights'])\n",
    "                \n",
    "                rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                r2 = r2_score(y_val, predictions)\n",
    "                \n",
    "                fold_scores.append({\n",
    "                    'rmse': rmse,\n",
    "                    'r2': r2\n",
    "                })\n",
    "                fold_predictions.extend(predictions)\n",
    "                fold_actuals.extend(y_val)\n",
    "                \n",
    "                print(f\"{model_name} - Fold {fold} - RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "            \n",
    "            # 모델별 평균 성능 계산\n",
    "            avg_rmse = np.mean([score['rmse'] for score in fold_scores])\n",
    "            avg_r2 = np.mean([score['r2'] for score in fold_scores])\n",
    "            std_rmse = np.std([score['rmse'] for score in fold_scores])\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'avg_rmse': avg_rmse,\n",
    "                'avg_r2': avg_r2,\n",
    "                'std_rmse': std_rmse,\n",
    "                'predictions': fold_predictions,\n",
    "                'actuals': fold_actuals\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{model_name} 최종 성능:\")\n",
    "            print(f\"평균 RMSE: {avg_rmse:.4f} (+/- {std_rmse*2:.4f})\")\n",
    "            print(f\"평균 R2: {avg_r2:.4f}\")\n",
    "            \n",
    "            # 오차 분석\n",
    "            errors = np.array(fold_predictions) - np.array(fold_actuals)\n",
    "            print(f\"평균 오차: {np.mean(errors):.4f}\")\n",
    "            print(f\"오차 표준편차: {np.std(errors):.4f}\")\n",
    "            print(f\"최대 오차: {np.max(np.abs(errors)):.4f}\")\n",
    "            print(\"=\"*50)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def fit(self, train_df, test_df=None):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        print(\"모델 성능 평가 중...\")\n",
    "        self.evaluation_results = self.evaluate(train_df)\n",
    "        \n",
    "        print(\"\\n전체 데이터로 최종 모델 학습 중...\")\n",
    "        for model_name in self.model_configs.keys():\n",
    "            model_data = train_df[train_df['모델'] == model_name].copy()\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n{model_name} 모델 학습:\")\n",
    "            # 데이터 전처리\n",
    "            model_data = self.preprocess_data(model_data, model_name)\n",
    "            \n",
    "            # 특성 생성\n",
    "            X = self.create_features(model_data, model_name)\n",
    "            \n",
    "            # 특성 선택\n",
    "            feature_cols = self.get_feature_columns(model_name)\n",
    "            X = X[feature_cols]\n",
    "            y = model_data['가격(백만원)']\n",
    "            \n",
    "            # 모델 학습\n",
    "            print(f\"{len(feature_cols)}개 특성으로 학습 중...\")\n",
    "            self.models[model_name] = self.train_model(\n",
    "                X, y,\n",
    "                self.model_configs[model_name]\n",
    "            )\n",
    "            print(f\"{model_name} 모델 학습 완료\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        predictions = {}\n",
    "        print(\"\\n테스트 데이터 예측 중...\")\n",
    "        \n",
    "        for model_name in self.model_configs.keys():\n",
    "            model_data = test_df[test_df['모델'] == model_name].copy()\n",
    "            if len(model_data) == 0 or model_name not in self.models:\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n{model_name} 예측 중...\")\n",
    "            # 데이터 전처리\n",
    "            model_data = self.preprocess_data(model_data, model_name, is_test=True)\n",
    "            \n",
    "            # 특성 생성\n",
    "            X = self.create_features(model_data, model_name)\n",
    "            \n",
    "            # 특성 선택\n",
    "            feature_cols = self.get_feature_columns(model_name)\n",
    "            X = X[feature_cols]\n",
    "            \n",
    "            # 예측\n",
    "            model_predictions = self.predict_model(\n",
    "                X,\n",
    "                self.models[model_name],\n",
    "                self.model_configs[model_name]['weights']\n",
    "            )\n",
    "            \n",
    "            # 예측값 저장\n",
    "            for idx, pred in zip(model_data.index, model_predictions):\n",
    "                predictions[idx] = pred\n",
    "            \n",
    "            print(f\"{len(model_predictions)}개 데이터 예측 완료\")\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "def save_predictions(predictions, sample_submission_path, output_path):\n",
    "    \"\"\"예측 결과 저장\"\"\"\n",
    "    submission = pd.read_csv(sample_submission_path)\n",
    "    \n",
    "    # 예측값 업데이트\n",
    "    for idx, pred in predictions.items():\n",
    "        submission.loc[idx, '가격(백만원)'] = pred\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    print(f\"\\n예측 결과가 {output_path}에 저장되었습니다.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    print(\"데이터 로딩 중...\")\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 특정 모델만 선택\n",
    "    target_models = ['IONIQ', 'TayCT', 'Tay']\n",
    "    train_specific = train_data[train_data['모델'].isin(target_models)].copy()\n",
    "    test_specific = test_data[test_data['모델'].isin(target_models)].copy()\n",
    "    \n",
    "    print(f\"\\n선택된 모델: {target_models}\")\n",
    "    print(f\"학습 데이터 크기: {len(train_specific)}\")\n",
    "    print(f\"테스트 데이터 크기: {len(test_specific)}\")\n",
    "    \n",
    "    # 모델 학습\n",
    "    predictor = ImprovedSpecificPredictor()\n",
    "    predictor.fit(train_specific, test_specific)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = predictor.predict(test_specific)\n",
    "    \n",
    "    # 결과 저장\n",
    "    save_predictions(predictions, 'sample_submission.csv', 'improved_specific_model_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중...\n",
      "\n",
      "선택된 모델: ['IONIQ', 'TayCT', 'Tay']\n",
      "학습 데이터 크기: 836\n",
      "테스트 데이터 크기: 95\n",
      "모델 성능 평가 중...\n",
      "\n",
      "=== 교차 검증 결과 ===\n",
      "IONIQ - Fold 1 - RMSE: 5.3150, R2: -0.1541\n",
      "IONIQ - Fold 2 - RMSE: 5.3587, R2: 0.0026\n",
      "IONIQ - Fold 3 - RMSE: 4.8466, R2: -0.0329\n",
      "IONIQ - Fold 4 - RMSE: 6.6284, R2: -0.0059\n",
      "IONIQ - Fold 5 - RMSE: 4.9686, R2: -0.0210\n",
      "\n",
      "IONIQ 최종 성능:\n",
      "평균 RMSE: 5.4235 (+/- 1.2673)\n",
      "평균 R2: -0.0422\n",
      "평균 오차: -0.0531\n",
      "오차 표준편차: 5.4601\n",
      "최대 오차: 9.5873\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: 'Brand New'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:225\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_to_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:165\u001b[0m, in \u001b[0;36m_map_to_integer\u001b[1;34m(values, uniques)\u001b[0m\n\u001b[0;32m    164\u001b[0m table \u001b[38;5;241m=\u001b[39m _nandict({val: i \u001b[38;5;28;01mfor\u001b[39;00m i, val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(uniques)})\n\u001b[1;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:159\u001b[0m, in \u001b[0;36m_nandict.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnan_value\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Brand New'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 439\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[0;32m    438\u001b[0m predictor \u001b[38;5;241m=\u001b[39m ImprovedSpecificPredictor()\n\u001b[1;32m--> 439\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_specific\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# 예측\u001b[39;00m\n\u001b[0;32m    442\u001b[0m predictions \u001b[38;5;241m=\u001b[39m predictor\u001b[38;5;241m.\u001b[39mpredict(test_specific)\n",
      "Cell \u001b[1;32mIn[109], line 323\u001b[0m, in \u001b[0;36mImprovedSpecificPredictor.fit\u001b[1;34m(self, train_df, test_df)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"모델 학습\"\"\"\u001b[39;00m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m모델 성능 평가 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m전체 데이터로 최종 모델 학습 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_configs\u001b[38;5;241m.\u001b[39mkeys():\n",
      "Cell \u001b[1;32mIn[109], line 256\u001b[0m, in \u001b[0;36mImprovedSpecificPredictor.evaluate\u001b[1;34m(self, train_df)\u001b[0m\n\u001b[0;32m    253\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_data(train_data, model_name)\n\u001b[0;32m    254\u001b[0m val_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_data(val_data, model_name)\n\u001b[1;32m--> 256\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m X_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_features(val_data, model_name)\n\u001b[0;32m    259\u001b[0m feature_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_feature_columns(model_name)\n",
      "Cell \u001b[1;32mIn[109], line 190\u001b[0m, in \u001b[0;36mImprovedSpecificPredictor.create_features\u001b[1;34m(self, df, model_name)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_encoders[col] \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_encoders[col]\u001b[38;5;241m.\u001b[39mfit(features[col])\n\u001b[1;32m--> 190\u001b[0m     features[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_encoded\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_encoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m features\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniques\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_encode.py:227\u001b[0m, in \u001b[0;36m_encode\u001b[1;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _map_to_integer(values, uniques)\n\u001b[0;32m    226\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 227\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_unknown:\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: 'Brand New'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ImprovedSpecificPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scalers = {}\n",
    "        self.models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 모델별 파라미터 개선\n",
    "        self.model_configs = {\n",
    "            'IONIQ': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 1200,\n",
    "                    'max_depth': 15,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'max_features': 'sqrt',\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 4000,\n",
    "                    'learning_rate': 0.002,\n",
    "                    'max_depth': 10,\n",
    "                    'l2_regularization': 1.2,\n",
    "                    'early_stopping': True,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'gbm_params': {\n",
    "                    'n_estimators': 1000,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 8,\n",
    "                    'subsample': 0.85,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.45, 'hgb': 0.35, 'gbm': 0.2}\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 1500,\n",
    "                    'max_depth': 16,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'max_features': 'sqrt',\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 4500,\n",
    "                    'learning_rate': 0.001,\n",
    "                    'max_depth': 12,\n",
    "                    'l2_regularization': 1.5,\n",
    "                    'early_stopping': True,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'gbm_params': {\n",
    "                    'n_estimators': 1200,\n",
    "                    'learning_rate': 0.006,\n",
    "                    'max_depth': 9,\n",
    "                    'subsample': 0.8,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.4, 'hgb': 0.4, 'gbm': 0.2}\n",
    "            },\n",
    "            'Tay': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 1300,\n",
    "                    'max_depth': 14,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'max_features': 'sqrt',\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 4200,\n",
    "                    'learning_rate': 0.0015,\n",
    "                    'max_depth': 11,\n",
    "                    'l2_regularization': 1.3,\n",
    "                    'early_stopping': True,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'gbm_params': {\n",
    "                    'n_estimators': 1100,\n",
    "                    'learning_rate': 0.007,\n",
    "                    'max_depth': 8,\n",
    "                    'subsample': 0.82,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'weights': {'rf': 0.4, 'hgb': 0.4, 'gbm': 0.2}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def preprocess_data(self, df, model_name, is_test=False):\n",
    "        \"\"\"개선된 데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 결측치 처리\n",
    "        numeric_cols = ['주행거리(km)', '배터리용량', '보증기간(년)', '연식(년)']\n",
    "        if not is_test:\n",
    "            numeric_cols.append('가격(백만원)')\n",
    "            \n",
    "        # 모델별 특화 결측치 처리\n",
    "        for col in numeric_cols:\n",
    "            if df[col].isna().any():\n",
    "                # 차량상태별 중앙값으로 결측치 처리\n",
    "                for condition in df['차량상태'].unique():\n",
    "                    mask = df['차량상태'] == condition\n",
    "                    median_val = df.loc[mask, col].median()\n",
    "                    df.loc[mask & df[col].isna(), col] = median_val\n",
    "\n",
    "        # 범주형 변수 결측치 처리\n",
    "        categorical_cols = ['차량상태', '구동방식']\n",
    "        for col in categorical_cols:\n",
    "            if df[col].isna().any():\n",
    "                mode_val = df[df['모델'] == model_name][col].mode()[0]\n",
    "                df[col] = df[col].fillna(mode_val)\n",
    "\n",
    "        # 이상치 처리\n",
    "        for col in numeric_cols:\n",
    "            Q1 = df[col].quantile(0.05)\n",
    "            Q3 = df[col].quantile(0.95)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_features(self, df, model_name):\n",
    "        \"\"\"개선된 특성 엔지니어링\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 공통 특성\n",
    "        features['km_per_year'] = features['주행거리(km)'] / np.maximum(features['연식(년)'], 1)\n",
    "        features['battery_per_km'] = features['배터리용량'] / features['주행거리(km)'].clip(lower=1)\n",
    "        features['efficiency_score'] = features['배터리용량'] / (features['주행거리(km)'] + 1000)\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            # IONIQ 특화 특성\n",
    "            features['km_normalized'] = features['주행거리(km)'] / features['주행거리(km)'].mean()\n",
    "            features['battery_normalized'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            features['battery_health'] = features['battery_normalized'] * np.exp(-0.1 * features['연식(년)'])\n",
    "            features['usage_intensity'] = features['주행거리(km)'] / (features['연식(년)'] * 12000 + 1)\n",
    "            features['premium_factor'] = features['차량상태'].map({\n",
    "                'Brand New': 1.2,\n",
    "                'Nearly New': 1.1,\n",
    "                'Pre-Owned': 1.0\n",
    "            }).fillna(1.0)\n",
    "            features['total_value'] = (features['battery_health'] * \n",
    "                                     (1 - features['usage_intensity']) * \n",
    "                                     features['premium_factor'])\n",
    "            \n",
    "        elif model_name == 'TayCT':\n",
    "            # TayCT 특화 특성\n",
    "            features['luxury_factor'] = features['배터리용량'] / features['배터리용량'].mean()\n",
    "            features['age_penalty'] = np.exp(-0.2 * features['연식(년)'])\n",
    "            features['usage_penalty'] = np.exp(-0.15 * features['주행거리(km)'] / 40000)\n",
    "            features['condition_bonus'] = features['차량상태'].map({\n",
    "                'Brand New': 1.3,\n",
    "                'Nearly New': 1.15,\n",
    "                'Pre-Owned': 1.0\n",
    "            }).fillna(1.0)\n",
    "            features['total_score'] = (features['luxury_factor'] * \n",
    "                                     features['age_penalty'] * \n",
    "                                     features['usage_penalty'] * \n",
    "                                     features['condition_bonus'])\n",
    "            \n",
    "        elif model_name == 'Tay':\n",
    "            # Tay 특화 특성\n",
    "            features['battery_premium'] = features['배터리용량'] / features['배터리용량'].max()\n",
    "            features['mileage_factor'] = 1 / (1 + features['주행거리(km)'] / 80000)\n",
    "            features['age_factor'] = np.exp(-0.25 * features['연식(년)'])\n",
    "            features['warranty_value'] = np.log1p(features['보증기간(년)']) * features['age_factor']\n",
    "            features['total_premium'] = (features['battery_premium'] * \n",
    "                                       features['mileage_factor'] * \n",
    "                                       features['warranty_value'])\n",
    "\n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['차량상태', '구동방식']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(features[col])\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "\n",
    "        return features\n",
    "\n",
    "    def get_feature_columns(self, model_name):\n",
    "        \"\"\"모델별 사용할 특성 컬럼 반환\"\"\"\n",
    "        common_cols = ['배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)', \n",
    "                      '차량상태_encoded', '구동방식_encoded', \n",
    "                      'km_per_year', 'battery_per_km', 'efficiency_score']\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            return common_cols + ['km_normalized', 'battery_normalized', 'battery_health',\n",
    "                                'usage_intensity', 'premium_factor', 'total_value']\n",
    "        elif model_name == 'TayCT':\n",
    "            return common_cols + ['luxury_factor', 'age_penalty', 'usage_penalty',\n",
    "                                'condition_bonus', 'total_score']\n",
    "        elif model_name == 'Tay':\n",
    "            return common_cols + ['battery_premium', 'mileage_factor', 'age_factor',\n",
    "                                'warranty_value', 'total_premium']\n",
    "        \n",
    "        return common_cols\n",
    "\n",
    "    def train_model(self, X, y, model_config):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        rf = RandomForestRegressor(**model_config['rf_params'])\n",
    "        hgb = HistGradientBoostingRegressor(**model_config['hgb_params'])\n",
    "        gbm = GradientBoostingRegressor(**model_config['gbm_params'])\n",
    "        \n",
    "        rf.fit(X, y)\n",
    "        hgb.fit(X, y)\n",
    "        gbm.fit(X, y)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb, 'gbm': gbm}\n",
    "\n",
    "    def predict_model(self, X, models, weights):\n",
    "        \"\"\"앙상블 예측\"\"\"\n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        gbm_pred = models['gbm'].predict(X)\n",
    "        \n",
    "        return (weights['rf'] * rf_pred + \n",
    "                weights['hgb'] * hgb_pred + \n",
    "                weights['gbm'] * gbm_pred)\n",
    "\n",
    "    def evaluate(self, train_df):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        results = {}\n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        \n",
    "        for model_name in self.model_configs.keys():\n",
    "            model_data = train_df[train_df['모델'] == model_name].copy()\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            fold_scores = []\n",
    "            fold_predictions = []\n",
    "            fold_actuals = []\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(self.kf.split(model_data), 1):\n",
    "                train_data = model_data.iloc[train_idx]\n",
    "                val_data = model_data.iloc[val_idx]\n",
    "                \n",
    "                # 전처리 및 특성 생성\n",
    "                train_data = self.preprocess_data(train_data, model_name)\n",
    "                val_data = self.preprocess_data(val_data, model_name)\n",
    "                \n",
    "                X_train = self.create_features(train_data, model_name)\n",
    "                X_val = self.create_features(val_data, model_name)\n",
    "                \n",
    "                feature_cols = self.get_feature_columns(model_name)\n",
    "                X_train = X_train[feature_cols]\n",
    "                X_val = X_val[feature_cols]\n",
    "                \n",
    "                y_train = train_data['가격(백만원)']\n",
    "                y_val = val_data['가격(백만원)']\n",
    "                \n",
    "                # 스케일링 적용\n",
    "                if model_name not in self.scalers:\n",
    "                    self.scalers[model_name] = RobustScaler()\n",
    "                    X_train = pd.DataFrame(\n",
    "                        self.scalers[model_name].fit_transform(X_train),\n",
    "                        columns=X_train.columns\n",
    "                    )\n",
    "                X_val = pd.DataFrame(\n",
    "                    self.scalers[model_name].transform(X_val),\n",
    "                    columns=X_val.columns\n",
    "                )\n",
    "                \n",
    "                # 모델 학습 및 예측\n",
    "                model = self.train_model(X_train, y_train, self.model_configs[model_name])\n",
    "                predictions = self.predict_model(X_val, model, self.model_configs[model_name]['weights'])\n",
    "                \n",
    "                rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                r2 = r2_score(y_val, predictions)\n",
    "                \n",
    "                fold_scores.append({\n",
    "                    'rmse': rmse,\n",
    "                    'r2': r2\n",
    "                })\n",
    "                fold_predictions.extend(predictions)\n",
    "                fold_actuals.extend(y_val)\n",
    "                \n",
    "                print(f\"{model_name} - Fold {fold} - RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "            \n",
    "            # 모델별 평균 성능 계산\n",
    "            avg_rmse = np.mean([score['rmse'] for score in fold_scores])\n",
    "            avg_r2 = np.mean([score['r2'] for score in fold_scores])\n",
    "            std_rmse = np.std([score['rmse'] for score in fold_scores])\n",
    "            \n",
    "            results[model_name] = {\n",
    "                'avg_rmse': avg_rmse,\n",
    "                'avg_r2': avg_r2,\n",
    "                'std_rmse': std_rmse,\n",
    "                'predictions': fold_predictions,\n",
    "                'actuals': fold_actuals\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{model_name} 최종 성능:\")\n",
    "            print(f\"평균 RMSE: {avg_rmse:.4f} (+/- {std_rmse*2:.4f})\")\n",
    "            print(f\"평균 R2: {avg_r2:.4f}\")\n",
    "            \n",
    "            # 오차 분석\n",
    "            errors = np.array(fold_predictions) - np.array(fold_actuals)\n",
    "            print(f\"평균 오차: {np.mean(errors):.4f}\")\n",
    "            print(f\"오차 표준편차: {np.std(errors):.4f}\")\n",
    "            print(f\"최대 오차: {np.max(np.abs(errors)):.4f}\")\n",
    "            print(\"=\"*50)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    def fit(self, train_df, test_df=None):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        print(\"모델 성능 평가 중...\")\n",
    "        self.evaluation_results = self.evaluate(train_df)\n",
    "        \n",
    "        print(\"\\n전체 데이터로 최종 모델 학습 중...\")\n",
    "        for model_name in self.model_configs.keys():\n",
    "            model_data = train_df[train_df['모델'] == model_name].copy()\n",
    "            if len(model_data) == 0:\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\n{model_name} 모델 학습:\")\n",
    "            # 데이터 전처리\n",
    "            model_data = self.preprocess_data(model_data, model_name)\n",
    "            \n",
    "            # 특성 생성\n",
    "            X = self.create_features(model_data, model_name)\n",
    "            \n",
    "            # 특성 선택\n",
    "            feature_cols = self.get_feature_columns(model_name)\n",
    "            X = X[feature_cols]\n",
    "            \n",
    "            # 스케일링 적용\n",
    "            if model_name not in self.scalers:\n",
    "                self.scalers[model_name] = RobustScaler()\n",
    "                X = pd.DataFrame(\n",
    "                    self.scalers[model_name].fit_transform(X),\n",
    "                    columns=X.columns\n",
    "                )\n",
    "            else:\n",
    "                X = pd.DataFrame(\n",
    "                    self.scalers[model_name].transform(X),\n",
    "                    columns=X.columns\n",
    "                )\n",
    "            \n",
    "            y = model_data['가격(백만원)']\n",
    "            \n",
    "            # 모델 학습\n",
    "            print(f\"{len(feature_cols)}개 특성으로 학습 중...\")\n",
    "            self.models[model_name] = self.train_model(\n",
    "                X, y,\n",
    "                self.model_configs[model_name]\n",
    "            )\n",
    "            print(f\"{model_name} 모델 학습 완료\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        predictions = {}\n",
    "        print(\"\\n테스트 데이터 예측 중...\")\n",
    "        \n",
    "        for model_name in self.model_configs.keys():\n",
    "            model_data = test_df[test_df['모델'] == model_name].copy()\n",
    "            if len(model_data) == 0 or model_name not in self.models:\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\n{model_name} 예측 중...\")\n",
    "            # 데이터 전처리\n",
    "            model_data = self.preprocess_data(model_data, model_name, is_test=True)\n",
    "            \n",
    "            # 특성 생성\n",
    "            X = self.create_features(model_data, model_name)\n",
    "            \n",
    "            # 특성 선택\n",
    "            feature_cols = self.get_feature_columns(model_name)\n",
    "            X = X[feature_cols]\n",
    "            \n",
    "            # 스케일링 적용\n",
    "            X = pd.DataFrame(\n",
    "                self.scalers[model_name].transform(X),\n",
    "                columns=X.columns\n",
    "            )\n",
    "            \n",
    "            # 예측\n",
    "            model_predictions = self.predict_model(\n",
    "                X,\n",
    "                self.models[model_name],\n",
    "                self.model_configs[model_name]['weights']\n",
    "            )\n",
    "            \n",
    "            # 예측값 저장\n",
    "            for idx, pred in zip(model_data.index, model_predictions):\n",
    "                predictions[idx] = pred\n",
    "            \n",
    "            print(f\"{len(model_predictions)}개 데이터 예측 완료\")\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "def save_predictions(predictions, sample_submission_path, output_path):\n",
    "    \"\"\"예측 결과 저장\"\"\"\n",
    "    submission = pd.read_csv(sample_submission_path)\n",
    "    \n",
    "    # 예측값 업데이트\n",
    "    for idx, pred in predictions.items():\n",
    "        submission.loc[idx, '가격(백만원)'] = pred\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission.to_csv(output_path, index=False)\n",
    "    print(f\"\\n예측 결과가 {output_path}에 저장되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    print(\"데이터 로딩 중...\")\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 특정 모델만 선택\n",
    "    target_models = ['IONIQ', 'TayCT', 'Tay']\n",
    "    train_specific = train_data[train_data['모델'].isin(target_models)].copy()\n",
    "    test_specific = test_data[test_data['모델'].isin(target_models)].copy()\n",
    "    \n",
    "    print(f\"\\n선택된 모델: {target_models}\")\n",
    "    print(f\"학습 데이터 크기: {len(train_specific)}\")\n",
    "    print(f\"테스트 데이터 크기: {len(test_specific)}\")\n",
    "    \n",
    "    # 모델 학습\n",
    "    predictor = ImprovedSpecificPredictor()\n",
    "    predictor.fit(train_specific)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = predictor.predict(test_specific)\n",
    "    \n",
    "    # 결과 저장\n",
    "    save_predictions(predictions, 'sample_submission.csv', 'improved_specific_model_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4249, R2: 0.9985\n",
      "Fold 2 - RMSE: 1.4824, R2: 0.9984\n",
      "Fold 3 - RMSE: 1.3611, R2: 0.9986\n",
      "Fold 4 - RMSE: 1.2330, R2: 0.9989\n",
      "Fold 5 - RMSE: 1.3081, R2: 0.9986\n",
      "\n",
      "평균 RMSE: 1.3619 (+/- 0.1744)\n",
      "\n",
      "=== 모델별 RMSE ===\n",
      "IONIQ: 5.7148\n",
      "MX: 0.8373\n",
      "Tay: 2.8360\n",
      "TayCT: 3.6508\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class EnhancedHybridPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.independent_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 독립 모델 설정\n",
    "        self.independent_config = {\n",
    "            'IONIQ': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 500,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2500,\n",
    "                    'learning_rate': 0.003,\n",
    "                    'max_depth': 8,\n",
    "                    'l2_regularization': 1.5,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 600,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 3000,\n",
    "                    'learning_rate': 0.002,\n",
    "                    'max_depth': 7,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            'Tay': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 550,\n",
    "                    'max_depth': 8,\n",
    "                    'min_samples_split': 3,\n",
    "                    'min_samples_leaf': 2,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2800,\n",
    "                    'learning_rate': 0.003,\n",
    "                    'max_depth': 8,\n",
    "                    'l2_regularization': 1.8,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            'MX': {\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 450,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2500,\n",
    "                    'learning_rate': 0.004,\n",
    "                    'max_depth': 7,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # 세그먼트별 파라미터\n",
    "        self.segment_params = {\n",
    "            1: {  # 엔트리\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 200,\n",
    "                    'max_depth': 6,\n",
    "                    'min_samples_split': 5,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 1500,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 5,\n",
    "                    'l2_regularization': 2.0,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            },\n",
    "            6: {  # 프리미엄\n",
    "                'rf_params': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': 7,\n",
    "                    'min_samples_split': 4,\n",
    "                    'min_samples_leaf': 3,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'hgb_params': {\n",
    "                    'max_iter': 2000,\n",
    "                    'learning_rate': 0.008,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 2.5,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get_model_weights(self, model_name, has_missing=False):\n",
    "        \"\"\"모델별 가중치 결정\"\"\"\n",
    "        if model_name in ['TayCT', 'Tay']:\n",
    "            if has_missing:\n",
    "                return {'rf': 0.8, 'hgb': 0.2}\n",
    "            return {'rf': 0.6, 'hgb': 0.4}\n",
    "        elif model_name == 'IONIQ':\n",
    "            return {'rf': 0.7, 'hgb': 0.3}\n",
    "        elif model_name == 'MX':\n",
    "            return {'rf': 0.75, 'hgb': 0.25}\n",
    "        else:  # 기본 세그먼트 모델\n",
    "            return {'rf': 0.65, 'hgb': 0.35}\n",
    "\n",
    "    def handle_outliers(self, df, model_name):\n",
    "        \"\"\"개선된 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        if model_name == 'IONIQ':\n",
    "            for col in ['주행거리(km)', '배터리용량']:\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                \n",
    "                df[col] = df[col].clip(lower_bound, upper_bound)\n",
    "                \n",
    "        elif model_name in ['TayCT', 'Tay']:\n",
    "            # 주행거리가 매우 낮은 Brand New 차량은 별도 처리\n",
    "            brand_new_mask = (df['차량상태'] == 'Brand New') & (df['주행거리(km)'] <= 5000)\n",
    "            \n",
    "            for col in ['주행거리(km)', '배터리용량']:\n",
    "                # Brand New 차량 외 처리\n",
    "                non_new_mask = ~brand_new_mask\n",
    "                Q1 = df.loc[non_new_mask, col].quantile(0.1)\n",
    "                Q3 = df.loc[non_new_mask, col].quantile(0.9)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 2 * IQR\n",
    "                upper_bound = Q3 + 2 * IQR\n",
    "                \n",
    "                df.loc[non_new_mask, col] = df.loc[non_new_mask, col].clip(lower_bound, upper_bound)\n",
    "        \n",
    "        elif model_name == 'MX':\n",
    "            for col in ['주행거리(km)', '배터리용량']:\n",
    "                Q1 = df[col].quantile(0.1)\n",
    "                Q3 = df[col].quantile(0.9)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 2 * IQR\n",
    "                upper_bound = Q3 + 2 * IQR\n",
    "                \n",
    "                df[col] = df[col].clip(lower_bound, upper_bound)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def handle_battery_missing(self, df, model_name):\n",
    "        \"\"\"개선된 배터리용량 결측치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        if model_name in ['TayCT', 'Tay']:\n",
    "            # 주행거리 기반 처리\n",
    "            df.loc[(df['차량상태'] == 'Brand New') & \n",
    "                  (df['주행거리(km)'] <= 10000) & \n",
    "                  (df['배터리용량'].isnull()), '배터리용량'] = 76.093  # Nearly New의 평균값\n",
    "                  \n",
    "            # 나머지 결측치 처리\n",
    "            df.loc[df['배터리용량'].isnull(), '배터리용량'] = \\\n",
    "                df[df['배터리용량'].notnull()]['배터리용량'].mean()\n",
    "                \n",
    "        elif model_name == 'IONIQ':\n",
    "            for condition in ['Pre-Owned', 'Nearly New', 'Brand New']:\n",
    "                mask = (df['차량상태'] == condition)\n",
    "                mean_value = df[mask & df['배터리용량'].notnull()]['배터리용량'].mean()\n",
    "                if pd.isna(mean_value):  # 해당 상태의 평균을 구할 수 없는 경우\n",
    "                    mean_value = df[df['배터리용량'].notnull()]['배터리용량'].mean()\n",
    "                df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = mean_value\n",
    "                \n",
    "        elif model_name == 'MX':\n",
    "            # 주행거리 구간별 처리\n",
    "            conditions = [\n",
    "                (df['주행거리(km)'] <= 10000),  # Brand New\n",
    "                (df['주행거리(km)'] <= 50000),  # Nearly New\n",
    "                (df['주행거리(km)'] > 50000)    # Pre-Owned\n",
    "            ]\n",
    "            \n",
    "            for condition in conditions:\n",
    "                mask = condition\n",
    "                mean_value = df[mask & df['배터리용량'].notnull()]['배터리용량'].mean()\n",
    "                if pd.isna(mean_value):\n",
    "                    mean_value = df[df['배터리용량'].notnull()]['배터리용량'].mean()\n",
    "                df.loc[mask & df['배터리용량'].isnull(), '배터리용량'] = mean_value\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_improved_features(self, df, model_name):\n",
    "        \"\"\"개선된 특성 생성\"\"\"\n",
    "        features = df.copy()\n",
    "        \n",
    "        # 공통 특성\n",
    "        features['age_warranty_ratio'] = features['연식(년)'] / features['보증기간(년)'].replace(0, 0.1)\n",
    "        features['battery_distance_ratio'] = features['배터리용량'] / np.log1p(features['주행거리(km)'])\n",
    "        \n",
    "        if model_name in ['TayCT', 'Tay']:\n",
    "            # 주행거리 구간별 프리미엄 점수\n",
    "            features['distance_premium'] = np.where(\n",
    "                features['주행거리(km)'] <= 10000,\n",
    "                1.2,  # 신차 프리미엄\n",
    "                np.exp(-0.1 * features['주행거리(km)'] / 50000)\n",
    "            )\n",
    "            \n",
    "            # Brand New 차량의 배터리 용량 보정\n",
    "            features['battery_premium'] = np.where(\n",
    "                (features['차량상태'] == 'Brand New') & (features['주행거리(km)'] <= 10000),\n",
    "                features['배터리용량'] * 1.15,  # 15% 프리미엄\n",
    "                features['배터리용량']\n",
    "            )\n",
    "            \n",
    "            features['condition_value'] = features['차량상태'].map({\n",
    "                'Brand New': 1.2,\n",
    "                'Nearly New': 1.1,\n",
    "                'Pre-Owned': 1.0\n",
    "            })\n",
    "            \n",
    "        elif model_name == 'IONIQ':\n",
    "            features['condition_encoded'] = features['차량상태'].map({\n",
    "                'Brand New': 3,\n",
    "                'Nearly New': 2,\n",
    "                'Pre-Owned': 1\n",
    "            })\n",
    "            features['distance_per_year'] = features['주행거리(km)'] / features['연식(년)'].replace(0, 1)\n",
    "            features['battery_age_interaction'] = features['배터리용량'] * np.exp(-0.1 * features['연식(년)'])\n",
    "            \n",
    "        elif model_name == 'MX':\n",
    "            features['luxury_score'] = (\n",
    "                (features['배터리용량'] / features['배터리용량'].max()) * \n",
    "                np.exp(-0.08 * features['연식(년)']) * \n",
    "                np.exp(-0.15 * features['주행거리(km)'] / 40000)\n",
    "            )\n",
    "            features['battery_efficiency'] = features['배터리용량'] / (features['주행거리(km)'] + 1000)\n",
    "            \n",
    "        return features\n",
    "\n",
    "    def prepare_features(self, df, model_name):\n",
    "        \"\"\"특성 준비\"\"\"\n",
    "        # 이상치 처리\n",
    "        df = self.handle_outliers(df, model_name)\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df = self.handle_battery_missing(df, model_name)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        features = df.copy()\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            features[f'{col}_encoded'] = self.label_encoders[col].transform(features[col])\n",
    "        \n",
    "        # 기본 특성\n",
    "        base_features = [\n",
    "            '제조사_encoded', '모델_encoded', '구동방식_encoded', '차량상태_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)'\n",
    "        ]\n",
    "        \n",
    "        # 개선된 특성 추가\n",
    "        improved_features = self.create_improved_features(features, model_name)\n",
    "        result = features[base_features].copy()\n",
    "        \n",
    "        # 모델별 추가 특성\n",
    "        if model_name in ['TayCT', 'Tay']:\n",
    "            additional_cols = ['distance_premium', 'battery_premium', 'condition_value']\n",
    "        elif model_name == 'IONIQ':\n",
    "            additional_cols = ['condition_encoded', 'distance_per_year', 'battery_age_interaction']\n",
    "        elif model_name == 'MX':\n",
    "            additional_cols = ['luxury_score', 'battery_efficiency']\n",
    "        else:\n",
    "            additional_cols = []\n",
    "            \n",
    "        for col in additional_cols:\n",
    "            result[col] = improved_features[col]\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def initialize_label_encoders(self, train_df, test_df=None):\n",
    "        \"\"\"레이블 인코더 초기화\"\"\"\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            self.label_encoders[col] = LabelEncoder()\n",
    "            unique_values = set(train_df[col].unique())\n",
    "            \n",
    "            if test_df is not None:\n",
    "                unique_values.update(test_df[col].unique())\n",
    "            \n",
    "            self.label_encoders[col].fit(sorted(list(unique_values)))\n",
    "\n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def train_model(self, X, y, model_config, has_missing=False):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        rf = RandomForestRegressor(**model_config['rf_params'])\n",
    "        hgb = HistGradientBoostingRegressor(**model_config['hgb_params'])\n",
    "        \n",
    "        rf.fit(X, y)\n",
    "        hgb.fit(X, y)\n",
    "        \n",
    "        return {'rf': rf, 'hgb': hgb}\n",
    "\n",
    "    def predict_model(self, X, models, model_name, has_missing=False):\n",
    "        \"\"\"모델 예측\"\"\"\n",
    "        weights = self.get_model_weights(model_name, has_missing)\n",
    "        rf_pred = models['rf'].predict(X)\n",
    "        hgb_pred = models['hgb'].predict(X)\n",
    "        \n",
    "        return weights['rf'] * rf_pred + weights['hgb'] * hgb_pred\n",
    "\n",
    "    def cv_evaluate(self, train_df):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        model_scores = {}\n",
    "        independent_models = set(self.independent_config.keys())\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(train_df), 1):\n",
    "            train_data = train_df.iloc[train_idx]\n",
    "            val_data = train_df.iloc[val_idx]\n",
    "            \n",
    "            fold_predictions = np.zeros(len(val_data))\n",
    "            \n",
    "            # 독립 모델 예측\n",
    "            for model_name in independent_models:\n",
    "                train_mask = train_data['모델'] == model_name\n",
    "                val_mask = val_data['모델'] == model_name\n",
    "                \n",
    "                if sum(train_mask) > 0 and sum(val_mask) > 0:\n",
    "                    # 결측치 여부 확인\n",
    "                    has_missing = train_data[train_mask]['배터리용량'].isnull().any()\n",
    "                    \n",
    "                    X_train = self.prepare_features(\n",
    "                        train_data[train_mask],\n",
    "                        model_name=model_name\n",
    "                    )\n",
    "                    y_train = train_data[train_mask]['가격(백만원)']\n",
    "                    \n",
    "                    X_val = self.prepare_features(\n",
    "                        val_data[val_mask],\n",
    "                        model_name=model_name\n",
    "                    )\n",
    "                    y_val = val_data[val_mask]['가격(백만원)']\n",
    "                    \n",
    "                    model = self.train_model(\n",
    "                        X_train,\n",
    "                        y_train,\n",
    "                        self.independent_config[model_name],\n",
    "                        has_missing\n",
    "                    )\n",
    "                    predictions = self.predict_model(\n",
    "                        X_val,\n",
    "                        model,\n",
    "                        model_name,\n",
    "                        has_missing\n",
    "                    )\n",
    "                    \n",
    "                    fold_predictions[val_mask] = predictions\n",
    "                    \n",
    "                    model_rmse = np.sqrt(mean_squared_error(y_val, predictions))\n",
    "                    if model_name not in model_scores:\n",
    "                        model_scores[model_name] = []\n",
    "                    model_scores[model_name].append(model_rmse)\n",
    "            \n",
    "            # 세그먼트 모델 예측\n",
    "            segment_data = train_data[~train_data['모델'].isin(independent_models)].copy()\n",
    "            segment_val_data = val_data[~val_data['모델'].isin(independent_models)].copy()\n",
    "            \n",
    "            if len(segment_data) > 0 and len(segment_val_data) > 0:\n",
    "                segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "                segment_val_data['segment'] = segment_val_data['모델'].apply(self.get_segment)\n",
    "                \n",
    "                for segment in range(1, 8):\n",
    "                    segment_mask_train = segment_data['segment'] == segment\n",
    "                    segment_mask_val = segment_val_data['segment'] == segment\n",
    "                    \n",
    "                    if sum(segment_mask_train) > 0 and sum(segment_mask_val) > 0:\n",
    "                        segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                        \n",
    "                        X_train = self.prepare_features(\n",
    "                            segment_data[segment_mask_train],\n",
    "                            model_name=segment_data[segment_mask_train]['모델'].iloc[0]\n",
    "                        )\n",
    "                        y_train = segment_data[segment_mask_train]['가격(백만원)']\n",
    "                        \n",
    "                        X_val = self.prepare_features(\n",
    "                            segment_val_data[segment_mask_val],\n",
    "                            model_name=segment_val_data[segment_mask_val]['모델'].iloc[0]\n",
    "                        )\n",
    "                        y_val = segment_val_data[segment_mask_val]['가격(백만원)']\n",
    "                        \n",
    "                        model = self.train_model(X_train, y_train, segment_config)\n",
    "                        predictions = self.predict_model(\n",
    "                            X_val,\n",
    "                            model,\n",
    "                            segment_val_data[segment_mask_val]['모델'].iloc[0]\n",
    "                        )\n",
    "                        \n",
    "                        val_indices = val_data.index[~val_data['모델'].isin(independent_models)]\n",
    "                        segment_indices = val_indices[segment_mask_val]\n",
    "                        fold_predictions[val_data.index.get_indexer(segment_indices)] = predictions\n",
    "            \n",
    "            # 전체 폴드 성능 계산\n",
    "            fold_rmse = np.sqrt(mean_squared_error(val_data['가격(백만원)'], fold_predictions))\n",
    "            fold_r2 = r2_score(val_data['가격(백만원)'], fold_predictions)\n",
    "            \n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 모델별 RMSE ===\")\n",
    "        for model_name in sorted(model_scores.keys()):\n",
    "            print(f\"{model_name}: {np.mean(model_scores[model_name]):.4f}\")\n",
    "        \n",
    "        return cv_scores, model_scores\n",
    "\n",
    "    def fit(self, train_df, test_df=None):\n",
    "        \"\"\"전체 모델 학습\"\"\"\n",
    "        # 레이블 인코더 초기화\n",
    "        self.initialize_label_encoders(train_df, test_df)\n",
    "        \n",
    "        # 교차 검증 수행\n",
    "        cv_scores, model_scores = self.cv_evaluate(train_df)\n",
    "        \n",
    "        # 독립 모델 학습\n",
    "        for model_name in self.independent_config.keys():\n",
    "            model_data = train_df[train_df['모델'] == model_name]\n",
    "            \n",
    "            if len(model_data) > 0:\n",
    "                has_missing = model_data['배터리용량'].isnull().any()\n",
    "                X = self.prepare_features(model_data, model_name=model_name)\n",
    "                y = model_data['가격(백만원)']\n",
    "                \n",
    "                self.independent_models[model_name] = self.train_model(\n",
    "                    X, y,\n",
    "                    self.independent_config[model_name],\n",
    "                    has_missing\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 학습\n",
    "        segment_data = train_df[~train_df['모델'].isin(self.independent_config.keys())].copy()\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment in range(1, 8):\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(\n",
    "                        segment_data[segment_mask],\n",
    "                        model_name=segment_data[segment_mask]['모델'].iloc[0]\n",
    "                    )\n",
    "                    y = segment_data[segment_mask]['가격(백만원)']\n",
    "                    \n",
    "                    segment_config = self.segment_params.get(segment, self.segment_params[1])\n",
    "                    self.segment_models[segment] = self.train_model(X, y, segment_config)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        # 독립 모델 예측\n",
    "        for model_name, model in self.independent_models.items():\n",
    "            model_mask = test_df['모델'] == model_name\n",
    "            if sum(model_mask) > 0:\n",
    "                X = self.prepare_features(\n",
    "                    test_df[model_mask],\n",
    "                    model_name=model_name\n",
    "                )\n",
    "                has_missing = test_df[model_mask]['배터리용량'].isnull().any()\n",
    "                predictions[model_mask] = self.predict_model(\n",
    "                    X,\n",
    "                    model,\n",
    "                    model_name,\n",
    "                    has_missing\n",
    "                )\n",
    "        \n",
    "        # 세그먼트 모델 예측\n",
    "        segment_data = test_df[~test_df['모델'].isin(self.independent_config.keys())].copy()\n",
    "        if len(segment_data) > 0:\n",
    "            segment_data['segment'] = segment_data['모델'].apply(self.get_segment)\n",
    "            \n",
    "            for segment, model in self.segment_models.items():\n",
    "                segment_mask = segment_data['segment'] == segment\n",
    "                if sum(segment_mask) > 0:\n",
    "                    X = self.prepare_features(\n",
    "                        segment_data[segment_mask],\n",
    "                        model_name=segment_data[segment_mask]['모델'].iloc[0]\n",
    "                    )\n",
    "                    \n",
    "                    test_indices = test_df.index[~test_df['모델'].isin(self.independent_config.keys())]\n",
    "                    segment_indices = test_indices[segment_mask]\n",
    "                    predictions[test_df.index.get_indexer(segment_indices)] = self.predict_model(\n",
    "                        X,\n",
    "                        model,\n",
    "                        segment_data[segment_mask]['모델'].iloc[0]\n",
    "                    )\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측 실행\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 모델 초기화 및 학습\n",
    "    predictor = EnhancedHybridPredictor()\n",
    "    predictor.fit(train_data, test_data)\n",
    "    \n",
    "    # 예측 및 저장\n",
    "    predictions = predictor.predict(test_data)\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('enhanced_hybrid_model_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 중...\n",
      "\n",
      "모델 초기화 및 학습 시작...\n",
      "\n",
      "모델 학습 중...\n",
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 18.5229, R2: 0.7503\n",
      "Fold 2 - RMSE: 19.5808, R2: 0.7234\n",
      "Fold 3 - RMSE: 18.8874, R2: 0.7392\n",
      "Fold 4 - RMSE: 19.1357, R2: 0.7276\n",
      "Fold 5 - RMSE: 21.0433, R2: 0.6433\n",
      "\n",
      "평균 RMSE: 19.4340 (+/- 1.7502)\n",
      "\n",
      "=== 세그먼트별 RMSE ===\n",
      "세그먼트 1: 40.3872\n",
      "세그먼트 2: 0.5276\n",
      "세그먼트 3: 0.4089\n",
      "세그먼트 4: 0.6304\n",
      "세그먼트 5: 0.6119\n",
      "세그먼트 6: 11.4416\n",
      "세그먼트 7: 0.3273\n",
      "\n",
      "=== 준프리미엄 모델 주행거리별 RMSE ===\n",
      "\n",
      "Tay 모델:\n",
      "- low: 13.8291\n",
      "- medium: 18.1389\n",
      "- high: 17.5002\n",
      "\n",
      "TayCT 모델:\n",
      "- low: 6.0085\n",
      "- medium: 4.1307\n",
      "- high: 3.9943\n",
      "\n",
      "예측 수행 중...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- TayCT_price_level_0\n- TayCT_price_nan\n- Tay_price_level_0\n- Tay_price_level_3\n- Tay_price_nan\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[117], line 572\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;66;03m# 예측 수행\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m예측 수행 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 572\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# 예측값 후처리\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m예측값 후처리 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[117], line 551\u001b[0m, in \u001b[0;36mEnhancedSegmentPredictor.predict\u001b[1;34m(self, test_df)\u001b[0m\n\u001b[0;32m    549\u001b[0m             predictions[mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_segment_6(X[mask], model)\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m             predictions[mask] \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1769\u001b[0m, in \u001b[0;36mHistGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1766\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# Return inverse link of raw predictions after converting\u001b[39;00m\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;66;03m# shape (n_samples, 1) to (n_samples,)\u001b[39;00m\n\u001b[1;32m-> 1769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39mlink\u001b[38;5;241m.\u001b[39minverse(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel())\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:1278\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._raw_predict\u001b[1;34m(self, X, n_threads)\u001b[0m\n\u001b[0;32m   1276\u001b[0m is_binned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_in_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_binned:\n\u001b[1;32m-> 1278\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_preprocess_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1280\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1281\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[0;32m   1282\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(n_samples, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_trees_per_iteration_),\n\u001b[0;32m   1283\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_baseline_prediction\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1284\u001b[0m     order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1285\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py:268\u001b[0m, in \u001b[0;36mBaseHistGradientBoosting._preprocess_X\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reset:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_X_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocessor\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# At this point, reset is False, which runs during `fit`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:608\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    539\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    545\u001b[0m ):\n\u001b[0;32m    546\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    612\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    613\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    614\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    531\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m     )\n\u001b[1;32m--> 535\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names seen at fit time, yet now missing:\n- TayCT_price_level_0\n- TayCT_price_nan\n- Tay_price_level_0\n- Tay_price_level_3\n- Tay_price_nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class EnhancedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.premium_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        self.model_stats = {}\n",
    "        \n",
    "        # 모델별 파라미터 설정\n",
    "        self.model_params = {\n",
    "            'Tay': {\n",
    "                'condition_weights': {\n",
    "                    'Brand New': {'base': 3.5, 'distance_factor': -0.02},\n",
    "                    'Nearly New': {'base': 2.5, 'distance_factor': -0.015},\n",
    "                    'Pre-Owned': {'base': 1.0, 'distance_factor': -0.01}\n",
    "                },\n",
    "                'price_ranges': [90, 100, 110, 120],\n",
    "                'distance_thresholds': [10000, 50000, 100000, 150000],\n",
    "                'battery_premium_factor': 1.15\n",
    "            },\n",
    "            'TayCT': {\n",
    "                'condition_weights': {\n",
    "                    'Brand New': {'base': 3.8, 'distance_factor': -0.025},\n",
    "                    'Nearly New': {'base': 2.8, 'distance_factor': -0.018},\n",
    "                    'Pre-Owned': {'base': 1.2, 'distance_factor': -0.012}\n",
    "                },\n",
    "                'price_ranges': [110, 120, 130, 140],\n",
    "                'distance_thresholds': [8000, 40000, 80000, 120000],\n",
    "                'battery_premium_factor': 1.2\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def handle_premium_outliers(self, df, model_name):\n",
    "        \"\"\"준프리미엄 세그먼트 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        params = self.model_params[model_name]\n",
    "        \n",
    "        # 주행거리 기반 가중치 조정\n",
    "        df['distance_weight'] = 1.0\n",
    "        for i, threshold in enumerate(params['distance_thresholds']):\n",
    "            if i > 0:\n",
    "                mask = (df['주행거리(km)'] > params['distance_thresholds'][i-1]) & \\\n",
    "                       (df['주행거리(km)'] <= threshold)\n",
    "                df.loc[mask, 'distance_weight'] = 1.0 - (i * 0.1)\n",
    "        \n",
    "        df.loc[df['주행거리(km)'] > params['distance_thresholds'][-1], 'distance_weight'] = 0.6\n",
    "        \n",
    "        # 차량상태와 주행거리 복합 가중치\n",
    "        for condition, weights in params['condition_weights'].items():\n",
    "            mask = df['차량상태'] == condition\n",
    "            base_weight = weights['base']\n",
    "            distance_factor = weights['distance_factor']\n",
    "            df.loc[mask, 'condition_weight'] = base_weight + \\\n",
    "                (df.loc[mask, '주행거리(km)'] / 10000 * distance_factor)\n",
    "        \n",
    "        # 배터리 용량 프리미엄\n",
    "        if 'battery_premium_factor' in params:\n",
    "            brand_new_low_mileage = (df['차량상태'] == 'Brand New') & \\\n",
    "                                   (df['주행거리(km)'] <= params['distance_thresholds'][0])\n",
    "            df.loc[brand_new_low_mileage, 'battery_weight'] = params['battery_premium_factor']\n",
    "        \n",
    "        # 최종 가중치 계산\n",
    "        df['price_weight'] = df['distance_weight'] * df['condition_weight']\n",
    "        if 'battery_weight' in df.columns:\n",
    "            df['price_weight'] *= df['battery_weight']\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def handle_entry_outliers(self, df):\n",
    "        \"\"\"엔트리 세그먼트 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # IONIQ 특별 처리\n",
    "        ioniq_mask = df['모델'] == 'IONIQ'\n",
    "        if sum(ioniq_mask) > 0:\n",
    "            # 주행거리 기반 가중치\n",
    "            df.loc[ioniq_mask, 'distance_weight'] = np.exp(-df.loc[ioniq_mask, '주행거리(km)'] / 100000)\n",
    "            \n",
    "            # 배터리 용량 기반 가중치\n",
    "            if '배터리용량' in df.columns:\n",
    "                battery_mean = df.loc[ioniq_mask, '배터리용량'].mean()\n",
    "                df.loc[ioniq_mask, 'battery_weight'] = \\\n",
    "                    df.loc[ioniq_mask, '배터리용량'] / battery_mean\n",
    "            \n",
    "            # 차량상태 가중치\n",
    "            condition_weights = {\n",
    "                'Brand New': 1.2,\n",
    "                'Nearly New': 1.1,\n",
    "                'Pre-Owned': 0.9\n",
    "            }\n",
    "            df.loc[ioniq_mask, 'condition_weight'] = \\\n",
    "                df.loc[ioniq_mask, '차량상태'].map(condition_weights)\n",
    "        \n",
    "        # Soul 모델 처리\n",
    "        soul_mask = df['모델'] == 'Soul'\n",
    "        if sum(soul_mask) > 0:\n",
    "            # 보증기간 프리미엄\n",
    "            df.loc[soul_mask, 'warranty_factor'] = \\\n",
    "                1.0 + (df.loc[soul_mask, '보증기간(년)'] - 5) * 0.05\n",
    "            \n",
    "            # 사고이력 패널티\n",
    "            df.loc[soul_mask & (df['사고이력'] == 'Yes'), 'price_weight'] *= 0.85\n",
    "        \n",
    "        # 최종 가중치 계산\n",
    "        weight_columns = ['distance_weight', 'battery_weight', 'condition_weight']\n",
    "        df['price_weight'] = 1.0\n",
    "        for col in weight_columns:\n",
    "            if col in df.columns:\n",
    "                df['price_weight'] *= df[col]\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_model_specific_features(self, df, model_name):\n",
    "        \"\"\"모델별 특화 특성 생성 개선\"\"\"\n",
    "        features = {}\n",
    "        params = self.model_params.get(model_name, {})\n",
    "        \n",
    "        if model_name in ['Tay', 'TayCT']:\n",
    "            # 주행거리 구간화\n",
    "            distance_ranges = [0] + params['distance_thresholds'] + [float('inf')]\n",
    "            labels = ['very_low', 'low', 'medium', 'high', 'very_high']\n",
    "            \n",
    "            features['distance_level'] = pd.cut(\n",
    "                df['주행거리(km)'],\n",
    "                bins=distance_ranges,\n",
    "                labels=labels,\n",
    "                include_lowest=True,\n",
    "                duplicates='drop'\n",
    "            ).astype(str)\n",
    "            \n",
    "            # 가격 구간 예측을 위한 특성\n",
    "            if '가격(백만원)' in df.columns:\n",
    "                unique_bins = sorted(list(set([0] + params['price_ranges'])))\n",
    "                features['price_range'] = pd.cut(\n",
    "                    df['주행거리(km)'],\n",
    "                    bins=unique_bins,\n",
    "                    labels=['level_' + str(i) for i in range(len(unique_bins)-1)],\n",
    "                    include_lowest=True,\n",
    "                    duplicates='drop'\n",
    "                ).astype(str)\n",
    "            else:\n",
    "                features['price_range'] = None\n",
    "            \n",
    "            # 배터리 효율성 점수\n",
    "            features['battery_efficiency'] = np.where(\n",
    "                df['배터리용량'].isna(),\n",
    "                0,\n",
    "                df['배터리용량'] / (np.log1p(df['주행거리(km)']) + 1)\n",
    "            )\n",
    "            \n",
    "            # 보증기간 영향도\n",
    "            features['warranty_score'] = df['보증기간(년)'] * \\\n",
    "                np.exp(-0.1 * df['연식(년)'])\n",
    "            \n",
    "            # 차량상태와 주행거리 복합 점수\n",
    "            for condition, weights in params['condition_weights'].items():\n",
    "                mask = df['차량상태'] == condition\n",
    "                features[f'condition_{condition.lower()}_score'] = np.where(\n",
    "                    mask,\n",
    "                    weights['base'] * np.exp(weights['distance_factor'] * \\\n",
    "                        df['주행거리(km)'] / 10000),\n",
    "                    0\n",
    "                )\n",
    "        \n",
    "        # DataFrame으로 변환 및 전처리\n",
    "        features_df = pd.DataFrame(features)\n",
    "        if 'distance_level' in features_df.columns:\n",
    "            distance_dummies = pd.get_dummies(\n",
    "                features_df['distance_level'],\n",
    "                prefix='distance'\n",
    "            )\n",
    "            features_df = pd.concat([features_df, distance_dummies], axis=1)\n",
    "            features_df.drop('distance_level', axis=1, inplace=True)\n",
    "        \n",
    "        if 'price_range' in features_df.columns and features_df['price_range'] is not None:\n",
    "            price_dummies = pd.get_dummies(\n",
    "                features_df['price_range'],\n",
    "                prefix='price'\n",
    "            )\n",
    "            features_df = pd.concat([features_df, price_dummies], axis=1)\n",
    "            features_df.drop('price_range', axis=1, inplace=True)\n",
    "        \n",
    "        return features_df\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 가중치 초기화\n",
    "        df['price_weight'] = 1.0\n",
    "        df['warranty_factor'] = 1.0\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby(['모델', '차량상태'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 이상치 처리\n",
    "        premium_mask = df['model_segment'] == 6\n",
    "        entry_mask = df['model_segment'] == 1\n",
    "        \n",
    "        if sum(premium_mask) > 0:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = df['모델'] == model\n",
    "                if sum(model_mask) > 0:\n",
    "                    df.loc[model_mask] = self.handle_premium_outliers(\n",
    "                        df[model_mask], \n",
    "                        model\n",
    "                    )\n",
    "        \n",
    "        if sum(entry_mask) > 0:\n",
    "            df.loc[entry_mask] = self.handle_entry_outliers(df[entry_mask])\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:\n",
    "                    unique_values = sorted(list(set(\n",
    "                        list(self.label_encoders[col].classes_) + \\\n",
    "                        list(unique_values)\n",
    "                    )))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 기본 특성 생성\n",
    "        features = {\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'] * df['warranty_factor'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'distance': df['주행거리(km)'],\n",
    "            'price_weight': df['price_weight']\n",
    "        }\n",
    "        \n",
    "        # 세그먼트별 특화 특성\n",
    "        if '모델' in df.columns:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = (df['모델'] == model)\n",
    "                if sum(model_mask) > 0:\n",
    "                    model_features = self.get_model_specific_features(\n",
    "                        df[model_mask], \n",
    "                        model\n",
    "                    )\n",
    "                    if not model_features.empty:\n",
    "                        for col in model_features.columns:\n",
    "                            features[f'{model}_{col}'] = np.zeros(len(df))\n",
    "                            features[f'{model}_{col}'][model_mask] = \\\n",
    "                                model_features[col].values\n",
    "        \n",
    "        features_df = pd.DataFrame(features).fillna(0)\n",
    "        return features_df\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        mask = X['model_segment'] == segment\n",
    "        if sum(mask) > 0:\n",
    "            if segment == 6:  # 준프리미엄 세그먼트\n",
    "                models = {}\n",
    "                for model in ['Tay', 'TayCT']:\n",
    "                    mask = X['model_encoded'] == self.label_encoders['모델'].transform([model])[0]\n",
    "                    if sum(mask) > 0:\n",
    "                        # 주행거리 기반 모델 분리\n",
    "                        base_params = {\n",
    "                            'Tay': {\n",
    "                                'max_iter': 800,\n",
    "                                'learning_rate': 0.008,\n",
    "                                'max_depth': 5,\n",
    "                                'l2_regularization': 1.8\n",
    "                            },\n",
    "                            'TayCT': {\n",
    "                                'max_iter': 600,\n",
    "                                'learning_rate': 0.01,\n",
    "                                'max_depth': 4,\n",
    "                                'l2_regularization': 2.0\n",
    "                            }\n",
    "                        }[model]\n",
    "\n",
    "                        # 주행거리별 특화 모델\n",
    "                        distance_splits = {\n",
    "                            'low': lambda x: x <= 50000,\n",
    "                            'medium': lambda x: (x > 50000) & (x <= 100000),\n",
    "                            'high': lambda x: x > 100000\n",
    "                        }\n",
    "\n",
    "                        model_collection = {}\n",
    "                        model_cols = [col for col in X.columns if model in col or col in [\n",
    "                            'distance', 'battery_capacity', 'age', 'warranty',\n",
    "                            'accident', 'condition_encoded', 'drive_encoded',\n",
    "                            'price_weight'\n",
    "                        ]]\n",
    "\n",
    "                        # 기본 모델 학습\n",
    "                        try:\n",
    "                            base_model = HistGradientBoostingRegressor(\n",
    "                                random_state=42,\n",
    "                                **base_params\n",
    "                            )\n",
    "                            model_X = X[mask][model_cols]\n",
    "                            model_y = y[mask]\n",
    "                            weights = X[mask]['price_weight'] if 'price_weight' in X.columns else None\n",
    "                            \n",
    "                            if weights is not None and np.sum(weights) == 0:\n",
    "                                continue\n",
    "                                \n",
    "                            base_model.fit(model_X, model_y, sample_weight=weights)\n",
    "                            model_collection['base'] = (base_model, model_cols)\n",
    "                        except (ZeroDivisionError, ValueError) as e:\n",
    "                            print(f\"Warning: Failed to train base model for {model}\")\n",
    "                            continue\n",
    "\n",
    "                        # 주행거리별 특화 모델 학습\n",
    "                        for distance_range, condition in distance_splits.items():\n",
    "                            range_mask = condition(X[mask]['distance'])\n",
    "                            if sum(range_mask) >= 20:  # 최소 샘플 수 확보\n",
    "                                try:\n",
    "                                    range_model = HistGradientBoostingRegressor(\n",
    "                                        random_state=42,\n",
    "                                        **base_params\n",
    "                                    )\n",
    "                                    range_X = X[mask][model_cols][range_mask]\n",
    "                                    range_y = model_y[range_mask]\n",
    "                                    range_weights = weights[range_mask] if weights is not None else None\n",
    "\n",
    "                                    # 가중치 합이 0인지 확인\n",
    "                                    if range_weights is not None and np.sum(range_weights) == 0:\n",
    "                                        continue\n",
    "                                        \n",
    "                                    range_model.fit(range_X, range_y, sample_weight=range_weights)\n",
    "                                    model_collection[distance_range] = (range_model, model_cols)\n",
    "                                except (ZeroDivisionError, ValueError) as e:\n",
    "                                    print(f\"Warning: Skipping {distance_range} range for {model} due to insufficient data\")\n",
    "\n",
    "                        if model_collection:  # 모델이 하나라도 학습된 경우에만 추가\n",
    "                            models[model] = model_collection\n",
    "\n",
    "                return models\n",
    "            else:\n",
    "                # 다른 세그먼트 모델 파라미터\n",
    "                params = {\n",
    "                    1: {  # 엔트리\n",
    "                        'max_iter': 1200,\n",
    "                        'learning_rate': 0.008,\n",
    "                        'max_depth': 4,\n",
    "                        'l2_regularization': 2.0,\n",
    "                    },\n",
    "                    7: {  # 프리미엄\n",
    "                        'max_iter': 800,\n",
    "                        'learning_rate': 0.01,\n",
    "                        'max_depth': 3,\n",
    "                        'l2_regularization': 1.5,\n",
    "                    }\n",
    "                }.get(segment, {\n",
    "                    'max_iter': 1000,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'max_depth': 6,\n",
    "                    'l2_regularization': 1.0,\n",
    "                })\n",
    "\n",
    "                try:\n",
    "                    model = HistGradientBoostingRegressor(\n",
    "                        random_state=42,\n",
    "                        **params\n",
    "                    )\n",
    "                    segment_X = X[mask]\n",
    "                    segment_y = y[mask]\n",
    "                    weights = X[mask]['price_weight'] if 'price_weight' in X.columns else None\n",
    "\n",
    "                    # 가중치 합이 0인지 확인\n",
    "                    if weights is not None and np.sum(weights) == 0:\n",
    "                        return None\n",
    "\n",
    "                    model.fit(segment_X, segment_y, sample_weight=weights)\n",
    "                    return model\n",
    "                except (ZeroDivisionError, ValueError) as e:\n",
    "                    print(f\"Warning: Failed to train model for segment {segment}\")\n",
    "                    return None\n",
    "\n",
    "        return None\n",
    "\n",
    "    def predict_segment_6(self, X, models):\n",
    "        \"\"\"준프리미엄 세그먼트 예측\"\"\"\n",
    "        predictions = np.zeros(len(X))\n",
    "        for model_name, model_collection in models.items():\n",
    "            mask = X['model_encoded'] == self.label_encoders['모델'].transform([model_name])[0]\n",
    "            if sum(mask) > 0:\n",
    "                # 기본 모델 예측\n",
    "                base_model, cols = model_collection['base']\n",
    "                predictions[mask] = base_model.predict(X[mask][cols])\n",
    "\n",
    "                # 주행거리 구간별 보정\n",
    "                distance_ranges = {\n",
    "                    'low': (0, 50000),\n",
    "                    'medium': (50000, 100000),\n",
    "                    'high': (100000, float('inf'))\n",
    "                }\n",
    "\n",
    "                for range_name, (min_dist, max_dist) in distance_ranges.items():\n",
    "                    if range_name in model_collection:\n",
    "                        range_model, range_cols = model_collection[range_name]\n",
    "                        range_mask = mask & (X['distance'] > min_dist) & (X['distance'] <= max_dist)\n",
    "                        if sum(range_mask) > 0:\n",
    "                            range_pred = range_model.predict(X[range_mask][range_cols])\n",
    "                            # 거리에 따른 가중치 적용\n",
    "                            weight = np.exp(-0.5 * (X.loc[range_mask, 'distance'] - min_dist) / (max_dist - min_dist))\n",
    "                            predictions[range_mask] = weight * range_pred + (1 - weight) * predictions[range_mask]\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def cv_evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        segment_scores = {i: [] for i in range(1, 8)}\n",
    "        model_scores = {\n",
    "            'Tay': {'low': [], 'medium': [], 'high': []},\n",
    "            'TayCT': {'low': [], 'medium': [], 'high': []}\n",
    "        }\n",
    "\n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            fold_predictions = np.zeros_like(y_val)\n",
    "\n",
    "            for segment in range(1, 8):\n",
    "                model = self.train_segment_model(X_train, y_train, segment)\n",
    "                if model is not None:\n",
    "                    mask = X_val['model_segment'] == segment\n",
    "                    if sum(mask) > 0:\n",
    "                        if segment == 6:\n",
    "                            segment_pred = self.predict_segment_6(X_val[mask], model)\n",
    "                            \n",
    "                            # 주행거리 구간별 성능 평가\n",
    "                            for model_name in ['Tay', 'TayCT']:\n",
    "                                model_mask = X_val[mask]['model_encoded'] == \\\n",
    "                                    self.label_encoders['모델'].transform([model_name])[0]\n",
    "                                if sum(model_mask) > 0:\n",
    "                                    for range_name, (min_dist, max_dist) in {\n",
    "                                        'low': (0, 50000),\n",
    "                                        'medium': (50000, 100000),\n",
    "                                        'high': (100000, float('inf'))\n",
    "                                    }.items():\n",
    "                                        range_mask = model_mask & \\\n",
    "                                            (X_val[mask]['distance'] > min_dist) & \\\n",
    "                                            (X_val[mask]['distance'] <= max_dist)\n",
    "                                        if sum(range_mask) > 0:\n",
    "                                            range_rmse = np.sqrt(mean_squared_error(\n",
    "                                                y_val[mask][range_mask],\n",
    "                                                segment_pred[range_mask]\n",
    "                                            ))\n",
    "                                            model_scores[model_name][range_name].append(range_rmse)\n",
    "                        else:\n",
    "                            segment_pred = model.predict(X_val[mask])\n",
    "\n",
    "                        fold_predictions[mask] = segment_pred\n",
    "                        segment_rmse = np.sqrt(mean_squared_error(y_val[mask], segment_pred))\n",
    "                        segment_scores[segment].append(segment_rmse)\n",
    "\n",
    "            fold_rmse = np.sqrt(mean_squared_error(y_val, fold_predictions))\n",
    "            fold_r2 = r2_score(y_val, fold_predictions)\n",
    "\n",
    "            cv_scores.append(fold_rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {fold_rmse:.4f}, R2: {fold_r2:.4f}\")\n",
    "\n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        print(\"\\n=== 세그먼트별 RMSE ===\")\n",
    "        for segment in range(1, 8):\n",
    "            if segment_scores[segment]:\n",
    "                mean_score = np.mean(segment_scores[segment])\n",
    "                print(f\"세그먼트 {segment}: {mean_score:.4f}\")\n",
    "\n",
    "        print(\"\\n=== 준프리미엄 모델 주행거리별 RMSE ===\")\n",
    "        for model_name in ['Tay', 'TayCT']:\n",
    "            print(f\"\\n{model_name} 모델:\")\n",
    "            for range_name in ['low', 'medium', 'high']:\n",
    "                if model_scores[model_name][range_name]:\n",
    "                    mean_score = np.mean(model_scores[model_name][range_name])\n",
    "                    print(f\"- {range_name}: {mean_score:.4f}\")\n",
    "\n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "\n",
    "        cv_scores = self.cv_evaluate(X, y)\n",
    "\n",
    "        # 최종 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            self.segment_models[segment] = self.train_segment_model(X, y, segment)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(X))\n",
    "\n",
    "        for segment, model in self.segment_models.items():\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                if segment == 6:\n",
    "                    predictions[mask] = self.predict_segment_6(X[mask], model)\n",
    "                elif model is not None:\n",
    "                    predictions[mask] = model.predict(X[mask])\n",
    "\n",
    "        return predictions\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    print(\"데이터 로드 중...\")\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "\n",
    "    # 모델 초기화\n",
    "    print(\"\\n모델 초기화 및 학습 시작...\")\n",
    "    predictor = EnhancedSegmentPredictor()\n",
    "    \n",
    "    # 모델 학습\n",
    "    print(\"\\n모델 학습 중...\")\n",
    "    predictor.fit(train_data)\n",
    "    \n",
    "    # 예측 수행\n",
    "    print(\"\\n예측 수행 중...\")\n",
    "    predictions = predictor.predict(test_data)\n",
    "    \n",
    "    # 예측값 후처리\n",
    "    print(\"\\n예측값 후처리 중...\")\n",
    "    \n",
    "    # 세그먼트별 최소/최대 가격 범위 설정\n",
    "    price_ranges = {\n",
    "        7: (150, 170),    # 프리미엄\n",
    "        6: (90, 140),     # 준프리미엄\n",
    "        5: (75, 110),     # 럭셔리\n",
    "        4: (55, 85),      # 중상급\n",
    "        3: (45, 65),      # 중급\n",
    "        2: (30, 50),      # 기본\n",
    "        1: (15, 35)       # 엔트리\n",
    "    }\n",
    "    \n",
    "    # 각 세그먼트별로 예측값 보정\n",
    "    segment_predictions = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        'model_segment': test_data['모델'].apply(predictor.get_detailed_segment),\n",
    "        'prediction': predictions\n",
    "    })\n",
    "    \n",
    "    for segment, (min_price, max_price) in price_ranges.items():\n",
    "        segment_mask = segment_predictions['model_segment'] == segment\n",
    "        if sum(segment_mask) > 0:\n",
    "            segment_predictions.loc[segment_mask, 'prediction'] = \\\n",
    "                segment_predictions.loc[segment_mask, 'prediction'].clip(min_price, max_price)\n",
    "    \n",
    "    # Brand New 차량의 예측값 보정\n",
    "    brand_new_mask = test_data['차량상태'] == 'Brand New'\n",
    "    if sum(brand_new_mask) > 0:\n",
    "        for segment in range(1, 8):\n",
    "            segment_mask = (segment_predictions['model_segment'] == segment) & brand_new_mask\n",
    "            if sum(segment_mask) > 0:\n",
    "                min_price, max_price = price_ranges[segment]\n",
    "                # Brand New는 세그먼트 최대가의 90-100% 범위\n",
    "                segment_predictions.loc[segment_mask, 'prediction'] = \\\n",
    "                    segment_predictions.loc[segment_mask, 'prediction'].clip(max_price * 0.9, max_price)\n",
    "    \n",
    "    # 최종 결과 저장\n",
    "    print(\"\\n결과 저장 중...\")\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': segment_predictions['prediction']\n",
    "    })\n",
    "    \n",
    "    # 파일명에 타임스탬프 추가\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    submission.to_csv(f'enhanced_segment_submission_{timestamp}.csv', index=False)\n",
    "    \n",
    "    print(f\"\\n작업 완료! 결과가 'enhanced_segment_submission_{timestamp}.csv'에 저장되었습니다.\")\n",
    "    \n",
    "    # 세그먼트별 예측 통계 출력\n",
    "    print(\"\\n=== 세그먼트별 예측 통계 ===\")\n",
    "    segment_stats = segment_predictions.groupby('model_segment')['prediction'].agg(['mean', 'std', 'min', 'max'])\n",
    "    for segment in range(1, 8):\n",
    "        if segment in segment_stats.index:\n",
    "            stats = segment_stats.loc[segment]\n",
    "            segment_names = {\n",
    "                7: \"프리미엄\",\n",
    "                6: \"준프리미엄\",\n",
    "                5: \"럭셔리\",\n",
    "                4: \"중상급\",\n",
    "                3: \"중급\",\n",
    "                2: \"기본\",\n",
    "                1: \"엔트리\"\n",
    "            }\n",
    "            print(f\"\\n{segment_names[segment]} 세그먼트 (레벨 {segment}):\")\n",
    "            print(f\"- 평균 가격: {stats['mean']:.2f}\")\n",
    "            print(f\"- 표준 편차: {stats['std']:.2f}\")\n",
    "            print(f\"- 가격 범위: {stats['min']:.2f} ~ {stats['max']:.2f}\")\n",
    "    \n",
    "    # 모델별 예측 통계\n",
    "    print(\"\\n=== 주요 모델별 예측 통계 ===\")\n",
    "    model_stats = pd.DataFrame({\n",
    "        'model': test_data['모델'],\n",
    "        'prediction': segment_predictions['prediction']\n",
    "    }).groupby('model').agg({\n",
    "        'prediction': ['count', 'mean', 'std', 'min', 'max']\n",
    "    })\n",
    "    \n",
    "    for model in model_stats.index:\n",
    "        stats = model_stats.loc[model]\n",
    "        print(f\"\\n{model} 모델:\")\n",
    "        print(f\"- 데이터 수: {stats['prediction']['count']:.0f}\")\n",
    "        print(f\"- 평균 가격: {stats['prediction']['mean']:.2f}\")\n",
    "        print(f\"- 표준 편차: {stats['prediction']['std']:.2f}\")\n",
    "        print(f\"- 가격 범위: {stats['prediction']['min']:.2f} ~ {stats['prediction']['max']:.2f}\")\n",
    "\n",
    "    # 차량상태별 예측 통계\n",
    "    print(\"\\n=== 차량상태별 예측 통계 ===\")\n",
    "    condition_stats = pd.DataFrame({\n",
    "        'condition': test_data['차량상태'],\n",
    "        'prediction': segment_predictions['prediction']\n",
    "    }).groupby('condition').agg({\n",
    "        'prediction': ['count', 'mean', 'std', 'min', 'max']\n",
    "    })\n",
    "    \n",
    "    for condition in condition_stats.index:\n",
    "        stats = condition_stats.loc[condition]\n",
    "        print(f\"\\n{condition}:\")\n",
    "        print(f\"- 데이터 수: {stats['prediction']['count']:.0f}\")\n",
    "        print(f\"- 평균 가격: {stats['prediction']['mean']:.2f}\")\n",
    "        print(f\"- 표준 편차: {stats['prediction']['std']:.2f}\")\n",
    "        print(f\"- 가격 범위: {stats['prediction']['min']:.2f} ~ {stats['prediction']['max']:.2f}\")\n",
    "\n",
    "    print(\"\\n=== 예측 결과 요약 ===\")\n",
    "    print(f\"전체 예측 건수: {len(predictions)}\")\n",
    "    print(f\"전체 평균 가격: {predictions.mean():.2f}\")\n",
    "    print(f\"전체 가격 범위: {predictions.min():.2f} ~ {predictions.max():.2f}\")\n",
    "    print(f\"90% 신뢰구간: {np.percentile(predictions, 5):.2f} ~ {np.percentile(predictions, 95):.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 교차 검증 결과 ===\n",
      "Fold 1 - RMSE: 1.4203, R2: 0.9985\n",
      "Fold 2 - RMSE: 1.4144, R2: 0.9986\n",
      "Fold 3 - RMSE: 1.3836, R2: 0.9986\n",
      "Fold 4 - RMSE: 1.2425, R2: 0.9989\n",
      "Fold 5 - RMSE: 1.3720, R2: 0.9985\n",
      "\n",
      "평균 RMSE: 1.3665 (+/- 0.1293)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class EnhancedEVPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scalers = {}\n",
    "        self.models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 보조금 정보 설정\n",
    "        self.subsidy_info = {\n",
    "            'IONIQ5': {'국비': 6900000, '지자체': 1500000},\n",
    "            'IONIQ6': {'국비': 6900000, '지자체': 1500000},\n",
    "            'EV6': {'국비': 6840000, '지자체': 1450000},\n",
    "            'EV9': {'국비': 3010000, '지자체': 690000},\n",
    "            'EVX': {'국비': 4570000, '지자체': 1050000},\n",
    "            'ID4': {'국비': 4920000, '지자체': 1130000},\n",
    "            'Model Y': {'국비': 1950000, '지자체': 450000},\n",
    "            'EQB': {'국비': 2170000, '지자체': 500000}\n",
    "        }\n",
    "        \n",
    "        # 차량 세그먼트 정보\n",
    "        self.segment_info = {\n",
    "            'Premium': ['Model Y', 'EQB', 'EVX'],\n",
    "            'UpperMiddle': ['IONIQ6', 'EV6', 'ID4'],\n",
    "            'Middle': ['IONIQ5'],\n",
    "            'Large': ['EV9']\n",
    "        }\n",
    "\n",
    "    def get_segment(self, model):\n",
    "        \"\"\"차량 세그먼트 반환\"\"\"\n",
    "        for segment, models in self.segment_info.items():\n",
    "            if model in models:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "\n",
    "    def calculate_subsidy(self, model):\n",
    "        \"\"\"모델별 보조금 계산\"\"\"\n",
    "        info = self.subsidy_info.get(model, {'국비': 0, '지자체': 0})\n",
    "        return info['국비'] + info['지자체']\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 보조금 정보 추가\n",
    "        df['total_subsidy'] = df['모델'].map(lambda x: self.calculate_subsidy(x))\n",
    "        df['subsidy_ratio'] = df['total_subsidy'] / (df['가격(백만원)'] * 1000000) if '가격(백만원)' in df.columns else 0\n",
    "        \n",
    "        # 세그먼트 정보 추가\n",
    "        df['segment'] = df['모델'].map(self.get_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        categorical_cols = ['제조사', '모델', '구동방식', '차량상태', 'segment']\n",
    "        for col in categorical_cols:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(df[col])\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 특성 생성\n",
    "        df['km_per_year'] = df['주행거리(km)'] / (df['연식(년)'] + 1)\n",
    "        df['battery_efficiency'] = df['배터리용량'] / np.log1p(df['주행거리(km)'])\n",
    "        df['warranty_value'] = df['보증기간(년)'] * df['battery_efficiency']\n",
    "        df['price_after_subsidy'] = df['가격(백만원)'] - (df['total_subsidy'] / 1000000) if '가격(백만원)' in df.columns else 0\n",
    "        \n",
    "        # 사고이력 이진화\n",
    "        df['accident_binary'] = (df['사고이력'] == 'Yes').astype(int)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성\"\"\"\n",
    "        feature_cols = [\n",
    "            'km_per_year', 'battery_efficiency', 'warranty_value',\n",
    "            'subsidy_ratio', 'total_subsidy',\n",
    "            'segment_encoded', '제조사_encoded', '모델_encoded',\n",
    "            '구동방식_encoded', '차량상태_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)',\n",
    "            'accident_binary'\n",
    "        ]\n",
    "        \n",
    "        X = df[feature_cols]\n",
    "        \n",
    "        # 스케일링\n",
    "        if '가격(백만원)' in df.columns:  # 학습 데이터\n",
    "            self.scaler = StandardScaler()\n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "        else:  # 테스트 데이터\n",
    "            X_scaled = self.scaler.transform(X)\n",
    "            \n",
    "        return X_scaled\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        params = {\n",
    "            'Premium': {\n",
    "                'max_iter': 1000,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 5\n",
    "            },\n",
    "            'UpperMiddle': {\n",
    "                'max_iter': 1200,\n",
    "                'learning_rate': 0.008,\n",
    "                'max_depth': 6\n",
    "            },\n",
    "            'Middle': {\n",
    "                'max_iter': 1000,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 5\n",
    "            },\n",
    "            'Large': {\n",
    "                'max_iter': 800,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 4\n",
    "            },\n",
    "            'Other': {\n",
    "                'max_iter': 1000,\n",
    "                'learning_rate': 0.01,\n",
    "                'max_depth': 5\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        model = HistGradientBoostingRegressor(\n",
    "            random_state=42,\n",
    "            **params.get(segment, params['Other'])\n",
    "        )\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"교차 검증 평가\"\"\"\n",
    "        cv_scores = []\n",
    "        predictions = np.zeros_like(y)\n",
    "        \n",
    "        print(\"\\n=== 교차 검증 결과 ===\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X), 1):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            model = self.train_segment_model(X_train, y_train, 'All')\n",
    "            y_pred = model.predict(X_val)\n",
    "            predictions[val_idx] = y_pred\n",
    "            \n",
    "            rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            \n",
    "            cv_scores.append(rmse)\n",
    "            print(f\"Fold {fold} - RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "        \n",
    "        print(f\"\\n평균 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores)*2:.4f})\")\n",
    "        return cv_scores\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        processed_df = self.preprocess_data(train_df)\n",
    "        X = self.create_features(processed_df)\n",
    "        y = processed_df['가격(백만원)'].values\n",
    "        \n",
    "        # 교차 검증 평가\n",
    "        cv_scores = self.evaluate(X, y)\n",
    "        \n",
    "        # 전체 데이터로 최종 모델 학습\n",
    "        for segment in set(processed_df['segment']):\n",
    "            mask = processed_df['segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                self.models[segment] = self.train_segment_model(\n",
    "                    X[mask], y[mask], segment\n",
    "                )\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        processed_df = self.preprocess_data(test_df)\n",
    "        X = self.create_features(processed_df)\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        for segment in set(processed_df['segment']):\n",
    "            mask = processed_df['segment'] == segment\n",
    "            if sum(mask) > 0 and segment in self.models:\n",
    "                predictions[mask] = self.models[segment].predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 모델 학습\n",
    "    predictor = EnhancedEVPricePredictor()\n",
    "    predictor.fit(train_data)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = predictor.predict(test_data)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('subsidy_enhanced_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Other 세그먼트 최적화 ===\n",
      "데이터 수: 6523\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 195\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# 최적화 실행\u001b[39;00m\n\u001b[0;32m    194\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m SegmentGridSearchOptimizer()\n\u001b[1;32m--> 195\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# 최적 파라미터 저장\u001b[39;00m\n\u001b[0;32m    198\u001b[0m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\u001b[38;5;241m.\u001b[39mto_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimal_parameters.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 167\u001b[0m, in \u001b[0;36mSegmentGridSearchOptimizer.run_optimization\u001b[1;34m(self, train_df)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscalers[segment] \u001b[38;5;241m=\u001b[39m scaler\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# 최적화 수행\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m best_params, best_rmse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m results[segment] \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_params\u001b[39m\u001b[38;5;124m'\u001b[39m: best_params,\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m'\u001b[39m: best_rmse,\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_count\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28msum\u001b[39m(segment_mask)\n\u001b[0;32m    173\u001b[0m }\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params[segment] \u001b[38;5;241m=\u001b[39m best_params\n",
      "Cell \u001b[1;32mIn[2], line 142\u001b[0m, in \u001b[0;36mSegmentGridSearchOptimizer.optimize_segment\u001b[1;34m(self, X, y, segment)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# 그리드 서치 수행\u001b[39;00m\n\u001b[0;32m    133\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m    134\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mHistGradientBoostingRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m),\n\u001b[0;32m    135\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    140\u001b[0m )\n\u001b[1;32m--> 142\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m최적 파라미터: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SegmentGridSearchOptimizer:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scalers = {}\n",
    "        self.best_params = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 보조금 정보 설정\n",
    "        self.subsidy_info = {\n",
    "            'IONIQ5': {'국비': 6900000, '지자체': 1500000},\n",
    "            'IONIQ6': {'국비': 6900000, '지자체': 1500000},\n",
    "            'EV6': {'국비': 6840000, '지자체': 1450000},\n",
    "            'EV9': {'국비': 3010000, '지자체': 690000},\n",
    "            'EVX': {'국비': 4570000, '지자체': 1050000},\n",
    "            'ID4': {'국비': 4920000, '지자체': 1130000},\n",
    "            'Model Y': {'국비': 1950000, '지자체': 450000},\n",
    "            'EQB': {'국비': 2170000, '지자체': 500000}\n",
    "        }\n",
    "        \n",
    "        # 세그먼트 정보\n",
    "        self.segment_info = {\n",
    "            'Premium': ['Model Y', 'EQB', 'EVX'],\n",
    "            'UpperMiddle': ['IONIQ6', 'EV6', 'ID4'],\n",
    "            'Middle': ['IONIQ5'],\n",
    "            'Large': ['EV9']\n",
    "        }\n",
    "        \n",
    "        # 그리드 서치 파라미터\n",
    "        self.param_grid = {\n",
    "            'max_iter': [500, 800, 1000, 1200],\n",
    "            'learning_rate': [0.005, 0.008, 0.01, 0.015],\n",
    "            'max_depth': [3, 4, 5, 6],\n",
    "            'min_samples_leaf': [10, 20, 30],\n",
    "            'l2_regularization': [0.5, 1, 2]\n",
    "        }\n",
    "\n",
    "    def get_segment(self, model):\n",
    "        \"\"\"차량 세그먼트 반환\"\"\"\n",
    "        for segment, models in self.segment_info.items():\n",
    "            if model in models:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "\n",
    "    def calculate_subsidy(self, model):\n",
    "        \"\"\"모델별 보조금 계산\"\"\"\n",
    "        info = self.subsidy_info.get(model, {'국비': 0, '지자체': 0})\n",
    "        return info['국비'] + info['지자체']\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 보조금 정보 추가\n",
    "        df['total_subsidy'] = df['모델'].map(lambda x: self.calculate_subsidy(x))\n",
    "        df['subsidy_ratio'] = df['total_subsidy'] / (df['가격(백만원)'] * 1000000) if '가격(백만원)' in df.columns else 0\n",
    "        \n",
    "        # 세그먼트 정보 추가\n",
    "        df['segment'] = df['모델'].map(self.get_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        categorical_cols = ['제조사', '모델', '구동방식', '차량상태', 'segment']\n",
    "        for col in categorical_cols:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(df[col])\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 특성 생성\n",
    "        df['km_per_year'] = df['주행거리(km)'] / (df['연식(년)'] + 1)\n",
    "        df['battery_efficiency'] = df['배터리용량'] / np.log1p(df['주행거리(km)'])\n",
    "        df['warranty_value'] = df['보증기간(년)'] * df['battery_efficiency']\n",
    "        df['price_after_subsidy'] = df['가격(백만원)'] - (df['total_subsidy'] / 1000000) if '가격(백만원)' in df.columns else 0\n",
    "        \n",
    "        # 사고이력 이진화\n",
    "        df['accident_binary'] = (df['사고이력'] == 'Yes').astype(int)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_features(self, df, segment):\n",
    "        \"\"\"세그먼트별 특화된 특성 생성\"\"\"\n",
    "        base_features = [\n",
    "            'km_per_year', 'battery_efficiency', 'warranty_value',\n",
    "            'subsidy_ratio', 'total_subsidy',\n",
    "            'segment_encoded', '제조사_encoded', '모델_encoded',\n",
    "            '구동방식_encoded', '차량상태_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)',\n",
    "            'accident_binary'\n",
    "        ]\n",
    "        \n",
    "        # 세그먼트별 특화 특성 추가\n",
    "        if segment == 'Premium':\n",
    "            additional_features = [\n",
    "                df['배터리용량'] * df['battery_efficiency'],\n",
    "                df['보증기간(년)'] * df['price_after_subsidy']\n",
    "            ]\n",
    "        elif segment == 'UpperMiddle':\n",
    "            additional_features = [\n",
    "                df['warranty_value'] * df['battery_efficiency'],\n",
    "                df['km_per_year'] / df['배터리용량']\n",
    "            ]\n",
    "        else:\n",
    "            additional_features = []\n",
    "        \n",
    "        # 기본 특성 추출\n",
    "        X = df[base_features].copy()\n",
    "        \n",
    "        # 추가 특성 결합\n",
    "        for i, feat in enumerate(additional_features):\n",
    "            X[f'special_feature_{i}'] = feat\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def optimize_segment(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 그리드 서치 수행\"\"\"\n",
    "        print(f\"\\n=== {segment} 세그먼트 최적화 ===\")\n",
    "        print(f\"데이터 수: {len(y)}\")\n",
    "        \n",
    "        # RMSE 스코어러 정의\n",
    "        rmse_scorer = make_scorer(\n",
    "            lambda y_true, y_pred: -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        )\n",
    "        \n",
    "        # 그리드 서치 수행\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=HistGradientBoostingRegressor(random_state=42),\n",
    "            param_grid=self.param_grid,\n",
    "            cv=self.kf,\n",
    "            scoring=rmse_scorer,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(f\"\\n최적 파라미터: {grid_search.best_params_}\")\n",
    "        print(f\"최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        return grid_search.best_params_, -grid_search.best_score_\n",
    "\n",
    "    def run_optimization(self, train_df):\n",
    "        \"\"\"전체 최적화 프로세스 실행\"\"\"\n",
    "        processed_df = self.preprocess_data(train_df)\n",
    "        \n",
    "        results = {}\n",
    "        for segment in set(processed_df['segment']):\n",
    "            segment_mask = processed_df['segment'] == segment\n",
    "            if sum(segment_mask) > 0:\n",
    "                X = self.create_features(processed_df[segment_mask], segment)\n",
    "                y = processed_df[segment_mask]['가격(백만원)'].values\n",
    "                \n",
    "                # 스케일링\n",
    "                scaler = StandardScaler()\n",
    "                X_scaled = scaler.fit_transform(X)\n",
    "                self.scalers[segment] = scaler\n",
    "                \n",
    "                # 최적화 수행\n",
    "                best_params, best_rmse = self.optimize_segment(X_scaled, y, segment)\n",
    "                \n",
    "                results[segment] = {\n",
    "                    'best_params': best_params,\n",
    "                    'rmse': best_rmse,\n",
    "                    'data_count': sum(segment_mask)\n",
    "                }\n",
    "                \n",
    "                self.best_params[segment] = best_params\n",
    "        \n",
    "        # 전체 결과 요약\n",
    "        print(\"\\n=== 최적화 결과 요약 ===\")\n",
    "        for segment, result in results.items():\n",
    "            print(f\"\\n{segment}:\")\n",
    "            print(f\"데이터 수: {result['data_count']}\")\n",
    "            print(f\"RMSE: {result['rmse']:.4f}\")\n",
    "            print(\"최적 파라미터:\")\n",
    "            for param, value in result['best_params'].items():\n",
    "                print(f\"  - {param}: {value}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    \n",
    "    # 최적화 실행\n",
    "    optimizer = SegmentGridSearchOptimizer()\n",
    "    results = optimizer.run_optimization(train_data)\n",
    "    \n",
    "    # 최적 파라미터 저장\n",
    "    pd.DataFrame(results).to_json('optimal_parameters.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedEVPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scalers = {}\n",
    "        self.best_params = {}\n",
    "        self.models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 기본 보조금 정보 (백만원 단위)\n",
    "        self.subsidy_info = {\n",
    "            'EV6': {'국비': 6.84, '지자체': 1.45},\n",
    "            'EV9': {'국비': 3.01, '지자체': 0.69},\n",
    "            'EVX': {'국비': 4.57, '지자체': 1.05},\n",
    "            'ID4': {'국비': 4.92, '지자체': 1.13},\n",
    "            'Model Y': {'국비': 1.95, '지자체': 0.45},\n",
    "            'EQB': {'국비': 2.17, '지자체': 0.50}\n",
    "        }\n",
    "        \n",
    "        # 차량 세그먼트 정보\n",
    "        self.segment_info = {\n",
    "            'Premium': ['Model Y', 'EQB', 'EVX'],\n",
    "            'UpperMiddle': ['IONIQ6', 'EV6', 'ID4'],\n",
    "            'Middle': ['IONIQ5'],\n",
    "            'Large': ['EV9']\n",
    "        }\n",
    "        \n",
    "        # 그리드 서치 파라미터\n",
    "        self.param_grid = {\n",
    "            'max_iter': [500, 800, 1000, 1200],\n",
    "            'learning_rate': [0.005, 0.008, 0.01, 0.015],\n",
    "            'max_depth': [3, 4, 5, 6],\n",
    "            'min_samples_leaf': [10, 20, 30],\n",
    "            'l2_regularization': [0.5, 1, 2]\n",
    "        }\n",
    "\n",
    "    def get_ioniq_model_version(self, battery_capacity):\n",
    "        \"\"\"IONIQ 모델 버전 판별\"\"\"\n",
    "        if pd.isna(battery_capacity):\n",
    "            return 'Unknown'\n",
    "        elif battery_capacity <= 55:\n",
    "            return 'Standard'\n",
    "        elif battery_capacity <= 65:\n",
    "            return 'Plus'\n",
    "        else:\n",
    "            return 'Premium'\n",
    "\n",
    "    def get_ioniq_subsidy(self, model_version, condition, age):\n",
    "        \"\"\"IONIQ 모델별 보조금 계산\"\"\"\n",
    "        base_subsidies = {\n",
    "            'Standard': {'국비': 6.9, '지자체': 1.5},\n",
    "            'Plus': {'국비': 6.9, '지자체': 1.5},\n",
    "            'Premium': {'국비': 6.5, '지자체': 1.4},\n",
    "            'Unknown': {'국비': 6.7, '지자체': 1.45}\n",
    "        }\n",
    "        \n",
    "        # 차량 상태에 따른 보조금 조정\n",
    "        condition_multiplier = {\n",
    "            'Nearly New': 1.0,\n",
    "            'Pre-Owned': 0.8\n",
    "        }\n",
    "        \n",
    "        # 연식에 따른 보조금 조정\n",
    "        age_multiplier = 1.0 if age == 0 else (0.9 if age == 1 else 0.8)\n",
    "        \n",
    "        subsidy = base_subsidies[model_version]\n",
    "        total_multiplier = condition_multiplier[condition] * age_multiplier\n",
    "        \n",
    "        return {\n",
    "            '국비': subsidy['국비'] * total_multiplier,\n",
    "            '지자체': subsidy['지자체'] * total_multiplier\n",
    "        }\n",
    "\n",
    "    def calculate_subsidy(self, row):\n",
    "        \"\"\"모델별 보조금 계산\"\"\"\n",
    "        if row['모델'] == 'IONIQ':\n",
    "            model_version = self.get_ioniq_model_version(row['배터리용량'])\n",
    "            subsidy = self.get_ioniq_subsidy(model_version, row['차량상태'], row['연식(년)'])\n",
    "            return subsidy['국비'] + subsidy['지자체']\n",
    "        else:\n",
    "            info = self.subsidy_info.get(row['모델'], {'국비': 0, '지자체': 0})\n",
    "            return info['국비'] + info['지자체']\n",
    "\n",
    "    def get_segment(self, model):\n",
    "        \"\"\"차량 세그먼트 반환\"\"\"\n",
    "        for segment, models in self.segment_info.items():\n",
    "            if model in models:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 보조금 정보 추가\n",
    "        df['total_subsidy'] = df.apply(self.calculate_subsidy, axis=1)\n",
    "        df['subsidy_ratio'] = df['total_subsidy'] / df['가격(백만원)'] if '가격(백만원)' in df.columns else 0\n",
    "        df['price_after_subsidy'] = df['가격(백만원)'] - df['total_subsidy'] if '가격(백만원)' in df.columns else 0\n",
    "        \n",
    "        # IONIQ 모델 버전 추가\n",
    "        df['ioniq_version'] = df.apply(\n",
    "            lambda x: self.get_ioniq_model_version(x['배터리용량']) if x['모델'] == 'IONIQ' else 'NA',\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # 세그먼트 정보 추가\n",
    "        df['segment'] = df['모델'].map(self.get_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        categorical_cols = ['제조사', '모델', '구동방식', '차량상태', 'segment', 'ioniq_version']\n",
    "        for col in categorical_cols:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                self.label_encoders[col].fit(df[col])\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby(['모델', 'ioniq_version'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.median())\n",
    "        )\n",
    "        \n",
    "        # 특성 생성\n",
    "        df['km_per_year'] = df['주행거리(km)'] / (df['연식(년)'] + 1)\n",
    "        df['battery_efficiency'] = df['배터리용량'] / np.log1p(df['주행거리(km)'])\n",
    "        df['warranty_value'] = df['보증기간(년)'] * df['battery_efficiency']\n",
    "        \n",
    "        # 사고이력 이진화\n",
    "        df['accident_binary'] = (df['사고이력'] == 'Yes').astype(int)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_segment_features(self, df, segment):\n",
    "        \"\"\"세그먼트별 특화된 특성 생성\"\"\"\n",
    "        base_features = [\n",
    "            'km_per_year', 'battery_efficiency', 'warranty_value',\n",
    "            'subsidy_ratio', 'total_subsidy', 'price_after_subsidy',\n",
    "            'segment_encoded', '제조사_encoded', '모델_encoded',\n",
    "            '구동방식_encoded', '차량상태_encoded', 'ioniq_version_encoded',\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)',\n",
    "            'accident_binary'\n",
    "        ]\n",
    "        \n",
    "        # IONIQ 특화 특성\n",
    "        if segment == 'Middle' or 'UpperMiddle':\n",
    "            df['battery_age_score'] = df['배터리용량'] * (1 - df['연식(년)'] * 0.1)\n",
    "            df['warranty_efficiency'] = df['보증기간(년)'] * df['battery_efficiency']\n",
    "            base_features.extend(['battery_age_score', 'warranty_efficiency'])\n",
    "        \n",
    "        return df[base_features]\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 모델 학습\"\"\"\n",
    "        model = HistGradientBoostingRegressor(\n",
    "            random_state=42,\n",
    "            max_iter=1000,\n",
    "            learning_rate=0.01,\n",
    "            max_depth=5\n",
    "        )\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        processed_df = self.preprocess_data(train_df)\n",
    "        \n",
    "        for segment in set(processed_df['segment']):\n",
    "            segment_mask = processed_df['segment'] == segment\n",
    "            if sum(segment_mask) >= 20:\n",
    "                segment_df = processed_df[segment_mask].copy()\n",
    "                X = self.create_segment_features(segment_df, segment)\n",
    "                y = segment_df['가격(백만원)'].values\n",
    "                \n",
    "                # 스케일링\n",
    "                scaler = StandardScaler()\n",
    "                X_scaled = scaler.fit_transform(X)\n",
    "                self.scalers[segment] = scaler\n",
    "                \n",
    "                # 모델 학습\n",
    "                self.models[segment] = self.train_segment_model(X_scaled, y, segment)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        processed_df = self.preprocess_data(test_df)\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        for segment in set(processed_df['segment']):\n",
    "            segment_mask = processed_df['segment'] == segment\n",
    "            if sum(segment_mask) > 0 and segment in self.models:\n",
    "                segment_df = processed_df[segment_mask].copy()\n",
    "                X = self.create_segment_features(segment_df, segment)\n",
    "                X_scaled = self.scalers[segment].transform(X)\n",
    "                predictions[segment_mask] = self.models[segment].predict(X_scaled)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 모델 학습\n",
    "    predictor = EnhancedEVPricePredictor()\n",
    "    predictor.fit(train_data)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = predictor.predict(test_data)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('refined_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "처리 중: 세그먼트 1 (데이터 수: 1679)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "=== 세그먼트 1 그리드서치 결과 ===\n",
      "최적 파라미터: {'l2_regularization': 1, 'learning_rate': 0.005, 'max_depth': 4, 'max_iter': 1200, 'min_samples_leaf': 20}\n",
      "최적 RMSE: 1.6387\n",
      "\n",
      "처리 중: 세그먼트 2 (데이터 수: 2100)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "=== 세그먼트 2 그리드서치 결과 ===\n",
      "최적 파라미터: {'l2_regularization': 1.2, 'learning_rate': 0.01, 'max_depth': 4, 'max_iter': 600, 'min_samples_leaf': 15}\n",
      "최적 RMSE: 0.5206\n",
      "\n",
      "처리 중: 세그먼트 3 (데이터 수: 657)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "=== 세그먼트 3 그리드서치 결과 ===\n",
      "최적 파라미터: {'l2_regularization': 1, 'learning_rate': 0.01, 'max_depth': 4, 'max_iter': 800, 'min_samples_leaf': 10}\n",
      "최적 RMSE: 0.4069\n",
      "\n",
      "처리 중: 세그먼트 4 (데이터 수: 1359)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "=== 세그먼트 4 그리드서치 결과 ===\n",
      "최적 파라미터: {'l2_regularization': 1.5, 'learning_rate': 0.008, 'max_depth': 6, 'max_iter': 1000, 'min_samples_leaf': 12}\n",
      "최적 RMSE: 0.5871\n",
      "\n",
      "처리 중: 세그먼트 5 (데이터 수: 631)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "=== 세그먼트 5 그리드서치 결과 ===\n",
      "최적 파라미터: {'l2_regularization': 1.2, 'learning_rate': 0.01, 'max_depth': 4, 'max_iter': 800, 'min_samples_leaf': 10}\n",
      "최적 RMSE: 0.6210\n",
      "\n",
      "처리 중: 세그먼트 6 (데이터 수: 696)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "=== 세그먼트 6 그리드서치 결과 ===\n",
      "최적 파라미터: {'l2_regularization': 2, 'learning_rate': 0.005, 'max_depth': 5, 'max_iter': 1200, 'min_samples_leaf': 20}\n",
      "최적 RMSE: 3.2685\n",
      "\n",
      "처리 중: 세그먼트 7 (데이터 수: 375)\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "=== 세그먼트 7 그리드서치 결과 ===\n",
      "최적 파라미터: {'l2_regularization': 1.5, 'learning_rate': 0.008, 'max_depth': 4, 'max_iter': 1000, 'min_samples_leaf': 15}\n",
      "최적 RMSE: 0.3344\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ImprovedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.premium_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        self.model_stats = {}\n",
    "        self.best_params = {}\n",
    "        \n",
    "        # 세그먼트별 그리드서치 파라미터 설정\n",
    "        self.param_grids = {\n",
    "            1: {  # 엔트리 세그먼트\n",
    "                'max_iter': [800, 1000, 1200],\n",
    "                'learning_rate': [0.005, 0.008, 0.01],\n",
    "                'max_depth': [3, 4, 5],\n",
    "                'min_samples_leaf': [10, 20],\n",
    "                'l2_regularization': [1, 2]\n",
    "            },\n",
    "            2: {  # 기본 세그먼트\n",
    "                'max_iter': [600, 800, 1000],\n",
    "                'learning_rate': [0.008, 0.01, 0.015],\n",
    "                'max_depth': [4, 5, 6],\n",
    "                'min_samples_leaf': [15, 20],\n",
    "                'l2_regularization': [0.8, 1.2]\n",
    "            },\n",
    "            3: {  # 중형 세그먼트\n",
    "                'max_iter': [800, 1000, 1200],\n",
    "                'learning_rate': [0.01, 0.015, 0.02],\n",
    "                'max_depth': [4, 5, 6],\n",
    "                'min_samples_leaf': [10, 15],\n",
    "                'l2_regularization': [0.5, 1]\n",
    "            },\n",
    "            4: {  # 상위중형 세그먼트\n",
    "                'max_iter': [1000, 1200, 1400],\n",
    "                'learning_rate': [0.008, 0.01, 0.012],\n",
    "                'max_depth': [5, 6, 7],\n",
    "                'min_samples_leaf': [12, 15],\n",
    "                'l2_regularization': [1, 1.5]\n",
    "            },\n",
    "            5: {  # 럭셔리 세그먼트\n",
    "                'max_iter': [800, 1000, 1200],\n",
    "                'learning_rate': [0.01, 0.015, 0.02],\n",
    "                'max_depth': [4, 5, 6],\n",
    "                'min_samples_leaf': [8, 10],\n",
    "                'l2_regularization': [0.8, 1.2]\n",
    "            },\n",
    "            6: {  # 준프리미엄 세그먼트\n",
    "                'max_iter': [1200, 1500, 1800],\n",
    "                'learning_rate': [0.005, 0.008, 0.01],\n",
    "                'max_depth': [5, 6, 7],\n",
    "                'min_samples_leaf': [15, 20],\n",
    "                'l2_regularization': [1.5, 2]\n",
    "            },\n",
    "            7: {  # 프리미엄 세그먼트\n",
    "                'max_iter': [1000, 1200, 1400],\n",
    "                'learning_rate': [0.008, 0.01, 0.015],\n",
    "                'max_depth': [4, 5, 6],\n",
    "                'min_samples_leaf': [10, 15],\n",
    "                'l2_regularization': [1, 1.5]\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def handle_premium_outliers(self, df, model_name):\n",
    "        \"\"\"준프리미엄 세그먼트 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        if model_name == 'Tay':\n",
    "            high_mileage_mask = (df['주행거리(km)'] > 150000) & (df['차량상태'] == 'Pre-Owned')\n",
    "            df.loc[high_mileage_mask, 'price_weight'] *= 0.7\n",
    "            \n",
    "            if '가격(백만원)' in df.columns:\n",
    "                expected_price = 122 - (df['주행거리(km)'] / 20000)\n",
    "                price_diff = np.abs(df['가격(백만원)'] - expected_price)\n",
    "                df.loc[price_diff > 15, 'price_weight'] *= 0.8\n",
    "                \n",
    "        elif model_name == 'TayCT':\n",
    "            df.loc[df['주행거리(km)'] > 120000, 'price_weight'] *= 0.7\n",
    "            df.loc[(df['주행거리(km)'] > 80000) & (df['주행거리(km)'] <= 120000), 'price_weight'] *= 0.85\n",
    "            \n",
    "            if '가격(백만원)' in df.columns:\n",
    "                brand_new_mask = df['차량상태'] == 'Brand New'\n",
    "                brand_new_mean = df.loc[brand_new_mask, '가격(백만원)'].mean()\n",
    "                brand_new_std = df.loc[brand_new_mask, '가격(백만원)'].std()\n",
    "                price_outlier_mask = np.abs(df['가격(백만원)'] - brand_new_mean) > 2 * brand_new_std\n",
    "                df.loc[brand_new_mask & price_outlier_mask, 'price_weight'] *= 0.8\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def handle_entry_outliers(self, df):\n",
    "        \"\"\"엔트리 세그먼트 이상치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        ioniq_mask = df['모델'] == 'IONIQ'\n",
    "        if sum(ioniq_mask) > 0 and '가격(백만원)' in df.columns:\n",
    "            ioniq_mean = df[ioniq_mask]['가격(백만원)'].mean()\n",
    "            ioniq_std = df[ioniq_mask]['가격(백만원)'].std()\n",
    "            outlier_mask = np.abs(df[ioniq_mask]['가격(백만원)'] - ioniq_mean) > 2 * ioniq_std\n",
    "            df.loc[ioniq_mask & outlier_mask, 'price_weight'] *= 0.7\n",
    "        \n",
    "        soul_mask = (df['모델'] == 'Soul') & (df['보증기간(년)'] >= 9)\n",
    "        df.loc[soul_mask, 'warranty_factor'] = 1.2\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 가중치 초기화\n",
    "        df['price_weight'] = 1.0\n",
    "        df['warranty_factor'] = 1.0\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(lambda x: x.fillna(x.mean()))\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 이상치 처리\n",
    "        premium_mask = df['model_segment'] == 6\n",
    "        entry_mask = df['model_segment'] == 1\n",
    "        \n",
    "        if sum(premium_mask) > 0:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = df['모델'] == model\n",
    "                if sum(model_mask) > 0:\n",
    "                    df.loc[model_mask] = self.handle_premium_outliers(df[model_mask], model)\n",
    "        \n",
    "        if sum(entry_mask) > 0:\n",
    "            df.loc[entry_mask] = self.handle_entry_outliers(df[entry_mask])\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "\n",
    "        # 기본 특성 생성\n",
    "        features = {\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'] * df['warranty_factor'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'distance': df['주행거리(km)'],\n",
    "            'price_weight': df['price_weight']\n",
    "        }\n",
    "        \n",
    "        # 추가 특성 생성\n",
    "        features['km_per_year'] = df['주행거리(km)'] / (df['연식(년)'] + 1)\n",
    "        features['battery_efficiency'] = df['배터리용량'] / np.log1p(df['주행거리(km)'])\n",
    "        features['warranty_value'] = features['warranty'] * features['battery_efficiency']\n",
    "        \n",
    "        return pd.DataFrame(features)\n",
    "\n",
    "    def grid_search_segment(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 그리드서치 수행\"\"\"\n",
    "        param_grid = self.param_grids[segment]\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=HistGradientBoostingRegressor(random_state=42),\n",
    "            param_grid=param_grid,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            cv=self.kf,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y, sample_weight=X['price_weight'] if 'price_weight' in X.columns else None)\n",
    "        \n",
    "        print(f\"\\n=== 세그먼트 {segment} 그리드서치 결과 ===\")\n",
    "        print(f\"최적 파라미터: {grid_search.best_params_}\")\n",
    "        print(f\"최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        return grid_search.best_params_, -grid_search.best_score_\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        # 세그먼트별 그리드서치 및 모델 학습\n",
    "        for segment in range(1, 8):\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                print(f\"\\n처리 중: 세그먼트 {segment} (데이터 수: {sum(mask)})\")\n",
    "                \n",
    "                # 그리드서치 수행\n",
    "                best_params, best_rmse = self.grid_search_segment(X[mask], y[mask], segment)\n",
    "                self.best_params[segment] = best_params\n",
    "                \n",
    "                # 최적 파라미터로 모델 학습\n",
    "                model = HistGradientBoostingRegressor(\n",
    "                    random_state=42,\n",
    "                    **best_params\n",
    "                )\n",
    "                model.fit(\n",
    "                    X[mask],\n",
    "                    y[mask],\n",
    "                    sample_weight=X[mask]['price_weight'] if 'price_weight' in X.columns else None\n",
    "                )\n",
    "                self.segment_models[segment] = model\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        for segment, model in self.segment_models.items():\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                predictions[mask] = model.predict(X[mask])\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 모델 학습\n",
    "    predictor = ImprovedSegmentPredictor()\n",
    "    predictor.fit(train_data)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = predictor.predict(test_data)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('grid_search_submission.csv', index=False)\n",
    "    \n",
    "    # 최적 파라미터 저장\n",
    "    pd.DataFrame(predictor.best_params).to_json('segment_best_params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 세그먼트별 모델 학습 ===\n",
      "\n",
      "처리 중: 세그먼트 1 (데이터 수: 1679)\n",
      "RMSE: 0.4805, R2: 0.9998\n",
      "HGB 가중치: 0.5000, RF 가중치: 0.5000\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.0, 'learning_rate': 0.01, 'max_depth': 5, 'max_iter': 1200, 'min_samples_leaf': 20}\n",
      "\n",
      "처리 중: 세그먼트 2 (데이터 수: 2100)\n",
      "RMSE: 0.4343, R2: 0.9945\n",
      "HGB 가중치: 0.4998, RF 가중치: 0.5002\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.0, 'learning_rate': 0.008, 'max_depth': 5, 'max_iter': 800, 'min_samples_leaf': 15}\n",
      "\n",
      "처리 중: 세그먼트 3 (데이터 수: 657)\n",
      "RMSE: 0.2883, R2: 0.9950\n",
      "HGB 가중치: 0.4994, RF 가중치: 0.5006\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.0, 'learning_rate': 0.01, 'max_depth': 4, 'max_iter': 800, 'min_samples_leaf': 10}\n",
      "\n",
      "처리 중: 세그먼트 4 (데이터 수: 1359)\n",
      "RMSE: 0.4385, R2: 0.9958\n",
      "HGB 가중치: 0.4997, RF 가중치: 0.5003\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.2, 'learning_rate': 0.008, 'max_depth': 5, 'max_iter': 1000, 'min_samples_leaf': 15}\n",
      "\n",
      "처리 중: 세그먼트 5 (데이터 수: 631)\n",
      "RMSE: 0.4937, R2: 0.9919\n",
      "HGB 가중치: 0.5001, RF 가중치: 0.4999\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.0, 'learning_rate': 0.01, 'max_depth': 4, 'max_iter': 800, 'min_samples_leaf': 8}\n",
      "\n",
      "처리 중: 세그먼트 6 (데이터 수: 696)\n",
      "RMSE: 1.6252, R2: 0.9795\n",
      "HGB 가중치: 0.4971, RF 가중치: 0.5029\n",
      "HGB 최적 파라미터: {'l2_regularization': 3.0, 'learning_rate': 0.008, 'max_depth': 7, 'max_iter': 2000, 'min_samples_leaf': 30}\n",
      "\n",
      "처리 중: 세그먼트 7 (데이터 수: 375)\n",
      "RMSE: 0.2491, R2: 0.9932\n",
      "HGB 가중치: 0.4996, RF 가중치: 0.5004\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.5, 'learning_rate': 0.008, 'max_depth': 4, 'max_iter': 1000, 'min_samples_leaf': 15}\n",
      "\n",
      "=== 모델 학습 완료 ===\n",
      "\n",
      "세그먼트별 성능 요약:\n",
      "\n",
      "세그먼트 1:\n",
      "데이터 수: 1679\n",
      "RMSE: 0.4805\n",
      "R2: 0.9998\n",
      "HGB 가중치: 0.5000\n",
      "RF 가중치: 0.5000\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.0, 'learning_rate': 0.01, 'max_depth': 5, 'max_iter': 1200, 'min_samples_leaf': 20}\n",
      "\n",
      "세그먼트 2:\n",
      "데이터 수: 2100\n",
      "RMSE: 0.4343\n",
      "R2: 0.9945\n",
      "HGB 가중치: 0.4998\n",
      "RF 가중치: 0.5002\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.0, 'learning_rate': 0.008, 'max_depth': 5, 'max_iter': 800, 'min_samples_leaf': 15}\n",
      "\n",
      "세그먼트 3:\n",
      "데이터 수: 657\n",
      "RMSE: 0.2883\n",
      "R2: 0.9950\n",
      "HGB 가중치: 0.4994\n",
      "RF 가중치: 0.5006\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.0, 'learning_rate': 0.01, 'max_depth': 4, 'max_iter': 800, 'min_samples_leaf': 10}\n",
      "\n",
      "세그먼트 4:\n",
      "데이터 수: 1359\n",
      "RMSE: 0.4385\n",
      "R2: 0.9958\n",
      "HGB 가중치: 0.4997\n",
      "RF 가중치: 0.5003\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.2, 'learning_rate': 0.008, 'max_depth': 5, 'max_iter': 1000, 'min_samples_leaf': 15}\n",
      "\n",
      "세그먼트 5:\n",
      "데이터 수: 631\n",
      "RMSE: 0.4937\n",
      "R2: 0.9919\n",
      "HGB 가중치: 0.5001\n",
      "RF 가중치: 0.4999\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.0, 'learning_rate': 0.01, 'max_depth': 4, 'max_iter': 800, 'min_samples_leaf': 8}\n",
      "\n",
      "세그먼트 6:\n",
      "데이터 수: 696\n",
      "RMSE: 1.6252\n",
      "R2: 0.9795\n",
      "HGB 가중치: 0.4971\n",
      "RF 가중치: 0.5029\n",
      "HGB 최적 파라미터: {'l2_regularization': 3.0, 'learning_rate': 0.008, 'max_depth': 7, 'max_iter': 2000, 'min_samples_leaf': 30}\n",
      "\n",
      "세그먼트 7:\n",
      "데이터 수: 375\n",
      "RMSE: 0.2491\n",
      "R2: 0.9932\n",
      "HGB 가중치: 0.4996\n",
      "RF 가중치: 0.5004\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.5, 'learning_rate': 0.008, 'max_depth': 4, 'max_iter': 1000, 'min_samples_leaf': 15}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ImprovedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 세그먼트별 RF 파라미터\n",
    "        self.rf_params = {\n",
    "            1: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 4},\n",
    "            2: {'n_estimators': 150, 'max_depth': 8, 'min_samples_split': 4, 'min_samples_leaf': 3},\n",
    "            3: {'n_estimators': 180, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 2},\n",
    "            4: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3},\n",
    "            5: {'n_estimators': 150, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 4},\n",
    "            6: {'n_estimators': 250, 'max_depth': 12, 'min_samples_split': 3, 'min_samples_leaf': 2},\n",
    "            7: {'n_estimators': 200, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 3}\n",
    "        }\n",
    "        \n",
    "        # HGB 그리드서치 파라미터\n",
    "        self.hgb_param_grids = {\n",
    "            1: {  # 엔트리\n",
    "                'max_iter': [800, 1000, 1200],\n",
    "                'learning_rate': [0.005, 0.008, 0.01],\n",
    "                'max_depth': [3, 4, 5],\n",
    "                'min_samples_leaf': [10, 20],\n",
    "                'l2_regularization': [1.0, 1.5, 2.0]\n",
    "            },\n",
    "            2: {  # 기본\n",
    "                'max_iter': [600, 800, 1000],\n",
    "                'learning_rate': [0.008, 0.01, 0.015],\n",
    "                'max_depth': [4, 5, 6],\n",
    "                'min_samples_leaf': [15, 20],\n",
    "                'l2_regularization': [0.8, 1.0, 1.2]\n",
    "            },\n",
    "            3: {  # 중형\n",
    "                'max_iter': [800, 1000, 1200],\n",
    "                'learning_rate': [0.01, 0.015, 0.02],\n",
    "                'max_depth': [4, 5, 6],\n",
    "                'min_samples_leaf': [10, 15],\n",
    "                'l2_regularization': [0.5, 0.8, 1.0]\n",
    "            },\n",
    "            4: {  # 상위중형\n",
    "                'max_iter': [1000, 1200, 1400],\n",
    "                'learning_rate': [0.008, 0.01, 0.012],\n",
    "                'max_depth': [5, 6, 7],\n",
    "                'min_samples_leaf': [12, 15],\n",
    "                'l2_regularization': [1.0, 1.2, 1.5]\n",
    "            },\n",
    "            5: {  # 럭셔리\n",
    "                'max_iter': [800, 1000, 1200],\n",
    "                'learning_rate': [0.01, 0.015, 0.02],\n",
    "                'max_depth': [4, 5, 6],\n",
    "                'min_samples_leaf': [8, 10],\n",
    "                'l2_regularization': [0.8, 1.0, 1.2]\n",
    "            },\n",
    "            6: {  # 준프리미엄\n",
    "                'max_iter': [1500, 1800, 2000],\n",
    "                'learning_rate': [0.003, 0.005, 0.008],\n",
    "                'max_depth': [5, 6, 7],\n",
    "                'min_samples_leaf': [30, 40, 50],\n",
    "                'l2_regularization': [2.0, 2.5, 3.0]\n",
    "            },\n",
    "            7: {  # 프리미엄\n",
    "                'max_iter': [1000, 1200, 1400],\n",
    "                'learning_rate': [0.008, 0.01, 0.015],\n",
    "                'max_depth': [4, 5, 6],\n",
    "                'min_samples_leaf': [10, 15],\n",
    "                'l2_regularization': [1.0, 1.2, 1.5]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def handle_battery_missing(self, df):\n",
    "        \"\"\"모델별 특화된 배터리 결측치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # IONIQ 처리\n",
    "        ioniq_mask = df['모델'] == 'IONIQ'\n",
    "        if sum(ioniq_mask) > 0:\n",
    "            df.loc[ioniq_mask, '배터리용량'] = df[ioniq_mask].groupby(\n",
    "                ['차량상태', '연식(년)']\n",
    "            )['배터리용량'].transform(lambda x: x.fillna(x.median()))\n",
    "        \n",
    "        # TayCT 처리\n",
    "        tayct_mask = df['모델'] == 'TayCT'\n",
    "        if sum(tayct_mask) > 0:\n",
    "            brand_new_missing = tayct_mask & (df['차량상태'] == 'Brand New') & df['배터리용량'].isna()\n",
    "            if sum(brand_new_missing) > 0:\n",
    "                reference_value = df[\n",
    "                    tayct_mask & \n",
    "                    (df['차량상태'] == 'Brand New') & \n",
    "                    (df['주행거리(km)'] <= 5000) & \n",
    "                    df['배터리용량'].notna()\n",
    "                ]['배터리용량'].mean()\n",
    "                df.loc[brand_new_missing, '배터리용량'] = reference_value\n",
    "        \n",
    "        # Tay 처리\n",
    "        tay_mask = df['모델'] == 'Tay'\n",
    "        if sum(tay_mask) > 0:\n",
    "            brand_new_missing = tay_mask & (df['차량상태'] == 'Brand New') & df['배터리용량'].isna()\n",
    "            if sum(brand_new_missing) > 0:\n",
    "                df.loc[brand_new_missing, '배터리용량'] = df[\n",
    "                    tay_mask & \n",
    "                    (df['차량상태'] == 'Brand New') & \n",
    "                    df['배터리용량'].notna()\n",
    "                ]['배터리용량'].mean()\n",
    "                \n",
    "                if '가격(백만원)' in df.columns:\n",
    "                    price_factor = df.loc[brand_new_missing, '가격(백만원)'] / 100\n",
    "                    df.loc[brand_new_missing, '배터리용량'] *= price_factor\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df = self.handle_battery_missing(df)\n",
    "        \n",
    "        # 기본 가중치 초기화\n",
    "        df['price_weight'] = 1.0\n",
    "        df['warranty_factor'] = 1.0\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "\n",
    "        # 특성 생성\n",
    "        features = {\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'] * df['warranty_factor'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'distance': df['주행거리(km)'],\n",
    "            'price_weight': df['price_weight'],\n",
    "            'km_per_year': df['주행거리(km)'] / (df['연식(년)'] + 1),\n",
    "            'battery_efficiency': df['배터리용량'] / np.log1p(df['주행거리(km)']),\n",
    "            'price_efficiency': df['가격(백만원)'] / (df['주행거리(km)'] / 10000) if '가격(백만원)' in df.columns else 0\n",
    "        }\n",
    "        \n",
    "        return pd.DataFrame(features)\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 앙상블 모델 학습\"\"\"\n",
    "        if 'price_weight' in X.columns:\n",
    "            weights = X['price_weight']\n",
    "            X = X.drop('price_weight', axis=1)\n",
    "        else:\n",
    "            weights = None\n",
    "            \n",
    "        # HGB 그리드서치\n",
    "        hgb_grid = GridSearchCV(\n",
    "            HistGradientBoostingRegressor(random_state=42),\n",
    "            param_grid=self.hgb_param_grids[segment],\n",
    "            cv=self.kf,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # RF 모델\n",
    "        rf = RandomForestRegressor(random_state=42, **self.rf_params[segment])\n",
    "        \n",
    "        # 모델 학습\n",
    "        hgb_grid.fit(X, y, sample_weight=weights)\n",
    "        rf.fit(X, y, sample_weight=weights)\n",
    "        \n",
    "        # 최적 HGB 모델\n",
    "        hgb = hgb_grid.best_estimator_\n",
    "        \n",
    "        # 성능 평가\n",
    "        hgb_pred = hgb.predict(X)\n",
    "        rf_pred = rf.predict(X)\n",
    "        \n",
    "        hgb_score = r2_score(y, hgb_pred)\n",
    "        rf_score = r2_score(y, rf_pred)\n",
    "        \n",
    "        total_score = hgb_score + rf_score\n",
    "        hgb_weight = hgb_score / total_score\n",
    "        rf_weight = rf_score / total_score\n",
    "        \n",
    "        return {\n",
    "            'hgb': (hgb, hgb_weight),\n",
    "            'rf': (rf, rf_weight),\n",
    "            'best_params': hgb_grid.best_params_\n",
    "        }\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 모델 학습 ===\")\n",
    "        for segment in range(1, 8):\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                print(f\"\\n처리 중: 세그먼트 {segment} (데이터 수: {sum(mask)})\")\n",
    "                \n",
    "                X_segment = X[mask]\n",
    "                y_segment = y[mask]\n",
    "                \n",
    "                # 모델 학습\n",
    "                models = self.train_segment_model(X_segment, y_segment, segment)\n",
    "                self.segment_models[segment] = models\n",
    "                \n",
    "                # 성능 평가\n",
    "                if 'price_weight' in X_segment.columns:\n",
    "                    X_pred = X_segment.drop('price_weight', axis=1)\n",
    "                else:\n",
    "                    X_pred = X_segment\n",
    "                \n",
    "                hgb_model, hgb_weight = models['hgb']\n",
    "                rf_model, rf_weight = models['rf']\n",
    "                \n",
    "                hgb_pred = hgb_model.predict(X_pred)\n",
    "                rf_pred = rf_model.predict(X_pred)\n",
    "                \n",
    "                ensemble_pred = hgb_pred * hgb_weight + rf_pred * rf_weight\n",
    "                rmse = np.sqrt(mean_squared_error(y_segment, ensemble_pred))\n",
    "                r2 = r2_score(y_segment, ensemble_pred)\n",
    "                \n",
    "                print(f\"RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "                print(f\"HGB 가중치: {hgb_weight:.4f}, RF 가중치: {rf_weight:.4f}\")\n",
    "                print(\"HGB 최적 파라미터:\", models['best_params'])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        for segment, models in self.segment_models.items():\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                if 'price_weight' in X.columns:\n",
    "                    X_pred = X[mask].drop('price_weight', axis=1)\n",
    "                else:\n",
    "                    X_pred = X[mask]\n",
    "                \n",
    "                hgb_model, hgb_weight = models['hgb']\n",
    "                rf_model, rf_weight = models['rf']\n",
    "                \n",
    "                hgb_pred = hgb_model.predict(X_pred)\n",
    "                rf_pred = rf_model.predict(X_pred)\n",
    "                \n",
    "                predictions[mask] = hgb_pred * hgb_weight + rf_pred * rf_weight\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 모델 학습\n",
    "    predictor = ImprovedSegmentPredictor()\n",
    "    predictor.fit(train_data)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = predictor.predict(test_data)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('final_ensemble_submission.csv', index=False)\n",
    "    \n",
    "    # 모델 성능 통계 저장\n",
    "    model_stats = {\n",
    "        'segment': [],\n",
    "        'data_count': [],\n",
    "        'hgb_weight': [],\n",
    "        'rf_weight': [],\n",
    "        'rmse': [],\n",
    "        'r2': [],\n",
    "        'hgb_params': []\n",
    "    }\n",
    "    \n",
    "    for segment, models in predictor.segment_models.items():\n",
    "        mask = train_data['모델'].apply(predictor.get_detailed_segment) == segment\n",
    "        X = predictor.create_features(train_data[mask])\n",
    "        y = train_data[mask]['가격(백만원)']\n",
    "        \n",
    "        if 'price_weight' in X.columns:\n",
    "            X_pred = X.drop('price_weight', axis=1)\n",
    "        else:\n",
    "            X_pred = X\n",
    "            \n",
    "        hgb_model, hgb_weight = models['hgb']\n",
    "        rf_model, rf_weight = models['rf']\n",
    "        \n",
    "        hgb_pred = hgb_model.predict(X_pred)\n",
    "        rf_pred = rf_model.predict(X_pred)\n",
    "        \n",
    "        ensemble_pred = hgb_pred * hgb_weight + rf_pred * rf_weight\n",
    "        rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "        r2 = r2_score(y, ensemble_pred)\n",
    "        \n",
    "        model_stats['segment'].append(segment)\n",
    "        model_stats['data_count'].append(sum(mask))\n",
    "        model_stats['hgb_weight'].append(hgb_weight)\n",
    "        model_stats['rf_weight'].append(rf_weight)\n",
    "        model_stats['rmse'].append(rmse)\n",
    "        model_stats['r2'].append(r2)\n",
    "        model_stats['hgb_params'].append(models['best_params'])\n",
    "    \n",
    "    # 성능 통계 저장\n",
    "    stats_df = pd.DataFrame(model_stats)\n",
    "    stats_df.to_csv('model_performance_stats.csv', index=False)\n",
    "    \n",
    "    # 배터리 결측치 처리 통계\n",
    "    missing_stats = {\n",
    "        'model': [],\n",
    "        'total_count': [],\n",
    "        'missing_count': [],\n",
    "        'missing_ratio': [],\n",
    "        'avg_price_with_missing': [],\n",
    "        'avg_price_without_missing': []\n",
    "    }\n",
    "    \n",
    "    for model in ['IONIQ', 'TayCT', 'Tay']:\n",
    "        model_data = train_data[train_data['모델'] == model]\n",
    "        missing_mask = model_data['배터리용량'].isna()\n",
    "        \n",
    "        missing_stats['model'].append(model)\n",
    "        missing_stats['total_count'].append(len(model_data))\n",
    "        missing_stats['missing_count'].append(sum(missing_mask))\n",
    "        missing_stats['missing_ratio'].append(sum(missing_mask) / len(model_data))\n",
    "        missing_stats['avg_price_with_missing'].append(\n",
    "            model_data[missing_mask]['가격(백만원)'].mean()\n",
    "        )\n",
    "        missing_stats['avg_price_without_missing'].append(\n",
    "            model_data[~missing_mask]['가격(백만원)'].mean()\n",
    "        )\n",
    "    \n",
    "    # 결측치 통계 저장\n",
    "    pd.DataFrame(missing_stats).to_csv('battery_missing_stats.csv', index=False)\n",
    "    \n",
    "    print(\"\\n=== 모델 학습 완료 ===\")\n",
    "    print(\"\\n세그먼트별 성능 요약:\")\n",
    "    for segment in range(1, 8):\n",
    "        if segment in predictor.segment_models:\n",
    "            print(f\"\\n세그먼트 {segment}:\")\n",
    "            print(f\"데이터 수: {model_stats['data_count'][segment-1]}\")\n",
    "            print(f\"RMSE: {model_stats['rmse'][segment-1]:.4f}\")\n",
    "            print(f\"R2: {model_stats['r2'][segment-1]:.4f}\")\n",
    "            print(f\"HGB 가중치: {model_stats['hgb_weight'][segment-1]:.4f}\")\n",
    "            print(f\"RF 가중치: {model_stats['rf_weight'][segment-1]:.4f}\")\n",
    "            print(\"HGB 최적 파라미터:\", model_stats['hgb_params'][segment-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 세그먼트별 모델 학습 ===\n",
      "\n",
      "처리 중: 세그먼트 1 (데이터 수: 1679)\n",
      "RMSE: 1.4149, R2: 0.9979\n",
      "HGB 가중치: 0.5000, RF 가중치: 0.5000\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.5, 'learning_rate': 0.008, 'max_depth': 4, 'max_iter': 800, 'min_samples_leaf': 20}\n",
      "\n",
      "처리 중: 세그먼트 2 (데이터 수: 2100)\n",
      "RMSE: 0.4786, R2: 0.9933\n",
      "HGB 가중치: 0.5000, RF 가중치: 0.5000\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.5, 'learning_rate': 0.01, 'max_depth': 4, 'max_iter': 600, 'min_samples_leaf': 25}\n",
      "\n",
      "처리 중: 세그먼트 3 (데이터 수: 657)\n",
      "RMSE: 0.3367, R2: 0.9932\n",
      "HGB 가중치: 0.5002, RF 가중치: 0.4998\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.2, 'learning_rate': 0.008, 'max_depth': 4, 'max_iter': 800, 'min_samples_leaf': 20}\n",
      "\n",
      "처리 중: 세그먼트 4 (데이터 수: 1359)\n",
      "RMSE: 0.4860, R2: 0.9948\n",
      "HGB 가중치: 0.5001, RF 가중치: 0.4999\n",
      "HGB 최적 파라미터: {'l2_regularization': 2.0, 'learning_rate': 0.006, 'max_depth': 5, 'max_iter': 1000, 'min_samples_leaf': 15}\n",
      "\n",
      "처리 중: 세그먼트 5 (데이터 수: 631)\n",
      "RMSE: 0.5405, R2: 0.9903\n",
      "HGB 가중치: 0.5000, RF 가중치: 0.5000\n",
      "HGB 최적 파라미터: {'l2_regularization': 1.5, 'learning_rate': 0.008, 'max_depth': 3, 'max_iter': 800, 'min_samples_leaf': 10}\n",
      "\n",
      "처리 중: 세그먼트 6 (데이터 수: 696)\n",
      "RMSE: 2.6870, R2: 0.9439\n",
      "HGB 가중치: 0.5009, RF 가중치: 0.4991\n",
      "HGB 최적 파라미터: {'l2_regularization': 4.0, 'learning_rate': 0.005, 'max_depth': 5, 'max_iter': 1500, 'min_samples_leaf': 40}\n",
      "\n",
      "처리 중: 세그먼트 7 (데이터 수: 375)\n",
      "RMSE: 0.2806, R2: 0.9913\n",
      "HGB 가중치: 0.5001, RF 가중치: 0.4999\n",
      "HGB 최적 파라미터: {'l2_regularization': 2.0, 'learning_rate': 0.006, 'max_depth': 3, 'max_iter': 1000, 'min_samples_leaf': 20}\n",
      "\n",
      "=== 세그먼트별 성능 분석 ===\n",
      "\n",
      "세그먼트 1:\n",
      "데이터 수: 1679\n",
      "HGB RMSE: 2.8946\n",
      "RF RMSE: 2.9298\n",
      "Ensemble RMSE: 2.9061\n",
      "Ensemble R2: 0.9912\n",
      "\n",
      "Top 5 Important Features (HGB):\n",
      "manufacturer_encoded    1.982492\n",
      "model_encoded           0.134867\n",
      "warranty                0.001167\n",
      "warranty_value          0.000284\n",
      "condition_encoded       0.000214\n",
      "dtype: float64\n",
      "\n",
      "Top 5 Important Features (RF):\n",
      "manufacturer_encoded    0.912446\n",
      "model_encoded           0.081719\n",
      "warranty                0.004213\n",
      "distance                0.000409\n",
      "km_per_year             0.000406\n",
      "dtype: float64\n",
      "\n",
      "세그먼트 2:\n",
      "데이터 수: 2100\n",
      "HGB RMSE: 1.9680\n",
      "RF RMSE: 1.7438\n",
      "Ensemble RMSE: 1.7788\n",
      "Ensemble R2: 0.9074\n",
      "\n",
      "Top 5 Important Features (HGB):\n",
      "model_encoded           1.844286\n",
      "condition_encoded       0.061242\n",
      "manufacturer_encoded    0.057489\n",
      "distance                0.003058\n",
      "warranty_value          0.001711\n",
      "dtype: float64\n",
      "\n",
      "Top 5 Important Features (RF):\n",
      "model_encoded           0.862104\n",
      "warranty                0.058082\n",
      "warranty_value          0.026138\n",
      "battery_capacity        0.014870\n",
      "manufacturer_encoded    0.010834\n",
      "dtype: float64\n",
      "\n",
      "세그먼트 3:\n",
      "데이터 수: 657\n",
      "HGB RMSE: 0.7440\n",
      "RF RMSE: 0.5543\n",
      "Ensemble RMSE: 0.6197\n",
      "Ensemble R2: 0.9770\n",
      "\n",
      "Top 5 Important Features (HGB):\n",
      "manufacturer_encoded    1.674167\n",
      "warranty                0.368803\n",
      "age                     0.162535\n",
      "battery_capacity        0.059919\n",
      "condition_encoded       0.043645\n",
      "dtype: float64\n",
      "\n",
      "Top 5 Important Features (RF):\n",
      "model_encoded           0.312214\n",
      "manufacturer_encoded    0.155405\n",
      "drive_encoded           0.144070\n",
      "warranty                0.116055\n",
      "age                     0.070654\n",
      "dtype: float64\n",
      "\n",
      "세그먼트 4:\n",
      "데이터 수: 1359\n",
      "HGB RMSE: 4.1249\n",
      "RF RMSE: 4.1420\n",
      "Ensemble RMSE: 4.0615\n",
      "Ensemble R2: 0.6374\n",
      "\n",
      "Top 5 Important Features (HGB):\n",
      "manufacturer_encoded    1.121090\n",
      "condition_encoded       0.416211\n",
      "model_encoded           0.045205\n",
      "battery_capacity        0.034851\n",
      "distance                0.013993\n",
      "dtype: float64\n",
      "\n",
      "Top 5 Important Features (RF):\n",
      "model_encoded           0.337102\n",
      "warranty                0.249840\n",
      "manufacturer_encoded    0.115200\n",
      "distance                0.108665\n",
      "battery_capacity        0.104765\n",
      "dtype: float64\n",
      "\n",
      "세그먼트 5:\n",
      "데이터 수: 631\n",
      "HGB RMSE: 2.6259\n",
      "RF RMSE: 4.0170\n",
      "Ensemble RMSE: 3.3788\n",
      "Ensemble R2: 0.6203\n",
      "\n",
      "Top 5 Important Features (HGB):\n",
      "condition_encoded       1.034185\n",
      "warranty                0.150671\n",
      "manufacturer_encoded    0.061149\n",
      "battery_capacity        0.004971\n",
      "warranty_value          0.003932\n",
      "dtype: float64\n",
      "\n",
      "Top 5 Important Features (RF):\n",
      "warranty             0.686102\n",
      "battery_capacity     0.188633\n",
      "distance             0.049092\n",
      "condition_encoded    0.046600\n",
      "warranty_value       0.009810\n",
      "dtype: float64\n",
      "\n",
      "세그먼트 6:\n",
      "데이터 수: 696\n",
      "HGB RMSE: 3.7886\n",
      "RF RMSE: 4.6971\n",
      "Ensemble RMSE: 4.3180\n",
      "Ensemble R2: 0.8552\n",
      "\n",
      "Top 5 Important Features (HGB):\n",
      "model_encoded        1.311083\n",
      "condition_encoded    0.599305\n",
      "km_per_year          0.017351\n",
      "warranty_value       0.012134\n",
      "distance             0.011012\n",
      "dtype: float64\n",
      "\n",
      "Top 5 Important Features (RF):\n",
      "model_encoded         0.544238\n",
      "warranty_value        0.132477\n",
      "distance              0.117936\n",
      "condition_encoded     0.080777\n",
      "battery_efficiency    0.058411\n",
      "dtype: float64\n",
      "\n",
      "세그먼트 7:\n",
      "데이터 수: 375\n",
      "HGB RMSE: 1.9275\n",
      "RF RMSE: 2.2668\n",
      "Ensemble RMSE: 2.0765\n",
      "Ensemble R2: 0.5259\n",
      "\n",
      "Top 5 Important Features (HGB):\n",
      "condition_encoded    0.885406\n",
      "distance             0.005845\n",
      "age                  0.000278\n",
      "warranty_value       0.000214\n",
      "warranty             0.000011\n",
      "dtype: float64\n",
      "\n",
      "Top 5 Important Features (RF):\n",
      "battery_capacity      0.382582\n",
      "battery_efficiency    0.191708\n",
      "km_per_year           0.167952\n",
      "condition_encoded     0.143698\n",
      "distance              0.112185\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "from sklearn.inspection import permutation_importance\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedSegmentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segment_models = {}\n",
    "        self.scalers = {}\n",
    "        self.kf = KFold(n_splits=10, shuffle=True, random_state=42)  # 교차 검증 강화\n",
    "        \n",
    "        # 세그먼트별 RF 파라미터\n",
    "        self.rf_params = {\n",
    "            1: {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 10, 'min_samples_leaf': 8},\n",
    "            2: {'n_estimators': 250, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 6},\n",
    "            3: {'n_estimators': 280, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4},\n",
    "            4: {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6},\n",
    "            5: {'n_estimators': 250, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 8},\n",
    "            6: {'n_estimators': 350, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 4},\n",
    "            7: {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 8, 'min_samples_leaf': 6}\n",
    "        }\n",
    "        \n",
    "        # HGB 그리드서치 파라미터\n",
    "        self.hgb_param_grids = {\n",
    "            1: {\n",
    "                'max_iter': [800, 1000],\n",
    "                'learning_rate': [0.005, 0.008],\n",
    "                'max_depth': [4, 5],\n",
    "                'min_samples_leaf': [15, 20],\n",
    "                'l2_regularization': [1.5, 2.0]\n",
    "            },\n",
    "            2: {\n",
    "                'max_iter': [600, 800],\n",
    "                'learning_rate': [0.008, 0.01],\n",
    "                'max_depth': [4, 5],\n",
    "                'min_samples_leaf': [20, 25],\n",
    "                'l2_regularization': [1.2, 1.5]\n",
    "            },\n",
    "            3: {\n",
    "                'max_iter': [800, 1000],\n",
    "                'learning_rate': [0.008, 0.01],\n",
    "                'max_depth': [3, 4],\n",
    "                'min_samples_leaf': [15, 20],\n",
    "                'l2_regularization': [1.0, 1.2]\n",
    "            },\n",
    "            4: {\n",
    "                'max_iter': [1000, 1200],\n",
    "                'learning_rate': [0.006, 0.008],\n",
    "                'max_depth': [4, 5],\n",
    "                'min_samples_leaf': [15, 20],\n",
    "                'l2_regularization': [1.5, 2.0]\n",
    "            },\n",
    "            5: {\n",
    "                'max_iter': [800, 1000],\n",
    "                'learning_rate': [0.008, 0.01],\n",
    "                'max_depth': [3, 4],\n",
    "                'min_samples_leaf': [10, 15],\n",
    "                'l2_regularization': [1.2, 1.5]\n",
    "            },\n",
    "            6: {  # 준프리미엄 세그먼트 정규화 강화\n",
    "                'max_iter': [1500, 1800],\n",
    "                'learning_rate': [0.003, 0.005],\n",
    "                'max_depth': [4, 5],\n",
    "                'min_samples_leaf': [40, 50],\n",
    "                'l2_regularization': [4.0, 5.0]\n",
    "            },\n",
    "            7: {\n",
    "                'max_iter': [1000, 1200],\n",
    "                'learning_rate': [0.006, 0.008],\n",
    "                'max_depth': [3, 4],\n",
    "                'min_samples_leaf': [15, 20],\n",
    "                'l2_regularization': [1.5, 2.0]\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get_detailed_segment(self, model_name):\n",
    "        \"\"\"세분화된 모델 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def handle_battery_missing(self, df):\n",
    "        \"\"\"강화된 배터리 결측치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 주행거리 구간화\n",
    "        df['distance_group'] = pd.qcut(df['주행거리(km)'], q=5, labels=['Very_Low', 'Low', 'Mid', 'High', 'Very_High'])\n",
    "        \n",
    "        for model in ['IONIQ', 'TayCT', 'Tay']:\n",
    "            model_mask = df['모델'] == model\n",
    "            if sum(model_mask) > 0:\n",
    "                # 차량상태, 연식, 주행거리 구간별 중앙값으로 대체\n",
    "                df.loc[model_mask, '배터리용량'] = df[model_mask].groupby(\n",
    "                    ['차량상태', '연식(년)', 'distance_group']\n",
    "                )['배터리용량'].transform(lambda x: x.fillna(x.median()))\n",
    "                \n",
    "                # 여전히 남아있는 결측치는 모델별 전체 중앙값으로 대체\n",
    "                remaining_missing = df.loc[model_mask, '배터리용량'].isna()\n",
    "                if sum(remaining_missing) > 0:\n",
    "                    model_median = df.loc[model_mask, '배터리용량'].median()\n",
    "                    df.loc[model_mask & df['배터리용량'].isna(), '배터리용량'] = model_median\n",
    "        \n",
    "        df.drop('distance_group', axis=1, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성 및 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df = self.handle_battery_missing(df)\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['model_segment'] = df['모델'].apply(self.get_detailed_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "\n",
    "        # 특성 생성\n",
    "        features = {\n",
    "            'model_segment': df['model_segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'distance': df['주행거리(km)']\n",
    "        }\n",
    "        \n",
    "        # 추가 특성\n",
    "        df_features = pd.DataFrame(features)\n",
    "        df_features['km_per_year'] = df_features['distance'] / (df_features['age'] + 1)\n",
    "        df_features['battery_efficiency'] = df_features['battery_capacity'] / np.log1p(df_features['distance'])\n",
    "        df_features['warranty_value'] = df_features['warranty'] * df_features['battery_efficiency']\n",
    "        \n",
    "        # 스케일링\n",
    "        if '가격(백만원)' in df.columns:  # 학습 시\n",
    "            scaler = StandardScaler()\n",
    "            numeric_cols = ['battery_capacity', 'age', 'warranty', 'distance', 'km_per_year', \n",
    "                          'battery_efficiency', 'warranty_value']\n",
    "            df_features[numeric_cols] = scaler.fit_transform(df_features[numeric_cols])\n",
    "            self.scaler = scaler\n",
    "        else:  # 예측 시\n",
    "            numeric_cols = ['battery_capacity', 'age', 'warranty', 'distance', 'km_per_year', \n",
    "                          'battery_efficiency', 'warranty_value']\n",
    "            df_features[numeric_cols] = self.scaler.transform(df_features[numeric_cols])\n",
    "        \n",
    "        return df_features\n",
    "\n",
    "    def ensemble_predict(self, X, models, weights=None):\n",
    "        \"\"\"동적 가중치 앙상블 예측\"\"\"\n",
    "        hgb_model, base_hgb_weight = models['hgb']\n",
    "        rf_model, base_rf_weight = models['rf']\n",
    "        \n",
    "        hgb_pred = hgb_model.predict(X)\n",
    "        rf_pred = rf_model.predict(X)\n",
    "        \n",
    "        if weights is not None:\n",
    "            return hgb_pred * weights['hgb'] + rf_pred * weights['rf']\n",
    "        \n",
    "        # 예측값 차이에 기반한 동적 가중치 계산\n",
    "        diff = np.abs(hgb_pred - rf_pred)\n",
    "        confidence = 1 / (1 + diff)\n",
    "        \n",
    "        # 기본 가중치와 신뢰도 기반 가중치 결합\n",
    "        final_hgb_weight = (base_hgb_weight + confidence) / 2\n",
    "        final_rf_weight = 1 - final_hgb_weight\n",
    "        \n",
    "        return hgb_pred * final_hgb_weight + rf_pred * final_rf_weight\n",
    "\n",
    "    def train_segment_model(self, X, y, segment):\n",
    "        \"\"\"세그먼트별 앙상블 모델 학습\"\"\"\n",
    "        # 내부 교차 검증\n",
    "        inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # HGB 그리드서치\n",
    "        hgb_grid = GridSearchCV(\n",
    "            HistGradientBoostingRegressor(random_state=42),\n",
    "            param_grid=self.hgb_param_grids[segment],\n",
    "            cv=inner_cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # RF 모델\n",
    "        rf = RandomForestRegressor(random_state=42, **self.rf_params[segment])\n",
    "        \n",
    "        # 모델 학습\n",
    "        hgb_grid.fit(X, y)\n",
    "        rf.fit(X, y)\n",
    "        \n",
    "        # 교차 검증 성능 평가\n",
    "        hgb_pred = cross_val_predict(hgb_grid.best_estimator_, X, y, cv=inner_cv)\n",
    "        rf_pred = cross_val_predict(rf, X, y, cv=inner_cv)\n",
    "        \n",
    "        hgb_score = r2_score(y, hgb_pred)\n",
    "        rf_score = r2_score(y, rf_pred)\n",
    "        \n",
    "        # 최종 가중치 계산\n",
    "        total_score = hgb_score + rf_score\n",
    "        hgb_weight = hgb_score / total_score\n",
    "        rf_weight = rf_score / total_score\n",
    "        \n",
    "        return {\n",
    "            'hgb': (hgb_grid.best_estimator_, hgb_weight),\n",
    "            'rf': (rf, rf_weight),\n",
    "            'best_params': hgb_grid.best_params_\n",
    "        }\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        X = self.create_features(train_df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 모델 학습 ===\")\n",
    "        for segment in range(1, 8):\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                print(f\"\\n처리 중: 세그먼트 {segment} (데이터 수: {sum(mask)})\")\n",
    "                \n",
    "                X_segment = X[mask]\n",
    "                y_segment = y[mask]\n",
    "                \n",
    "                # 모델 학습\n",
    "                models = self.train_segment_model(X_segment, y_segment, segment)\n",
    "                self.segment_models[segment] = models\n",
    "                \n",
    "                # 성능 평가\n",
    "                ensemble_pred = self.ensemble_predict(X_segment, models)\n",
    "                rmse = np.sqrt(mean_squared_error(y_segment, ensemble_pred))\n",
    "                r2 = r2_score(y_segment, ensemble_pred)\n",
    "                \n",
    "                print(f\"RMSE: {rmse:.4f}, R2: {r2:.4f}\")\n",
    "                print(f\"HGB 가중치: {models['hgb'][1]:.4f}, RF 가중치: {models['rf'][1]:.4f}\")\n",
    "                print(\"HGB 최적 파라미터:\", models['best_params'])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.create_features(test_df)\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        for segment, models in self.segment_models.items():\n",
    "            mask = X['model_segment'] == segment\n",
    "            if sum(mask) > 0:\n",
    "                predictions[mask] = self.ensemble_predict(X[mask], models)\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 모델 학습\n",
    "    predictor = EnhancedSegmentPredictor()\n",
    "    predictor.fit(train_data)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = predictor.predict(test_data)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('enhanced_generalization_submission.csv', index=False)\n",
    "    \n",
    "    # 모델 성능 통계 저장\n",
    "    model_stats = {\n",
    "        'segment': [],\n",
    "        'data_count': [],\n",
    "        'hgb_weight': [],\n",
    "        'rf_weight': [],\n",
    "        'rmse': [],\n",
    "        'r2': [],\n",
    "        'hgb_params': []\n",
    "    }\n",
    "    \n",
    "    # 세그먼트별 상세 성능 분석\n",
    "    for segment, models in predictor.segment_models.items():\n",
    "        mask = train_data['모델'].apply(predictor.get_detailed_segment) == segment\n",
    "        X = predictor.create_features(train_data[mask])\n",
    "        y = train_data[mask]['가격(백만원)']\n",
    "        \n",
    "        # 예측 및 성능 평가\n",
    "        ensemble_pred = predictor.ensemble_predict(X, models)\n",
    "        rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "        r2 = r2_score(y, ensemble_pred)\n",
    "        \n",
    "        model_stats['segment'].append(segment)\n",
    "        model_stats['data_count'].append(sum(mask))\n",
    "        model_stats['hgb_weight'].append(models['hgb'][1])\n",
    "        model_stats['rf_weight'].append(models['rf'][1])\n",
    "        model_stats['rmse'].append(rmse)\n",
    "        model_stats['r2'].append(r2)\n",
    "        model_stats['hgb_params'].append(models['best_params'])\n",
    "    \n",
    "    # 성능 통계 저장\n",
    "    stats_df = pd.DataFrame(model_stats)\n",
    "    stats_df.to_csv('model_performance_stats.csv', index=False)\n",
    "    \n",
    "    # 세그먼트별 모델 성능 분석\n",
    "    print(\"\\n=== 세그먼트별 성능 분석 ===\")\n",
    "for segment in range(1, 8):\n",
    "    if segment in predictor.segment_models:\n",
    "        print(f\"\\n세그먼트 {segment}:\")\n",
    "        mask = train_data['모델'].apply(predictor.get_detailed_segment) == segment\n",
    "        models = predictor.segment_models[segment]\n",
    "        \n",
    "        # 모델별 개별 성능\n",
    "        X = predictor.create_features(train_data[mask])\n",
    "        y = train_data[mask]['가격(백만원)']\n",
    "        \n",
    "        hgb_model, _ = models['hgb']\n",
    "        rf_model, _ = models['rf']\n",
    "        \n",
    "        hgb_pred = hgb_model.predict(X)\n",
    "        rf_pred = rf_model.predict(X)\n",
    "        ensemble_pred = predictor.ensemble_predict(X, models)\n",
    "        \n",
    "        print(f\"데이터 수: {sum(mask)}\")\n",
    "        print(f\"HGB RMSE: {np.sqrt(mean_squared_error(y, hgb_pred)):.4f}\")\n",
    "        print(f\"RF RMSE: {np.sqrt(mean_squared_error(y, rf_pred)):.4f}\")\n",
    "        print(f\"Ensemble RMSE: {np.sqrt(mean_squared_error(y, ensemble_pred)):.4f}\")\n",
    "        print(f\"Ensemble R2: {r2_score(y, ensemble_pred):.4f}\")\n",
    "        \n",
    "        # 특성 중요도 분석\n",
    "        if sum(mask) > 0:\n",
    "            feature_names = X.columns\n",
    "            \n",
    "            # HGB 특성 중요도\n",
    "            hgb_importance = permutation_importance(\n",
    "                hgb_model, X, y, n_repeats=10, random_state=42\n",
    "            )\n",
    "            hgb_importances = pd.Series(\n",
    "                hgb_importance.importances_mean,\n",
    "                index=feature_names\n",
    "            ).sort_values(ascending=False)\n",
    "            \n",
    "            # RF는 기존 feature_importances_ 사용\n",
    "            rf_importance = pd.Series(\n",
    "                rf_model.feature_importances_,\n",
    "                index=feature_names\n",
    "            ).sort_values(ascending=False)\n",
    "            \n",
    "            print(\"\\nTop 5 Important Features (HGB):\")\n",
    "            print(hgb_importances.head())\n",
    "            print(\"\\nTop 5 Important Features (RF):\")\n",
    "            print(rf_importance.head())\n",
    "    \n",
    "    # 배터리 결측치 처리 통계\n",
    "    missing_stats = {\n",
    "        'model': [],\n",
    "        'total_count': [],\n",
    "        'missing_count': [],\n",
    "        'missing_ratio': [],\n",
    "        'avg_price_with_missing': [],\n",
    "        'avg_price_without_missing': []\n",
    "    }\n",
    "    \n",
    "    for model in ['IONIQ', 'TayCT', 'Tay']:\n",
    "        model_data = train_data[train_data['모델'] == model]\n",
    "        missing_mask = model_data['배터리용량'].isna()\n",
    "        \n",
    "        missing_stats['model'].append(model)\n",
    "        missing_stats['total_count'].append(len(model_data))\n",
    "        missing_stats['missing_count'].append(sum(missing_mask))\n",
    "        missing_stats['missing_ratio'].append(sum(missing_mask) / len(model_data))\n",
    "        missing_stats['avg_price_with_missing'].append(\n",
    "            model_data[missing_mask]['가격(백만원)'].mean()\n",
    "        )\n",
    "        missing_stats['avg_price_without_missing'].append(\n",
    "            model_data[~missing_mask]['가격(백만원)'].mean()\n",
    "        )\n",
    "    \n",
    "    # 결측치 통계 저장\n",
    "    pd.DataFrame(missing_stats).to_csv('battery_missing_stats.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 세그먼트별 모델 학습 ===\n",
      "\n",
      "처리 중: 세그먼트 1 (데이터 수: 1679)\n",
      "HGB RMSE: 1.7058\n",
      "RF RMSE: 1.6860\n",
      "Ensemble RMSE: 1.6874\n",
      "\n",
      "처리 중: 세그먼트 2 (데이터 수: 2100)\n",
      "HGB RMSE: 0.5287\n",
      "RF RMSE: 0.5420\n",
      "Ensemble RMSE: 0.5288\n",
      "\n",
      "처리 중: 세그먼트 3 (데이터 수: 657)\n",
      "HGB RMSE: 0.5520\n",
      "RF RMSE: 0.4648\n",
      "Ensemble RMSE: 0.4805\n",
      "\n",
      "처리 중: 세그먼트 4 (데이터 수: 1359)\n",
      "HGB RMSE: 0.8302\n",
      "RF RMSE: 0.7168\n",
      "Ensemble RMSE: 0.7096\n",
      "\n",
      "처리 중: 세그먼트 5 (데이터 수: 631)\n",
      "HGB RMSE: 0.8905\n",
      "RF RMSE: 0.9060\n",
      "Ensemble RMSE: 0.8706\n",
      "\n",
      "처리 중: 세그먼트 6 (데이터 수: 696)\n",
      "\n",
      "- Tay 모델 처리 (데이터 수: 361)\n",
      "HGB RMSE: 4.4111\n",
      "RF RMSE: 2.8658\n",
      "Ensemble RMSE: 2.9225\n",
      "\n",
      "- TayCT 모델 처리 (데이터 수: 335)\n",
      "HGB RMSE: 4.0850\n",
      "RF RMSE: 3.7090\n",
      "Ensemble RMSE: 3.7558\n",
      "\n",
      "처리 중: 세그먼트 7 (데이터 수: 375)\n",
      "HGB RMSE: 0.5148\n",
      "RF RMSE: 0.3419\n",
      "Ensemble RMSE: 0.4091\n",
      "\n",
      "=== 전체 성능 통계 ===\n",
      "\n",
      "평균 RMSE:\n",
      "HGB: 1.6898\n",
      "RF: 1.4041\n",
      "Ensemble: 1.4205\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedEVPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scalers = {}\n",
    "        self.segment_models = {}\n",
    "        self.kf = TimeSeriesSplit(n_splits=5)\n",
    "        \n",
    "        # 세그먼트별 모델 파라미터\n",
    "        self.model_params = {\n",
    "            'premium': {\n",
    "                'hgb': {'max_iter': 1200, 'learning_rate': 0.006, 'max_depth': 3,\n",
    "                       'min_samples_leaf': 20, 'l2_regularization': 2.0},\n",
    "                'rf': {'n_estimators': 300, 'max_depth': 8, 'min_samples_split': 8,\n",
    "                      'min_samples_leaf': 6}\n",
    "            },\n",
    "            'tay': {  # Tay 모델 전용\n",
    "                'hgb': {'max_iter': 1500, 'learning_rate': 0.004, 'max_depth': 4,\n",
    "                       'min_samples_leaf': 40, 'l2_regularization': 4.0},\n",
    "                'rf': {'n_estimators': 400, 'max_depth': 6, 'min_samples_split': 10,\n",
    "                      'min_samples_leaf': 8}\n",
    "            },\n",
    "            'tayct': {  # TayCT 모델 전용\n",
    "                'hgb': {'max_iter': 1800, 'learning_rate': 0.003, 'max_depth': 5,\n",
    "                       'min_samples_leaf': 50, 'l2_regularization': 5.0},\n",
    "                'rf': {'n_estimators': 500, 'max_depth': 7, 'min_samples_split': 12,\n",
    "                      'min_samples_leaf': 10}\n",
    "            },\n",
    "            'standard': {  # 기본 파라미터\n",
    "                'hgb': {'max_iter': 1000, 'learning_rate': 0.008, 'max_depth': 4,\n",
    "                       'min_samples_leaf': 15, 'l2_regularization': 1.5},\n",
    "                'rf': {'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 5,\n",
    "                      'min_samples_leaf': 4}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get_segment(self, model_name):\n",
    "        \"\"\"차량 세그먼트 분류\"\"\"\n",
    "        premium = ['TayGTS']\n",
    "        semi_premium = ['TayCT', 'Tay']\n",
    "        luxury = ['RSeGT', 'MX', 'iX']\n",
    "        upper_mid = ['MS', 'MY', 'eT', 'i5']\n",
    "        mid = ['Q4eT', 'M3', 'i4']\n",
    "        basic = ['ID4', 'ION6', 'ION5', 'Niro', 'KNE']\n",
    "        entry = ['i3', 'Soul', 'IONIQ']\n",
    "        \n",
    "        if model_name in premium:\n",
    "            return 7\n",
    "        elif model_name in semi_premium:\n",
    "            return 6\n",
    "        elif model_name in luxury:\n",
    "            return 5\n",
    "        elif model_name in upper_mid:\n",
    "            return 4\n",
    "        elif model_name in mid:\n",
    "            return 3\n",
    "        elif model_name in basic:\n",
    "            return 2\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def get_model_params(self, model_name, segment):\n",
    "        \"\"\"모델별 파라미터 선택\"\"\"\n",
    "        if model_name == 'Tay':\n",
    "            return self.model_params['tay']\n",
    "        elif model_name == 'TayCT':\n",
    "            return self.model_params['tayct']\n",
    "        elif segment == 7:\n",
    "            return self.model_params['premium']\n",
    "        else:\n",
    "            return self.model_params['standard']\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.get_segment)\n",
    "        \n",
    "        # 범주형 변수 인코딩\n",
    "        for col in ['제조사', '모델', '구동방식', '차량상태']:\n",
    "            if col not in self.label_encoders:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                unique_values = sorted(df[col].unique())\n",
    "                if '가격(백만원)' not in df.columns:\n",
    "                    unique_values = sorted(list(set(list(self.label_encoders[col].classes_) + list(unique_values))))\n",
    "                self.label_encoders[col].fit(unique_values)\n",
    "            df[f'{col}_encoded'] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리\n",
    "        if '배터리용량' in df.columns:\n",
    "            df['배터리용량'] = df.groupby(['모델', '차량상태'])['배터리용량'].transform(\n",
    "                lambda x: x.fillna(x.median())\n",
    "            )\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성\"\"\"\n",
    "        df = df.copy()\n",
    "    \n",
    "        # 기본 특성\n",
    "        features = {\n",
    "            'segment': df['segment'],\n",
    "            'manufacturer_encoded': df['제조사_encoded'],\n",
    "            'model_encoded': df['모델_encoded'],\n",
    "            'condition_encoded': df['차량상태_encoded'],\n",
    "            'drive_encoded': df['구동방식_encoded'],\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int),\n",
    "            'distance': df['주행거리(km)']\n",
    "        }\n",
    "    \n",
    "    # 파생 특성\n",
    "        df_features = pd.DataFrame(features)\n",
    "        df_features['km_per_year'] = df_features['distance'] / (df_features['age'] + 1)\n",
    "        df_features['battery_efficiency'] = df_features['battery_capacity'] / np.log1p(df_features['distance'])\n",
    "        df_features['warranty_value'] = df_features['warranty'] * df_features['battery_efficiency']\n",
    "        df_features['battery_age'] = df_features['battery_capacity'] * np.exp(-df_features['age'] / 2)\n",
    "    \n",
    "        # 세그먼트 6 특화 처리\n",
    "        segment_6_mask = df_features['segment'] == 6\n",
    "        if sum(segment_6_mask) > 0:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                model_mask = df['모델'] == model\n",
    "                if sum(model_mask) > 0:\n",
    "                    # 주행거리 구간화 - 숫자로 변환\n",
    "                    try:\n",
    "                        distance_bins = pd.qcut(\n",
    "                            df_features.loc[model_mask, 'distance'],\n",
    "                            q=5,\n",
    "                            duplicates='drop'\n",
    "                        )\n",
    "                        df_features.loc[model_mask, 'distance_group'] = \\\n",
    "                            distance_bins.cat.codes\n",
    "                    except:\n",
    "                        df_features.loc[model_mask, 'distance_group'] = 2  # 중간값\n",
    "                \n",
    "                    # 보증 가치\n",
    "                    df_features.loc[model_mask, 'warranty_score'] = \\\n",
    "                        df_features.loc[model_mask, 'warranty'] * \\\n",
    "                        (1 - df_features.loc[model_mask, 'age'] * 0.1)\n",
    "                \n",
    "                    # 차량 상태 가중치\n",
    "                    condition_weights = {'Brand New': 1.2, 'Nearly New': 1.0, 'Pre-Owned': 0.8}\n",
    "                    df_features.loc[model_mask, 'condition_weight'] = \\\n",
    "                        df['차량상태'].map(condition_weights).fillna(1.0)\n",
    "                \n",
    "                    # 추가 특성\n",
    "                    df_features.loc[model_mask, 'price_factor'] = \\\n",
    "                        df_features.loc[model_mask, 'battery_efficiency'] * \\\n",
    "                        df_features.loc[model_mask, 'condition_weight']\n",
    "    \n",
    "    # 범주형 변수 제거\n",
    "        numeric_features = df_features.select_dtypes(include=[np.number]).columns\n",
    "        return df_features[numeric_features]\n",
    "\n",
    "    def train_model(self, X, y, model_params):\n",
    "        \"\"\"단일 모델 학습\"\"\"\n",
    "        # 스케일링\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # 모델 생성\n",
    "        hgb = HistGradientBoostingRegressor(random_state=42, **model_params['hgb'])\n",
    "        rf = RandomForestRegressor(random_state=42, **model_params['rf'])\n",
    "        \n",
    "        # 교차 검증\n",
    "        hgb_scores = []\n",
    "        rf_scores = []\n",
    "        ensemble_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in self.kf.split(X_scaled):\n",
    "            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # 모델 학습\n",
    "            hgb.fit(X_train, y_train)\n",
    "            rf.fit(X_train, y_train)\n",
    "            \n",
    "            # 예측\n",
    "            hgb_pred = hgb.predict(X_val)\n",
    "            rf_pred = rf.predict(X_val)\n",
    "            \n",
    "            # 동적 가중치 계산\n",
    "            hgb_rmse = np.sqrt(mean_squared_error(y_val, hgb_pred))\n",
    "            rf_rmse = np.sqrt(mean_squared_error(y_val, rf_pred))\n",
    "            \n",
    "            diff = np.abs(hgb_pred - rf_pred)\n",
    "            conf = 1 / (1 + diff)\n",
    "            ensemble_pred = hgb_pred * conf + rf_pred * (1 - conf)\n",
    "            \n",
    "            # 점수 저장\n",
    "            hgb_scores.append(hgb_rmse)\n",
    "            rf_scores.append(rf_rmse)\n",
    "            ensemble_scores.append(np.sqrt(mean_squared_error(y_val, ensemble_pred)))\n",
    "        \n",
    "        # 최종 학습\n",
    "        hgb.fit(X_scaled, y)\n",
    "        rf.fit(X_scaled, y)\n",
    "        \n",
    "        return {\n",
    "            'hgb': hgb,\n",
    "            'rf': rf,\n",
    "            'scaler': scaler,\n",
    "            'scores': {\n",
    "                'hgb': np.mean(hgb_scores),\n",
    "                'rf': np.mean(rf_scores),\n",
    "                'ensemble': np.mean(ensemble_scores)\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        # 데이터 전처리\n",
    "        df = self.preprocess_data(train_df)\n",
    "        \n",
    "        # 특성 생성\n",
    "        X = self.create_features(df)\n",
    "        y = train_df['가격(백만원)']\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 모델 학습 ===\")\n",
    "        \n",
    "        # 세그먼트별 학습\n",
    "        for segment in range(1, 8):\n",
    "            segment_mask = X['segment'] == segment\n",
    "            if sum(segment_mask) > 0:\n",
    "                print(f\"\\n처리 중: 세그먼트 {segment} (데이터 수: {sum(segment_mask)})\")\n",
    "                \n",
    "                if segment == 6:  # 준프리미엄 세그먼트\n",
    "                    for model in ['Tay', 'TayCT']:\n",
    "                        model_mask = df['모델'] == model\n",
    "                        if sum(model_mask) > 0:\n",
    "                            print(f\"\\n- {model} 모델 처리 (데이터 수: {sum(model_mask)})\")\n",
    "                            \n",
    "                            # 모델별 학습\n",
    "                            X_model = X[model_mask]\n",
    "                            y_model = y[model_mask]\n",
    "                            \n",
    "                            model_params = self.get_model_params(model, segment)\n",
    "                            model_results = self.train_model(X_model, y_model, model_params)\n",
    "                            \n",
    "                            # 모델 저장\n",
    "                            self.segment_models[f\"{segment}_{model}\"] = model_results\n",
    "                            \n",
    "                            # 성능 출력\n",
    "                            scores = model_results['scores']\n",
    "                            print(f\"HGB RMSE: {scores['hgb']:.4f}\")\n",
    "                            print(f\"RF RMSE: {scores['rf']:.4f}\")\n",
    "                            print(f\"Ensemble RMSE: {scores['ensemble']:.4f}\")\n",
    "                else:\n",
    "                    # 일반 세그먼트 학습\n",
    "                    X_segment = X[segment_mask]\n",
    "                    y_segment = y[segment_mask]\n",
    "                    \n",
    "                    model_params = self.get_model_params(None, segment)\n",
    "                    model_results = self.train_model(X_segment, y_segment, model_params)\n",
    "                    \n",
    "                    # 모델 저장\n",
    "                    self.segment_models[segment] = model_results\n",
    "                    \n",
    "                    # 성능 출력\n",
    "                    scores = model_results['scores']\n",
    "                    print(f\"HGB RMSE: {scores['hgb']:.4f}\")\n",
    "                    print(f\"RF RMSE: {scores['rf']:.4f}\")\n",
    "                    print(f\"Ensemble RMSE: {scores['ensemble']:.4f}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측\"\"\"\n",
    "        # 데이터 전처리\n",
    "        df = self.preprocess_data(test_df)\n",
    "        \n",
    "        # 특성 생성\n",
    "        X = self.create_features(df)\n",
    "        predictions = np.zeros(len(test_df))\n",
    "        \n",
    "        # 세그먼트별 예측\n",
    "        for segment in range(1, 8):\n",
    "            segment_mask = X['segment'] == segment\n",
    "            if sum(segment_mask) > 0:\n",
    "                if segment == 6:  # 준프리미엄 세그먼트\n",
    "                    for model in ['Tay', 'TayCT']:\n",
    "                        model_mask = df['모델'] == model\n",
    "                        if sum(model_mask) > 0:\n",
    "                            key = f\"{segment}_{model}\"\n",
    "                            if key in self.segment_models:\n",
    "                                models = self.segment_models[key]\n",
    "                                X_model = X[model_mask]\n",
    "                                \n",
    "                                # 스케일링\n",
    "                                X_scaled = models['scaler'].transform(X_model)\n",
    "                                \n",
    "                                # 예측\n",
    "                                hgb_pred = models['hgb'].predict(X_scaled)\n",
    "                                rf_pred = models['rf'].predict(X_scaled)\n",
    "                                \n",
    "                                # 동적 가중치 계산\n",
    "                                diff = np.abs(hgb_pred - rf_pred)\n",
    "                                conf = 1 / (1 + diff)\n",
    "                                predictions[model_mask] = hgb_pred * conf + rf_pred * (1 - conf)\n",
    "                else:\n",
    "                    if segment in self.segment_models:\n",
    "                        models = self.segment_models[segment]\n",
    "                        X_segment = X[segment_mask]\n",
    "                        \n",
    "                        # 스케일링\n",
    "                        X_scaled = models['scaler'].transform(X_segment)\n",
    "                        \n",
    "                        # 예측\n",
    "                        hgb_pred = models['hgb'].predict(X_scaled)\n",
    "                        rf_pred = models['rf'].predict(X_scaled)\n",
    "                        \n",
    "                        # 동적 가중치 계산\n",
    "                        diff = np.abs(hgb_pred - rf_pred)\n",
    "                        conf = 1 / (1 + diff)\n",
    "                        predictions[segment_mask] = hgb_pred * conf + rf_pred * (1 - conf)\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # 모델 학습\n",
    "    predictor = EnhancedEVPredictor()\n",
    "    predictor.fit(train_data)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = predictor.predict(test_data)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_data['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('enhanced_stable_predictions.csv', index=False)\n",
    "    \n",
    "    # 세그먼트별 성능 분석 저장\n",
    "    performance_stats = {\n",
    "        'segment': [],\n",
    "        'data_count': [],\n",
    "        'hgb_rmse': [],\n",
    "        'rf_rmse': [],\n",
    "        'ensemble_rmse': []\n",
    "    }\n",
    "    \n",
    "    for segment in range(1, 8):\n",
    "        if segment == 6:\n",
    "            for model in ['Tay', 'TayCT']:\n",
    "                key = f\"{segment}_{model}\"\n",
    "                if key in predictor.segment_models:\n",
    "                    model_count = sum((train_data['모델'] == model) & \n",
    "                                    (train_data['모델'].apply(predictor.get_segment) == segment))\n",
    "                    scores = predictor.segment_models[key]['scores']\n",
    "                    \n",
    "                    performance_stats['segment'].append(f\"{segment}_{model}\")\n",
    "                    performance_stats['data_count'].append(model_count)\n",
    "                    performance_stats['hgb_rmse'].append(scores['hgb'])\n",
    "                    performance_stats['rf_rmse'].append(scores['rf'])\n",
    "                    performance_stats['ensemble_rmse'].append(scores['ensemble'])\n",
    "        else:\n",
    "            if segment in predictor.segment_models:\n",
    "                segment_count = sum(train_data['모델'].apply(predictor.get_segment) == segment)\n",
    "                scores = predictor.segment_models[segment]['scores']\n",
    "                \n",
    "                performance_stats['segment'].append(str(segment))\n",
    "                performance_stats['data_count'].append(segment_count)\n",
    "                performance_stats['hgb_rmse'].append(scores['hgb'])\n",
    "                performance_stats['rf_rmse'].append(scores['rf'])\n",
    "                performance_stats['ensemble_rmse'].append(scores['ensemble'])\n",
    "    \n",
    "    # 성능 통계 저장\n",
    "    pd.DataFrame(performance_stats).to_csv('segment_performance_stats.csv', index=False)\n",
    "    \n",
    "    print(\"\\n=== 전체 성능 통계 ===\")\n",
    "    stats_df = pd.DataFrame(performance_stats)\n",
    "    print(\"\\n평균 RMSE:\")\n",
    "    print(f\"HGB: {stats_df['hgb_rmse'].mean():.4f}\")\n",
    "    print(f\"RF: {stats_df['rf_rmse'].mean():.4f}\")\n",
    "    print(f\"Ensemble: {stats_df['ensemble_rmse'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== IONIQ 모델 학습 ===\n",
      "\n",
      "Nearly New 상태 처리 (데이터 수: 66)\n",
      "RF RMSE: 5.0084\n",
      "HGB RMSE: 5.1488\n",
      "Ensemble RMSE: 4.7903\n",
      "최적 가중치: RF=0.42, HGB=0.58\n",
      "\n",
      "Pre-Owned 상태 처리 (데이터 수: 74)\n",
      "RF RMSE: 5.8991\n",
      "HGB RMSE: 5.7467\n",
      "Ensemble RMSE: 5.5991\n",
      "최적 가중치: RF=0.00, HGB=1.00\n",
      "\n",
      "=== TayCT 모델 학습 ===\n",
      "\n",
      "Nearly New 상태 처리 (데이터 수: 90)\n",
      "RF RMSE: 0.4653\n",
      "HGB RMSE: 0.5508\n",
      "Ensemble RMSE: 0.4442\n",
      "최적 가중치: RF=1.00, HGB=0.00\n",
      "\n",
      "Brand New 상태 처리 (데이터 수: 149)\n",
      "RF RMSE: 5.1397\n",
      "HGB RMSE: 5.0827\n",
      "Ensemble RMSE: 5.0531\n",
      "최적 가중치: RF=0.14, HGB=0.86\n",
      "\n",
      "Pre-Owned 상태 처리 (데이터 수: 96)\n",
      "RF RMSE: 2.1249\n",
      "HGB RMSE: 2.0254\n",
      "Ensemble RMSE: 1.9984\n",
      "최적 가중치: RF=0.16, HGB=0.84\n",
      "\n",
      "=== Tay 모델 학습 ===\n",
      "\n",
      "Brand New 상태 처리 (데이터 수: 168)\n",
      "RF RMSE: 4.0189\n",
      "HGB RMSE: 4.0334\n",
      "Ensemble RMSE: 3.9797\n",
      "최적 가중치: RF=1.00, HGB=0.00\n",
      "\n",
      "Nearly New 상태 처리 (데이터 수: 99)\n",
      "RF RMSE: 0.6679\n",
      "HGB RMSE: 0.6309\n",
      "Ensemble RMSE: 0.6309\n",
      "최적 가중치: RF=0.00, HGB=1.00\n",
      "\n",
      "Pre-Owned 상태 처리 (데이터 수: 94)\n",
      "RF RMSE: 0.5885\n",
      "HGB RMSE: 0.5503\n",
      "Ensemble RMSE: 0.5395\n",
      "최적 가중치: RF=0.00, HGB=1.00\n",
      "\n",
      "=== 모델 성능 요약 ===\n",
      "\n",
      "IONIQ_Nearly New:\n",
      "RF RMSE: 5.0084\n",
      "HGB RMSE: 5.1488\n",
      "Ensemble RMSE: 4.7903\n",
      "가중치: RF=0.42, HGB=0.58\n",
      "\n",
      "IONIQ_Pre-Owned:\n",
      "RF RMSE: 5.8991\n",
      "HGB RMSE: 5.7467\n",
      "Ensemble RMSE: 5.5991\n",
      "가중치: RF=0.00, HGB=1.00\n",
      "\n",
      "TayCT_Nearly New:\n",
      "RF RMSE: 0.4653\n",
      "HGB RMSE: 0.5508\n",
      "Ensemble RMSE: 0.4442\n",
      "가중치: RF=1.00, HGB=0.00\n",
      "\n",
      "TayCT_Brand New:\n",
      "RF RMSE: 5.1397\n",
      "HGB RMSE: 5.0827\n",
      "Ensemble RMSE: 5.0531\n",
      "가중치: RF=0.14, HGB=0.86\n",
      "\n",
      "TayCT_Pre-Owned:\n",
      "RF RMSE: 2.1249\n",
      "HGB RMSE: 2.0254\n",
      "Ensemble RMSE: 1.9984\n",
      "가중치: RF=0.16, HGB=0.84\n",
      "\n",
      "Tay_Brand New:\n",
      "RF RMSE: 4.0189\n",
      "HGB RMSE: 4.0334\n",
      "Ensemble RMSE: 3.9797\n",
      "가중치: RF=1.00, HGB=0.00\n",
      "\n",
      "Tay_Nearly New:\n",
      "RF RMSE: 0.6679\n",
      "HGB RMSE: 0.6309\n",
      "Ensemble RMSE: 0.6309\n",
      "가중치: RF=0.00, HGB=1.00\n",
      "\n",
      "Tay_Pre-Owned:\n",
      "RF RMSE: 0.5885\n",
      "HGB RMSE: 0.5503\n",
      "Ensemble RMSE: 0.5395\n",
      "가중치: RF=0.00, HGB=1.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "class RefinedIndependentPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scalers = {}\n",
    "        self.models = {}\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 모델별 표준 배터리 용량\n",
    "        self.standard_battery = {\n",
    "            'TayCT': {'Brand New': 100.0, 'Nearly New': 95.0, 'Pre-Owned': 90.0},\n",
    "            'Tay': {'Brand New': 85.0, 'Nearly New': 82.0, 'Pre-Owned': 78.0},\n",
    "            'IONIQ': {'Nearly New': 64.0, 'Pre-Owned': 58.0}\n",
    "        }\n",
    "        \n",
    "        # 모델별 하이퍼파라미터 설정\n",
    "        self.model_params = {\n",
    "            'TayCT_Brand New': {\n",
    "                'rf': {'n_estimators': 400, 'max_depth': 4, 'min_samples_split': 5},\n",
    "                'hgb': {'learning_rate': 0.002, 'max_iter': 2000, 'l2_regularization': 5.0}\n",
    "            },\n",
    "            'TayCT_Used': {\n",
    "                'rf': {'n_estimators': 300, 'max_depth': 6, 'min_samples_split': 3},\n",
    "                'hgb': {'learning_rate': 0.005, 'max_iter': 1500, 'l2_regularization': 3.0}\n",
    "            },\n",
    "            'Tay_Brand New': {\n",
    "                'rf': {'n_estimators': 400, 'max_depth': 4, 'min_samples_split': 5},\n",
    "                'hgb': {'learning_rate': 0.002, 'max_iter': 2000, 'l2_regularization': 5.0}\n",
    "            },\n",
    "            'Tay_Used': {\n",
    "                'rf': {'n_estimators': 300, 'max_depth': 5, 'min_samples_split': 4},\n",
    "                'hgb': {'learning_rate': 0.005, 'max_iter': 1500, 'l2_regularization': 3.0}\n",
    "            },\n",
    "            'IONIQ': {\n",
    "                'rf': {'n_estimators': 200, 'max_depth': 4, 'min_samples_split': 4},\n",
    "                'hgb': {'learning_rate': 0.005, 'max_iter': 1000, 'l2_regularization': 2.5}\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def handle_brand_new_missing(self, df):\n",
    "        \"\"\"Brand New 차량 특화 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        for model in ['TayCT', 'Tay']:\n",
    "            for condition in ['Brand New', 'Nearly New', 'Pre-Owned']:\n",
    "                mask = (df['모델'] == model) & \\\n",
    "                       (df['차량상태'] == condition) & \\\n",
    "                       df['배터리용량'].isnull()\n",
    "                \n",
    "                if sum(mask) > 0:\n",
    "                    # 표준 배터리 용량 적용\n",
    "                    df.loc[mask, '배터리용량'] = self.standard_battery[model][condition]\n",
    "                    \n",
    "                    # Brand New 특화 처리\n",
    "                    if condition == 'Brand New':\n",
    "                        df.loc[mask, 'is_brand_new'] = 1\n",
    "                        df.loc[mask, 'price_factor'] = 1.0\n",
    "                        df.loc[mask, 'distance_score'] = 1.0 - (df.loc[mask, '주행거리(km)'] / 10000)\n",
    "                    else:\n",
    "                        df.loc[mask, 'is_brand_new'] = 0\n",
    "                        df.loc[mask, 'price_factor'] = 0.9 if condition == 'Nearly New' else 0.8\n",
    "                        df.loc[mask, 'distance_score'] = 1.0 - (df.loc[mask, '주행거리(km)'] / 100000)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def handle_ioniq_data(self, df):\n",
    "        \"\"\"IONIQ 모델 특화 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        mask = df['모델'] == 'IONIQ'\n",
    "        \n",
    "        if sum(mask) > 0:\n",
    "            # 결측치 처리\n",
    "            for condition in ['Nearly New', 'Pre-Owned']:\n",
    "                condition_mask = (df['모델'] == 'IONIQ') & \\\n",
    "                               (df['차량상태'] == condition) & \\\n",
    "                               df['배터리용량'].isnull()\n",
    "                \n",
    "                if sum(condition_mask) > 0:\n",
    "                    df.loc[condition_mask, '배터리용량'] = self.standard_battery['IONIQ'][condition]\n",
    "            \n",
    "            # 주행거리 구간화\n",
    "            df.loc[mask, 'distance_group'] = pd.qcut(\n",
    "                df.loc[mask, '주행거리(km)'],\n",
    "                q=4,\n",
    "                labels=['Low', 'Mid', 'High', 'Very_High']\n",
    "            )\n",
    "            \n",
    "            # IONIQ 특화 특성\n",
    "            df.loc[mask, 'efficiency_score'] = df.loc[mask, '배터리용량'] / \\\n",
    "                np.log1p(df.loc[mask, '주행거리(km)'])\n",
    "            df.loc[mask, 'age_factor'] = np.exp(-df.loc[mask, '연식(년)'] / 2)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def create_model_features(self, df, model_name):\n",
    "        \"\"\"모델별 특화 특성 생성\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 특성\n",
    "        features = {\n",
    "            'battery_capacity': df['배터리용량'],\n",
    "            'distance': df['주행거리(km)'],\n",
    "            'age': df['연식(년)'],\n",
    "            'warranty': df['보증기간(년)'],\n",
    "            'accident': (df['사고이력'] == 'Yes').astype(int)\n",
    "        }\n",
    "        \n",
    "        # 공통 파생 특성\n",
    "        features['km_per_year'] = features['distance'] / (features['age'] + 1)\n",
    "        features['battery_efficiency'] = features['battery_capacity'] / \\\n",
    "            np.log1p(features['distance'])\n",
    "        features['warranty_value'] = features['warranty'] * features['battery_efficiency']\n",
    "        \n",
    "        # 모델별 특화 특성\n",
    "        if model_name in ['TayCT', 'Tay']:\n",
    "            if 'is_brand_new' in df.columns:\n",
    "                features['is_brand_new'] = df['is_brand_new']\n",
    "                features['price_factor'] = df['price_factor']\n",
    "                features['distance_score'] = df['distance_score']\n",
    "        elif model_name == 'IONIQ':\n",
    "            if 'distance_group' in df.columns:\n",
    "                distance_dummies = pd.get_dummies(df['distance_group'], prefix='distance')\n",
    "                for col in distance_dummies.columns:\n",
    "                    features[col] = distance_dummies[col]\n",
    "            if 'efficiency_score' in df.columns:\n",
    "                features['efficiency_score'] = df['efficiency_score']\n",
    "                features['age_factor'] = df['age_factor']\n",
    "        \n",
    "        return pd.DataFrame(features)\n",
    "\n",
    "    def train_model(self, X, y, model_key):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        # 스케일링\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # 기본 모델 파라미터\n",
    "        if 'Brand New' in model_key:\n",
    "            params = self.model_params[f\"{model_key.split('_')[0]}_Brand New\"]\n",
    "        elif model_key.startswith('IONIQ'):\n",
    "            params = self.model_params['IONIQ']\n",
    "        else:\n",
    "            params = self.model_params[f\"{model_key.split('_')[0]}_Used\"]\n",
    "        \n",
    "        # 모델 생성\n",
    "        rf = RandomForestRegressor(**params['rf'], random_state=42)\n",
    "        hgb = HistGradientBoostingRegressor(**params['hgb'], random_state=42)\n",
    "        \n",
    "        # 교차 검증\n",
    "        cv_scores = {\n",
    "            'rf': [],\n",
    "            'hgb': [],\n",
    "            'ensemble': []\n",
    "        }\n",
    "        \n",
    "        for train_idx, val_idx in self.kf.split(X_scaled):\n",
    "            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            rf.fit(X_train, y_train)\n",
    "            hgb.fit(X_train, y_train)\n",
    "            \n",
    "            rf_pred = rf.predict(X_val)\n",
    "            hgb_pred = hgb.predict(X_val)\n",
    "            \n",
    "            # 가중치 최적화\n",
    "            def objective(weights):\n",
    "                w_rf, w_hgb = weights\n",
    "                pred = w_rf * rf_pred + w_hgb * hgb_pred\n",
    "                return np.sqrt(mean_squared_error(y_val, pred))\n",
    "            \n",
    "            constraints = ({'type': 'eq', 'fun': lambda w: sum(w) - 1})\n",
    "            bounds = [(0, 1), (0, 1)]\n",
    "            result = minimize(objective, x0=[0.5, 0.5], bounds=bounds, constraints=constraints)\n",
    "            \n",
    "            ensemble_pred = result.x[0] * rf_pred + result.x[1] * hgb_pred\n",
    "            \n",
    "            cv_scores['rf'].append(np.sqrt(mean_squared_error(y_val, rf_pred)))\n",
    "            cv_scores['hgb'].append(np.sqrt(mean_squared_error(y_val, hgb_pred)))\n",
    "            cv_scores['ensemble'].append(np.sqrt(mean_squared_error(y_val, ensemble_pred)))\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        rf.fit(X_scaled, y)\n",
    "        hgb.fit(X_scaled, y)\n",
    "        \n",
    "        return {\n",
    "            'rf': rf,\n",
    "            'hgb': hgb,\n",
    "            'scaler': scaler,\n",
    "            'weights': {'rf': result.x[0], 'hgb': result.x[1]},\n",
    "            'scores': {\n",
    "                'rf': np.mean(cv_scores['rf']),\n",
    "                'hgb': np.mean(cv_scores['hgb']),\n",
    "                'ensemble': np.mean(cv_scores['ensemble'])\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def fit(self, train_df):\n",
    "        \"\"\"전체 모델 학습\"\"\"\n",
    "        # Brand New 차량 처리\n",
    "        df = self.handle_brand_new_missing(train_df)\n",
    "        \n",
    "        # IONIQ 처리\n",
    "        df = self.handle_ioniq_data(df)\n",
    "        \n",
    "        # 모델별 학습\n",
    "        for model_name in ['IONIQ', 'TayCT', 'Tay']:\n",
    "            print(f\"\\n=== {model_name} 모델 학습 ===\")\n",
    "            model_mask = df['모델'] == model_name\n",
    "            \n",
    "            if sum(model_mask) > 0:\n",
    "                model_data = df[model_mask]\n",
    "                \n",
    "                # 차량 상태별 학습\n",
    "                for condition in model_data['차량상태'].unique():\n",
    "                    condition_mask = model_data['차량상태'] == condition\n",
    "                    if sum(condition_mask) > 0:\n",
    "                        print(f\"\\n{condition} 상태 처리 (데이터 수: {sum(condition_mask)})\")\n",
    "                        \n",
    "                        # 특성 생성\n",
    "                        X = self.create_model_features(\n",
    "                            model_data[condition_mask], \n",
    "                            model_name\n",
    "                        )\n",
    "                        y = model_data[condition_mask]['가격(백만원)']\n",
    "                        \n",
    "                        # 모델 학습\n",
    "                        model_key = f\"{model_name}_{condition}\"\n",
    "                        self.models[model_key] = self.train_model(X, y, model_key)\n",
    "                        \n",
    "                        # 성능 출력\n",
    "                        scores = self.models[model_key]['scores']\n",
    "                        print(f\"RF RMSE: {scores['rf']:.4f}\")\n",
    "                        print(f\"HGB RMSE: {scores['hgb']:.4f}\")\n",
    "                        print(f\"Ensemble RMSE: {scores['ensemble']:.4f}\")\n",
    "                        print(f\"최적 가중치: RF={self.models[model_key]['weights']['rf']:.2f}, \"\n",
    "                              f\"HGB={self.models[model_key]['weights']['hgb']:.2f}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, test_df):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        # 데이터 전처리\n",
    "        df = self.handle_brand_new_missing(test_df)\n",
    "        df = self.handle_ioniq_data(df)\n",
    "        \n",
    "        predictions = pd.Series(index=df.index, dtype=float)\n",
    "        \n",
    "        # 모델별 예측\n",
    "        for model_name in ['IONIQ', 'TayCT', 'Tay']:\n",
    "            model_mask = df['모델'] == model_name\n",
    "            \n",
    "            if sum(model_mask) > 0:\n",
    "                model_data = df[model_mask]\n",
    "                \n",
    "                # 차량 상태별 예측\n",
    "                for condition in model_data['차량상태'].unique():\n",
    "                    condition_mask = model_data['차량상태'] == condition\n",
    "                    if sum(condition_mask) > 0:\n",
    "                        current_mask = model_mask & condition_mask\n",
    "                        model_key = f\"{model_name}_{condition}\"\n",
    "                        \n",
    "                        if model_key in self.models:\n",
    "                            X = self.create_model_features(\n",
    "                                df[current_mask],\n",
    "                                model_name\n",
    "                            )\n",
    "                            \n",
    "                            # 스케일링\n",
    "                            X_scaled = self.models[model_key]['scaler'].transform(X)\n",
    "                            \n",
    "                            # 예측\n",
    "                            rf_pred = self.models[model_key]['rf'].predict(X_scaled)\n",
    "                            hgb_pred = self.models[model_key]['hgb'].predict(X_scaled)\n",
    "                            \n",
    "                            # 앙상블\n",
    "                            predictions[current_mask] = \\\n",
    "                                self.models[model_key]['weights']['rf'] * rf_pred + \\\n",
    "                                self.models[model_key]['weights']['hgb'] * hgb_pred\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   # 데이터 로드\n",
    "   train_data = pd.read_csv('train.csv')\n",
    "   test_data = pd.read_csv('test.csv')\n",
    "   \n",
    "   # IONIQ, TayCT, Tay 모델만 선택\n",
    "   train_models = train_data[train_data['모델'].isin(['IONIQ', 'TayCT', 'Tay'])]\n",
    "   test_models = test_data[test_data['모델'].isin(['IONIQ', 'TayCT', 'Tay'])]\n",
    "   \n",
    "   # 모델 학습\n",
    "   predictor = RefinedIndependentPredictor()\n",
    "   predictor.fit(train_models)\n",
    "   \n",
    "   # 예측\n",
    "   predictions = predictor.predict(test_models)\n",
    "   \n",
    "   # 결과 저장\n",
    "   submission = pd.DataFrame({\n",
    "       'ID': test_models['ID'],\n",
    "       '가격(백만원)': predictions\n",
    "   })\n",
    "   \n",
    "   submission.to_csv('refined_model_submission.csv', index=False)\n",
    "   \n",
    "   # 모델 성능 분석\n",
    "   print(\"\\n=== 모델 성능 요약 ===\")\n",
    "   for model_key, model_info in predictor.models.items():\n",
    "       print(f\"\\n{model_key}:\")\n",
    "       scores = model_info['scores']\n",
    "       weights = model_info['weights']\n",
    "       print(f\"RF RMSE: {scores['rf']:.4f}\")\n",
    "       print(f\"HGB RMSE: {scores['hgb']:.4f}\")\n",
    "       print(f\"Ensemble RMSE: {scores['ensemble']:.4f}\")\n",
    "       print(f\"가중치: RF={weights['rf']:.2f}, HGB={weights['hgb']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== IONIQ 모델 학습 ===\n",
      "\n",
      "교차 검증 결과:\n",
      "\n",
      "Fold 1:\n",
      "RF RMSE: 5.0217\n",
      "HGB RMSE: 5.3167\n",
      "Ensemble RMSE: 5.1597\n",
      "\n",
      "Fold 2:\n",
      "RF RMSE: 6.0546\n",
      "HGB RMSE: 6.0156\n",
      "Ensemble RMSE: 6.0175\n",
      "\n",
      "Fold 3:\n",
      "RF RMSE: 5.1103\n",
      "HGB RMSE: 5.3355\n",
      "Ensemble RMSE: 5.1878\n",
      "\n",
      "Fold 4:\n",
      "RF RMSE: 7.2867\n",
      "HGB RMSE: 7.3536\n",
      "Ensemble RMSE: 7.3057\n",
      "\n",
      "Fold 5:\n",
      "RF RMSE: 5.3526\n",
      "HGB RMSE: 5.5039\n",
      "Ensemble RMSE: 5.4131\n",
      "\n",
      "평균 성능:\n",
      "RF RMSE: 5.7652 (+/- 0.8427)\n",
      "HGB RMSE: 5.9051 (+/- 0.7671)\n",
      "Ensemble RMSE: 5.8168 (+/- 0.8059)\n",
      "\n",
      "특성 중요도:\n",
      "              feature  importance\n",
      "5        price_factor    0.238392\n",
      "1  battery_efficiency    0.189941\n",
      "0       battery_score    0.153928\n",
      "9            주행거리(km)    0.129355\n",
      "2     distance_factor    0.129148\n",
      "6    adjusted_subsidy    0.074414\n",
      "7               연식(년)    0.051877\n",
      "3   condition_encoded    0.019511\n",
      "8             보증기간(년)    0.013434\n",
      "4            accident    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "class IONIQPredictor:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = None\n",
    "        self.model = None\n",
    "        self.kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        # 기본 파라미터\n",
    "        self.model_params = {\n",
    "            'rf': {\n",
    "                'n_estimators': 200,\n",
    "                'max_depth': 5,\n",
    "                'min_samples_split': 4,\n",
    "                'min_samples_leaf': 3,\n",
    "                'random_state': 42\n",
    "            },\n",
    "            'hgb': {\n",
    "                'max_iter': 1000,\n",
    "                'learning_rate': 0.005,\n",
    "                'max_depth': 4,\n",
    "                'l2_regularization': 2.5,\n",
    "                'random_state': 42\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def calculate_subsidy(self, data):\n",
    "        \"\"\"보조금 계산\"\"\"\n",
    "        base_subsidy = 8.4  # 국비(6.9) + 지자체(1.5)\n",
    "        \n",
    "        # 차량 상태별 보조금 비율\n",
    "        subsidy_ratio = {\n",
    "            'Nearly New': 0.8,\n",
    "            'Pre-Owned': 0.6\n",
    "        }\n",
    "        \n",
    "        # 연식별 보조금 감소\n",
    "        adjusted_subsidy = base_subsidy * \\\n",
    "            data['차량상태'].map(subsidy_ratio) * \\\n",
    "            np.exp(-data['연식(년)'] * 0.2)\n",
    "            \n",
    "        return adjusted_subsidy\n",
    "\n",
    "    def prepare_features(self, df):\n",
    "        \"\"\"특성 준비\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 보조금 계산 및 적용\n",
    "        df['adjusted_subsidy'] = self.calculate_subsidy(df)\n",
    "        \n",
    "        # 주행거리 기반 가치 조정\n",
    "        df['distance_factor'] = 1 - (df['주행거리(km)'] / 100000)\n",
    "        \n",
    "        # 배터리 효율성\n",
    "        df['battery_score'] = df['배터리용량'] / df['배터리용량'].max()\n",
    "        df['battery_efficiency'] = df['배터리용량'] / np.log1p(df['주행거리(km)'])\n",
    "        \n",
    "        # 차량 상태 인코딩\n",
    "        if '차량상태' not in self.label_encoders:\n",
    "            self.label_encoders['차량상태'] = LabelEncoder()\n",
    "            self.label_encoders['차량상태'].fit(df['차량상태'])\n",
    "        df['condition_encoded'] = self.label_encoders['차량상태'].transform(df['차량상태'])\n",
    "        \n",
    "        # 사고이력 변환\n",
    "        df['accident'] = (df['사고이력'] == 'Yes').astype(int)\n",
    "        \n",
    "        # 가격 영향 요소\n",
    "        df['price_factor'] = (\n",
    "            df['distance_factor'] * 0.4 +\n",
    "            df['battery_score'] * 0.4 +\n",
    "            (df['보증기간(년)'] / df['보증기간(년)'].max()) * 0.2\n",
    "        )\n",
    "        \n",
    "        # 최종 특성 선택\n",
    "        features = [\n",
    "            'battery_score', 'battery_efficiency', 'distance_factor',\n",
    "            'condition_encoded', 'accident', 'price_factor',\n",
    "            'adjusted_subsidy', '연식(년)', '보증기간(년)', '주행거리(km)'\n",
    "        ]\n",
    "        \n",
    "        return df[features]\n",
    "\n",
    "    def fit(self, train_data):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        print(\"=== IONIQ 모델 학습 ===\")\n",
    "        X = self.prepare_features(train_data)\n",
    "        y = train_data['가격(백만원)']\n",
    "        \n",
    "        # 스케일링\n",
    "        self.scaler = StandardScaler()\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        # 교차 검증\n",
    "        rf_scores = []\n",
    "        hgb_scores = []\n",
    "        ensemble_scores = []\n",
    "        \n",
    "        print(\"\\n교차 검증 결과:\")\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.kf.split(X_scaled), 1):\n",
    "            X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # RF 모델\n",
    "            rf = RandomForestRegressor(**self.model_params['rf'])\n",
    "            rf.fit(X_train, y_train)\n",
    "            rf_pred = rf.predict(X_val)\n",
    "            rf_rmse = np.sqrt(mean_squared_error(y_val, rf_pred))\n",
    "            rf_scores.append(rf_rmse)\n",
    "            \n",
    "            # HGB 모델\n",
    "            hgb = HistGradientBoostingRegressor(**self.model_params['hgb'])\n",
    "            hgb.fit(X_train, y_train)\n",
    "            hgb_pred = hgb.predict(X_val)\n",
    "            hgb_rmse = np.sqrt(mean_squared_error(y_val, hgb_pred))\n",
    "            hgb_scores.append(hgb_rmse)\n",
    "            \n",
    "            # 앙상블\n",
    "            ensemble_pred = (rf_pred + hgb_pred) / 2\n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y_val, ensemble_pred))\n",
    "            ensemble_scores.append(ensemble_rmse)\n",
    "            \n",
    "            print(f\"\\nFold {fold}:\")\n",
    "            print(f\"RF RMSE: {rf_rmse:.4f}\")\n",
    "            print(f\"HGB RMSE: {hgb_rmse:.4f}\")\n",
    "            print(f\"Ensemble RMSE: {ensemble_rmse:.4f}\")\n",
    "        \n",
    "        print(\"\\n평균 성능:\")\n",
    "        print(f\"RF RMSE: {np.mean(rf_scores):.4f} (+/- {np.std(rf_scores):.4f})\")\n",
    "        print(f\"HGB RMSE: {np.mean(hgb_scores):.4f} (+/- {np.std(hgb_scores):.4f})\")\n",
    "        print(f\"Ensemble RMSE: {np.mean(ensemble_scores):.4f} (+/- {np.std(ensemble_scores):.4f})\")\n",
    "        \n",
    "        # 최종 모델 학습\n",
    "        self.rf = RandomForestRegressor(**self.model_params['rf'])\n",
    "        self.hgb = HistGradientBoostingRegressor(**self.model_params['hgb'])\n",
    "        \n",
    "        self.rf.fit(X_scaled, y)\n",
    "        self.hgb.fit(X_scaled, y)\n",
    "        \n",
    "        # 특성 중요도 출력\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X.columns,\n",
    "            'importance': self.rf.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(\"\\n특성 중요도:\")\n",
    "        print(feature_importance)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        \"\"\"예측\"\"\"\n",
    "        X = self.prepare_features(test_data)\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # 앙상블 예측\n",
    "        rf_pred = self.rf.predict(X_scaled)\n",
    "        hgb_pred = self.hgb.predict(X_scaled)\n",
    "        predictions = (rf_pred + hgb_pred) / 2\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 데이터 로드\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    # IONIQ 모델만 선택\n",
    "    train_ioniq = train_data[train_data['모델'] == 'IONIQ'].copy()\n",
    "    test_ioniq = test_data[test_data['모델'] == 'IONIQ'].copy()\n",
    "    \n",
    "    # 모델 학습\n",
    "    predictor = IONIQPredictor()\n",
    "    predictor.fit(train_ioniq)\n",
    "    \n",
    "    # 예측\n",
    "    predictions = predictor.predict(test_ioniq)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test_ioniq['ID'],\n",
    "        '가격(백만원)': predictions\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('ioniq_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGBoost Parameters: {'colsample_bytree': 1.0, 'learning_rate': 0.1, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Best XGBoost Score: 1.3596366806449227\n",
      "Best Random Forest Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best Random Forest Score: 1.409063755355195\n",
      "\n",
      "Best Ensemble Weight (XGBoost): 0.0\n",
      "Ensemble RMSE: 1.405949724669568\n",
      "\n",
      "XGBoost Feature Importance:\n",
      "    feature  importance\n",
      "0       제조사    0.686109\n",
      "1        모델    0.258747\n",
      "3     배터리용량    0.038458\n",
      "2      차량상태    0.008290\n",
      "6   보증기간(년)    0.007275\n",
      "5  주행거리(km)    0.000654\n",
      "8     연식(년)    0.000262\n",
      "4      구동방식    0.000149\n",
      "7      사고이력    0.000055\n",
      "\n",
      "Random Forest Feature Importance:\n",
      "    feature  importance\n",
      "1        모델    0.555545\n",
      "0       제조사    0.303804\n",
      "3     배터리용량    0.103237\n",
      "6   보증기간(년)    0.029395\n",
      "5  주행거리(km)    0.003723\n",
      "2      차량상태    0.002019\n",
      "4      구동방식    0.001866\n",
      "8     연식(년)    0.000401\n",
      "7      사고이력    0.000008\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_data(df):\n",
    "    # 레이블 인코딩\n",
    "    le = LabelEncoder()\n",
    "    categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    # 결측치 처리\n",
    "    df['배터리용량'] = df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'))\n",
    "    # 그룹 평균으로도 채울 수 없는 결측치는 전체 평균으로 채움\n",
    "    df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 데이터 전처리\n",
    "train_processed = preprocess_data(train.copy())\n",
    "test_processed = preprocess_data(test.copy())\n",
    "\n",
    "# 특성과 타겟 분리\n",
    "feature_columns = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "                  '보증기간(년)', '사고이력', '연식(년)']\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['가격(백만원)']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost 그리드 서치\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "xgb_grid = GridSearchCV(xgb, xgb_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best XGBoost Parameters:\", xgb_grid.best_params_)\n",
    "print(\"Best XGBoost Score:\", np.sqrt(-xgb_grid.best_score_))\n",
    "\n",
    "# Random Forest 그리드 서치\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Best Random Forest Score:\", np.sqrt(-rf_grid.best_score_))\n",
    "\n",
    "# 최적의 모델로 예측\n",
    "xgb_pred = xgb_grid.best_estimator_.predict(X_val)\n",
    "rf_pred = rf_grid.best_estimator_.predict(X_val)\n",
    "\n",
    "# 앙상블 가중치 최적화 (간단한 그리드 서치)\n",
    "best_rmse = float('inf')\n",
    "best_weight = 0.5\n",
    "\n",
    "for weight in np.arange(0, 1.1, 0.1):\n",
    "    ensemble_pred = weight * xgb_pred + (1 - weight) * rf_pred\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, ensemble_pred))\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_weight = weight\n",
    "\n",
    "print(f\"\\nBest Ensemble Weight (XGBoost): {best_weight}\")\n",
    "print(f\"Ensemble RMSE: {best_rmse}\")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "X_test = test_processed[feature_columns]\n",
    "xgb_test_pred = xgb_grid.best_estimator_.predict(X_test)\n",
    "rf_test_pred = rf_grid.best_estimator_.predict(X_test)\n",
    "final_pred = best_weight * xgb_test_pred + (1 - best_weight) * rf_test_pred\n",
    "\n",
    "# 결과 저장\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    '가격(백만원)': final_pred\n",
    "})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# 특성 중요도 확인\n",
    "print(\"\\nXGBoost Feature Importance:\")\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': xgb_grid.best_estimator_.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(xgb_importance)\n",
    "\n",
    "print(\"\\nRandom Forest Feature Importance:\")\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_grid.best_estimator_.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(rf_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 모델별 예측 오차 분석 ===\n",
      "        평균오차  오차표준편차  데이터수  평균상대오차(%)  평균실제가격\n",
      "모델                                           \n",
      "IONIQ   6.16    3.06    29      39.03   17.69\n",
      "TayCT   2.82    2.11    69       2.24  126.44\n",
      "Tay     2.21    1.92    68       2.17  109.49\n",
      "KNE     0.53    0.38    81       2.14   25.93\n",
      "Soul    0.46    0.28    88       2.10   22.24\n",
      "Niro    0.54    0.30    60       2.01   27.00\n",
      "i3      0.34    0.40    80       1.43   23.60\n",
      "ID4     0.50    0.30   107       1.33   37.92\n",
      "EV6     0.49    0.34    73       1.12   44.50\n",
      "M3      0.43    0.35    45       0.86   51.70\n",
      "i5      0.52    0.33    85       0.83   62.84\n",
      "MX      0.67    0.58    66       0.79   84.43\n",
      "ION5    0.28    0.22    76       0.79   34.89\n",
      "MS      0.55    0.32    71       0.75   73.51\n",
      "ION6    0.27    0.18    77       0.70   38.19\n",
      "eT      0.46    0.32    84       0.70   66.95\n",
      "MY      0.51    0.31    47       0.69   73.15\n",
      "Q4eT    0.34    0.28    75       0.59   58.23\n",
      "iX      0.44    0.28    69       0.55   80.17\n",
      "RSeTGT  0.27    0.25    70       0.27   98.65\n",
      "TayGTS  0.31    0.27    80       0.20  158.61\n",
      "\n",
      "=== 가격대별 예측 오차 분석 ===\n",
      "          오차             상대오차(%)\n",
      "        mean   std count    mean\n",
      "가격대                             \n",
      "0-30    0.95  1.86   338    5.10\n",
      "30-50   0.40  0.31   346    1.04\n",
      "50-70   0.43  0.30   284    0.71\n",
      "70-100  0.67  0.88   305    0.78\n",
      "100+    1.41  1.82   227    1.16\n",
      "\n",
      "=== 오차가 큰 상위 20개 케이스 ===\n",
      "     제조사     모델    실제가격        예측가격         오차    상대오차(%)\n",
      "6929  H사  IONIQ   24.66   10.684688  13.975312  56.671988\n",
      "1662  H사  IONIQ   26.95   14.130251  12.819749  47.568642\n",
      "6830  H사  IONIQ   23.82   14.106504   9.713496  40.778742\n",
      "5425  H사  IONIQ    9.94   18.842795   8.902795  89.565339\n",
      "2118  H사  IONIQ   10.86   19.435564   8.575564  78.964681\n",
      "4522  H사  IONIQ   25.06   16.575092   8.484908  33.858374\n",
      "7487  H사  IONIQ   11.39   19.797759   8.407759  73.817023\n",
      "254   H사  IONIQ    9.77   18.034069   8.264069  84.586176\n",
      "346   H사  IONIQ   23.45   15.402453   8.047547  34.317900\n",
      "5672  P사  TayCT  120.00  127.430923   7.430923   6.192436\n",
      "5920  P사  TayCT  130.94  123.694522   7.245478   5.533434\n",
      "2850  H사  IONIQ   11.93   18.925450   6.995450  58.637467\n",
      "6765  P사  TayCT  130.66  123.694491   6.965509   5.331019\n",
      "5643  H사  IONIQ   26.10   19.172407   6.927593  26.542500\n",
      "1919  H사  IONIQ   20.76   13.944903   6.815097  32.828018\n",
      "199   P사  TayCT  120.48  127.064288   6.584288   5.465046\n",
      "3494  P사  TayCT  120.04  126.524932   6.484932   5.402309\n",
      "1039  H사  IONIQ   13.55   19.971561   6.421561  47.391596\n",
      "2083  P사  TayCT  120.04  126.295655   6.255655   5.211309\n",
      "2440  H사  IONIQ   23.60   17.354124   6.245876  26.465578\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 모델 개선 제안 ===\n",
      "1. 오차가 큰 모델들의 특징:\n",
      "       평균오차  평균상대오차(%)  데이터수\n",
      "모델                          \n",
      "IONIQ  6.16      39.03    29\n",
      "\n",
      "2. 가격대별 성능 차이:\n",
      "          오차             상대오차(%)\n",
      "        mean   std count    mean\n",
      "가격대                             \n",
      "0-30    0.95  1.86   338    5.10\n",
      "30-50   0.40  0.31   346    1.04\n",
      "50-70   0.43  0.30   284    0.71\n",
      "70-100  0.67  0.88   305    0.78\n",
      "100+    1.41  1.82   227    1.16\n",
      "Best XGBoost Parameters: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best XGBoost Score: 1.3647639960671067\n",
      "Best Random Forest Parameters: {'max_depth': 10, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}\n",
      "Best Random Forest Score: 1.404258870000548\n",
      "Validation RMSE: 1.4616468593818857\n",
      "\n",
      "XGBoost Feature Importance:\n",
      "     feature  importance\n",
      "0        제조사    0.684515\n",
      "1         모델    0.253975\n",
      "3      배터리용량    0.042091\n",
      "2       차량상태    0.009019\n",
      "6    보증기간(년)    0.006341\n",
      "12    제조사_모델    0.002799\n",
      "5   주행거리(km)    0.000766\n",
      "9      배터리효율    0.000221\n",
      "8      연식(년)    0.000201\n",
      "4       구동방식    0.000038\n",
      "7       사고이력    0.000034\n",
      "10      차량나이    0.000000\n",
      "11   감가상각_지수    0.000000\n",
      "\n",
      "Random Forest Feature Importance:\n",
      "     feature  importance\n",
      "1         모델    0.432633\n",
      "12    제조사_모델    0.225944\n",
      "0        제조사    0.191345\n",
      "3      배터리용량    0.107549\n",
      "6    보증기간(년)    0.034484\n",
      "5   주행거리(km)    0.002917\n",
      "4       구동방식    0.001869\n",
      "2       차량상태    0.001684\n",
      "9      배터리효율    0.001055\n",
      "10      차량나이    0.000271\n",
      "8      연식(년)    0.000242\n",
      "7       사고이력    0.000006\n",
      "11   감가상각_지수    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "\n",
    "# 전처리 및 특성 엔지니어링 함수\n",
    "def preprocess_data(df):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # 레이블 인코딩\n",
    "   le = LabelEncoder()\n",
    "   categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력']\n",
    "   \n",
    "   for col in categorical_cols:\n",
    "       df[col] = le.fit_transform(df[col])\n",
    "   \n",
    "   # 결측치 처리\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'))\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "   \n",
    "   # 새로운 특성 추가\n",
    "   # 배터리 효율성\n",
    "   df['배터리효율'] = df['주행거리(km)'] / df['배터리용량']\n",
    "   \n",
    "   # 차량 나이에 따른 가치 감소 지수\n",
    "   current_year = 2024\n",
    "   df['차량나이'] = current_year - df['연식(년)']\n",
    "   df['감가상각_지수'] = np.exp(-0.1 * df['차량나이'])\n",
    "   \n",
    "   # 제조사-모델 조합\n",
    "   df['제조사_모델'] = df['제조사'].astype(str) + '_' + df['모델'].astype(str)\n",
    "   df['제조사_모델'] = le.fit_transform(df['제조사_모델'])\n",
    "   \n",
    "   return df\n",
    "\n",
    "# 데이터 전처리\n",
    "train_processed = preprocess_data(train)\n",
    "test_processed = preprocess_data(test)\n",
    "# 기존의 전처리와 모델 학습 코드는 동일하게 유지하고, 검증 단계에서 다음 코드를 추가\n",
    "\n",
    "# 검증 데이터에서 모델별 오차 분석\n",
    "val_pred = stacking.predict(X_val)\n",
    "val_df = pd.DataFrame({\n",
    "    '실제가격': y_val,\n",
    "    '예측가격': val_pred,\n",
    "    '오차': np.abs(y_val - val_pred),\n",
    "    '상대오차(%)': np.abs((y_val - val_pred) / y_val) * 100\n",
    "})\n",
    "\n",
    "# 원본 데이터의 모델명 정보 추가\n",
    "val_df['모델'] = train.iloc[X_val.index]['모델']\n",
    "val_df['제조사'] = train.iloc[X_val.index]['제조사']\n",
    "\n",
    "# 모델별 평균 오차 계산\n",
    "model_errors = val_df.groupby('모델').agg({\n",
    "    '오차': ['mean', 'std', 'count'],\n",
    "    '상대오차(%)': 'mean',\n",
    "    '실제가격': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "model_errors.columns = ['평균오차', '오차표준편차', '데이터수', '평균상대오차(%)', '평균실제가격']\n",
    "model_errors = model_errors.sort_values('평균상대오차(%)', ascending=False)\n",
    "\n",
    "print(\"\\n=== 모델별 예측 오차 분석 ===\")\n",
    "print(model_errors)\n",
    "\n",
    "# 가격대별 오차 분석\n",
    "val_df['가격대'] = pd.cut(val_df['실제가격'], \n",
    "                      bins=[0, 30, 50, 70, 100, float('inf')],\n",
    "                      labels=['0-30', '30-50', '50-70', '70-100', '100+'])\n",
    "\n",
    "price_range_errors = val_df.groupby('가격대').agg({\n",
    "    '오차': ['mean', 'std', 'count'],\n",
    "    '상대오차(%)': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\n=== 가격대별 예측 오차 분석 ===\")\n",
    "print(price_range_errors)\n",
    "\n",
    "# 오차가 큰 상위 20개 케이스 분석\n",
    "print(\"\\n=== 오차가 큰 상위 20개 케이스 ===\")\n",
    "worst_predictions = val_df.nlargest(20, '오차')\n",
    "print(worst_predictions[['제조사', '모델', '실제가격', '예측가격', '오차', '상대오차(%)']])\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# 모델별 평균 상대오차\n",
    "plt.subplot(1, 2, 1)\n",
    "model_errors.nlargest(10, '평균상대오차(%)')[['평균상대오차(%)']].plot(kind='bar')\n",
    "plt.title('모델별 평균 상대오차 (상위 10개)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "\n",
    "# 실제가격 vs 예측가격 산점도\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(val_df['실제가격'], val_df['예측가격'], alpha=0.5)\n",
    "plt.plot([val_df['실제가격'].min(), val_df['실제가격'].max()], \n",
    "         [val_df['실제가격'].min(), val_df['실제가격'].max()], \n",
    "         'r--')\n",
    "plt.xlabel('실제가격')\n",
    "plt.ylabel('예측가격')\n",
    "plt.title('실제가격 vs 예측가격')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 이 분석을 바탕으로 모델 개선 제안\n",
    "print(\"\\n=== 모델 개선 제안 ===\")\n",
    "print(\"1. 오차가 큰 모델들의 특징:\")\n",
    "high_error_models = model_errors[model_errors['평균상대오차(%)'] > model_errors['평균상대오차(%)'].mean()]\n",
    "print(high_error_models[['평균오차', '평균상대오차(%)', '데이터수']])\n",
    "\n",
    "# 가격대별 특별 처리가 필요한지 확인\n",
    "print(\"\\n2. 가격대별 성능 차이:\")\n",
    "print(price_range_errors)\n",
    "# 특성과 타겟 분리\n",
    "feature_columns = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "                 '보증기간(년)', '사고이력', '연식(년)', '배터리효율', '차량나이', \n",
    "                 '감가상각_지수', '제조사_모델']\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['가격(백만원)']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost 그리드 서치\n",
    "xgb_params = {\n",
    "   'n_estimators': [200, 300, 400],\n",
    "   'max_depth': [5, 6, 7],\n",
    "   'learning_rate': [0.05, 0.1, 0.15],\n",
    "   'subsample': [0.8, 0.9, 1.0],\n",
    "   'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "   'min_child_weight': [1, 3, 5],\n",
    "   'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb = XGBRegressor(random_state=42)\n",
    "xgb_grid = GridSearchCV(xgb, xgb_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best XGBoost Parameters:\", xgb_grid.best_params_)\n",
    "print(\"Best XGBoost Score:\", np.sqrt(-xgb_grid.best_score_))\n",
    "\n",
    "# Random Forest 그리드 서치\n",
    "rf_params = {\n",
    "   'n_estimators': [200, 300, 400],\n",
    "   'max_depth': [10, 15, 20],\n",
    "   'min_samples_split': [2, 4, 6],\n",
    "   'min_samples_leaf': [1, 2, 3],\n",
    "   'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Best Random Forest Score:\", np.sqrt(-rf_grid.best_score_))\n",
    "\n",
    "# 스태킹 앙상블\n",
    "estimators = [\n",
    "   ('xgb', xgb_grid.best_estimator_),\n",
    "   ('rf', rf_grid.best_estimator_)\n",
    "]\n",
    "\n",
    "stacking = StackingRegressor(\n",
    "   estimators=estimators,\n",
    "   final_estimator=LassoCV(),\n",
    "   cv=5\n",
    ")\n",
    "\n",
    "stacking.fit(X_train, y_train)\n",
    "\n",
    "# 검증 데이터에서의 성능 평가\n",
    "val_pred = stacking.predict(X_val)\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "print(f\"Validation RMSE: {val_rmse}\")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "X_test = test_processed[feature_columns]\n",
    "final_pred = stacking.predict(X_test)\n",
    "\n",
    "# 결과 저장\n",
    "submission = pd.DataFrame({\n",
    "   'ID': test['ID'],\n",
    "   '가격(백만원)': final_pred\n",
    "})\n",
    "submission.to_csv('submission3.csv', index=False)\n",
    "\n",
    "# 특성 중요도 (XGBoost)\n",
    "xgb_importance = pd.DataFrame({\n",
    "   'feature': feature_columns,\n",
    "   'importance': xgb_grid.best_estimator_.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nXGBoost Feature Importance:\")\n",
    "print(xgb_importance)\n",
    "\n",
    "# 특성 중요도 (Random Forest)\n",
    "rf_importance = pd.DataFrame({\n",
    "   'feature': feature_columns,\n",
    "   'importance': rf_grid.best_estimator_.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(\"\\nRandom Forest Feature Importance:\")\n",
    "print(rf_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 최종 모델 성능 ===\n",
      "검증 세트 RMSE: 0.9537\n",
      "\n",
      "=== 앙상블 가중치 ===\n",
      "기본 모델: 1.0000\n",
      "가격대 100+ 모델: 0.0000\n",
      "가격대 0-30 모델: 0.0000\n",
      "가격대 50-70 모델: 0.0000\n",
      "가격대 70-100 모델: 0.0000\n",
      "가격대 30-50 모델: 0.0000\n",
      "\n",
      "=== 기본 모델 XGBoost 특성 중요도 ===\n",
      "         feature  importance\n",
      "0            제조사    0.631896\n",
      "1             모델    0.174789\n",
      "12        제조사_모델    0.081002\n",
      "3          배터리용량    0.048922\n",
      "4           구동방식    0.039186\n",
      "6        보증기간(년)    0.011358\n",
      "2           차량상태    0.008859\n",
      "13      is_ioniq    0.001924\n",
      "5       주행거리(km)    0.000708\n",
      "14  ioniq_age_km    0.000415\n",
      "8          연식(년)    0.000316\n",
      "9          배터리효율    0.000302\n",
      "10          차량나이    0.000291\n",
      "7           사고이력    0.000032\n",
      "11       감가상각_지수    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "import platform\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "if platform.system() == 'Darwin':  # Mac OS\n",
    "   plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':  # Windows\n",
    "   plt.rc('font', family='Malgun Gothic')\n",
    "   \n",
    "plt.rc('axes', unicode_minus=False)  # 마이너스 기호 깨짐 방지\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_data(df):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # IONIQ 특별 처리 (레이블 인코딩 전)\n",
    "   df['is_ioniq'] = (df['모델'] == 'IONIQ').astype(int)\n",
    "   \n",
    "   # 레이블 인코딩\n",
    "   le = LabelEncoder()\n",
    "   categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력']\n",
    "   \n",
    "   for col in categorical_cols:\n",
    "       df[col] = le.fit_transform(df[col])\n",
    "   \n",
    "   # 결측치 처리\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'))\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "   \n",
    "   # 특성 엔지니어링\n",
    "   # 배터리 효율성\n",
    "   df['배터리효율'] = df['주행거리(km)'] / df['배터리용량']\n",
    "   \n",
    "   # 차량 나이 관련 특성\n",
    "   current_year = 2024\n",
    "   df['차량나이'] = current_year - df['연식(년)']\n",
    "   df['감가상각_지수'] = np.exp(-0.1 * df['차량나이'])\n",
    "   \n",
    "   # IONIQ 관련 추가 특성\n",
    "   df['ioniq_age_km'] = df['is_ioniq'] * df['차량나이'] * df['주행거리(km)']\n",
    "   \n",
    "   # 제조사-모델 조합\n",
    "   df['제조사_모델'] = df['제조사'].astype(str) + '_' + df['모델'].astype(str)\n",
    "   df['제조사_모델'] = le.fit_transform(df['제조사_모델'])\n",
    "   \n",
    "   return df\n",
    "\n",
    "# 가격대별 모델 학습 함수\n",
    "def train_by_price_range(X, y, xgb_params, rf_params):\n",
    "   price_ranges = pd.cut(y, bins=[0, 30, 50, 70, 100, float('inf')],\n",
    "                        labels=['0-30', '30-50', '50-70', '70-100', '100+'])\n",
    "   models = {}\n",
    "   \n",
    "   for price_range in price_ranges.unique():\n",
    "       mask = price_ranges == price_range\n",
    "       if mask.sum() > 0:\n",
    "           model = StackingRegressor(\n",
    "               estimators=[\n",
    "                   ('xgb', XGBRegressor(**xgb_params)),\n",
    "                   ('rf', RandomForestRegressor(**rf_params))\n",
    "               ],\n",
    "               final_estimator=LassoCV(),\n",
    "               cv=5\n",
    "           )\n",
    "           model.fit(X[mask], y[mask])\n",
    "           models[price_range] = model\n",
    "   \n",
    "   return models\n",
    "\n",
    "# 앙상블 가중치 최적화 함수\n",
    "def optimize_weights(predictions_list, y_true):\n",
    "   def objective(weights):\n",
    "       weighted_pred = np.zeros_like(y_true)\n",
    "       for i, pred in enumerate(predictions_list):\n",
    "           weighted_pred += weights[i] * pred\n",
    "       return np.sqrt(mean_squared_error(y_true, weighted_pred))\n",
    "   \n",
    "   constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n",
    "   bounds = [(0, 1)] * len(predictions_list)\n",
    "   \n",
    "   result = minimize(objective, x0=np.ones(len(predictions_list))/len(predictions_list),\n",
    "                    constraints=constraints, bounds=bounds)\n",
    "   \n",
    "   return result.x\n",
    "\n",
    "# 데이터 전처리\n",
    "train_processed = preprocess_data(train)\n",
    "test_processed = preprocess_data(test)\n",
    "\n",
    "# 특성 선택\n",
    "feature_columns = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "                 '보증기간(년)', '사고이력', '연식(년)', '배터리효율', '차량나이', \n",
    "                 '감가상각_지수', '제조사_모델', 'is_ioniq', 'ioniq_age_km']\n",
    "\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['가격(백만원)']\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "xgb_params = {\n",
    "   'n_estimators': 300,\n",
    "   'max_depth': 6,\n",
    "   'learning_rate': 0.05,\n",
    "   'subsample': 0.8,\n",
    "   'colsample_bytree': 0.8,\n",
    "   'min_child_weight': 3,\n",
    "   'gamma': 0\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "   'n_estimators': 400,\n",
    "   'max_depth': 10,\n",
    "   'min_samples_split': 2,\n",
    "   'min_samples_leaf': 1,\n",
    "   'max_features': None\n",
    "}\n",
    "\n",
    "# 가격대별 모델 학습\n",
    "price_range_models = train_by_price_range(X, y, xgb_params, rf_params)\n",
    "\n",
    "# 전체 데이터에 대한 기본 모델\n",
    "base_model = StackingRegressor(\n",
    "   estimators=[\n",
    "       ('xgb', XGBRegressor(**xgb_params)),\n",
    "       ('rf', RandomForestRegressor(**rf_params))\n",
    "   ],\n",
    "   final_estimator=LassoCV(),\n",
    "   cv=5\n",
    ")\n",
    "base_model.fit(X, y)\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "X_test = test_processed[feature_columns]\n",
    "predictions = []\n",
    "\n",
    "# 기본 모델 예측\n",
    "predictions.append(base_model.predict(X_test))\n",
    "\n",
    "# 가격대별 모델 예측\n",
    "for model in price_range_models.values():\n",
    "   predictions.append(model.predict(X_test))\n",
    "\n",
    "# 앙상블 가중치 최적화\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "val_predictions = [base_model.predict(X_val)]\n",
    "for model in price_range_models.values():\n",
    "   val_predictions.append(model.predict(X_val))\n",
    "optimal_weights = optimize_weights(val_predictions, y_val)\n",
    "\n",
    "# 최종 예측\n",
    "final_prediction = np.zeros(len(test))\n",
    "for i, pred in enumerate(predictions):\n",
    "   final_prediction += optimal_weights[i] * pred\n",
    "\n",
    "# 결과 저장\n",
    "submission = pd.DataFrame({\n",
    "   'ID': test['ID'],\n",
    "   '가격(백만원)': final_prediction\n",
    "})\n",
    "submission.to_csv('submission4.csv', index=False)\n",
    "\n",
    "# 모델 성능 평가\n",
    "print(\"=== 최종 모델 성능 ===\")\n",
    "val_pred = np.zeros_like(y_val)\n",
    "for i, pred in enumerate(val_predictions):\n",
    "   val_pred += optimal_weights[i] * pred\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "print(f\"검증 세트 RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "# 가중치 출력\n",
    "print(\"\\n=== 앙상블 가중치 ===\")\n",
    "model_names = ['기본 모델'] + [f'가격대 {pr} 모델' for pr in price_range_models.keys()]\n",
    "for name, weight in zip(model_names, optimal_weights):\n",
    "   print(f\"{name}: {weight:.4f}\")\n",
    "\n",
    "# 특성 중요도 출력\n",
    "print(\"\\n=== 기본 모델 XGBoost 특성 중요도 ===\")\n",
    "xgb_importance = pd.DataFrame({\n",
    "   'feature': feature_columns,\n",
    "   'importance': base_model.named_estimators_['xgb'].feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(xgb_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 모델별 예측 성능 분석 ===\n",
      "        평균실제가격  평균예측가격  평균오차  오차표준편차  평균상대오차(%)  상대오차표준편차(%)  데이터수\n",
      "모델                                                                \n",
      "IONIQ    17.69   18.43  5.15    2.49      35.20        26.14    29\n",
      "i3       23.60   23.83  0.87    2.19       3.61         8.95    80\n",
      "Niro     27.00   27.04  0.85    0.78       3.33         3.53    60\n",
      "KNE      25.93   25.96  0.76    0.58       3.10         2.71    81\n",
      "TayCT   126.44  126.20  3.01    1.55       2.39         1.27    69\n",
      "Tay     109.49  109.30  2.31    1.73       2.25         1.77    68\n",
      "Soul     22.24   22.42  0.47    0.29       2.14         1.44    88\n",
      "EV6      44.50   44.22  0.94    0.51       2.09         1.10    73\n",
      "ID4      37.92   38.00  0.53    0.32       1.42         0.89   107\n",
      "M3       51.70   51.64  0.63    0.50       1.24         1.04    45\n",
      "ION5     34.89   35.17  0.37    0.32       1.07         0.92    76\n",
      "MX       84.43   84.00  0.91    0.79       1.05         0.89    66\n",
      "ION6     38.19   37.95  0.40    0.33       1.03         0.86    77\n",
      "MY       73.15   73.09  0.74    0.51       1.01         0.69    47\n",
      "i5       62.84   62.92  0.58    0.39       0.93         0.63    85\n",
      "eT       66.95   67.00  0.61    0.41       0.92         0.61    84\n",
      "MS       73.51   73.72  0.64    0.51       0.88         0.71    71\n",
      "Q4eT     58.23   58.35  0.48    0.42       0.83         0.71    75\n",
      "iX       80.17   79.94  0.45    0.29       0.56         0.36    69\n",
      "RSeTGT   98.65   98.56  0.49    0.36       0.50         0.37    70\n",
      "TayGTS  158.61  158.59  0.39    0.33       0.24         0.21    80\n",
      "\n",
      "=== 오차가 가장 큰 상위 20개 케이스 ===\n",
      "         모델    실제가격    예측가격     오차  상대오차(%)\n",
      "3337     i3   24.48   36.67  12.19    49.78\n",
      "6045     i3   24.33   36.16  11.83    48.63\n",
      "3693     i3   24.70   35.97  11.27    45.65\n",
      "5425  IONIQ    9.94   18.58   8.64    86.91\n",
      "7487  IONIQ   11.39   19.67   8.28    72.72\n",
      "6435  IONIQ    9.00   16.97   7.97    88.59\n",
      "6929  IONIQ   24.66   16.71   7.95    32.22\n",
      "1662  IONIQ   26.95   19.12   7.83    29.04\n",
      "2118  IONIQ   10.86   18.46   7.60    70.00\n",
      "254   IONIQ    9.77   17.36   7.59    77.70\n",
      "7227  IONIQ   10.22   17.48   7.26    71.04\n",
      "5643  IONIQ   26.10   19.03   7.07    27.08\n",
      "7379  IONIQ   10.85   17.80   6.95    64.08\n",
      "346   IONIQ   23.45   17.30   6.15    26.21\n",
      "2345  IONIQ   26.39   20.32   6.07    23.00\n",
      "1465  TayCT  120.00  126.03   6.03     5.02\n",
      "3494  TayCT  120.04  126.03   5.99     4.99\n",
      "2083  TayCT  120.04  126.03   5.99     4.99\n",
      "6487  TayCT  120.08  126.03   5.95     4.95\n",
      "2302  TayCT  120.18  126.06   5.88     4.90\n",
      "\n",
      "=== 가격대별 예측 성능 ===\n",
      "          오차       상대오차(%)         실제가격\n",
      "        mean   std    mean    std count\n",
      "가격대                                    \n",
      "0-30    1.10  1.85    5.76  12.72   338\n",
      "30-50   0.57  0.44    1.42   1.03   346\n",
      "50-70   0.54  0.40    0.89   0.67   284\n",
      "70-100  0.84  0.92    0.99   0.99   305\n",
      "100+    1.52  1.64    1.26   1.41   227\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 최종 모델 성능 ===\n",
      "검증 세트 RMSE: 1.5217\n",
      "\n",
      "=== XGBoost 특성 중요도 ===\n",
      "    feature  importance\n",
      "0       제조사    0.515807\n",
      "9    제조사_모델    0.165720\n",
      "1        모델    0.153328\n",
      "3     배터리용량    0.075751\n",
      "4      구동방식    0.057266\n",
      "6   보증기간(년)    0.017772\n",
      "2      차량상태    0.011383\n",
      "5  주행거리(km)    0.002457\n",
      "8     연식(년)    0.000514\n",
      "7      사고이력    0.000002\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "import platform\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "if platform.system() == 'Darwin':  # Mac OS\n",
    "   plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':  # Windows\n",
    "   plt.rc('font', family='Malgun Gothic')\n",
    "   \n",
    "plt.rc('axes', unicode_minus=False)  # 마이너스 기호 깨짐 방지\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_data(df):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # 레이블 인코딩\n",
    "   le = LabelEncoder()\n",
    "   categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력']\n",
    "   \n",
    "   for col in categorical_cols:\n",
    "       df[col] = le.fit_transform(df[col])\n",
    "   \n",
    "   # 결측치 처리\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'))\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "   \n",
    "   # 제조사-모델 조합\n",
    "   df['제조사_모델'] = df['제조사'].astype(str) + '_' + df['모델'].astype(str)\n",
    "   df['제조사_모델'] = le.fit_transform(df['제조사_모델'])\n",
    "   \n",
    "   return df\n",
    "\n",
    "# 데이터 전처리\n",
    "train_processed = preprocess_data(train)\n",
    "test_processed = preprocess_data(test)\n",
    "\n",
    "# 특성 선택\n",
    "feature_columns = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "                 '보증기간(년)', '사고이력', '연식(년)', '제조사_모델']\n",
    "\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['가격(백만원)']\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "xgb_params = {\n",
    "   'n_estimators': 200,\n",
    "   'max_depth': 5,\n",
    "   'learning_rate': 0.03,\n",
    "   'subsample': 0.8,\n",
    "   'colsample_bytree': 0.8,\n",
    "   'min_child_weight': 5,\n",
    "   'gamma': 0.1,\n",
    "   'reg_alpha': 0.1,\n",
    "   'reg_lambda': 1.0\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "   'n_estimators': 300,\n",
    "   'max_depth': 8,\n",
    "   'min_samples_split': 5,\n",
    "   'min_samples_leaf': 3,\n",
    "   'max_features': 'sqrt'\n",
    "}\n",
    "\n",
    "# 기본 모델\n",
    "base_model = StackingRegressor(\n",
    "   estimators=[\n",
    "       ('xgb', XGBRegressor(**xgb_params)),\n",
    "       ('rf', RandomForestRegressor(**rf_params))\n",
    "   ],\n",
    "   final_estimator=LassoCV(cv=5),\n",
    "   cv=10\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "base_model.fit(X, y)\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "X_test = test_processed[feature_columns]\n",
    "final_prediction = base_model.predict(X_test)\n",
    "\n",
    "# 검증 세트에서의 모델별 성능 분석\n",
    "val_predictions = base_model.predict(X_val)\n",
    "val_analysis = pd.DataFrame({\n",
    "   '모델': train.iloc[X_val.index]['모델'],\n",
    "   '실제가격': y_val,\n",
    "   '예측가격': val_predictions,\n",
    "   '오차': np.abs(y_val - val_predictions),\n",
    "   '상대오차(%)': np.abs((y_val - val_predictions) / y_val) * 100\n",
    "})\n",
    "\n",
    "# 모델별 평균 성능\n",
    "model_performance = pd.DataFrame()\n",
    "model_performance = val_analysis.groupby('모델').agg({\n",
    "   '실제가격': 'mean',\n",
    "   '예측가격': 'mean',\n",
    "   '오차': ['mean', 'std'],\n",
    "   '상대오차(%)': ['mean', 'std'],\n",
    "}).round(2)\n",
    "\n",
    "# 데이터 수 추가\n",
    "model_counts = val_analysis['모델'].value_counts()\n",
    "model_performance['데이터수'] = model_counts\n",
    "\n",
    "# MultiIndex 컬럼을 단일 레벨로 변경\n",
    "model_performance.columns = pd.Index([\n",
    "   '평균실제가격', '평균예측가격',\n",
    "   '평균오차', '오차표준편차',\n",
    "   '평균상대오차(%)', '상대오차표준편차(%)',\n",
    "   '데이터수'\n",
    "])\n",
    "\n",
    "# 평균 상대오차로 정렬\n",
    "model_performance = model_performance.sort_values('평균상대오차(%)', ascending=False)\n",
    "\n",
    "print(\"\\n=== 모델별 예측 성능 분석 ===\")\n",
    "print(model_performance)\n",
    "\n",
    "# 가장 오차가 큰 상위 20개 케이스\n",
    "print(\"\\n=== 오차가 가장 큰 상위 20개 케이스 ===\")\n",
    "worst_predictions = val_analysis.nlargest(20, '오차')\n",
    "print(worst_predictions.round(2))\n",
    "\n",
    "# 각 가격대별 성능\n",
    "val_analysis['가격대'] = pd.cut(val_analysis['실제가격'], \n",
    "                           bins=[0, 30, 50, 70, 100, float('inf')],\n",
    "                           labels=['0-30', '30-50', '50-70', '70-100', '100+'])\n",
    "\n",
    "price_range_performance = val_analysis.groupby('가격대').agg({\n",
    "   '오차': ['mean', 'std'],\n",
    "   '상대오차(%)': ['mean', 'std'],\n",
    "   '실제가격': 'count'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\n=== 가격대별 예측 성능 ===\")\n",
    "print(price_range_performance)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 실제가격 vs 예측가격 산점도\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(val_analysis['실제가격'], val_analysis['예측가격'], alpha=0.5)\n",
    "plt.plot([val_analysis['실제가격'].min(), val_analysis['실제가격'].max()], \n",
    "        [val_analysis['실제가격'].min(), val_analysis['실제가격'].max()], \n",
    "        'r--')\n",
    "plt.xlabel('실제가격')\n",
    "plt.ylabel('예측가격')\n",
    "plt.title('실제가격 vs 예측가격')\n",
    "\n",
    "# 모델별 평균 상대오차 막대 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "model_performance['평균상대오차(%)'].plot(kind='bar')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('모델별 평균 상대오차')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최종 모델 성능\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "print(f\"\\n=== 최종 모델 성능 ===\")\n",
    "print(f\"검증 세트 RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "# 특성 중요도 출력\n",
    "print(\"\\n=== XGBoost 특성 중요도 ===\")\n",
    "xgb_importance = pd.DataFrame({\n",
    "   'feature': feature_columns,\n",
    "   'importance': base_model.named_estimators_['xgb'].feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(xgb_importance)\n",
    "\n",
    "# 결과 저장\n",
    "submission = pd.DataFrame({\n",
    "   'ID': test['ID'],\n",
    "   '가격(백만원)': final_prediction\n",
    "})\n",
    "submission.to_csv('submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 모델별 예측 성능 분석 ===\n",
      "        평균실제가격  평균예측가격  평균오차  오차표준편차  평균상대오차(%)  상대오차표준편차(%)  데이터수\n",
      "모델                                                                \n",
      "IONIQ    18.28   17.98  4.92    2.71      29.12        19.14    27\n",
      "i3       23.57   23.87  1.11    2.21       4.60         8.87    81\n",
      "TayCT   126.83  126.69  3.40    1.75       2.71         1.45    61\n",
      "Soul     22.21   22.28  0.53    0.31       2.43         1.53    81\n",
      "MY       73.01   72.94  1.65    0.89       2.27         1.29    49\n",
      "MX       84.21   83.72  1.92    1.59       2.21         1.66    54\n",
      "KNE      25.63   25.67  0.52    0.38       2.09         1.62    71\n",
      "Niro     26.96   26.82  0.56    0.36       2.08         1.36    71\n",
      "ID4      38.48   38.46  0.76    0.56       1.98         1.49   118\n",
      "Tay     111.78  111.72  1.93    1.54       1.82         1.60    77\n",
      "Q4eT     58.22   58.60  0.98    0.97       1.67         1.63    64\n",
      "M3       51.54   51.68  0.79    0.52       1.55         1.08    53\n",
      "EV6      44.60   44.29  0.58    0.41       1.29         0.88    74\n",
      "i5       62.59   62.78  0.77    0.58       1.23         0.94    94\n",
      "MS       75.68   75.91  0.87    0.69       1.13         0.86    65\n",
      "eT       68.08   68.18  0.71    0.60       1.06         0.89    84\n",
      "ION5     35.17   35.22  0.30    0.19       0.84         0.56    81\n",
      "ION6     38.14   37.95  0.32    0.15       0.83         0.40    74\n",
      "TayGTS  157.60  157.60  1.11    1.11       0.72         0.73    71\n",
      "iX       80.06   79.83  0.50    0.31       0.63         0.38    67\n",
      "RSeTGT   98.64   98.52  0.56    0.46       0.57         0.46    83\n",
      "\n",
      "=== 오차가 가장 큰 상위 20개 케이스 ===\n",
      "         모델    실제가격    예측가격     오차  상대오차(%)\n",
      "1203     i3   24.92   39.37  14.45    57.97\n",
      "3946     i3   24.96   39.29  14.33    57.40\n",
      "580   IONIQ   27.42   17.72   9.70    35.36\n",
      "2159  IONIQ   26.56   17.21   9.35    35.22\n",
      "2016  IONIQ   26.81   18.05   8.76    32.68\n",
      "6994  IONIQ    9.83   18.31   8.48    86.26\n",
      "1063    Tay   96.82  104.76   7.94     8.20\n",
      "4522  IONIQ   25.06   17.34   7.72    30.80\n",
      "2583  IONIQ   11.61   18.86   7.25    62.42\n",
      "6929  IONIQ   24.66   17.77   6.89    27.94\n",
      "970   TayCT  119.02  125.30   6.28     5.28\n",
      "4264  IONIQ   12.09   18.31   6.22    51.45\n",
      "1969  TayCT  119.00  125.08   6.08     5.11\n",
      "3485  IONIQ   11.99   18.06   6.07    50.66\n",
      "6980     MX   94.75   88.70   6.05     6.39\n",
      "5659  TayCT  119.00  125.05   6.05     5.08\n",
      "452   TayCT  119.04  125.08   6.04     5.07\n",
      "1728     MX   94.53   88.62   5.91     6.26\n",
      "6757  TayCT  120.00  125.90   5.90     4.92\n",
      "7091  TayCT  120.00  125.90   5.90     4.92\n",
      "\n",
      "=== 가격대별 예측 성능 ===\n",
      "          오차       상대오차(%)         실제가격\n",
      "        mean   std    mean    std count\n",
      "가격대                                    \n",
      "0-30    1.03  1.80    4.99  10.12   331\n",
      "30-50   0.54  0.47    1.36   1.16   360\n",
      "50-70   0.84  0.72    1.38   1.18   274\n",
      "70-100  1.12  1.23    1.33   1.35   310\n",
      "100+    1.79  1.61    1.43   1.32   225\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 최종 모델 성능 ===\n",
      "검증 세트 RMSE: 1.6518\n",
      "\n",
      "=== XGBoost 특성 중요도 ===\n",
      "     feature  importance\n",
      "11    제조사_그룹    0.712315\n",
      "6    보증기간(년)    0.058691\n",
      "0        제조사    0.057657\n",
      "3      배터리용량    0.043326\n",
      "1         모델    0.041562\n",
      "9     제조사_모델    0.039329\n",
      "2       차량상태    0.021289\n",
      "5   주행거리(km)    0.013250\n",
      "4       구동방식    0.011128\n",
      "10  is_ioniq    0.000643\n",
      "12   주행거리_구간    0.000431\n",
      "8      연식(년)    0.000351\n",
      "7       사고이력    0.000027\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "import platform\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "if platform.system() == 'Darwin':  # Mac OS\n",
    "   plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':  # Windows\n",
    "   plt.rc('font', family='Malgun Gothic')\n",
    "   \n",
    "plt.rc('axes', unicode_minus=False)  # 마이너스 기호 깨짐 방지\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "\n",
    "def enhanced_features(df):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # 제조사 그룹화 (국산/수입)\n",
    "   df['제조사_그룹'] = df['제조사'].map({\n",
    "       'H사': '국산', 'K사': '국산',\n",
    "       'B사': '수입', 'P사': '수입', 'V사': '수입'\n",
    "   })\n",
    "   \n",
    "   # 가격 구간화를 위한 임시 컬럼\n",
    "   if '가격(백만원)' in df.columns:\n",
    "       df['가격_구간'] = pd.qcut(df['가격(백만원)'], q=5, labels=['매우저가', '저가', '중가', '고가', '매우고가'])\n",
    "   \n",
    "   # 주행거리 구간화\n",
    "   df['주행거리_구간'] = pd.qcut(df['주행거리(km)'], q=5, labels=['매우낮음', '낮음', '중간', '높음', '매우높음'])\n",
    "   \n",
    "   return df\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_data(df, is_test=False):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # 추가 특성 생성\n",
    "   df = enhanced_features(df)\n",
    "   \n",
    "   # IONIQ 특별 처리\n",
    "   df['is_ioniq'] = (df['모델'] == 'IONIQ').astype(int)\n",
    "   \n",
    "   # 레이블 인코딩\n",
    "   le = LabelEncoder()\n",
    "   categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력', \n",
    "                      '제조사_그룹', '주행거리_구간']\n",
    "   if not is_test and '가격_구간' in df.columns:\n",
    "       categorical_cols.append('가격_구간')\n",
    "   \n",
    "   for col in categorical_cols:\n",
    "       df[col] = le.fit_transform(df[col])\n",
    "   \n",
    "   # 결측치 처리\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'))\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "   \n",
    "   # 제조사-모델 조합\n",
    "   df['제조사_모델'] = df['제조사'].astype(str) + '_' + df['모델'].astype(str)\n",
    "   df['제조사_모델'] = le.fit_transform(df['제조사_모델'])\n",
    "   \n",
    "   return df\n",
    "\n",
    "# 데이터 전처리\n",
    "train_processed = preprocess_data(train)\n",
    "test_processed = preprocess_data(test, is_test=True)\n",
    "\n",
    "# 특성 선택\n",
    "feature_columns = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "                 '보증기간(년)', '사고이력', '연식(년)', '제조사_모델', 'is_ioniq',\n",
    "                 '제조사_그룹', '주행거리_구간']\n",
    "\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['가격(백만원)']\n",
    "\n",
    "# 가격 구간으로 stratify\n",
    "price_bins = pd.qcut(y, q=5, labels=['매우저가', '저가', '중가', '고가', '매우고가'])\n",
    "\n",
    "# 학습 데이터와 검증 데이터 분할 (Stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "   X, y, test_size=0.2, random_state=42, stratify=price_bins\n",
    ")\n",
    "\n",
    "# 모델 파라미터\n",
    "xgb_params = {\n",
    "   'n_estimators': 200,\n",
    "   'max_depth': 5,\n",
    "   'learning_rate': 0.03,\n",
    "   'subsample': 0.8,\n",
    "   'colsample_bytree': 0.8,\n",
    "   'min_child_weight': 5,\n",
    "   'gamma': 0.1,\n",
    "   'reg_alpha': 0.1,\n",
    "   'reg_lambda': 1.0\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "   'n_estimators': 300,\n",
    "   'max_depth': 8,\n",
    "   'min_samples_split': 5,\n",
    "   'min_samples_leaf': 3,\n",
    "   'max_features': 'sqrt'\n",
    "}\n",
    "\n",
    "# IONIQ 모델을 위한 별도의 모델\n",
    "ioniq_mask = train['모델'] == 'IONIQ'\n",
    "X_ioniq = X[ioniq_mask]\n",
    "y_ioniq = y[ioniq_mask]\n",
    "\n",
    "ioniq_model = StackingRegressor(\n",
    "   estimators=[\n",
    "       ('xgb', XGBRegressor(\n",
    "           n_estimators=100,\n",
    "           max_depth=4,\n",
    "           learning_rate=0.01\n",
    "       )),\n",
    "       ('rf', RandomForestRegressor(\n",
    "           n_estimators=200,\n",
    "           max_depth=6\n",
    "       ))\n",
    "   ],\n",
    "   final_estimator=LassoCV(),\n",
    "   cv=5\n",
    ")\n",
    "\n",
    "ioniq_model.fit(X_ioniq, y_ioniq)\n",
    "\n",
    "# 기본 모델\n",
    "base_model = StackingRegressor(\n",
    "   estimators=[\n",
    "       ('xgb', XGBRegressor(**xgb_params)),\n",
    "       ('rf', RandomForestRegressor(**rf_params))\n",
    "   ],\n",
    "   final_estimator=LassoCV(),\n",
    "   cv=10\n",
    ")\n",
    "\n",
    "# 전체 데이터로 학습\n",
    "base_model.fit(X, y)\n",
    "\n",
    "# ... (이전 코드 동일) ...\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "X_test = test_processed[feature_columns]\n",
    "ioniq_mask_test = test['모델'] == 'IONIQ'\n",
    "\n",
    "# 예측값을 저장할 배열 초기화\n",
    "final_prediction = np.zeros(len(test))\n",
    "\n",
    "# IONIQ 모델 예측\n",
    "if ioniq_mask_test.any():\n",
    "    final_prediction[ioniq_mask_test] = ioniq_model.predict(X_test[ioniq_mask_test])\n",
    "\n",
    "# 나머지 모델 예측\n",
    "if (~ioniq_mask_test).any():\n",
    "    final_prediction[~ioniq_mask_test] = base_model.predict(X_test[~ioniq_mask_test])\n",
    "\n",
    "# 검증 세트에서의 모델별 성능 분석\n",
    "val_predictions = np.zeros(len(X_val))\n",
    "ioniq_mask_val = train.iloc[X_val.index]['모델'] == 'IONIQ'\n",
    "\n",
    "# 검증 세트 IONIQ 모델 예측\n",
    "if ioniq_mask_val.any():\n",
    "    val_predictions[ioniq_mask_val] = ioniq_model.predict(X_val[ioniq_mask_val])\n",
    "\n",
    "# 검증 세트 나머지 모델 예측\n",
    "if (~ioniq_mask_val).any():\n",
    "    val_predictions[~ioniq_mask_val] = base_model.predict(X_val[~ioniq_mask_val])\n",
    "\n",
    "# ... (이후 코드 동일) ...\n",
    "\n",
    "\n",
    "val_analysis = pd.DataFrame({\n",
    "   '모델': train.iloc[X_val.index]['모델'],\n",
    "   '실제가격': y_val,\n",
    "   '예측가격': val_predictions,\n",
    "   '오차': np.abs(y_val - val_predictions),\n",
    "   '상대오차(%)': np.abs((y_val - val_predictions) / y_val) * 100\n",
    "})\n",
    "\n",
    "# 모델별 평균 성능\n",
    "model_performance = pd.DataFrame()\n",
    "model_performance = val_analysis.groupby('모델').agg({\n",
    "   '실제가격': 'mean',\n",
    "   '예측가격': 'mean',\n",
    "   '오차': ['mean', 'std'],\n",
    "   '상대오차(%)': ['mean', 'std'],\n",
    "}).round(2)\n",
    "\n",
    "# 데이터 수 추가\n",
    "model_counts = val_analysis['모델'].value_counts()\n",
    "model_performance['데이터수'] = model_counts\n",
    "\n",
    "# MultiIndex 컬럼을 단일 레벨로 변경\n",
    "model_performance.columns = pd.Index([\n",
    "   '평균실제가격', '평균예측가격',\n",
    "   '평균오차', '오차표준편차',\n",
    "   '평균상대오차(%)', '상대오차표준편차(%)',\n",
    "   '데이터수'\n",
    "])\n",
    "\n",
    "# 평균 상대오차로 정렬\n",
    "model_performance = model_performance.sort_values('평균상대오차(%)', ascending=False)\n",
    "\n",
    "print(\"\\n=== 모델별 예측 성능 분석 ===\")\n",
    "print(model_performance)\n",
    "\n",
    "# 가장 오차가 큰 상위 20개 케이스\n",
    "print(\"\\n=== 오차가 가장 큰 상위 20개 케이스 ===\")\n",
    "worst_predictions = val_analysis.nlargest(20, '오차')\n",
    "print(worst_predictions.round(2))\n",
    "\n",
    "# 각 가격대별 성능\n",
    "val_analysis['가격대'] = pd.cut(val_analysis['실제가격'], \n",
    "                           bins=[0, 30, 50, 70, 100, float('inf')],\n",
    "                           labels=['0-30', '30-50', '50-70', '70-100', '100+'])\n",
    "\n",
    "price_range_performance = val_analysis.groupby('가격대').agg({\n",
    "   '오차': ['mean', 'std'],\n",
    "   '상대오차(%)': ['mean', 'std'],\n",
    "   '실제가격': 'count'\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\n=== 가격대별 예측 성능 ===\")\n",
    "print(price_range_performance)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 실제가격 vs 예측가격 산점도\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(val_analysis['실제가격'], val_analysis['예측가격'], alpha=0.5)\n",
    "plt.plot([val_analysis['실제가격'].min(), val_analysis['실제가격'].max()], \n",
    "        [val_analysis['실제가격'].min(), val_analysis['실제가격'].max()], \n",
    "        'r--')\n",
    "plt.xlabel('실제가격')\n",
    "plt.ylabel('예측가격')\n",
    "plt.title('실제가격 vs 예측가격')\n",
    "\n",
    "# 모델별 평균 상대오차 막대 그래프\n",
    "plt.subplot(1, 2, 2)\n",
    "model_performance['평균상대오차(%)'].plot(kind='bar')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('모델별 평균 상대오차')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최종 모델 성능\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "print(f\"\\n=== 최종 모델 성능 ===\")\n",
    "print(f\"검증 세트 RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "# 특성 중요도 출력\n",
    "print(\"\\n=== XGBoost 특성 중요도 ===\")\n",
    "xgb_importance = pd.DataFrame({\n",
    "   'feature': feature_columns,\n",
    "   'importance': base_model.named_estimators_['xgb'].feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "print(xgb_importance)\n",
    "\n",
    "# 결과 저장\n",
    "submission = pd.DataFrame({\n",
    "   'ID': test['ID'],\n",
    "   '가격(백만원)': final_prediction\n",
    "})\n",
    "submission.to_csv('submission6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "저가 세그먼트 학습: 1917 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 1917, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 31.053490\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "중가 세그먼트 학습: 2313 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 341\n",
      "[LightGBM] [Info] Number of data points in the train set: 2313, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 57.158945\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "고가 세그먼트 학습: 1767 샘플\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 331\n",
      "[LightGBM] [Info] Number of data points in the train set: 1767, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 102.662185\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Fold 1 RMSE: 1.4356\n",
      "\n",
      "Fold 2/5\n",
      "저가 세그먼트 학습: 1909 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 338\n",
      "[LightGBM] [Info] Number of data points in the train set: 1909, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 31.118512\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "중가 세그먼트 학습: 2330 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 2330, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 57.754176\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "고가 세그먼트 학습: 1758 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 331\n",
      "[LightGBM] [Info] Number of data points in the train set: 1758, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 102.442236\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Fold 2 RMSE: 1.5959\n",
      "\n",
      "Fold 3/5\n",
      "저가 세그먼트 학습: 1920 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 341\n",
      "[LightGBM] [Info] Number of data points in the train set: 1920, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 31.072458\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "중가 세그먼트 학습: 2297 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 341\n",
      "[LightGBM] [Info] Number of data points in the train set: 2297, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 57.430148\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "고가 세그먼트 학습: 1781 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 331\n",
      "[LightGBM] [Info] Number of data points in the train set: 1781, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 102.313728\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Fold 3 RMSE: 1.3915\n",
      "\n",
      "Fold 4/5\n",
      "저가 세그먼트 학습: 1906 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 339\n",
      "[LightGBM] [Info] Number of data points in the train set: 1906, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 31.073730\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "중가 세그먼트 학습: 2311 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 341\n",
      "[LightGBM] [Info] Number of data points in the train set: 2311, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 57.447849\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "고가 세그먼트 학습: 1781 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 331\n",
      "[LightGBM] [Info] Number of data points in the train set: 1781, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 102.617827\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Fold 4 RMSE: 1.2941\n",
      "\n",
      "Fold 5/5\n",
      "저가 세그먼트 학습: 1952 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 340\n",
      "[LightGBM] [Info] Number of data points in the train set: 1952, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 30.954616\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "중가 세그먼트 학습: 2281 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 341\n",
      "[LightGBM] [Info] Number of data points in the train set: 2281, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 57.376703\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "고가 세그먼트 학습: 1765 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 332\n",
      "[LightGBM] [Info] Number of data points in the train set: 1765, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 103.203881\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Fold 5 RMSE: 1.3877\n",
      "\n",
      "평균 교차 검증 RMSE: 1.4210 (+/- 0.0989)\n",
      "저가 세그먼트 학습: 2401 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 348\n",
      "[LightGBM] [Info] Number of data points in the train set: 2401, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 31.054127\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "중가 세그먼트 학습: 2883 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 341\n",
      "[LightGBM] [Info] Number of data points in the train set: 2883, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 57.434197\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "고가 세그먼트 학습: 2213 샘플\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 332\n",
      "[LightGBM] [Info] Number of data points in the train set: 2213, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 102.647479\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "=== 세그먼트별 통계 ===\n",
      "         가격(백만원)                              \n",
      "           count    mean    std    min     max\n",
      "제조사_세그먼트                                      \n",
      "고가          2213  102.65  34.54  52.01  161.09\n",
      "저가          2401   31.05   8.55   9.00   49.08\n",
      "중가          2883   57.43  20.73  21.72   94.75\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "import platform\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "if platform.system() == 'Darwin':  # Mac OS\n",
    "   plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':  # Windows\n",
    "   plt.rc('font', family='Malgun Gothic')\n",
    "   \n",
    "plt.rc('axes', unicode_minus=False)  # 마이너스 기호 깨짐 방지\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "\n",
    "# 제조사별 평균 가격 계산\n",
    "manufacturer_values = train.groupby('제조사')['가격(백만원)'].mean()\n",
    "segment_bounds = np.percentile(manufacturer_values, [33, 67])\n",
    "\n",
    "# 세그먼트 분류 함수\n",
    "def classify_segment(x):\n",
    "   if manufacturer_values[x] > segment_bounds[1]:\n",
    "       return '고가'\n",
    "   elif manufacturer_values[x] > segment_bounds[0]:\n",
    "       return '중가'\n",
    "   else:\n",
    "       return '저가'\n",
    "\n",
    "# 세그먼트 추가\n",
    "train['제조사_세그먼트'] = train['제조사'].map(classify_segment)\n",
    "test['제조사_세그먼트'] = test['제조사'].map(classify_segment)\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_data(df):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # 레이블 인코딩\n",
    "   le = LabelEncoder()\n",
    "   categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력', '제조사_세그먼트']\n",
    "   \n",
    "   for col in categorical_cols:\n",
    "       df[col] = le.fit_transform(df[col])\n",
    "   \n",
    "   # 결측치 처리\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'))\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "   \n",
    "   # 제조사-모델 조합\n",
    "   df['제조사_모델'] = df['제조사'].astype(str) + '_' + df['모델'].astype(str)\n",
    "   df['제조사_모델'] = le.fit_transform(df['제조사_모델'])\n",
    "   \n",
    "   return df\n",
    "\n",
    "def build_segment_models():\n",
    "   # 기본 모델들\n",
    "   models = {\n",
    "       'xgb': XGBRegressor(\n",
    "           n_estimators=200,\n",
    "           max_depth=5,\n",
    "           learning_rate=0.03,\n",
    "           subsample=0.8,\n",
    "           colsample_bytree=0.8,\n",
    "           min_child_weight=5,\n",
    "           gamma=0.1,\n",
    "           reg_alpha=0.1,\n",
    "           reg_lambda=1.0\n",
    "       ),\n",
    "       'rf': RandomForestRegressor(\n",
    "           n_estimators=300,\n",
    "           max_depth=8,\n",
    "           min_samples_split=5,\n",
    "           min_samples_leaf=3,\n",
    "           max_features='sqrt'\n",
    "       ),\n",
    "       'lgb': LGBMRegressor(\n",
    "           n_estimators=200,\n",
    "           num_leaves=31,\n",
    "           learning_rate=0.03,\n",
    "           max_depth=6,\n",
    "           reg_alpha=0.1,\n",
    "           reg_lambda=1.0\n",
    "       )\n",
    "   }\n",
    "   \n",
    "   # 세그먼트별 모델\n",
    "   segment_models = {}\n",
    "   for segment in ['저가', '중가', '고가']:\n",
    "       segment_models[segment] = VotingRegressor(\n",
    "           estimators=[\n",
    "               ('xgb', clone(models['xgb'])),\n",
    "               ('rf', clone(models['rf'])),\n",
    "               ('lgb', clone(models['lgb']))\n",
    "           ]\n",
    "       )\n",
    "   \n",
    "   return segment_models\n",
    "\n",
    "# 모델 학습 및 예측 함수\n",
    "def train_and_predict(X_train, y_train, X_test, segments_train, segments_test):\n",
    "   segment_models = build_segment_models()\n",
    "   predictions = np.zeros(len(X_test))\n",
    "   \n",
    "   for segment in ['저가', '중가', '고가']:\n",
    "       mask_train = segments_train == segment\n",
    "       mask_test = segments_test == segment\n",
    "       \n",
    "       if mask_train.any():\n",
    "           print(f\"{segment} 세그먼트 학습: {sum(mask_train)} 샘플\")\n",
    "           segment_models[segment].fit(X_train[mask_train], y_train[mask_train])\n",
    "           \n",
    "           if mask_test.any():\n",
    "               predictions[mask_test] = segment_models[segment].predict(X_test[mask_test])\n",
    "   \n",
    "   return predictions, segment_models\n",
    "\n",
    "# 데이터 전처리\n",
    "train_processed = preprocess_data(train)\n",
    "test_processed = preprocess_data(test)\n",
    "\n",
    "# 특성 선택\n",
    "feature_columns = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "                 '보증기간(년)', '사고이력', '연식(년)', '제조사_모델', '제조사_세그먼트']\n",
    "\n",
    "X = train_processed[feature_columns]\n",
    "y = train_processed['가격(백만원)']\n",
    "\n",
    "# 교차 검증\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "cv_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "   X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "   y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "   segments_train = train['제조사_세그먼트'].iloc[train_idx]\n",
    "   segments_val = train['제조사_세그먼트'].iloc[val_idx]\n",
    "   \n",
    "   print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "   val_pred, _ = train_and_predict(\n",
    "       X_train, y_train, X_val,\n",
    "       segments_train, segments_val\n",
    "   )\n",
    "   \n",
    "   fold_score = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "   cv_scores.append(fold_score)\n",
    "   print(f\"Fold {fold + 1} RMSE: {fold_score:.4f}\")\n",
    "\n",
    "print(f\"\\n평균 교차 검증 RMSE: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\n",
    "\n",
    "# 최종 모델 학습 및 예측\n",
    "final_predictions, final_models = train_and_predict(\n",
    "   X, y, test_processed[feature_columns],\n",
    "   train['제조사_세그먼트'], test['제조사_세그먼트']\n",
    ")\n",
    "\n",
    "# 세그먼트별 통계\n",
    "segment_stats = train.groupby('제조사_세그먼트').agg({\n",
    "   '가격(백만원)': ['count', 'mean', 'std', 'min', 'max']\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\n=== 세그먼트별 통계 ===\")\n",
    "print(segment_stats)\n",
    "\n",
    "# 결과 저장\n",
    "submission = pd.DataFrame({\n",
    "   'ID': test['ID'],\n",
    "   '가격(백만원)': final_predictions\n",
    "})\n",
    "submission.to_csv('submission7.csv', index=False)\n",
    "\n",
    "# 세그먼트별 분포 시각화\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=train, x='제조사_세그먼트', y='가격(백만원)')\n",
    "plt.title('세그먼트별 가격 분포')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "train['제조사_세그먼트'].value_counts().plot(kind='bar')\n",
    "plt.title('세그먼트별 데이터 수')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 초저가 세그먼트 ===\n",
      "\n",
      "XGBoost 그리드서치:\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "Best parameters: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Best RMSE: 1.7368\n",
      "\n",
      "RandomForest 그리드서치:\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Best RMSE: 1.7718\n",
      "\n",
      "LightGBM 그리드서치:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 334\n",
      "[LightGBM] [Info] Number of data points in the train set: 1688, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 24.034627\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters: {'learning_rate': 0.01, 'max_depth': 5, 'min_child_samples': 20, 'n_estimators': 300, 'num_leaves': 31}\n",
      "Best RMSE: 1.7201\n",
      "\n",
      "=== 저가 세그먼트 ===\n",
      "\n",
      "XGBoost 그리드서치:\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Best RMSE: 0.5109\n",
      "\n",
      "RandomForest 그리드서치:\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Best RMSE: 0.5333\n",
      "\n",
      "LightGBM 그리드서치:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 310\n",
      "[LightGBM] [Info] Number of data points in the train set: 1778, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 39.234134\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_samples': 30, 'n_estimators': 300, 'num_leaves': 31}\n",
      "Best RMSE: 0.5165\n",
      "\n",
      "=== 중가 세그먼트 ===\n",
      "\n",
      "XGBoost 그리드서치:\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "Best parameters: {'colsample_bytree': 0.9, 'gamma': 0, 'learning_rate': 0.03, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Best RMSE: 0.4990\n",
      "\n",
      "RandomForest 그리드서치:\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best RMSE: 0.5243\n",
      "\n",
      "LightGBM 그리드서치:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 320\n",
      "[LightGBM] [Info] Number of data points in the train set: 1392, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 60.637170\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 10, 'min_child_samples': 30, 'n_estimators': 300, 'num_leaves': 31}\n",
      "Best RMSE: 0.5301\n",
      "\n",
      "=== 고가 세그먼트 ===\n",
      "\n",
      "XGBoost 그리드서치:\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'gamma': 0.1, 'learning_rate': 0.03, 'max_depth': 6, 'min_child_weight': 5, 'n_estimators': 200, 'subsample': 1.0}\n",
      "Best RMSE: 0.5355\n",
      "\n",
      "RandomForest 그리드서치:\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Best RMSE: 0.5724\n",
      "\n",
      "LightGBM 그리드서치:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 320\n",
      "[LightGBM] [Info] Number of data points in the train set: 1473, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 82.357828\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_samples': 20, 'n_estimators': 300, 'num_leaves': 31}\n",
      "Best RMSE: 0.5526\n",
      "\n",
      "=== 프리미엄 세그먼트 ===\n",
      "\n",
      "XGBoost 그리드서치:\n",
      "Fitting 5 folds for each of 1458 candidates, totalling 7290 fits\n",
      "Best parameters: {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Best RMSE: 1.9932\n",
      "\n",
      "RandomForest 그리드서치:\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Best RMSE: 2.1247\n",
      "\n",
      "LightGBM 그리드서치:\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 299\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 129.720292\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_samples': 20, 'n_estimators': 100, 'num_leaves': 31}\n",
      "Best RMSE: 2.0719\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "\n",
    "# 전처리 함수\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 레이블 인코딩\n",
    "    le = LabelEncoder()\n",
    "    categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    # 결측치 처리\n",
    "    df['배터리용량'] = df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'))\n",
    "    df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 가격 세그먼트 정의\n",
    "def get_price_segment(price):\n",
    "    if price < 30:\n",
    "        return '초저가'\n",
    "    elif price < 50:\n",
    "        return '저가'\n",
    "    elif price < 70:\n",
    "        return '중가'\n",
    "    elif price < 100:\n",
    "        return '고가'\n",
    "    else:\n",
    "        return '프리미엄'\n",
    "\n",
    "# 그리드서치 파라미터 정의\n",
    "param_grid = {\n",
    "    'xgb': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [4, 5, 6],\n",
    "        'learning_rate': [0.01, 0.03, 0.05],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "        'gamma': [0, 0.1]\n",
    "    },\n",
    "    'rf': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'lgb': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'num_leaves': [31, 63],\n",
    "        'max_depth': [-1, 5, 10],\n",
    "        'learning_rate': [0.01, 0.03, 0.05],\n",
    "        'min_child_samples': [20, 30]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 그리드서치 수행\n",
    "def perform_grid_search(X, y, model_type='xgb', param_grid=None):\n",
    "    if model_type == 'xgb':\n",
    "        model = XGBRegressor(random_state=42)\n",
    "        params = param_grid['xgb']\n",
    "    elif model_type == 'rf':\n",
    "        model = RandomForestRegressor(random_state=42)\n",
    "        params = param_grid['rf']\n",
    "    else:  # lgb\n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        params = param_grid['lgb']\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=params,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_, grid_search.best_score_\n",
    "\n",
    "# 데이터 전처리\n",
    "train_processed = preprocess_data(train)\n",
    "test_processed = preprocess_data(test)\n",
    "\n",
    "# 가격 세그먼트 추가\n",
    "train_processed['가격_세그먼트'] = train_processed['가격(백만원)'].apply(get_price_segment)\n",
    "\n",
    "# 특성 선택\n",
    "feature_columns = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "                  '보증기간(년)', '사고이력', '연식(년)']\n",
    "\n",
    "# 세그먼트별 그리드서치\n",
    "for segment in ['초저가', '저가', '중가', '고가', '프리미엄']:\n",
    "    print(f\"\\n=== {segment} 세그먼트 ===\")\n",
    "    segment_data = train_processed[train_processed['가격_세그먼트'] == segment]\n",
    "    \n",
    "    if len(segment_data) > 0:  # 데이터가 있는 경우에만 수행\n",
    "        X = segment_data[feature_columns]\n",
    "        y = segment_data['가격(백만원)']\n",
    "        \n",
    "        print(\"\\nXGBoost 그리드서치:\")\n",
    "        best_params, best_score = perform_grid_search(X, y, 'xgb', param_grid)\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best RMSE: {-best_score:.4f}\")\n",
    "        \n",
    "        print(\"\\nRandomForest 그리드서치:\")\n",
    "        best_params, best_score = perform_grid_search(X, y, 'rf', param_grid)\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best RMSE: {-best_score:.4f}\")\n",
    "        \n",
    "        print(\"\\nLightGBM 그리드서치:\")\n",
    "        best_params, best_score = perform_grid_search(X, y, 'lgb', param_grid)\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "        print(f\"Best RMSE: {-best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 1.2869, R2: 0.8638\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4697, R2: 0.9868\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4368, R2: 0.9912\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4494, R2: 0.9974\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.7161, R2: 0.9938\n",
      "\n",
      "Fold 1 검증 성능:\n",
      "RMSE: 1.2494\n",
      "R2 Score: 0.9989\n",
      "MAE: 0.6278\n",
      "\n",
      "Fold 2/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 1.3251, R2: 0.8575\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4655, R2: 0.9872\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4465, R2: 0.9905\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4537, R2: 0.9974\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.5988, R2: 0.9948\n",
      "\n",
      "Fold 2 검증 성능:\n",
      "RMSE: 1.3170\n",
      "R2 Score: 0.9987\n",
      "MAE: 0.6657\n",
      "\n",
      "Fold 3/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 1.2755, R2: 0.8659\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4591, R2: 0.9883\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4425, R2: 0.9907\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4476, R2: 0.9974\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.7441, R2: 0.9935\n",
      "\n",
      "Fold 3 검증 성능:\n",
      "RMSE: 1.2366\n",
      "R2 Score: 0.9989\n",
      "MAE: 0.6185\n",
      "\n",
      "Fold 4/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 1.3741, R2: 0.8459\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4609, R2: 0.9879\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4406, R2: 0.9909\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4481, R2: 0.9974\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.6983, R2: 0.9940\n",
      "\n",
      "Fold 4 검증 성능:\n",
      "RMSE: 1.1579\n",
      "R2 Score: 0.9990\n",
      "MAE: 0.6128\n",
      "\n",
      "Fold 5/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 1.3563, R2: 0.8557\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4598, R2: 0.9873\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4408, R2: 0.9909\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4613, R2: 0.9972\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.7021, R2: 0.9940\n",
      "\n",
      "Fold 5 검증 성능:\n",
      "RMSE: 1.1309\n",
      "R2 Score: 0.9990\n",
      "MAE: 0.6157\n",
      "\n",
      "=== 평균 교차 검증 성능 ===\n",
      "RMSE: 1.2184 (+/- 0.0668)\n",
      "R2 Score: 0.9989 (+/- 0.0001)\n",
      "MAE: 0.6281 (+/- 0.0195)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "import platform\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "if platform.system() == 'Darwin':  # Mac OS\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':  # Windows\n",
    "    plt.rc('font', family='Malgun Gothic')\n",
    "    \n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "def get_price_segment(price):\n",
    "    if price < 30:\n",
    "        return '초저가'\n",
    "    elif price < 50:\n",
    "        return '저가'\n",
    "    elif price < 70:\n",
    "        return '중가'\n",
    "    elif price < 100:\n",
    "        return '고가'\n",
    "    else:\n",
    "        return '프리미엄'\n",
    "\n",
    "def init_segment_models():\n",
    "    models = {\n",
    "        '초저가': XGBRegressor(\n",
    "            n_estimators=300, learning_rate=0.01, max_depth=4,\n",
    "            min_child_weight=1, subsample=0.8, colsample_bytree=0.8,\n",
    "            gamma=0, random_state=42\n",
    "        ),\n",
    "        '저가': XGBRegressor(\n",
    "            n_estimators=100, learning_rate=0.05, max_depth=5,\n",
    "            min_child_weight=3, subsample=1.0, colsample_bytree=1.0,\n",
    "            gamma=0.1, random_state=42\n",
    "        ),\n",
    "        '중가': XGBRegressor(\n",
    "            n_estimators=200, learning_rate=0.03, max_depth=5,\n",
    "            min_child_weight=5, subsample=0.9, colsample_bytree=0.9,\n",
    "            gamma=0, random_state=42\n",
    "        ),\n",
    "        '고가': XGBRegressor(\n",
    "            n_estimators=200, learning_rate=0.03, max_depth=6,\n",
    "            min_child_weight=5, subsample=1.0, colsample_bytree=1.0,\n",
    "            gamma=0.1, random_state=42\n",
    "        ),\n",
    "        '프리미엄': XGBRegressor(\n",
    "            n_estimators=100, learning_rate=0.05, max_depth=5,\n",
    "            min_child_weight=5, subsample=0.8, colsample_bytree=1.0,\n",
    "            gamma=0, random_state=42\n",
    "        )\n",
    "    }\n",
    "    return models\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 레이블 인코딩\n",
    "    le = LabelEncoder()\n",
    "    categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    # 결측치 처리\n",
    "    df['배터리용량'] = df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'))\n",
    "    df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    train_processed = preprocess_data(train)\n",
    "    test_processed = preprocess_data(test)\n",
    "\n",
    "    # 특성 선택\n",
    "    feature_columns = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "                      '보증기간(년)', '사고이력', '연식(년)']\n",
    "\n",
    "    # 학습 데이터 세그먼트 추가\n",
    "    train_processed['가격_세그먼트'] = train_processed['가격(백만원)'].apply(get_price_segment)\n",
    "\n",
    "    # 세그먼트별 모델 초기화\n",
    "    segment_models = init_segment_models()\n",
    "    \n",
    "    # 교차 검증\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    cv_scores = {\n",
    "        'rmse': [],\n",
    "        'r2': [],\n",
    "        'mae': []\n",
    "    }\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_processed)):\n",
    "        print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "        \n",
    "        train_fold = train_processed.iloc[train_idx]\n",
    "        val_fold = train_processed.iloc[val_idx]\n",
    "        \n",
    "        # 세그먼트별 학습\n",
    "        for segment in segment_models.keys():\n",
    "            segment_train = train_fold[train_fold['가격_세그먼트'] == segment]\n",
    "            if len(segment_train) > 0:\n",
    "                X_train = segment_train[feature_columns]\n",
    "                y_train = segment_train['가격(백만원)']\n",
    "                segment_models[segment].fit(X_train, y_train)\n",
    "                \n",
    "                # 훈련 성능 평가\n",
    "                train_pred = segment_models[segment].predict(X_train)\n",
    "                train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "                train_r2 = r2_score(y_train, train_pred)\n",
    "                print(f\"\\n{segment} 세그먼트 훈련 성능:\")\n",
    "                print(f\"RMSE: {train_rmse:.4f}, R2: {train_r2:.4f}\")\n",
    "        \n",
    "        # 검증 세트 예측\n",
    "        val_predictions = np.zeros(len(val_fold))\n",
    "        for i, row in val_fold.iterrows():\n",
    "            # 실제 세그먼트의 모델로 예측\n",
    "            actual_segment = get_price_segment(row['가격(백만원)'])\n",
    "            val_predictions[val_fold.index.get_loc(i)] = segment_models[actual_segment].predict(\n",
    "                row[feature_columns].values.reshape(1, -1)\n",
    "            )[0]\n",
    "        \n",
    "        # 검증 성능 평가\n",
    "        val_rmse = np.sqrt(mean_squared_error(val_fold['가격(백만원)'], val_predictions))\n",
    "        val_r2 = r2_score(val_fold['가격(백만원)'], val_predictions)\n",
    "        val_mae = mean_absolute_error(val_fold['가격(백만원)'], val_predictions)\n",
    "        \n",
    "        print(f\"\\nFold {fold + 1} 검증 성능:\")\n",
    "        print(f\"RMSE: {val_rmse:.4f}\")\n",
    "        print(f\"R2 Score: {val_r2:.4f}\")\n",
    "        print(f\"MAE: {val_mae:.4f}\")\n",
    "        \n",
    "        cv_scores['rmse'].append(val_rmse)\n",
    "        cv_scores['r2'].append(val_r2)\n",
    "        cv_scores['mae'].append(val_mae)\n",
    "\n",
    "    # 평균 교차 검증 성능\n",
    "    print(\"\\n=== 평균 교차 검증 성능 ===\")\n",
    "    print(f\"RMSE: {np.mean(cv_scores['rmse']):.4f} (+/- {np.std(cv_scores['rmse']):.4f})\")\n",
    "    print(f\"R2 Score: {np.mean(cv_scores['r2']):.4f} (+/- {np.std(cv_scores['r2']):.4f})\")\n",
    "    print(f\"MAE: {np.mean(cv_scores['mae']):.4f} (+/- {np.std(cv_scores['mae']):.4f})\")\n",
    "\n",
    "    # 최종 모델 학습\n",
    "    final_predictions = np.zeros(len(test_processed))\n",
    "    \n",
    "    # 각 세그먼트별로 예측 수행\n",
    "    for segment in segment_models.keys():\n",
    "        # 해당 세그먼트의 가격 범위\n",
    "        if segment == '초저가':\n",
    "            price_range = (0, 30)\n",
    "        elif segment == '저가':\n",
    "            price_range = (30, 50)\n",
    "        elif segment == '중가':\n",
    "            price_range = (50, 70)\n",
    "        elif segment == '고가':\n",
    "            price_range = (70, 100)\n",
    "        else:  # 프리미엄\n",
    "            price_range = (100, float('inf'))\n",
    "        \n",
    "        # 해당 세그먼트 모델로 전체 예측\n",
    "        segment_predictions = segment_models[segment].predict(test_processed[feature_columns])\n",
    "        \n",
    "        # 가격 범위에 맞는 예측값만 사용\n",
    "        mask = (segment_predictions >= price_range[0]) & (segment_predictions < price_range[1])\n",
    "        final_predictions = np.where(mask, segment_predictions, final_predictions)\n",
    "\n",
    "    # 결과 저장\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': final_predictions\n",
    "    })\n",
    "    submission.to_csv('submission8.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 1.0080, R2: 0.9164\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4684, R2: 0.9869\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4331, R2: 0.9914\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4460, R2: 0.9975\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.4444, R2: 0.9956\n",
      "\n",
      "Fold 1 검증 성능:\n",
      "RMSE: 1.2988\n",
      "R2 Score: 0.9988\n",
      "MAE: 0.6310\n",
      "\n",
      "Fold 2/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 1.0220, R2: 0.9153\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4642, R2: 0.9873\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4410, R2: 0.9907\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4503, R2: 0.9974\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.3234, R2: 0.9964\n",
      "\n",
      "Fold 2 검증 성능:\n",
      "RMSE: 1.3678\n",
      "R2 Score: 0.9987\n",
      "MAE: 0.6631\n",
      "\n",
      "Fold 3/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.9597, R2: 0.9241\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4591, R2: 0.9883\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4392, R2: 0.9908\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4418, R2: 0.9975\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.4612, R2: 0.9954\n",
      "\n",
      "Fold 3 검증 성능:\n",
      "RMSE: 1.2718\n",
      "R2 Score: 0.9988\n",
      "MAE: 0.6201\n",
      "\n",
      "Fold 4/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 1.0645, R2: 0.9075\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4597, R2: 0.9879\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4366, R2: 0.9910\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4477, R2: 0.9974\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.4342, R2: 0.9957\n",
      "\n",
      "Fold 4 검증 성능:\n",
      "RMSE: 1.2185\n",
      "R2 Score: 0.9989\n",
      "MAE: 0.6091\n",
      "\n",
      "Fold 5/5\n",
      "\n",
      "초저가 세그먼트 훈련 성능:\n",
      "RMSE: 1.0496, R2: 0.9136\n",
      "\n",
      "저가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4588, R2: 0.9873\n",
      "\n",
      "중가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4396, R2: 0.9909\n",
      "\n",
      "고가 세그먼트 훈련 성능:\n",
      "RMSE: 0.4577, R2: 0.9972\n",
      "\n",
      "프리미엄 세그먼트 훈련 성능:\n",
      "RMSE: 1.4271, R2: 0.9957\n",
      "\n",
      "Fold 5 검증 성능:\n",
      "RMSE: 1.1574\n",
      "R2 Score: 0.9989\n",
      "MAE: 0.6163\n",
      "\n",
      "=== 평균 교차 검증 성능 ===\n",
      "RMSE: 1.2629 (+/- 0.0714)\n",
      "R2 Score: 0.9988 (+/- 0.0001)\n",
      "MAE: 0.6279 (+/- 0.0190)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor ##category boost도 앙상블 모델에 포함\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 설정\n",
    "import platform\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "if platform.system() == 'Darwin':  # Mac OS\n",
    "   plt.rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':  # Windows\n",
    "   plt.rc('font', family='Malgun Gothic')\n",
    "   \n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "def get_price_segment(price): ###세그먼트 분류 수정필요, 가격대로 분류할 경우 평균가는 분류가 될 수 있으나 브랜드와 모델별 중요도는 무시함. 해결 방법)세그먼트를 6개로 분류. [ioniq, i3], [저가], [중저가], [중고가] [tayct, tay], [고가]\n",
    "   if price < 30:\n",
    "       return '초저가'\n",
    "   elif price < 50:\n",
    "       return '저가'\n",
    "   elif price < 70:\n",
    "       return '중가'\n",
    "   elif price < 100:\n",
    "       return '고가'\n",
    "   else:\n",
    "       return '프리미엄'\n",
    "\n",
    "def init_segment_models():\n",
    "   models = {\n",
    "       '초저가': XGBRegressor(\n",
    "           n_estimators=400,\n",
    "           learning_rate=0.01,\n",
    "           max_depth=5,\n",
    "           min_child_weight=3,\n",
    "           subsample=0.9,\n",
    "           colsample_bytree=0.9,\n",
    "           gamma=0.1,\n",
    "           reg_alpha=0.1,\n",
    "           reg_lambda=1.0,\n",
    "           random_state=42\n",
    "       ),\n",
    "       '저가': XGBRegressor(\n",
    "           n_estimators=100,\n",
    "           learning_rate=0.05,\n",
    "           max_depth=5,\n",
    "           min_child_weight=3,\n",
    "           subsample=1.0,\n",
    "           colsample_bytree=1.0,\n",
    "           gamma=0.1,\n",
    "           reg_alpha=0.1,\n",
    "           reg_lambda=1.0,\n",
    "           random_state=42\n",
    "       ),\n",
    "       '중가': XGBRegressor(\n",
    "           n_estimators=200,\n",
    "           learning_rate=0.03,\n",
    "           max_depth=5,\n",
    "           min_child_weight=5,\n",
    "           subsample=0.9,\n",
    "           colsample_bytree=0.9,\n",
    "           gamma=0,\n",
    "           reg_alpha=0.1,\n",
    "           reg_lambda=1.0,\n",
    "           random_state=42\n",
    "       ),\n",
    "       '고가': XGBRegressor(\n",
    "           n_estimators=200,\n",
    "           learning_rate=0.03,\n",
    "           max_depth=6,\n",
    "           min_child_weight=5,\n",
    "           subsample=1.0,\n",
    "           colsample_bytree=1.0,\n",
    "           gamma=0.1,\n",
    "           reg_alpha=0.1,\n",
    "           reg_lambda=1.0,\n",
    "           random_state=42\n",
    "       ),\n",
    "       '프리미엄': XGBRegressor(\n",
    "           n_estimators=300,\n",
    "           learning_rate=0.03,\n",
    "           max_depth=6,\n",
    "           min_child_weight=7,\n",
    "           subsample=0.8,\n",
    "           colsample_bytree=0.8,\n",
    "           gamma=0.2,\n",
    "           reg_alpha=0.2,\n",
    "           reg_lambda=1.0,\n",
    "           random_state=42\n",
    "       )\n",
    "   }\n",
    "   return models\n",
    "\n",
    "def add_features(df):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # 가격대별 특화 피처\n",
    "   df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "   df['차량연식'] = 2024 - df['연식(년)'] ###차량 연식을 계산할 수 있으면 연식 별 보조금 책정 고려###\n",
    "   df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "   \n",
    "   # 배터리 관련 추가 피처\n",
    "   df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "   \n",
    "   # 보증기간 관련 피처\n",
    "   df['잔여보증기간'] = df['보증기간(년)'] - df['차량연식']\n",
    "   df['잔여보증기간'] = df['잔여보증기간'].clip(lower=0)\n",
    "   \n",
    "   return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # 레이블 인코딩\n",
    "   le = LabelEncoder()\n",
    "   categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력']\n",
    "   \n",
    "   for col in categorical_cols:\n",
    "       df[col] = le.fit_transform(df[col])\n",
    "   \n",
    "   # 결측치 처리 ###결측치 처리는 어떻게? \n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df.groupby('모델')['배터리용량'].transform('mean'))\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "   \n",
    "   # 특성 추가\n",
    "   df = add_features(df)\n",
    "   \n",
    "   return df\n",
    "\n",
    "def main():\n",
    "   # 데이터 로드\n",
    "   train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "   test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "   \n",
    "   # 데이터 전처리\n",
    "   train_processed = preprocess_data(train)\n",
    "   test_processed = preprocess_data(test)\n",
    "\n",
    "   # 특성 선택\n",
    "   feature_columns = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "                     '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "                     'km_per_year', '배터리_연식_효율', '잔여보증기간']\n",
    "\n",
    "   # 학습 데이터 세그먼트 추가\n",
    "   train_processed['가격_세그먼트'] = train_processed['가격(백만원)'].apply(get_price_segment)\n",
    "\n",
    "   # 세그먼트별 모델 초기화\n",
    "   segment_models = init_segment_models()\n",
    "   \n",
    "   # 교차 검증\n",
    "   n_splits = 5\n",
    "   kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "   cv_scores = {\n",
    "       'rmse': [],\n",
    "       'r2': [],\n",
    "       'mae': []\n",
    "   }\n",
    "\n",
    "   for fold, (train_idx, val_idx) in enumerate(kf.split(train_processed)):\n",
    "       print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
    "       \n",
    "       train_fold = train_processed.iloc[train_idx]\n",
    "       val_fold = train_processed.iloc[val_idx]\n",
    "       \n",
    "       # 세그먼트별 학습\n",
    "       for segment in segment_models.keys():\n",
    "           segment_train = train_fold[train_fold['가격_세그먼트'] == segment]\n",
    "           if len(segment_train) > 0:\n",
    "               X_train = segment_train[feature_columns]\n",
    "               y_train = segment_train['가격(백만원)']\n",
    "               segment_models[segment].fit(X_train, y_train)\n",
    "               \n",
    "               # 훈련 성능 평가\n",
    "               train_pred = segment_models[segment].predict(X_train)\n",
    "               train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "               train_r2 = r2_score(y_train, train_pred)\n",
    "               print(f\"\\n{segment} 세그먼트 훈련 성능:\")\n",
    "               print(f\"RMSE: {train_rmse:.4f}, R2: {train_r2:.4f}\")\n",
    "       \n",
    "       # 검증 세트 예측\n",
    "       val_predictions = np.zeros(len(val_fold))\n",
    "       for i, row in val_fold.iterrows():\n",
    "           # 실제 세그먼트의 모델로 예측\n",
    "           actual_segment = get_price_segment(row['가격(백만원)'])\n",
    "           val_predictions[val_fold.index.get_loc(i)] = segment_models[actual_segment].predict(\n",
    "               row[feature_columns].values.reshape(1, -1)\n",
    "           )[0]\n",
    "       \n",
    "       # 검증 성능 평가\n",
    "       val_rmse = np.sqrt(mean_squared_error(val_fold['가격(백만원)'], val_predictions))\n",
    "       val_r2 = r2_score(val_fold['가격(백만원)'], val_predictions)\n",
    "       val_mae = mean_absolute_error(val_fold['가격(백만원)'], val_predictions)\n",
    "       \n",
    "       print(f\"\\nFold {fold + 1} 검증 성능:\")\n",
    "       print(f\"RMSE: {val_rmse:.4f}\")\n",
    "       print(f\"R2 Score: {val_r2:.4f}\")\n",
    "       print(f\"MAE: {val_mae:.4f}\")\n",
    "       \n",
    "       cv_scores['rmse'].append(val_rmse)\n",
    "       cv_scores['r2'].append(val_r2)\n",
    "       cv_scores['mae'].append(val_mae)\n",
    "\n",
    "   # 평균 교차 검증 성능\n",
    "   print(\"\\n=== 평균 교차 검증 성능 ===\")\n",
    "   print(f\"RMSE: {np.mean(cv_scores['rmse']):.4f} (+/- {np.std(cv_scores['rmse']):.4f})\")\n",
    "   print(f\"R2 Score: {np.mean(cv_scores['r2']):.4f} (+/- {np.std(cv_scores['r2']):.4f})\")\n",
    "   print(f\"MAE: {np.mean(cv_scores['mae']):.4f} (+/- {np.std(cv_scores['mae']):.4f})\")\n",
    "\n",
    "   # 최종 모델 학습\n",
    "   final_predictions = np.zeros(len(test_processed))\n",
    "   \n",
    "   # 먼저 모든 세그먼트 모델로 예측\n",
    "   segment_predictions = {}\n",
    "   for segment, model in segment_models.items():\n",
    "       segment_predictions[segment] = model.predict(test_processed[feature_columns])\n",
    "   \n",
    "   # 각 샘플에 대해 가장 적절한 세그먼트의 예측값 선택\n",
    "   for i in range(len(test_processed)):\n",
    "       # 각 세그먼트 모델의 예측값과 해당 세그먼트의 범위를 비교\n",
    "       best_segment = min(\n",
    "           segment_predictions.items(),\n",
    "           key=lambda x: min(\n",
    "               abs(x[1][i] - get_segment_bounds(x[0])[0]),\n",
    "               abs(x[1][i] - get_segment_bounds(x[0])[1])\n",
    "           )\n",
    "       )[0]\n",
    "       final_predictions[i] = segment_predictions[best_segment][i]\n",
    "\n",
    "   # 결과 저장\n",
    "   submission = pd.DataFrame({\n",
    "       'ID': test['ID'],\n",
    "       '가격(백만원)': final_predictions\n",
    "   })\n",
    "   submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "def get_segment_bounds(segment):\n",
    "   if segment == '초저가':\n",
    "       return (0, 30)\n",
    "   elif segment == '저가':\n",
    "       return (30, 50)\n",
    "   elif segment == '중가':\n",
    "       return (50, 70)\n",
    "   elif segment == '고가':\n",
    "       return (70, 100)\n",
    "   else:  # 프리미엄\n",
    "       return (100, float('inf'))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 8\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 5\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 12\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 10\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 14\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 19\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 3\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 7\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 20\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 16\n",
      "Warning: Unknown model - 0\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 9\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 1\n",
      "Warning: Unknown model - 17\n",
      "Warning: Unknown model - 4\n",
      "Warning: Unknown model - 6\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 11\n",
      "Warning: Unknown model - 13\n",
      "Warning: Unknown model - 2\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 15\n",
      "Warning: Unknown model - 18\n",
      "Warning: Unknown model - 9\n",
      "\n",
      "=== 세그먼트별 모델 분포 ===\n",
      "           가격(백만원)               \n",
      "             count    mean    std\n",
      "가격_세그먼트 모델                       \n",
      "중가      0      369   44.20   3.63\n",
      "        1      605   38.41   2.80\n",
      "        2      353   35.07   0.70\n",
      "        3      379   38.10   0.74\n",
      "        4      140   17.99   5.42\n",
      "        5      365   25.74   2.60\n",
      "        6      279   51.63   3.04\n",
      "        7      277   74.54   7.30\n",
      "        8      264   83.05   8.15\n",
      "        9      289   72.05   5.31\n",
      "        10     398   26.97   2.08\n",
      "        11     378   58.07   2.14\n",
      "        12     385   98.80   2.09\n",
      "        13     397   22.12   1.71\n",
      "        14     361  109.93  10.04\n",
      "        15     335  126.31   4.48\n",
      "        16     375  158.30   3.02\n",
      "        17     379   68.10   5.35\n",
      "        18     388   23.56   0.80\n",
      "        19     414   62.87   1.76\n",
      "        20     367   80.03   0.57\n",
      "\n",
      "=== 세그먼트별 데이터 분포 ===\n",
      "중가: 7497개 샘플\n",
      "\n",
      "==================================================\n",
      "세그먼트 최적화 시작: 프리미엄\n",
      "데이터 수: 0개\n",
      "==================================================\n",
      "Warning: 프리미엄 세그먼트의 데이터가 너무 적습니다.\n",
      "\n",
      "==================================================\n",
      "세그먼트 최적화 시작: 고가\n",
      "데이터 수: 0개\n",
      "==================================================\n",
      "Warning: 고가 세그먼트의 데이터가 너무 적습니다.\n",
      "\n",
      "==================================================\n",
      "세그먼트 최적화 시작: 중고가\n",
      "데이터 수: 0개\n",
      "==================================================\n",
      "Warning: 중고가 세그먼트의 데이터가 너무 적습니다.\n",
      "\n",
      "==================================================\n",
      "세그먼트 최적화 시작: 중가\n",
      "데이터 수: 7497개\n",
      "==================================================\n",
      "\n",
      "XGB 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGB 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 6\n",
      "- min_child_weight: 5\n",
      "- n_estimators: 200\n",
      "- subsample: 0.8\n",
      "XGB 최적 RMSE: 1.3628\n",
      "\n",
      "LGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1162\n",
      "[LightGBM] [Info] Number of data points in the train set: 7497, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 62.331949\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 6\n",
      "- min_child_samples: 30\n",
      "- n_estimators: 300\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LGBM 최적 RMSE: 1.3443\n",
      "\n",
      "RF 최적화 시작...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "RF 최적 파라미터:\n",
      "- max_depth: 10\n",
      "- min_samples_leaf: 2\n",
      "- min_samples_split: 5\n",
      "- n_estimators: 300\n",
      "RF 최적 RMSE: 1.3923\n",
      "\n",
      "==================================================\n",
      "세그먼트 최적화 시작: 저가\n",
      "데이터 수: 0개\n",
      "==================================================\n",
      "Warning: 저가 세그먼트의 데이터가 너무 적습니다.\n",
      "\n",
      "==================================================\n",
      "세그먼트 최적화 시작: 초저가\n",
      "데이터 수: 0개\n",
      "==================================================\n",
      "Warning: 초저가 세그먼트의 데이터가 너무 적습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_price_segment(model):\n",
    "    # 모델별 가격대 기준으로 세그먼트 분류\n",
    "    premium = ['TayGTS', 'TayCT']  # 평균 126-158백만원\n",
    "    high = ['Tay', 'RSeGT']       # 평균 98-100백만원\n",
    "    upper_mid = ['MX', 'ix', 'MS', 'MY']  # 평균 72-83백만원\n",
    "    mid = ['eT', 'EV6', 'Q4eT']   # 평균 58-68백만원\n",
    "    low = ['M3', 'ID6', 'ID4', 'IONIQ', 'ION5']  # 평균 35-51백만원\n",
    "    entry = ['Niro', 'KNE', 'i4', 'Soul']  # 평균 22-27백만원\n",
    "    \n",
    "    if model in premium:\n",
    "        return '프리미엄'\n",
    "    elif model in high:\n",
    "        return '고가'\n",
    "    elif model in upper_mid:\n",
    "        return '중고가'\n",
    "    elif model in mid:\n",
    "        return '중가'\n",
    "    elif model in low:\n",
    "        return '저가'\n",
    "    elif model in entry:\n",
    "        return '초저가'\n",
    "    else:\n",
    "        print(f\"Warning: Unknown model - {model}\")\n",
    "        return '중가'\n",
    "\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 기본 피처 엔지니어링\n",
    "    df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "    df['차량연식'] = 2024 - df['연식(년)']\n",
    "    df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "    df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "    df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "    \n",
    "    # 모델별 통계\n",
    "    df['모델별_평균가격'] = df.groupby('모델')['가격(백만원)'].transform('mean')\n",
    "    df['모델별_가격편차'] = df.groupby('모델')['가격(백만원)'].transform('std')\n",
    "    \n",
    "    # 제조사별 통계\n",
    "    df['제조사별_평균가격'] = df.groupby('제조사')['가격(백만원)'].transform('mean')\n",
    "    df['제조사별_가격편차'] = df.groupby('제조사')['가격(백만원)'].transform('std')\n",
    "    \n",
    "    # 가격 변동성\n",
    "    df['모델별_가격변동성'] = df['모델별_가격편차'] / df['모델별_평균가격']\n",
    "    df['제조사별_가격변동성'] = df['제조사별_가격편차'] / df['제조사별_평균가격']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 레이블 인코딩\n",
    "    le = LabelEncoder()\n",
    "    categorical_cols = ['제조사', '모델', '차량상태', '구동방식', '사고이력']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    # 결측치 처리\n",
    "    df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "        lambda x: x.fillna(x.mean())\n",
    "    )\n",
    "    df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "        lambda x: x.fillna(x.mean())\n",
    "    )\n",
    "    df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "    \n",
    "    # 특성 추가\n",
    "    if '가격(백만원)' in df.columns:  # train 데이터의 경우\n",
    "        df = add_features(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def verify_segmentation(df):\n",
    "    segments = df.groupby(['가격_세그먼트', '모델']).agg({\n",
    "        '가격(백만원)': ['count', 'mean', 'std']\n",
    "    }).round(2)\n",
    "    \n",
    "    print(\"\\n=== 세그먼트별 모델 분포 ===\")\n",
    "    print(segments)\n",
    "    return segments\n",
    "\n",
    "def optimize_segment_models(train_data, feature_columns):\n",
    "    param_grid = {\n",
    "        'xgb': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.03, 0.05],\n",
    "            'max_depth': [4, 5, 6],\n",
    "            'min_child_weight': [3, 5],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9],\n",
    "            'gamma': [0, 0.1]\n",
    "        },\n",
    "        'lgbm': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.03, 0.05],\n",
    "            'num_leaves': [31, 63],\n",
    "            'max_depth': [4, 5, 6],\n",
    "            'min_child_samples': [20, 30],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        },\n",
    "        'rf': {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'min_samples_split': [2, 5],\n",
    "            'min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # 세그먼트별 데이터 수 확인\n",
    "    segment_counts = train_data['가격_세그먼트'].value_counts()\n",
    "    print(\"\\n=== 세그먼트별 데이터 분포 ===\")\n",
    "    for segment, count in segment_counts.items():\n",
    "        print(f\"{segment}: {count}개 샘플\")\n",
    "    \n",
    "    optimized_models = {}\n",
    "    \n",
    "    for segment in ['프리미엄', '고가', '중고가', '중가', '저가', '초저가']:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"세그먼트 최적화 시작: {segment}\")\n",
    "        print(f\"데이터 수: {segment_counts.get(segment, 0)}개\")\n",
    "        print('='*50)\n",
    "        \n",
    "        segment_data = train_data[train_data['가격_세그먼트'] == segment]\n",
    "        if len(segment_data) < 50:\n",
    "            print(f\"Warning: {segment} 세그먼트의 데이터가 너무 적습니다.\")\n",
    "            continue\n",
    "            \n",
    "        X = segment_data[feature_columns]\n",
    "        y = segment_data['가격(백만원)']\n",
    "        \n",
    "        optimized_models[segment] = {}\n",
    "        \n",
    "        # 각 모델 최적화\n",
    "        for model_type in ['xgb', 'lgbm', 'rf']:\n",
    "            print(f\"\\n{model_type.upper()} 최적화 시작...\")\n",
    "            \n",
    "            if model_type == 'xgb':\n",
    "                model = XGBRegressor(random_state=42)\n",
    "            elif model_type == 'lgbm':\n",
    "                model = LGBMRegressor(random_state=42)\n",
    "            else:  # rf\n",
    "                model = RandomForestRegressor(random_state=42)\n",
    "            \n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid[model_type],\n",
    "                cv=5,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=2\n",
    "            )\n",
    "            \n",
    "            try:\n",
    "                grid_search.fit(X, y)\n",
    "                optimized_models[segment][model_type] = grid_search.best_estimator_\n",
    "                print(f\"\\n{model_type.upper()} 최적 파라미터:\")\n",
    "                for param, value in grid_search.best_params_.items():\n",
    "                    print(f\"- {param}: {value}\")\n",
    "                print(f\"{model_type.upper()} 최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"{model_type.upper()} 최적화 중 에러 발생: {str(e)}\")\n",
    "    \n",
    "    return optimized_models\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    train_processed = preprocess_data(train)\n",
    "    test_processed = preprocess_data(test)\n",
    "    \n",
    "    # 세그먼트 분류\n",
    "    train_processed['가격_세그먼트'] = train_processed['모델'].apply(get_price_segment)\n",
    "    \n",
    "    # 세그먼트 분류 검증\n",
    "    verify_segmentation(train_processed)\n",
    "    \n",
    "    # 특성 선택\n",
    "    feature_columns = [\n",
    "        '제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "        '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "        'km_per_year', '배터리_연식_효율', '잔여보증기간',\n",
    "        '모델별_평균가격', '모델별_가격편차', '모델별_가격변동성',\n",
    "        '제조사별_평균가격', '제조사별_가격편차', '제조사별_가격변동성'\n",
    "    ]\n",
    "    \n",
    "    # 모델 최적화\n",
    "    optimized_models = optimize_segment_models(train_processed, feature_columns)\n",
    "    \n",
    "    return optimized_models\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimized_models = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 제조사별 데이터 분포 ===\n",
      "제조사\n",
      "H사    1237\n",
      "B사    1169\n",
      "K사    1164\n",
      "A사    1142\n",
      "T사    1109\n",
      "P사    1071\n",
      "V사     605\n",
      "Name: count, dtype: int64\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: P사\n",
      "데이터 수: 1071개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- gamma: 0\n",
      "- learning_rate: 0.05\n",
      "- max_depth: 4\n",
      "- min_child_weight: 5\n",
      "- n_estimators: 100\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 2.5611\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000317 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 844\n",
      "[LightGBM] [Info] Number of data points in the train set: 1071, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 131.990934\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.05\n",
      "- max_depth: 4\n",
      "- min_child_samples: 20\n",
      "- n_estimators: 100\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 2.5603\n",
      "\n",
      "RandomForest 최적화 시작...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "RandomForest 최적 파라미터:\n",
      "- max_depth: 10\n",
      "- min_samples_leaf: 2\n",
      "- min_samples_split: 5\n",
      "- n_estimators: 300\n",
      "RandomForest 최적 RMSE: 2.7670\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: K사\n",
      "데이터 수: 1164개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_weight: 3\n",
      "- n_estimators: 200\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 0.6029\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 827\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 30.779029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_samples: 20\n",
      "- n_estimators: 200\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.6030\n",
      "\n",
      "RandomForest 최적화 시작...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "RandomForest 최적 파라미터:\n",
      "- max_depth: 10\n",
      "- min_samples_leaf: 2\n",
      "- min_samples_split: 5\n",
      "- n_estimators: 300\n",
      "RandomForest 최적 RMSE: 0.6295\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: A사\n",
      "데이터 수: 1142개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.8\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_weight: 3\n",
      "- n_estimators: 200\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 0.3978\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 1142, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 75.128354\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_samples: 20\n",
      "- n_estimators: 200\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.3965\n",
      "\n",
      "RandomForest 최적화 시작...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "RandomForest 최적 파라미터:\n",
      "- max_depth: 10\n",
      "- min_samples_leaf: 2\n",
      "- min_samples_split: 5\n",
      "- n_estimators: 100\n",
      "RandomForest 최적 RMSE: 0.4320\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: B사\n",
      "데이터 수: 1169개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.8\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_weight: 5\n",
      "- n_estimators: 300\n",
      "- subsample: 0.8\n",
      "XGBoost 최적 RMSE: 0.5172\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 834\n",
      "[LightGBM] [Info] Number of data points in the train set: 1169, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 55.212344\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_samples: 30\n",
      "- n_estimators: 200\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.5145\n",
      "\n",
      "RandomForest 최적화 시작...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "RandomForest 최적 파라미터:\n",
      "- max_depth: 10\n",
      "- min_samples_leaf: 1\n",
      "- min_samples_split: 5\n",
      "- n_estimators: 300\n",
      "RandomForest 최적 RMSE: 0.5343\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: H사\n",
      "데이터 수: 1237개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.8\n",
      "- gamma: 0\n",
      "- learning_rate: 0.05\n",
      "- max_depth: 4\n",
      "- min_child_weight: 5\n",
      "- n_estimators: 100\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 1.9546\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 910\n",
      "[LightGBM] [Info] Number of data points in the train set: 1237, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 31.312991\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.8\n",
      "- learning_rate: 0.05\n",
      "- max_depth: 6\n",
      "- min_child_samples: 30\n",
      "- n_estimators: 100\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 1.9666\n",
      "\n",
      "RandomForest 최적화 시작...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "RandomForest 최적 파라미터:\n",
      "- max_depth: 10\n",
      "- min_samples_leaf: 2\n",
      "- min_samples_split: 5\n",
      "- n_estimators: 100\n",
      "RandomForest 최적 RMSE: 2.0221\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: T사\n",
      "데이터 수: 1109개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 5\n",
      "- min_child_weight: 5\n",
      "- n_estimators: 200\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 0.5938\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 856\n",
      "[LightGBM] [Info] Number of data points in the train set: 1109, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 70.153724\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 6\n",
      "- min_child_samples: 20\n",
      "- n_estimators: 200\n",
      "- num_leaves: 63\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.5972\n",
      "\n",
      "RandomForest 최적화 시작...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "RandomForest 최적 파라미터:\n",
      "- max_depth: 10\n",
      "- min_samples_leaf: 2\n",
      "- min_samples_split: 5\n",
      "- n_estimators: 100\n",
      "RandomForest 최적 RMSE: 0.6241\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: V사\n",
      "데이터 수: 605개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.05\n",
      "- max_depth: 4\n",
      "- min_child_weight: 3\n",
      "- n_estimators: 100\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 0.6370\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 649\n",
      "[LightGBM] [Info] Number of data points in the train set: 605, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 38.411703\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.8\n",
      "- learning_rate: 0.05\n",
      "- max_depth: 4\n",
      "- min_child_samples: 30\n",
      "- n_estimators: 100\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.6115\n",
      "\n",
      "RandomForest 최적화 시작...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "RandomForest 최적 파라미터:\n",
      "- max_depth: 10\n",
      "- min_samples_leaf: 2\n",
      "- min_samples_split: 5\n",
      "- n_estimators: 100\n",
      "RandomForest 최적 RMSE: 0.6599\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 기본 피처 엔지니어링\n",
    "    df['차량연식'] = 2024 - df['연식(년)']\n",
    "    df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "    df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "    df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "    df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "    \n",
    "    # 제조사별 통계\n",
    "    df['제조사별_평균가격'] = df.groupby('제조사')['가격(백만원)'].transform('mean')\n",
    "    df['제조사별_가격편차'] = df.groupby('제조사')['가격(백만원)'].transform('std')\n",
    "    df['제조사별_가격변동성'] = df['제조사별_가격편차'] / df['제조사별_평균가격']\n",
    "    \n",
    "    # 모델별 통계\n",
    "    df['모델별_평균가격'] = df.groupby('모델')['가격(백만원)'].transform('mean')\n",
    "    df['모델별_가격편차'] = df.groupby('모델')['가격(백만원)'].transform('std')\n",
    "    df['모델별_가격변동성'] = df['모델별_가격편차'] / df['모델별_평균가격']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 레이블 인코딩\n",
    "    le = LabelEncoder()\n",
    "    categorical_cols = ['모델', '차량상태', '구동방식', '사고이력']\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "    \n",
    "    # 결측치 처리\n",
    "    df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "        lambda x: x.fillna(x.mean())\n",
    "    )\n",
    "    df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "        lambda x: x.fillna(x.mean())\n",
    "    )\n",
    "    df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "    \n",
    "    # 특성 추가\n",
    "    if '가격(백만원)' in df.columns:  # train 데이터의 경우\n",
    "        df = add_features(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_param_grid():\n",
    "    xgb_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.03, 0.05],\n",
    "        'max_depth': [4, 5, 6],\n",
    "        'min_child_weight': [3, 5],\n",
    "        'subsample': [0.8, 0.9],\n",
    "        'colsample_bytree': [0.8, 0.9],\n",
    "        'gamma': [0, 0.1]\n",
    "    }\n",
    "    \n",
    "    lgb_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.03, 0.05],\n",
    "        'num_leaves': [31, 63],\n",
    "        'max_depth': [4, 5, 6],\n",
    "        'min_child_samples': [20, 30],\n",
    "        'subsample': [0.8, 0.9],\n",
    "        'colsample_bytree': [0.8, 0.9]\n",
    "    }\n",
    "    \n",
    "    rf_param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'xgb': xgb_param_grid,\n",
    "        'lgb': lgb_param_grid,\n",
    "        'rf': rf_param_grid\n",
    "    }\n",
    "\n",
    "def optimize_manufacturer_models(train_data, feature_columns):\n",
    "    param_grids = get_param_grid()\n",
    "    manufacturers = train_data['제조사'].unique()\n",
    "    \n",
    "    optimized_models = {}\n",
    "    \n",
    "    for manufacturer in manufacturers:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"제조사 최적화 시작: {manufacturer}\")\n",
    "        \n",
    "        # 제조사별 데이터 추출\n",
    "        manufacturer_data = train_data[train_data['제조사'] == manufacturer]\n",
    "        manufacturer_count = len(manufacturer_data)\n",
    "        print(f\"데이터 수: {manufacturer_count}개\")\n",
    "        \n",
    "        if manufacturer_count < 50:  # 최소 데이터 수 조건\n",
    "            print(f\"Warning: {manufacturer} 제조사의 데이터가 너무 적습니다.\")\n",
    "            continue\n",
    "            \n",
    "        X = manufacturer_data[feature_columns]\n",
    "        y = manufacturer_data['가격(백만원)']\n",
    "        \n",
    "        optimized_models[manufacturer] = {}\n",
    "        \n",
    "        # XGBoost 최적화\n",
    "        print(\"\\nXGBoost 최적화 시작...\")\n",
    "        xgb_model = XGBRegressor(random_state=42)\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=xgb_model,\n",
    "            param_grid=param_grids['xgb'],\n",
    "            cv=5,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            grid_search.fit(X, y)\n",
    "            optimized_models[manufacturer]['xgb'] = grid_search.best_estimator_\n",
    "            print(f\"\\nXGBoost 최적 파라미터:\")\n",
    "            for param, value in grid_search.best_params_.items():\n",
    "                print(f\"- {param}: {value}\")\n",
    "            print(f\"XGBoost 최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"XGBoost 최적화 중 에러 발생: {str(e)}\")\n",
    "        \n",
    "        # LightGBM 최적화\n",
    "        print(\"\\nLightGBM 최적화 시작...\")\n",
    "        lgb_model = LGBMRegressor(random_state=42)\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=lgb_model,\n",
    "            param_grid=param_grids['lgb'],\n",
    "            cv=5,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            grid_search.fit(X, y)\n",
    "            optimized_models[manufacturer]['lgb'] = grid_search.best_estimator_\n",
    "            print(f\"\\nLightGBM 최적 파라미터:\")\n",
    "            for param, value in grid_search.best_params_.items():\n",
    "                print(f\"- {param}: {value}\")\n",
    "            print(f\"LightGBM 최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"LightGBM 최적화 중 에러 발생: {str(e)}\")\n",
    "        \n",
    "        # RandomForest 최적화\n",
    "        print(\"\\nRandomForest 최적화 시작...\")\n",
    "        rf_model = RandomForestRegressor(random_state=42)\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=rf_model,\n",
    "            param_grid=param_grids['rf'],\n",
    "            cv=5,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=2\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            grid_search.fit(X, y)\n",
    "            optimized_models[manufacturer]['rf'] = grid_search.best_estimator_\n",
    "            print(f\"\\nRandomForest 최적 파라미터:\")\n",
    "            for param, value in grid_search.best_params_.items():\n",
    "                print(f\"- {param}: {value}\")\n",
    "            print(f\"RandomForest 최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"RandomForest 최적화 중 에러 발생: {str(e)}\")\n",
    "    \n",
    "    return optimized_models\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    # 데이터 전처리\n",
    "    train_processed = preprocess_data(train)\n",
    "    test_processed = preprocess_data(test)\n",
    "    \n",
    "    # 제조사별 데이터 분포 확인\n",
    "    manufacturer_counts = train_processed['제조사'].value_counts()\n",
    "    print(\"\\n=== 제조사별 데이터 분포 ===\")\n",
    "    print(manufacturer_counts)\n",
    "    \n",
    "    # 특성 선택\n",
    "    feature_columns = [\n",
    "        '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "        '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "        'km_per_year', '배터리_연식_효율', '잔여보증기간',\n",
    "        '제조사별_평균가격', '제조사별_가격편차', '제조사별_가격변동성',\n",
    "        '모델별_평균가격', '모델별_가격편차', '모델별_가격변동성'\n",
    "    ]\n",
    "    \n",
    "    # 모델 최적화\n",
    "    optimized_models = optimize_manufacturer_models(train_processed, feature_columns)\n",
    "    \n",
    "    return optimized_models\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    optimized_models = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: K사\n",
      "데이터 수: 1164개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.8\n",
      "- gamma: 0\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_weight: 3\n",
      "- n_estimators: 200\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 0.6028\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 827\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 30.779029\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_samples: 20\n",
      "- n_estimators: 200\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.6030\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: A사\n",
      "데이터 수: 1142개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.8\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_weight: 5\n",
      "- n_estimators: 200\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 0.3980\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 1142, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 75.128354\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_samples: 20\n",
      "- n_estimators: 200\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.3965\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: B사\n",
      "데이터 수: 1169개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.8\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_weight: 5\n",
      "- n_estimators: 300\n",
      "- subsample: 0.8\n",
      "XGBoost 최적 RMSE: 0.5174\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 834\n",
      "[LightGBM] [Info] Number of data points in the train set: 1169, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 55.212344\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 4\n",
      "- min_child_samples: 30\n",
      "- n_estimators: 200\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.5145\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: T사\n",
      "데이터 수: 1109개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 5\n",
      "- min_child_weight: 5\n",
      "- n_estimators: 200\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 0.5938\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 856\n",
      "[LightGBM] [Info] Number of data points in the train set: 1109, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 70.153724\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- learning_rate: 0.03\n",
      "- max_depth: 6\n",
      "- min_child_samples: 20\n",
      "- n_estimators: 200\n",
      "- num_leaves: 63\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.5972\n",
      "\n",
      "==================================================\n",
      "제조사 최적화 시작: V사\n",
      "데이터 수: 605개\n",
      "\n",
      "XGBoost 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "\n",
      "XGBoost 최적 파라미터:\n",
      "- colsample_bytree: 0.9\n",
      "- gamma: 0.1\n",
      "- learning_rate: 0.05\n",
      "- max_depth: 4\n",
      "- min_child_weight: 3\n",
      "- n_estimators: 100\n",
      "- subsample: 0.9\n",
      "XGBoost 최적 RMSE: 0.6370\n",
      "\n",
      "LightGBM 최적화 시작...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 649\n",
      "[LightGBM] [Info] Number of data points in the train set: 605, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 38.411703\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LightGBM 최적 파라미터:\n",
      "- colsample_bytree: 0.8\n",
      "- learning_rate: 0.05\n",
      "- max_depth: 4\n",
      "- min_child_samples: 30\n",
      "- n_estimators: 100\n",
      "- num_leaves: 31\n",
      "- subsample: 0.8\n",
      "LightGBM 최적 RMSE: 0.6115\n",
      "\n",
      "=== K사 특성 중요도 (상위 10개) ===\n",
      "feature\n",
      "주행거리(km)       386.000215\n",
      "배터리_효율         279.500073\n",
      "보증기간(년)        215.010077\n",
      "모델             172.199518\n",
      "차량상태            88.508311\n",
      "배터리용량           63.500103\n",
      "구동방식            51.000030\n",
      "km_per_year     15.000040\n",
      "모델별_평균가격         8.774707\n",
      "사고이력             3.000021\n",
      "Name: importance, dtype: float64\n",
      "\n",
      "K사 모델 성능:\n",
      "LightGBM RMSE: 0.5597\n",
      "XGBoost RMSE: 0.5442\n",
      "Ensemble RMSE: 0.5523\n",
      "\n",
      "=== A사 특성 중요도 (상위 10개) ===\n",
      "feature\n",
      "주행거리(km)       370.000083\n",
      "배터리용량          216.000930\n",
      "배터리_효율         162.500071\n",
      "보증기간(년)        144.500327\n",
      "차량상태           112.004349\n",
      "모델별_평균가격        94.641673\n",
      "모델              89.018458\n",
      "연식(년)           78.500133\n",
      "km_per_year     26.500077\n",
      "모델별_가격편차         9.116540\n",
      "Name: importance, dtype: float64\n",
      "\n",
      "A사 모델 성능:\n",
      "LightGBM RMSE: 0.3680\n",
      "XGBoost RMSE: 0.3667\n",
      "Ensemble RMSE: 0.3667\n",
      "\n",
      "=== B사 특성 중요도 (상위 10개) ===\n",
      "feature\n",
      "주행거리(km)       382.500017\n",
      "배터리_효율         196.500008\n",
      "모델             172.693820\n",
      "배터리용량          144.500215\n",
      "보증기간(년)        143.500157\n",
      "차량상태            71.000141\n",
      "구동방식            49.500004\n",
      "연식(년)           27.500186\n",
      "km_per_year     17.000015\n",
      "모델별_평균가격         8.293821\n",
      "Name: importance, dtype: float64\n",
      "\n",
      "B사 모델 성능:\n",
      "LightGBM RMSE: 0.4844\n",
      "XGBoost RMSE: 0.4518\n",
      "Ensemble RMSE: 0.4695\n",
      "\n",
      "=== T사 특성 중요도 (상위 10개) ===\n",
      "feature\n",
      "주행거리(km)       802.504043\n",
      "배터리용량          526.502926\n",
      "배터리_효율         472.500066\n",
      "보증기간(년)        414.013413\n",
      "모델             267.625491\n",
      "모델별_평균가격       162.030180\n",
      "차량상태           106.009670\n",
      "km_per_year    100.524827\n",
      "배터리_연식_효율       17.502084\n",
      "연식(년)           16.000227\n",
      "Name: importance, dtype: float64\n",
      "\n",
      "T사 모델 성능:\n",
      "LightGBM RMSE: 0.5024\n",
      "XGBoost RMSE: 0.4989\n",
      "Ensemble RMSE: 0.4962\n",
      "\n",
      "=== V사 특성 중요도 (상위 10개) ===\n",
      "feature\n",
      "주행거리(km)       134.505734\n",
      "배터리_효율         128.002151\n",
      "보증기간(년)         70.371659\n",
      "배터리용량           56.025759\n",
      "km_per_year     38.002538\n",
      "차량상태            26.091621\n",
      "배터리_연식_효율        2.000000\n",
      "연식(년)            0.500000\n",
      "사고이력             0.000538\n",
      "모델별_평균가격         0.000000\n",
      "Name: importance, dtype: float64\n",
      "\n",
      "V사 모델 성능:\n",
      "LightGBM RMSE: 0.5655\n",
      "XGBoost RMSE: 0.5186\n",
      "Ensemble RMSE: 0.5443\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def add_features(df):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # 기본 피처 엔지니어링\n",
    "   df['차량연식'] = 2024 - df['연식(년)']\n",
    "   df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "   df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "   df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "   df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "   \n",
    "   # 모델별 가격 통계\n",
    "   df['모델별_평균가격'] = df.groupby('모델')['가격(백만원)'].transform('mean')\n",
    "   df['모델별_가격편차'] = df.groupby('모델')['가격(백만원)'].transform('std')\n",
    "   df['모델별_가격변동성'] = df['모델별_가격편차'] / df['모델별_평균가격']\n",
    "   \n",
    "   # 제조사별 가격 통계\n",
    "   df['제조사별_평균가격'] = df.groupby('제조사')['가격(백만원)'].transform('mean')\n",
    "   df['제조사별_가격편차'] = df.groupby('제조사')['가격(백만원)'].transform('std')\n",
    "   df['제조사별_가격변동성'] = df['제조사별_가격편차'] / df['제조사별_평균가격']\n",
    "   \n",
    "   return df\n",
    "\n",
    "def preprocess_data(df):\n",
    "   df = df.copy()\n",
    "   \n",
    "   # 레이블 인코딩\n",
    "   le = LabelEncoder()\n",
    "   categorical_cols = ['모델', '차량상태', '구동방식', '사고이력']\n",
    "   \n",
    "   for col in categorical_cols:\n",
    "       df[col] = le.fit_transform(df[col])\n",
    "   \n",
    "   # 결측치 처리\n",
    "   df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "       lambda x: x.fillna(x.mean())\n",
    "   )\n",
    "   df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "       lambda x: x.fillna(x.mean())\n",
    "   )\n",
    "   df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "   \n",
    "   # 특성 추가\n",
    "   if '가격(백만원)' in df.columns:  # train 데이터의 경우\n",
    "       df = add_features(df)\n",
    "   \n",
    "   return df\n",
    "\n",
    "def optimize_manufacturer_models(train_data, feature_columns):\n",
    "   param_grid = {\n",
    "       'xgb': {\n",
    "           'n_estimators': [100, 200, 300],\n",
    "           'learning_rate': [0.01, 0.03, 0.05],\n",
    "           'max_depth': [4, 5, 6],\n",
    "           'min_child_weight': [3, 5],\n",
    "           'subsample': [0.8, 0.9],\n",
    "           'colsample_bytree': [0.8, 0.9],\n",
    "           'gamma': [0, 0.1]\n",
    "       },\n",
    "       'lgbm': {\n",
    "           'n_estimators': [100, 200, 300],\n",
    "           'learning_rate': [0.01, 0.03, 0.05],\n",
    "           'num_leaves': [31, 63],\n",
    "           'max_depth': [4, 5, 6],\n",
    "           'min_child_samples': [20, 30],\n",
    "           'subsample': [0.8, 0.9],\n",
    "           'colsample_bytree': [0.8, 0.9]\n",
    "       }\n",
    "   }\n",
    "   \n",
    "   manufacturers = train_data['제조사'].unique()\n",
    "   optimized_models = {}\n",
    "   \n",
    "   for manufacturer in manufacturers:\n",
    "       if manufacturer in ['P사', 'H사']:  # Skip P사와 H사\n",
    "           continue\n",
    "           \n",
    "       print(f\"\\n{'='*50}\")\n",
    "       print(f\"제조사 최적화 시작: {manufacturer}\")\n",
    "       \n",
    "       # 제조사별 데이터\n",
    "       manufacturer_data = train_data[train_data['제조사'] == manufacturer]\n",
    "       manufacturer_count = len(manufacturer_data)\n",
    "       print(f\"데이터 수: {manufacturer_count}개\")\n",
    "       \n",
    "       X = manufacturer_data[feature_columns]\n",
    "       y = manufacturer_data['가격(백만원)']\n",
    "       \n",
    "       optimized_models[manufacturer] = {}\n",
    "       \n",
    "       # XGBoost 최적화\n",
    "       print(\"\\nXGBoost 최적화 시작...\")\n",
    "       xgb_model = XGBRegressor(random_state=42)\n",
    "       grid_search = GridSearchCV(\n",
    "           estimator=xgb_model,\n",
    "           param_grid=param_grid['xgb'],\n",
    "           cv=5,\n",
    "           scoring='neg_root_mean_squared_error',\n",
    "           n_jobs=-1,\n",
    "           verbose=2\n",
    "       )\n",
    "       \n",
    "       grid_search.fit(X, y)\n",
    "       optimized_models[manufacturer]['xgb'] = grid_search.best_estimator_\n",
    "       print(f\"\\nXGBoost 최적 파라미터:\")\n",
    "       for param, value in grid_search.best_params_.items():\n",
    "           print(f\"- {param}: {value}\")\n",
    "       print(f\"XGBoost 최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "       \n",
    "       # LightGBM 최적화\n",
    "       print(\"\\nLightGBM 최적화 시작...\")\n",
    "       lgb_model = LGBMRegressor(random_state=42)\n",
    "       grid_search = GridSearchCV(\n",
    "           estimator=lgb_model,\n",
    "           param_grid=param_grid['lgbm'],\n",
    "           cv=5,\n",
    "           scoring='neg_root_mean_squared_error',\n",
    "           n_jobs=-1,\n",
    "           verbose=2\n",
    "       )\n",
    "       \n",
    "       grid_search.fit(X, y)\n",
    "       optimized_models[manufacturer]['lgb'] = grid_search.best_estimator_\n",
    "       print(f\"\\nLightGBM 최적 파라미터:\")\n",
    "       for param, value in grid_search.best_params_.items():\n",
    "           print(f\"- {param}: {value}\")\n",
    "       print(f\"LightGBM 최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "   \n",
    "   return optimized_models\n",
    "\n",
    "def analyze_feature_importance(models, feature_columns):\n",
    "   importance_dict = {}\n",
    "   \n",
    "   for manufacturer, model_dict in models.items():\n",
    "       # LightGBM과 XGBoost feature importance 분석\n",
    "       lgb_importance = pd.DataFrame({\n",
    "           'feature': feature_columns,\n",
    "           'importance': models[manufacturer]['lgb'].feature_importances_\n",
    "       })\n",
    "       xgb_importance = pd.DataFrame({\n",
    "           'feature': feature_columns,\n",
    "           'importance': models[manufacturer]['xgb'].feature_importances_\n",
    "       })\n",
    "       \n",
    "       # 평균 중요도 계산\n",
    "       importance = pd.concat([lgb_importance, xgb_importance])\n",
    "       importance = importance.groupby('feature')['importance'].mean().sort_values(ascending=False)\n",
    "       \n",
    "       importance_dict[manufacturer] = importance\n",
    "   \n",
    "   return importance_dict\n",
    "\n",
    "def evaluate_ensemble(models, X, y, weights={'lgb': 0.6, 'xgb': 0.4}):\n",
    "   results = {}\n",
    "   \n",
    "   for manufacturer, model_dict in models.items():\n",
    "       # 개별 모델 평가\n",
    "       lgb_pred = model_dict['lgb'].predict(X)\n",
    "       xgb_pred = model_dict['xgb'].predict(X)\n",
    "       lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "       xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "       \n",
    "       # 앙상블 모델 평가\n",
    "       ensemble_pred = weights['lgb'] * lgb_pred + weights['xgb'] * xgb_pred\n",
    "       ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "       \n",
    "       results[manufacturer] = {\n",
    "           'LightGBM RMSE': lgb_rmse,\n",
    "           'XGBoost RMSE': xgb_rmse,\n",
    "           'Ensemble RMSE': ensemble_rmse\n",
    "       }\n",
    "   \n",
    "   return results\n",
    "\n",
    "def main():\n",
    "   # 데이터 로드\n",
    "   train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "   test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "   \n",
    "   # 데이터 전처리\n",
    "   train_processed = preprocess_data(train)\n",
    "   test_processed = preprocess_data(test)\n",
    "   \n",
    "   # 특성 선택\n",
    "   feature_columns = [\n",
    "       '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "       '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "       'km_per_year', '배터리_연식_효율', '잔여보증기간',\n",
    "       '모델별_평균가격', '모델별_가격편차', '모델별_가격변동성',\n",
    "       '제조사별_평균가격', '제조사별_가격편차', '제조사별_가격변동성'\n",
    "   ]\n",
    "   \n",
    "   # 모델 최적화\n",
    "   optimized_models = optimize_manufacturer_models(train_processed, feature_columns)\n",
    "   \n",
    "   # 특성 중요도 분석\n",
    "   importance_dict = analyze_feature_importance(optimized_models, feature_columns)\n",
    "   \n",
    "   # 제조사별 분석 결과 출력\n",
    "   for manufacturer in importance_dict.keys():\n",
    "       print(f\"\\n=== {manufacturer} 특성 중요도 (상위 10개) ===\")\n",
    "       print(importance_dict[manufacturer].head(10))\n",
    "       \n",
    "       # 해당 제조사 데이터만 선택\n",
    "       mask = train_processed['제조사'] == manufacturer\n",
    "       X = train_processed[mask][feature_columns]\n",
    "       y = train_processed[mask]['가격(백만원)']\n",
    "       \n",
    "       # 앙상블 성능 평가\n",
    "       results = evaluate_ensemble(\n",
    "           {manufacturer: optimized_models[manufacturer]}, \n",
    "           X, \n",
    "           y\n",
    "       )\n",
    "       print(f\"\\n{manufacturer} 모델 성능:\")\n",
    "       for metric, value in results[manufacturer].items():\n",
    "           print(f\"{metric}: {value:.4f}\")\n",
    "   \n",
    "   return optimized_models, importance_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   optimized_models, importance_dict = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타 모델 사용 버전 학습 중...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 880, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 69.595511\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 943, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 30.754157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 913, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 75.465257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 935, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 55.382449\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000086 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 544\n",
      "[LightGBM] [Info] Number of data points in the train set: 498, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 38.518072\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "앙상블 버전 학습 중...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 841\n",
      "[LightGBM] [Info] Number of data points in the train set: 880, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 69.595511\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 815\n",
      "[LightGBM] [Info] Number of data points in the train set: 943, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 30.754157\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 913, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 75.465257\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 935, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 55.382449\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 544\n",
      "[LightGBM] [Info] Number of data points in the train set: 498, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 38.518072\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "=== 검증 성능 ===\n",
      "메타 모델 RMSE: 30.1621\n",
      "앙상블 RMSE: 52.9775\n",
      "\n",
      "메타 모델로 최종 예측 진행...\n",
      "\n",
      "예측 완료! submission.csv 파일이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ManufacturerBasedModel:\n",
    "    def __init__(self, use_meta_model=True):\n",
    "        self.manufacturer_models = {}\n",
    "        self.meta_model = None\n",
    "        self.label_encoders = {}\n",
    "        self.use_meta_model = use_meta_model\n",
    "        # 통계값 저장을 위한 변수를 빈 딕셔너리로 초기화\n",
    "        self.price_stats = {\n",
    "            '모델': {'mean': {}, 'std': {}}, \n",
    "            '제조사': {'mean': {}, 'std': {}}\n",
    "        }\n",
    "        \n",
    "    def add_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # 가격 통계는 학습 시에만 계산하고 저장\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "            # 모델별 통계\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['모델']['mean'] = model_stats['mean'].to_dict()\n",
    "            self.price_stats['모델']['std'] = model_stats['std'].to_dict()\n",
    "            \n",
    "            # 제조사별 통계\n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['제조사']['mean'] = manufacturer_stats['mean'].to_dict()\n",
    "            self.price_stats['제조사']['std'] = manufacturer_stats['std'].to_dict()\n",
    "        \n",
    "        # 저장된 통계값 적용 (누락값은 0으로 처리)\n",
    "        df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "        df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "        df['모델별_가격변동성'] = df.apply(\n",
    "            lambda x: x['모델별_가격편차'] / x['모델별_평균가격'] if x['모델별_평균가격'] != 0 else 0, \n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "        df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "        df['제조사별_가격변동성'] = df.apply(\n",
    "            lambda x: x['제조사별_가격편차'] / x['제조사별_평균가격'] if x['제조사별_평균가격'] != 0 else 0,\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 레이블 인코딩\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        # 피처 엔지니어링\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_manufacturer_model(self, manufacturer):\n",
    "        if manufacturer in ['P사', 'H사']:\n",
    "            return None\n",
    "            \n",
    "        if manufacturer == 'A사':\n",
    "            return {\n",
    "                'xgb': XGBRegressor(\n",
    "                    n_estimators=200,\n",
    "                    learning_rate=0.03,\n",
    "                    max_depth=4,\n",
    "                    min_child_weight=5,\n",
    "                    subsample=0.9,\n",
    "                    colsample_bytree=0.8,\n",
    "                    gamma=0.1,\n",
    "                    random_state=42\n",
    "                ),\n",
    "                'lgb': LGBMRegressor(\n",
    "                    n_estimators=200,\n",
    "                    learning_rate=0.03,\n",
    "                    max_depth=4,\n",
    "                    num_leaves=31,\n",
    "                    min_child_samples=20,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.9,\n",
    "                    random_state=42\n",
    "                )\n",
    "            }\n",
    "        elif manufacturer == 'B사':\n",
    "            return {\n",
    "                'xgb': XGBRegressor(\n",
    "                    n_estimators=300,\n",
    "                    learning_rate=0.03,\n",
    "                    max_depth=4,\n",
    "                    min_child_weight=5,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    gamma=0.1,\n",
    "                    random_state=42\n",
    "                ),\n",
    "                'lgb': LGBMRegressor(\n",
    "                    n_estimators=200,\n",
    "                    learning_rate=0.03,\n",
    "                    max_depth=4,\n",
    "                    num_leaves=31,\n",
    "                    min_child_samples=30,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.9,\n",
    "                    random_state=42\n",
    "                )\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'xgb': XGBRegressor(\n",
    "                    n_estimators=200,\n",
    "                    learning_rate=0.03,\n",
    "                    max_depth=5,\n",
    "                    min_child_weight=5,\n",
    "                    subsample=0.9,\n",
    "                    colsample_bytree=0.9,\n",
    "                    gamma=0.1,\n",
    "                    random_state=42\n",
    "                ),\n",
    "                'lgb': LGBMRegressor(\n",
    "                    n_estimators=200,\n",
    "                    learning_rate=0.03,\n",
    "                    max_depth=6,\n",
    "                    num_leaves=63,\n",
    "                    min_child_samples=20,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.9,\n",
    "                    random_state=42\n",
    "                )\n",
    "            }\n",
    "    \n",
    "    def train_manufacturer_models(self, X, y, manufacturer):\n",
    "        models = self.get_manufacturer_model(manufacturer)\n",
    "        if models is None:\n",
    "            return None\n",
    "            \n",
    "        for name, model in models.items():\n",
    "            model.fit(X, y)\n",
    "        return models\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # 데이터 전처리 및 피처 엔지니어링\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 특성 선택\n",
    "        self.feature_columns = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간',\n",
    "            '모델별_평균가격', '모델별_가격편차', '모델별_가격변동성',\n",
    "            '제조사별_평균가격', '제조사별_가격편차', '제조사별_가격변동성'\n",
    "        ]\n",
    "        \n",
    "        # 제조사별 모델 학습\n",
    "        meta_features = np.zeros((len(train_processed), 2))\n",
    "        \n",
    "        for manufacturer in train_processed['제조사'].unique():\n",
    "            mask = train_processed['제조사'] == manufacturer\n",
    "            X = train_processed[mask][self.feature_columns]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            if manufacturer not in ['P사', 'H사']:\n",
    "                models = self.train_manufacturer_models(X, y, manufacturer)\n",
    "                self.manufacturer_models[manufacturer] = models\n",
    "                \n",
    "                if self.use_meta_model:\n",
    "                    meta_features[mask, 0] = models['xgb'].predict(X)\n",
    "                    meta_features[mask, 1] = models['lgb'].predict(X)\n",
    "        \n",
    "        if self.use_meta_model:\n",
    "            self.meta_model = XGBRegressor(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.03,\n",
    "                max_depth=3,\n",
    "                random_state=42\n",
    "            )\n",
    "            self.meta_model.fit(meta_features, y_train)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # 데이터 전처리 및 피처 엔지니어링\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        \n",
    "        meta_features = np.zeros((len(test_processed), 2))\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        for manufacturer in test_processed['제조사'].unique():\n",
    "            if manufacturer in ['P사', 'H사']:\n",
    "                continue\n",
    "                \n",
    "            mask = test_processed['제조사'] == manufacturer\n",
    "            X = test_processed[mask][self.feature_columns]\n",
    "            \n",
    "            models = self.manufacturer_models[manufacturer]\n",
    "            \n",
    "            if self.use_meta_model:\n",
    "                meta_features[mask, 0] = models['xgb'].predict(X)\n",
    "                meta_features[mask, 1] = models['lgb'].predict(X)\n",
    "            else:\n",
    "                xgb_pred = models['xgb'].predict(X)\n",
    "                lgb_pred = models['lgb'].predict(X)\n",
    "                predictions[mask] = 0.4 * xgb_pred + 0.6 * lgb_pred\n",
    "        \n",
    "        if self.use_meta_model:\n",
    "            predictions = self.meta_model.predict(meta_features)\n",
    "            \n",
    "        return predictions\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    # 학습/검증 분할\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    print(\"메타 모델 사용 버전 학습 중...\")\n",
    "    model_with_meta = ManufacturerBasedModel(use_meta_model=True)\n",
    "    model_with_meta.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\n앙상블 버전 학습 중...\")\n",
    "    model_ensemble = ManufacturerBasedModel(use_meta_model=False)\n",
    "    model_ensemble.fit(X_train, y_train)\n",
    "    \n",
    "    # 검증 성능 평가\n",
    "    meta_pred = model_with_meta.predict(X_val)\n",
    "    ensemble_pred = model_ensemble.predict(X_val)\n",
    "    \n",
    "    meta_rmse = np.sqrt(mean_squared_error(y_val, meta_pred))\n",
    "    ensemble_rmse = np.sqrt(mean_squared_error(y_val, ensemble_pred))\n",
    "    \n",
    "    print(\"\\n=== 검증 성능 ===\")\n",
    "    print(f\"메타 모델 RMSE: {meta_rmse:.4f}\")\n",
    "    print(f\"앙상블 RMSE: {ensemble_rmse:.4f}\")\n",
    "    \n",
    "    # 테스트 예측\n",
    "    if meta_rmse < ensemble_rmse:\n",
    "        print(\"\\n메타 모델로 최종 예측 진행...\")\n",
    "        final_pred = model_with_meta.predict(test)\n",
    "    else:\n",
    "        print(\"\\n앙상블 모델로 최종 예측 진행...\")\n",
    "        final_pred = model_ensemble.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': final_pred\n",
    "    })\n",
    "    submission.to_csv('submission9.csv', index=False)\n",
    "    print(\"\\n예측 완료! submission.csv 파일이 생성되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SegmentBasedModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segments = {\n",
    "            'Premium': {'min_price': 150, 'models': ['TayGTS']},\n",
    "            'Luxury': {'min_price': 120, 'models': ['TayCT']}, ###개선 필요 1순위\n",
    "            'High-Premium': {'min_price': 95, 'models': ['Tay']}, ###개선 필요 2순위\n",
    "            'High': {'min_price': 80, 'models': ['RSeTGT', 'MX', 'iX']},\n",
    "            'Mid-High': {'min_price': 65, 'models': ['MS', 'MY', 'eT']},\n",
    "            'Mid': {'min_price': 50, 'models': ['i5', 'Q4eT', 'M3']},\n",
    "            'Mid-Entry': {'min_price': 35, 'models': ['EV6', 'ID4', 'ION6', 'ION5']},\n",
    "            'Entry': {'min_price': 25, 'models': ['Niro', 'KNE']},\n",
    "            'Basic': {'min_price': 0, 'models': ['i3', 'Soul', 'IONIQ']}  ###개선필요\n",
    "        }\n",
    "        self.segment_models = {}\n",
    "        self.price_stats = {}\n",
    "        \n",
    "    def assign_segment(self, model):\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "        \n",
    "    def add_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "    \n",
    "    # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "    \n",
    "    # 가격 통계는 학습 데이터일 때만 계산\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "        # 모델별 통계\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['모델'] = {\n",
    "                'mean': model_stats['mean'].to_dict(),\n",
    "                'std': model_stats['std'].to_dict()\n",
    "            }\n",
    "        \n",
    "        # 제조사별 통계\n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['제조사'] = {\n",
    "                'mean': manufacturer_stats['mean'].to_dict(),\n",
    "                'std': manufacturer_stats['std'].to_dict()\n",
    "            }\n",
    "    \n",
    "    # 통계 적용 (통계가 존재할 경우에만 실행)\n",
    "        if '모델' in self.price_stats and '제조사' in self.price_stats:\n",
    "            df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "            df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "            df['모델별_가격변동성'] = df.apply(\n",
    "                lambda x: x['모델별_가격편차'] / x['모델별_평균가격'] if x['모델별_평균가격'] != 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "            df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "            df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "            df['제조사별_가격변동성'] = df.apply(\n",
    "                lambda x: x['제조사별_가격편차'] / x['제조사별_평균가격'] if x['제조사별_평균가격'] != 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            # 통계가 없는 경우 기본값으로 설정\n",
    "            df['모델별_평균가격'] = 0\n",
    "            df['모델별_가격편차'] = 0\n",
    "            df['모델별_가격변동성'] = 0\n",
    "            df['제조사별_평균가격'] = 0\n",
    "            df['제조사별_가격편차'] = 0\n",
    "            df['제조사별_가격변동성'] = 0\n",
    "    \n",
    "        return df\n",
    "\n",
    "    \n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        # 레이블 인코딩\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        # 피처 엔지니어링\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def optimize_xgboost(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.03, 0.05],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'min_child_weight': [3, 5, 7],\n",
    "            'gamma': [0, 0.1, 0.2],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = XGBRegressor(random_state=42)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        print(f\"\\nXGBoost {segment} 세그먼트 최적 파라미터:\")\n",
    "        for param, value in grid_search.best_params_.items():\n",
    "            print(f\"- {param}: {value}\")\n",
    "        print(f\"XGBoost {segment} 세그먼트 최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def optimize_lightgbm(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.03, 0.05],\n",
    "            'max_depth': [3, 4, 6],\n",
    "            'num_leaves': [31, 63],\n",
    "            'min_child_samples': [20, 30, 40],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        print(f\"\\nLightGBM {segment} 세그먼트 최적 파라미터:\")\n",
    "        for param, value in grid_search.best_params_.items():\n",
    "            print(f\"- {param}: {value}\")\n",
    "        print(f\"LightGBM {segment} 세그먼트 최적 RMSE: {-grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # 데이터 전처리\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 특성 선택\n",
    "        self.feature_columns = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간', '제조사',\n",
    "            '모델별_평균가격', '모델별_가격편차', '모델별_가격변동성',\n",
    "            '제조사별_평균가격', '제조사별_가격편차', '제조사별_가격변동성'\n",
    "        ]\n",
    "        \n",
    "        # 세그먼트별로 모델 학습\n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            # 세그먼트별 데이터 선택\n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = train_processed[mask][self.feature_columns]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            print(f\"데이터 수: {len(X)}개\")\n",
    "            \n",
    "            # XGBoost와 LightGBM 최적화\n",
    "            xgb_model = self.optimize_xgboost(X, y, segment)\n",
    "            lgb_model = self.optimize_lightgbm(X, y, segment)\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'xgb': xgb_model,\n",
    "                'lgb': lgb_model\n",
    "            }\n",
    "            # 특성 중요도를 저장할 딕셔너리\n",
    "        self.feature_importance = {}\n",
    "    \n",
    "    # 세그먼트별로 모델 학습\n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "        \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            X = train_processed[mask][self.feature_columns]\n",
    "            y = y_train[mask]\n",
    "        \n",
    "        # XGBoost와 LightGBM 최적화\n",
    "            xgb_model = self.optimize_xgboost(X, y, segment)\n",
    "            lgb_model = self.optimize_lightgbm(X, y, segment)\n",
    "        \n",
    "        # 특성 중요도 저장\n",
    "            self.feature_importance[segment] = {\n",
    "                'xgb': dict(zip(self.feature_columns, xgb_model.feature_importances_)),\n",
    "                'lgb': dict(zip(self.feature_columns, lgb_model.feature_importances_))\n",
    "            }\n",
    "        \n",
    "            print(f\"\\n{segment} 세그먼트 Top 5 중요 특성:\")\n",
    "            xgb_importance = sorted(self.feature_importance[segment]['xgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            lgb_importance = sorted(self.feature_importance[segment]['lgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "        \n",
    "            print(\"XGBoost:\")\n",
    "            for feat, imp in xgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "        \n",
    "            print(\"\\nLightGBM:\")\n",
    "            for feat, imp in lgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # 데이터 전처리\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        # 세그먼트별 예측\n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = test_processed[mask][self.feature_columns]\n",
    "            \n",
    "            # XGBoost와 LightGBM 예측값의 가중 평균 계산\n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            predictions[mask] = 0.4 * xgb_pred + 0.6 * lgb_pred\n",
    "            \n",
    "        return predictions\n",
    "\n",
    "def evaluate_performance(self, X_val, y_val):\n",
    "    # 데이터 전처리\n",
    "    val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "    segment_metrics = {}\n",
    "    total_predictions = np.zeros(len(val_processed))\n",
    "    \n",
    "    print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "    print(f\"{'세그먼트':<15} {'데이터 수':>10} {'XGBoost RMSE':>15} {'LightGBM RMSE':>15} {'앙상블 RMSE':>15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for segment in self.segments.keys():\n",
    "        mask = val_processed['segment'] == segment\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "            \n",
    "        X = val_processed[mask][self.feature_columns]\n",
    "        y = y_val[mask]\n",
    "        \n",
    "        # XGBoost와 LightGBM 예측\n",
    "        xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "        lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "        \n",
    "        # 앙상블 예측\n",
    "        ensemble_pred = 0.4 * xgb_pred + 0.6 * lgb_pred\n",
    "        total_predictions[mask] = ensemble_pred\n",
    "        \n",
    "        # RMSE 계산\n",
    "        xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "        lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "        ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(f\"{segment:<15} {mask.sum():>10d} {xgb_rmse:>15.4f} {lgb_rmse:>15.4f} {ensemble_rmse:>15.4f}\")\n",
    "        \n",
    "        segment_metrics[segment] = {\n",
    "            'count': mask.sum(),\n",
    "            'xgb_rmse': xgb_rmse,\n",
    "            'lgb_rmse': lgb_rmse,\n",
    "            'ensemble_rmse': ensemble_rmse\n",
    "        }\n",
    "    \n",
    "    # 전체 RMSE 계산\n",
    "    total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'전체':<15} {len(y_val):>10d} {'':>15} {'':>15} {total_rmse:>15.4f}\")\n",
    "    \n",
    "    return segment_metrics, total_rmse\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    # 'id' 컬럼 확인 및 추가\n",
    "    if 'ID' not in test.columns:\n",
    "        test['ID'] = range(len(test))\n",
    "    \n",
    "    # 학습/검증 분할\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    print(\"세그먼트 기반 모델 학습 시작...\")\n",
    "    model = SegmentBasedModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 성능 평가\n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    \n",
    "    # 테스트 예측 및 제출 파일 생성\n",
    "    print(\"\\n테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission11.csv', index=False, encoding='utf-8')\n",
    "    print(\"제출 파일 생성 완료: submission10.csv\")\n",
    "\n",
    "    ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세그먼트 기반 모델 학습 시작...\n",
      "\n",
      "=== Premium 세그먼트 최적화 시작 ===\n",
      "데이터 수: 295개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 334\n",
      "[LightGBM] [Info] Number of data points in the train set: 295, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 158.215525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Premium 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.8296\n",
      "- 배터리용량: 0.1180\n",
      "- 배터리_연식_효율: 0.0285\n",
      "- 주행거리(km): 0.0123\n",
      "- 배터리_효율: 0.0065\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 170.0000\n",
      "- 배터리_효율: 124.0000\n",
      "- 주행거리(km): 113.0000\n",
      "- 차량상태: 61.0000\n",
      "- km_per_year: 34.0000\n",
      "\n",
      "=== Luxury 세그먼트 최적화 시작 ===\n",
      "데이터 수: 266개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 290\n",
      "[LightGBM] [Info] Number of data points in the train set: 266, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 126.280564\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Luxury 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 연식(년): 0.2127\n",
      "- 보증기간(년): 0.1887\n",
      "- 차량상태: 0.1437\n",
      "- 배터리용량: 0.1273\n",
      "- 배터리_연식_효율: 0.1062\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 457.0000\n",
      "- 주행거리(km): 330.0000\n",
      "- 배터리_연식_효율: 168.0000\n",
      "- km_per_year: 91.0000\n",
      "- 차량상태: 75.0000\n",
      "\n",
      "=== High-Premium 세그먼트 최적화 시작 ===\n",
      "데이터 수: 293개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 329\n",
      "[LightGBM] [Info] Number of data points in the train set: 293, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 110.034437\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "High-Premium 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.8216\n",
      "- 주행거리(km): 0.0945\n",
      "- km_per_year: 0.0354\n",
      "- 배터리용량: 0.0277\n",
      "- 배터리_연식_효율: 0.0148\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 216.0000\n",
      "- 주행거리(km): 134.0000\n",
      "- 배터리용량: 129.0000\n",
      "- 차량상태: 79.0000\n",
      "- km_per_year: 25.0000\n",
      "\n",
      "=== High 세그먼트 최적화 시작 ===\n",
      "데이터 수: 811개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 811, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 87.946128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "High 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 제조사: 0.6846\n",
      "- 모델: 0.1096\n",
      "- 차량상태: 0.0882\n",
      "- 배터리용량: 0.0546\n",
      "- 보증기간(년): 0.0409\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 287.0000\n",
      "- 보증기간(년): 272.0000\n",
      "- 주행거리(km): 251.0000\n",
      "- 제조사: 172.0000\n",
      "- 차량상태: 145.0000\n",
      "\n",
      "=== Mid-High 세그먼트 최적화 시작 ===\n",
      "데이터 수: 743개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 835\n",
      "[LightGBM] [Info] Number of data points in the train set: 743, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 71.330256\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Mid-High 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.2687\n",
      "- km_per_year: 0.1675\n",
      "- 제조사: 0.1515\n",
      "- 모델: 0.1481\n",
      "- 주행거리(km): 0.1323\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 654.0000\n",
      "- 배터리_효율: 575.0000\n",
      "- 배터리용량: 553.0000\n",
      "- 보증기간(년): 293.0000\n",
      "- km_per_year: 244.0000\n",
      "\n",
      "=== Mid 세그먼트 최적화 시작 ===\n",
      "데이터 수: 866개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 853\n",
      "[LightGBM] [Info] Number of data points in the train set: 866, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 58.140808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Mid 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 제조사: 0.4617\n",
      "- 모델: 0.3682\n",
      "- 차량연식: 0.0600\n",
      "- 차량상태: 0.0352\n",
      "- 보증기간(년): 0.0300\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 1336.0000\n",
      "- 배터리_효율: 917.0000\n",
      "- 배터리용량: 719.0000\n",
      "- 보증기간(년): 400.0000\n",
      "- 모델: 333.0000\n",
      "\n",
      "=== Mid-Entry 세그먼트 최적화 시작 ===\n",
      "데이터 수: 1373개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 840\n",
      "[LightGBM] [Info] Number of data points in the train set: 1373, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 38.946176\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Mid-Entry 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델: 0.4093\n",
      "- 보증기간(년): 0.2622\n",
      "- 제조사: 0.1743\n",
      "- 차량상태: 0.0527\n",
      "- 배터리용량: 0.0480\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 635.0000\n",
      "- 모델: 492.0000\n",
      "- 보증기간(년): 437.0000\n",
      "- 배터리_효율: 366.0000\n",
      "- 배터리용량: 274.0000\n",
      "\n",
      "=== Entry 세그먼트 최적화 시작 ===\n",
      "데이터 수: 622개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 681\n",
      "[LightGBM] [Info] Number of data points in the train set: 622, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 26.379421\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Entry 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.8855\n",
      "- 보증기간(년): 0.0653\n",
      "- 주행거리(km): 0.0365\n",
      "- 배터리_연식_효율: 0.0029\n",
      "- 배터리용량: 0.0023\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 232.0000\n",
      "- 주행거리(km): 130.0000\n",
      "- 보증기간(년): 113.0000\n",
      "- 배터리용량: 67.0000\n",
      "- 차량상태: 43.0000\n",
      "\n",
      "=== Basic 세그먼트 최적화 시작 ===\n",
      "데이터 수: 728개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 728, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 22.093723\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Basic 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델: 0.3141\n",
      "- 제조사: 0.1297\n",
      "- 보증기간(년): 0.0948\n",
      "- 배터리용량: 0.0777\n",
      "- 배터리_연식_효율: 0.0708\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 309.0000\n",
      "- 주행거리(km): 183.0000\n",
      "- 보증기간(년): 132.0000\n",
      "- 배터리_효율: 93.0000\n",
      "- 모델: 81.0000\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트                 데이터 수    XGBoost RMSE   LightGBM RMSE        앙상블 RMSE\n",
      "----------------------------------------------------------------------\n",
      "Premium                 80          0.3188          0.3124          0.3143\n",
      "Luxury                  69          3.5124          3.5460          3.5103\n",
      "High-Premium            68          2.9362          2.9294          2.9141\n",
      "High                   205          0.5191          0.5001          0.5041\n",
      "Mid-High               202          0.6015          0.8921          0.7337\n",
      "Mid                    205          0.5300          0.5201          0.5215\n",
      "Mid-Entry              333          0.4936          0.4928          0.4911\n",
      "Entry                  141          0.6252          0.6241          0.6230\n",
      "Basic                  197          2.4479          2.4748          2.4561\n",
      "======================================================================\n",
      "전체                    1500                                          1.4084\n",
      "\n",
      "테스트 데이터 예측 중...\n",
      "제출 파일 생성 완료: submission10.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SegmentBasedModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segments = {\n",
    "            'Premium': {'min_price': 150, 'models': ['TayGTS']},\n",
    "            'Luxury': {'min_price': 120, 'models': ['TayCT']},\n",
    "            'High-Premium': {'min_price': 95, 'models': ['Tay']},\n",
    "            'High': {'min_price': 80, 'models': ['RSeTGT', 'MX', 'iX']},\n",
    "            'Mid-High': {'min_price': 65, 'models': ['MS', 'MY', 'eT']},\n",
    "            'Mid': {'min_price': 50, 'models': ['i5', 'Q4eT', 'M3']},\n",
    "            'Mid-Entry': {'min_price': 35, 'models': ['EV6', 'ID4', 'ION6', 'ION5']},\n",
    "            'Entry': {'min_price': 25, 'models': ['Niro', 'KNE']},\n",
    "            'Basic': {'min_price': 0, 'models': ['i3', 'Soul', 'IONIQ']}\n",
    "        }\n",
    "        self.segment_models = {}\n",
    "        self.price_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def assign_segment(self, model):\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "        \n",
    "    def add_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # 가격 통계는 학습 데이터일 때만 계산\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "            # 모델별 통계\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['모델'] = {\n",
    "                'mean': model_stats['mean'].to_dict(),\n",
    "                'std': model_stats['std'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 제조사별 통계\n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['제조사'] = {\n",
    "                'mean': manufacturer_stats['mean'].to_dict(),\n",
    "                'std': manufacturer_stats['std'].to_dict()\n",
    "            }\n",
    "        \n",
    "        # 통계 적용\n",
    "        if '모델' in self.price_stats and '제조사' in self.price_stats:\n",
    "            df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "            df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "            df['모델별_가격변동성'] = df.apply(\n",
    "                lambda x: x['모델별_가격편차'] / x['모델별_평균가격'] if x['모델별_평균가격'] != 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "            df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "            df['제조사별_가격변동성'] = df.apply(\n",
    "                lambda x: x['제조사별_가격편차'] / x['제조사별_평균가격'] if x['제조사별_평균가격'] != 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            df['모델별_평균가격'] = 0\n",
    "            df['모델별_가격편차'] = 0\n",
    "            df['모델별_가격변동성'] = 0\n",
    "            df['제조사별_평균가격'] = 0\n",
    "            df['제조사별_가격편차'] = 0\n",
    "            df['제조사별_가격변동성'] = 0\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        # 레이블 인코딩\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        # 피처 엔지니어링\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def optimize_xgboost(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.03, 0.05],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'min_child_weight': [3, 5, 7],\n",
    "            'gamma': [0, 0.1, 0.2],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = XGBRegressor(random_state=42)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def optimize_lightgbm(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.03, 0.05],\n",
    "            'max_depth': [3, 4, 6],\n",
    "            'num_leaves': [31, 63],\n",
    "            'min_child_samples': [20, 30, 40],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # 데이터 전처리\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 특성 선택\n",
    "        self.feature_columns = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간', '제조사',\n",
    "            '모델별_평균가격', '모델별_가격편차', '모델별_가격변동성',\n",
    "            '제조사별_평균가격', '제조사별_가격편차', '제조사별_가격변동성'\n",
    "        ]\n",
    "        \n",
    "        # 세그먼트별로 모델 학습\n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = train_processed[mask][self.feature_columns]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            print(f\"데이터 수: {len(X)}개\")\n",
    "            \n",
    "            # XGBoost와 LightGBM 최적화\n",
    "            xgb_model = self.optimize_xgboost(X, y, segment)\n",
    "            lgb_model = self.optimize_lightgbm(X, y, segment)\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'xgb': xgb_model,\n",
    "                'lgb': lgb_model\n",
    "            }\n",
    "            \n",
    "            # 특성 중요도 저장\n",
    "            self.feature_importance[segment] = {\n",
    "                'xgb': dict(zip(self.feature_columns, xgb_model.feature_importances_)),\n",
    "                'lgb': dict(zip(self.feature_columns, lgb_model.feature_importances_))\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{segment} 세그먼트 Top 5 중요 특성:\")\n",
    "            xgb_importance = sorted(self.feature_importance[segment]['xgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            lgb_importance = sorted(self.feature_importance[segment]['lgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            \n",
    "            print(\"XGBoost:\")\n",
    "            for feat, imp in xgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "            \n",
    "            print(\"\\nLightGBM:\")\n",
    "            for feat, imp in lgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # 데이터 전처리\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        # 세그먼트별 예측\n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = test_processed[mask][self.feature_columns]\n",
    "            \n",
    "            # XGBoost와 LightGBM 예측값의 가중 평균 계산\n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            predictions[mask] = 0.4 * xgb_pred + 0.6 * lgb_pred\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        # 데이터 전처리\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<15} {'데이터 수':>10} {'XGBoost RMSE':>15} {'LightGBM RMSE':>15} {'앙상블 RMSE':>15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = val_processed[mask][self.feature_columns]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            # XGBoost와 LightGBM 예측\n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 앙상블 예측\n",
    "            ensemble_pred = 0.4 * xgb_pred + 0.6 * lgb_pred\n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            # RMSE 계산\n",
    "            xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "            lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"{segment:<15} {mask.sum():>10d} {xgb_rmse:>15.4f} {lgb_rmse:>15.4f} {ensemble_rmse:>15.4f}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'xgb_rmse': xgb_rmse,\n",
    "                'lgb_rmse': lgb_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse\n",
    "            }\n",
    "        \n",
    "        # 전체 RMSE 계산\n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'전체':<15} {len(y_val):>10d} {'':>15} {'':>15} {total_rmse:>15.4f}\")\n",
    "        \n",
    "        return segment_metrics, total_rmse\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    # 'id' 컬럼 확인 및 추가\n",
    "    if 'ID' not in test.columns:\n",
    "        test['ID'] = range(len(test))\n",
    "    \n",
    "    # 학습/검증 분할\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    print(\"세그먼트 기반 모델 학습 시작...\")\n",
    "    model = SegmentBasedModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 성능 평가\n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    \n",
    "    # 테스트 예측 및 제출 파일 생성\n",
    "    print(\"\\n테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission11.csv', index=False, encoding='utf-8')\n",
    "    print(\"제출 파일 생성 완료: submission10.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세그먼트 기반 모델 학습 시작...\n",
      "\n",
      "=== Premium 세그먼트 최적화 시작 ===\n",
      "데이터 수: 295개\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 646\n",
      "[LightGBM] [Info] Number of data points in the train set: 295, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 158.215525\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Premium 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.6180\n",
      "- 상태_배터리_점수: 0.1323\n",
      "- 배터리용량: 0.0931\n",
      "- 배터리_연식_효율: 0.0716\n",
      "- 주행거리(km): 0.0546\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 152.0000\n",
      "- 모델_효율_차이: 101.0000\n",
      "- 배터리_효율: 80.0000\n",
      "- 주행거리(km): 79.0000\n",
      "- 차량상태: 53.0000\n",
      "\n",
      "=== Luxury 세그먼트 최적화 시작 ===\n",
      "데이터 수: 266개\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 565\n",
      "[LightGBM] [Info] Number of data points in the train set: 266, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 126.280564\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Luxury 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 연식(년): 0.1929\n",
      "- 보증기간(년): 0.1825\n",
      "- 배터리용량: 0.1390\n",
      "- 차량상태: 0.1300\n",
      "- 배터리_연식_효율: 0.0942\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 332.0000\n",
      "- 주행거리(km): 163.0000\n",
      "- 배터리_연식_효율: 87.0000\n",
      "- 모델_효율_차이: 85.0000\n",
      "- 주행거리_배터리_보정: 67.0000\n",
      "\n",
      "=== High-Premium 세그먼트 최적화 시작 ===\n",
      "데이터 수: 293개\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 637\n",
      "[LightGBM] [Info] Number of data points in the train set: 293, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 110.034437\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "High-Premium 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.7431\n",
      "- 주행거리(km): 0.0871\n",
      "- km_per_year: 0.0552\n",
      "- 주행거리_배터리_보정: 0.0519\n",
      "- 배터리용량: 0.0286\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 100.0000\n",
      "- 주행거리_배터리_보정: 100.0000\n",
      "- 배터리용량: 95.0000\n",
      "- 차량상태: 79.0000\n",
      "- 모델_효율_차이: 61.0000\n",
      "\n",
      "=== High 세그먼트 최적화 시작 ===\n",
      "데이터 수: 811개\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1608\n",
      "[LightGBM] [Info] Number of data points in the train set: 811, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 87.946128\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "High 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 제조사: 0.6695\n",
      "- 모델: 0.0917\n",
      "- 차량상태: 0.0843\n",
      "- 배터리용량: 0.0411\n",
      "- 보증기간(년): 0.0404\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 298.0000\n",
      "- 보증기간(년): 261.0000\n",
      "- 주행거리(km): 170.0000\n",
      "- 제조사: 170.0000\n",
      "- 차량상태: 133.0000\n",
      "\n",
      "=== Mid-High 세그먼트 최적화 시작 ===\n",
      "데이터 수: 743개\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1619\n",
      "[LightGBM] [Info] Number of data points in the train set: 743, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 71.330256\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Mid-High 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델별_주행효율: 0.4086\n",
      "- 차량상태: 0.3017\n",
      "- 제조사: 0.1064\n",
      "- 모델: 0.0706\n",
      "- 주행거리(km): 0.0343\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 493.0000\n",
      "- 모델_효율_차이: 468.0000\n",
      "- 배터리_효율: 393.0000\n",
      "- 배터리용량: 290.0000\n",
      "- 보증기간(년): 266.0000\n",
      "\n",
      "=== Mid 세그먼트 최적화 시작 ===\n",
      "데이터 수: 866개\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000169 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1655\n",
      "[LightGBM] [Info] Number of data points in the train set: 866, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 58.140808\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Mid 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 제조사: 0.6391\n",
      "- 모델: 0.2422\n",
      "- 연식_보증_비율: 0.0387\n",
      "- 보증기간(년): 0.0233\n",
      "- 차량상태: 0.0194\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 394.0000\n",
      "- 배터리용량: 267.0000\n",
      "- 배터리_효율: 262.0000\n",
      "- 모델_효율_차이: 245.0000\n",
      "- 보증기간(년): 147.0000\n",
      "\n",
      "=== Mid-Entry 세그먼트 최적화 시작 ===\n",
      "데이터 수: 1373개\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1637\n",
      "[LightGBM] [Info] Number of data points in the train set: 1373, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 38.946176\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Mid-Entry 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델: 0.3485\n",
      "- 구동방식: 0.1645\n",
      "- 제조사: 0.1390\n",
      "- 모델별_주행효율: 0.1047\n",
      "- 차량상태: 0.0775\n",
      "\n",
      "LightGBM:\n",
      "- 보증기간(년): 245.0000\n",
      "- 주행거리(km): 226.0000\n",
      "- 모델_효율_차이: 160.0000\n",
      "- 배터리용량: 148.0000\n",
      "- 배터리_효율: 114.0000\n",
      "\n",
      "=== Entry 세그먼트 최적화 시작 ===\n",
      "데이터 수: 622개\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1319\n",
      "[LightGBM] [Info] Number of data points in the train set: 622, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 26.379421\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Entry 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.8522\n",
      "- 보증기간(년): 0.0705\n",
      "- 주행거리(km): 0.0599\n",
      "- 배터리용량: 0.0029\n",
      "- 배터리_효율: 0.0018\n",
      "\n",
      "LightGBM:\n",
      "- 보증기간(년): 117.0000\n",
      "- 배터리_효율: 105.0000\n",
      "- 주행거리(km): 79.0000\n",
      "- 모델_효율_차이: 62.0000\n",
      "- 차량상태: 44.0000\n",
      "\n",
      "=== Basic 세그먼트 최적화 시작 ===\n",
      "데이터 수: 728개\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1620\n",
      "[LightGBM] [Info] Number of data points in the train set: 728, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 22.093723\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Basic 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델별_주행효율: 0.2651\n",
      "- 모델: 0.1729\n",
      "- 보증기간(년): 0.0590\n",
      "- 차량상태: 0.0490\n",
      "- 제조사: 0.0463\n",
      "\n",
      "LightGBM:\n",
      "- 보증기간(년): 455.0000\n",
      "- 모델_효율_차이: 318.0000\n",
      "- 차량상태: 249.0000\n",
      "- 모델: 231.0000\n",
      "- 주행거리(km): 222.0000\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트                 데이터 수    XGBoost RMSE   LightGBM RMSE        앙상블 RMSE\n",
      "----------------------------------------------------------------------\n",
      "Premium                 80          0.3160          0.3324          0.3219\n",
      "Luxury                  69          3.5155          3.8391          3.6338\n",
      "High-Premium            68          2.9097          2.8584          2.8569\n",
      "High                   205          0.5455          0.5284          0.5304\n",
      "Mid-High               202          1.1199          1.0944          1.0292\n",
      "Mid                    205          0.6328          0.6195          0.5485\n",
      "Mid-Entry              333          2.3012          2.7721          2.4922\n",
      "Entry                  141          0.6442          0.6331          0.6351\n",
      "Basic                  197          2.5704          2.4600          2.4635\n",
      "======================================================================\n",
      "전체                    1500                                          1.8490\n",
      "\n",
      "테스트 데이터 예측 중...\n",
      "제출 파일 생성 완료: submission11.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SegmentBasedModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segments = {\n",
    "            'Premium': {'min_price': 150, 'models': ['TayGTS']},\n",
    "            'Luxury': {'min_price': 120, 'models': ['TayCT', 'TayS', 'TayX']},\n",
    "            'High-Premium': {'min_price': 95, 'models': ['Tay', 'RSe', 'EQS']},\n",
    "            'High': {'min_price': 80, 'models': ['RSeTGT', 'MX', 'iX']},\n",
    "            'Mid-High': {'min_price': 65, 'models': ['MS', 'MY', 'eT']},\n",
    "            'Mid': {'min_price': 50, 'models': ['i5', 'Q4eT', 'M3']},\n",
    "            'Mid-Entry': {'min_price': 35, 'models': ['EV6', 'ID4', 'ION6', 'ION5']},\n",
    "            'Entry': {'min_price': 25, 'models': ['Niro', 'KNE']},\n",
    "            'Basic': {'min_price': 0, 'models': ['i3', 'Soul', 'IONIQ', 'Leaf', 'Bolt']}\n",
    "        }\n",
    "        self.segment_models = {}\n",
    "        self.price_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def assign_segment(self, model):\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "        \n",
    "    def add_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # Luxury 세그먼트를 위한 특성\n",
    "        df['연식_보증_비율'] = df['연식(년)'] / df['보증기간(년)']\n",
    "        df['연식별_배터리효율'] = df['배터리_효율'] * df['차량연식']\n",
    "        \n",
    "        # High-Premium 세그먼트를 위한 특성\n",
    "        df['상태_배터리_점수'] = df.apply(\n",
    "            lambda x: x['배터리용량'] * (2 if x['차량상태'] == '우수' else 1),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Basic 세그먼트를 위한 특성\n",
    "        df['모델별_주행효율'] = df.groupby('모델')['배터리_효율'].transform('mean')\n",
    "        df['모델_효율_차이'] = df['배터리_효율'] - df['모델별_주행효율']\n",
    "        \n",
    "        # 공통 개선 특성\n",
    "        df['주행거리_배터리_보정'] = df['주행거리(km)'] / (df['배터리용량'] * df['차량연식'])\n",
    "        df['보증_연식_효율'] = df['잔여보증기간'] * df['배터리_효율']\n",
    "\n",
    "        # 가격 통계는 학습 데이터일 때만 계산\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "            # 모델별 통계\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['모델'] = {\n",
    "                'mean': model_stats['mean'].to_dict(),\n",
    "                'std': model_stats['std'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 제조사별 통계\n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['제조사'] = {\n",
    "                'mean': manufacturer_stats['mean'].to_dict(),\n",
    "                'std': manufacturer_stats['std'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 세그먼트별 통계\n",
    "            segment_stats = df.groupby('segment')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['segment'] = {\n",
    "                'mean': segment_stats['mean'].to_dict(),\n",
    "                'std': segment_stats['std'].to_dict()\n",
    "            }\n",
    "        \n",
    "        if '모델' in self.price_stats and '제조사' in self.price_stats:\n",
    "            df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "            df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "            df['모델별_가격변동성'] = df.apply(\n",
    "                lambda x: x['모델별_가격편차'] / x['모델별_평균가격'] if x['모델별_평균가격'] != 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "            df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "            df['제조사별_가격변동성'] = df.apply(\n",
    "                lambda x: x['제조사별_가격편차'] / x['제조사별_평균가격'] if x['제조사별_평균가격'] != 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            df['모델별_평균가격'] = 0\n",
    "            df['모델별_가격편차'] = 0\n",
    "            df['모델별_가격변동성'] = 0\n",
    "            df['제조사별_평균가격'] = 0\n",
    "            df['제조사별_가격편차'] = 0\n",
    "            df['제조사별_가격변동성'] = 0\n",
    "\n",
    "        # 무한대 값과 이상치 처리\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            # 무한대 값을 NaN으로 변환\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "            # NaN을 해당 컬럼의 평균값으로 대체\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "            # 이상치 처리 (99 percentile 기준)\n",
    "            q99 = df[col].quantile(0.99)\n",
    "            df[col] = df[col].clip(upper=q99)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        # 레이블 인코딩\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        # 피처 엔지니어링\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def optimize_xgboost(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300, 400],\n",
    "            'learning_rate': [0.01, 0.03, 0.05, 0.07],\n",
    "            'max_depth': [3, 4, 5, 6],\n",
    "            'min_child_weight': [3, 5, 7, 9],\n",
    "            'gamma': [0, 0.1, 0.2, 0.3],\n",
    "            'subsample': [0.7, 0.8, 0.9],\n",
    "            'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = XGBRegressor(\n",
    "            random_state=42,\n",
    "            missing=np.nan,  # 결측치 처리\n",
    "            tree_method='hist',  # 더 안정적인 트리 생성 방법\n",
    "            max_bin=256  # 비닝 개수 제한\n",
    "        )\n",
    "        \n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def optimize_lightgbm(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300, 400],\n",
    "            'learning_rate': [0.01, 0.03, 0.05, 0.07],\n",
    "            'max_depth': [3, 4, 6, 8],\n",
    "            'num_leaves': [31, 63, 127],\n",
    "            'min_child_samples': [20, 30, 40, 50],\n",
    "            'subsample': [0.7, 0.8, 0.9],\n",
    "            'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = LGBMRegressor(random_state=42)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        # 데이터 전처리\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 특성 선택\n",
    "        self.feature_columns = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간', '제조사',\n",
    "            '모델별_평균가격', '모델별_가격편차', '모델별_가격변동성',\n",
    "            '제조사별_평균가격', '제조사별_가격편차', '제조사별_가격변동성',\n",
    "            '연식_보증_비율', '연식별_배터리효율', '상태_배터리_점수',\n",
    "            '모델별_주행효율', '모델_효율_차이', '주행거리_배터리_보정',\n",
    "            '보증_연식_효율'\n",
    "        ]\n",
    "        \n",
    "        # 세그먼트별로 모델 학습\n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = train_processed[mask][self.feature_columns]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            print(f\"데이터 수: {len(X)}개\")\n",
    "            \n",
    "            # XGBoost와 LightGBM 최적화\n",
    "            xgb_model = self.optimize_xgboost(X, y, segment)\n",
    "            lgb_model = self.optimize_lightgbm(X, y, segment)\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'xgb': xgb_model,\n",
    "                'lgb': lgb_model\n",
    "            }\n",
    "            \n",
    "            # 특성 중요도 저장\n",
    "            self.feature_importance[segment] = {\n",
    "                'xgb': dict(zip(self.feature_columns, xgb_model.feature_importances_)),\n",
    "                'lgb': dict(zip(self.feature_columns, lgb_model.feature_importances_))\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{segment} 세그먼트 Top 5 중요 특성:\")\n",
    "            xgb_importance = sorted(self.feature_importance[segment]['xgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            lgb_importance = sorted(self.feature_importance[segment]['lgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            \n",
    "            print(\"XGBoost:\")\n",
    "            for feat, imp in xgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "            \n",
    "            print(\"\\nLightGBM:\")\n",
    "            for feat, imp in lgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # 데이터 전처리\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        # 세그먼트별 최적 가중치\n",
    "        weights = {\n",
    "            'Luxury': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'High-Premium': {'xgb': 0.3, 'lgb': 0.7},\n",
    "            'Basic': {'xgb': 0.6, 'lgb': 0.4}\n",
    "        }\n",
    "        \n",
    "        # 세그먼트별 예측\n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = test_processed[mask][self.feature_columns]\n",
    "            \n",
    "            # XGBoost와 LightGBM 예측값의 가중 평균 계산\n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 세그먼트별 가중치 적용\n",
    "            if segment in weights:\n",
    "                w = weights[segment]\n",
    "                predictions[mask] = w['xgb'] * xgb_pred + w['lgb'] * lgb_pred\n",
    "            else:\n",
    "                predictions[mask] = 0.4 * xgb_pred + 0.6 * lgb_pred\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        # 데이터 전처리\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<15} {'데이터 수':>10} {'XGBoost RMSE':>15} {'LightGBM RMSE':>15} {'앙상블 RMSE':>15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # 세그먼트별 가중치\n",
    "        weights = {\n",
    "            'Luxury': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'High-Premium': {'xgb': 0.3, 'lgb': 0.7},\n",
    "            'Basic': {'xgb': 0.6, 'lgb': 0.4}\n",
    "        }\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = val_processed[mask][self.feature_columns]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            # XGBoost와 LightGBM 예측\n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 앙상블 예측 (세그먼트별 가중치 적용)\n",
    "            if segment in weights:\n",
    "                w = weights[segment]\n",
    "                ensemble_pred = w['xgb'] * xgb_pred + w['lgb'] * lgb_pred\n",
    "            else:\n",
    "                ensemble_pred = 0.4 * xgb_pred + 0.6 * lgb_pred\n",
    "            \n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            # RMSE 계산\n",
    "            xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "            lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"{segment:<15} {mask.sum():>10d} {xgb_rmse:>15.4f} {lgb_rmse:>15.4f} {ensemble_rmse:>15.4f}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'xgb_rmse': xgb_rmse,\n",
    "                'lgb_rmse': lgb_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse\n",
    "            }\n",
    "        \n",
    "        # 전체 RMSE 계산\n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'전체':<15} {len(y_val):>10d} {'':>15} {'':>15} {total_rmse:>15.4f}\")\n",
    "        \n",
    "        return segment_metrics, total_rmse\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    # 'id' 컬럼 확인 및 추가\n",
    "    if 'ID' not in test.columns:\n",
    "        test['ID'] = range(len(test))\n",
    "    \n",
    "    # 학습/검증 분할\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    print(\"세그먼트 기반 모델 학습 시작...\")\n",
    "    model = SegmentBasedModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 성능 평가\n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    \n",
    "    # 테스트 예측 및 제출 파일 생성\n",
    "    print(\"\\n테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission12.csv', index=False, encoding='utf-8')\n",
    "    print(\"제출 파일 생성 완료: submission11.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세그먼트 기반 모델 학습 시작...\n",
      "\n",
      "=== Premium 세그먼트 최적화 시작 ===\n",
      "데이터 수: 295개\n",
      "\n",
      "Premium 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.7178\n",
      "- 배터리용량: 0.1169\n",
      "- 배터리_연식_효율: 0.0824\n",
      "- 주행거리_배터리_보정: 0.0223\n",
      "- 주행거리(km): 0.0204\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 126.0000\n",
      "- 배터리성능지수: 79.0000\n",
      "- 주행거리(km): 56.0000\n",
      "- 모델_효율_차이: 55.0000\n",
      "- 차량상태: 53.0000\n",
      "\n",
      "=== Luxury 세그먼트 최적화 시작 ===\n",
      "데이터 수: 266개\n",
      "\n",
      "Luxury 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.1999\n",
      "- 배터리용량: 0.1838\n",
      "- 연식(년): 0.1625\n",
      "- 차량상태: 0.0981\n",
      "- 배터리_연식_효율: 0.0709\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 82.0000\n",
      "- 배터리_효율: 71.0000\n",
      "- 배터리효율_보증기간: 62.0000\n",
      "- 배터리성능지수: 59.0000\n",
      "- 모델_효율_차이: 50.0000\n",
      "\n",
      "=== High-Premium 세그먼트 최적화 시작 ===\n",
      "데이터 수: 293개\n",
      "\n",
      "High-Premium 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.6771\n",
      "- 배터리효율_보증기간: 0.0981\n",
      "- 주행거리(km): 0.0977\n",
      "- 주행거리_배터리_보정: 0.0623\n",
      "- 배터리_연식_효율: 0.0249\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리_배터리_보정: 387.0000\n",
      "- 배터리용량: 378.0000\n",
      "- 차량상태: 282.0000\n",
      "- 배터리_효율: 244.0000\n",
      "- 주행거리_편차: 231.0000\n",
      "\n",
      "=== High 세그먼트 최적화 시작 ===\n",
      "데이터 수: 811개\n",
      "\n",
      "High 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 제조사: 0.6022\n",
      "- 모델: 0.1266\n",
      "- 배터리용량: 0.0697\n",
      "- 차량상태: 0.0584\n",
      "- 보증기간(년): 0.0576\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 261.0000\n",
      "- 보증기간(년): 231.0000\n",
      "- 제조사: 162.0000\n",
      "- 배터리효율_보증기간: 158.0000\n",
      "- 주행거리(km): 121.0000\n",
      "\n",
      "=== Mid-High 세그먼트 최적화 시작 ===\n",
      "데이터 수: 743개\n",
      "\n",
      "Mid-High 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.4592\n",
      "- 모델: 0.1800\n",
      "- 배터리_효율: 0.0756\n",
      "- 모델별_주행효율: 0.0556\n",
      "- 배터리_연식_효율: 0.0389\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 291.0000\n",
      "- 모델_효율_차이: 284.0000\n",
      "- 배터리효율_보증기간: 224.0000\n",
      "- 배터리성능지수: 189.0000\n",
      "- 주행거리(km): 186.0000\n",
      "\n",
      "=== Mid 세그먼트 최적화 시작 ===\n",
      "데이터 수: 866개\n",
      "\n",
      "Mid 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델: 0.6891\n",
      "- 제조사: 0.0846\n",
      "- 연식_보증_비율: 0.0725\n",
      "- 보증기간(년): 0.0525\n",
      "- 차량상태: 0.0399\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 626.0000\n",
      "- 배터리용량: 471.0000\n",
      "- 주행거리_편차: 360.0000\n",
      "- 보증기간(년): 325.0000\n",
      "- 배터리효율_보증기간: 321.0000\n",
      "\n",
      "=== Mid-Entry 세그먼트 최적화 시작 ===\n",
      "데이터 수: 1373개\n",
      "\n",
      "Mid-Entry 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델: 0.4920\n",
      "- 모델_주행거리_평균: 0.1374\n",
      "- 모델별_주행효율: 0.1092\n",
      "- 차량상태: 0.0955\n",
      "- 보증기간(년): 0.0702\n",
      "\n",
      "LightGBM:\n",
      "- 보증기간(년): 527.0000\n",
      "- 주행거리(km): 364.0000\n",
      "- 모델_효율_차이: 263.0000\n",
      "- 배터리용량: 209.0000\n",
      "- 배터리효율_보증기간: 203.0000\n",
      "\n",
      "=== Entry 세그먼트 최적화 시작 ===\n",
      "데이터 수: 622개\n",
      "\n",
      "Entry 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.7296\n",
      "- 주행거리(km): 0.1548\n",
      "- 보증기간(년): 0.0792\n",
      "- 배터리효율_보증기간: 0.0101\n",
      "- km_per_year: 0.0042\n",
      "\n",
      "LightGBM:\n",
      "- 보증기간(년): 518.0000\n",
      "- 배터리_효율: 376.0000\n",
      "- 주행거리_편차: 373.0000\n",
      "- 차량상태: 246.0000\n",
      "- 배터리효율_보증기간: 242.0000\n",
      "\n",
      "=== Basic 세그먼트 최적화 시작 ===\n",
      "데이터 수: 728개\n",
      "\n",
      "Basic 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델별_주행효율: 0.2435\n",
      "- 모델: 0.1566\n",
      "- 모델_주행거리_평균: 0.0875\n",
      "- 보증기간(년): 0.0636\n",
      "- 제조사: 0.0345\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 183.0000\n",
      "- 배터리효율_보증기간: 172.0000\n",
      "- 보증기간(년): 159.0000\n",
      "- 배터리용량: 147.0000\n",
      "- 모델_효율_차이: 145.0000\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트                 데이터 수    XGBoost RMSE   LightGBM RMSE        앙상블 RMSE\n",
      "----------------------------------------------------------------------\n",
      "Premium                 80          0.3169          0.3212          0.3179\n",
      "Luxury                  69          3.4358          3.6759          3.5133\n",
      "High-Premium            68          3.0457          4.0607          3.5533\n",
      "High                   205          0.5465          0.5396          0.5340\n",
      "Mid-High               202          0.8336          1.5232          1.2111\n",
      "Mid                    205          0.5953          0.5857          0.5492\n",
      "Mid-Entry              333          2.1534          2.7829          2.3207\n",
      "Entry                  141          0.6407          0.6348          0.6359\n",
      "Basic                  197          2.6528          2.4964          2.5405\n",
      "======================================================================\n",
      "전체                    1500                                          1.8721\n",
      "\n",
      "테스트 데이터 예측 중...\n",
      "제출 파일 생성 완료: submission12.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SegmentBasedModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segments = {\n",
    "            'Premium': {'min_price': 150, 'models': ['TayGTS']},\n",
    "            'Luxury': {'min_price': 120, 'models': ['TayCT', 'TayS', 'TayX']},\n",
    "            'High-Premium': {'min_price': 95, 'models': ['Tay', 'RSe', 'EQS']},\n",
    "            'High': {'min_price': 80, 'models': ['RSeTGT', 'MX', 'iX']},\n",
    "            'Mid-High': {'min_price': 65, 'models': ['MS', 'MY', 'eT']},\n",
    "            'Mid': {'min_price': 50, 'models': ['i5', 'Q4eT', 'M3']},\n",
    "            'Mid-Entry': {'min_price': 35, 'models': ['EV6', 'ID4', 'ION6', 'ION5']},\n",
    "            'Entry': {'min_price': 25, 'models': ['Niro', 'KNE']},\n",
    "            'Basic': {'min_price': 0, 'models': ['i3', 'Soul', 'IONIQ', 'Leaf', 'Bolt']}\n",
    "        }\n",
    "        self.segment_models = {}\n",
    "        self.price_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def assign_segment(self, model):\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "        \n",
    "    def add_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # Luxury 세그먼트를 위한 특성\n",
    "        df['연식_보증_비율'] = df['연식(년)'] / df['보증기간(년)']\n",
    "        df['연식별_배터리효율'] = df['배터리_효율'] * df['차량연식']\n",
    "        df['배터리효율_보증기간'] = df['배터리_효율'] * df['보증기간(년)']  # 새로운 특성\n",
    "        \n",
    "        # High-Premium 세그먼트를 위한 특성\n",
    "        df['상태_배터리_점수'] = df.apply(\n",
    "            lambda x: x['배터리용량'] * (2 if x['차량상태'] == '우수' else 1),\n",
    "            axis=1\n",
    "        )\n",
    "        df['주행거리_연식_비율'] = df['주행거리(km)'] / df['차량연식']  # 새로운 특성\n",
    "        \n",
    "        # Mid-Entry와 Basic 세그먼트를 위한 특성\n",
    "        df['모델별_주행효율'] = df.groupby('모델')['배터리_효율'].transform('mean')\n",
    "        df['모델_효율_차이'] = df['배터리_효율'] - df['모델별_주행효율']\n",
    "        df['모델_주행거리_평균'] = df.groupby('모델')['주행거리(km)'].transform('mean')  # 새로운 특성\n",
    "        df['주행거리_편차'] = df['주행거리(km)'] - df['모델_주행거리_평균']  # 새로운 특성\n",
    "        \n",
    "        # 공통 개선 특성\n",
    "        df['주행거리_배터리_보정'] = df['주행거리(km)'] / (df['배터리용량'] * df['차량연식'])\n",
    "        df['보증_연식_효율'] = df['잔여보증기간'] * df['배터리_효율']\n",
    "        df['배터리성능지수'] = (df['배터리용량'] * df['배터리_효율']) / df['차량연식']  # 새로운 특성\n",
    "        \n",
    "        # 가격 통계는 학습 데이터일 때만 계산\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "            # 모델별 통계\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['모델'] = {\n",
    "                'mean': model_stats['mean'].to_dict(),\n",
    "                'std': model_stats['std'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 제조사별 통계\n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['제조사'] = {\n",
    "                'mean': manufacturer_stats['mean'].to_dict(),\n",
    "                'std': manufacturer_stats['std'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 세그먼트별 통계\n",
    "            segment_stats = df.groupby('segment')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['segment'] = {\n",
    "                'mean': segment_stats['mean'].to_dict(),\n",
    "                'std': segment_stats['std'].to_dict()\n",
    "            }\n",
    "        \n",
    "        # 통계 기반 특성\n",
    "        if '모델' in self.price_stats:\n",
    "            df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "            df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "            df['모델별_가격변동성'] = df.apply(\n",
    "                lambda x: x['모델별_가격편차'] / x['모델별_평균가격'] if x['모델별_평균가격'] != 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "            df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "            df['제조사별_가격변동성'] = df.apply(\n",
    "                lambda x: x['제조사별_가격편차'] / x['제조사별_평균가격'] if x['제조사별_평균가격'] != 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "            \n",
    "            df['세그먼트별_평균가격'] = df['segment'].map(self.price_stats['segment']['mean']).fillna(0)\n",
    "            df['세그먼트별_가격편차'] = df['segment'].map(self.price_stats['segment']['std']).fillna(0)\n",
    "            df['세그먼트내_상대가격'] = df.apply(\n",
    "                lambda x: (x['모델별_평균가격'] - x['세그먼트별_평균가격']) / x['세그먼트별_가격편차']\n",
    "                if x['세그먼트별_가격편차'] != 0 else 0,\n",
    "                axis=1\n",
    "            )\n",
    "        else:\n",
    "            df['모델별_평균가격'] = 0\n",
    "            df['모델별_가격편차'] = 0\n",
    "            df['모델별_가격변동성'] = 0\n",
    "            df['제조사별_평균가격'] = 0\n",
    "            df['제조사별_가격편차'] = 0\n",
    "            df['제조사별_가격변동성'] = 0\n",
    "            df['세그먼트별_평균가격'] = 0\n",
    "            df['세그먼트별_가격편차'] = 0\n",
    "            df['세그먼트내_상대가격'] = 0\n",
    "    # 무한대 값과 이상치 처리\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            # 무한대 값을 NaN으로 변환\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "            # NaN을 해당 컬럼의 평균값으로 대체\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "            # 이상치 처리 (99 percentile 기준)\n",
    "            q99 = df[col].quantile(0.99)\n",
    "            df[col] = df[col].clip(upper=q99)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        # 레이블 인코딩\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        # 피처 엔지니어링\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def optimize_xgboost(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300, 400],\n",
    "            'learning_rate': [0.01, 0.03, 0.05, 0.07],\n",
    "            'max_depth': [3, 4, 5, 6],\n",
    "            'min_child_weight': [3, 5, 7, 9],\n",
    "            'gamma': [0, 0.1, 0.2, 0.3],\n",
    "            'subsample': [0.7, 0.8, 0.9],\n",
    "            'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = XGBRegressor(\n",
    "            random_state=42,\n",
    "            missing=np.nan,\n",
    "            tree_method='hist',\n",
    "            max_bin=256\n",
    "        )\n",
    "        \n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def optimize_lightgbm(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300, 400],\n",
    "            'learning_rate': [0.01, 0.03, 0.05, 0.07],\n",
    "            'max_depth': [3, 4, 6, 8],\n",
    "            'num_leaves': [31, 63, 127],\n",
    "            'min_child_samples': [20, 30, 40, 50],\n",
    "            'subsample': [0.7, 0.8, 0.9],\n",
    "            'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = LGBMRegressor(\n",
    "            random_state=42,\n",
    "            verbose=-1,\n",
    "            min_data_in_leaf=20\n",
    "        )\n",
    "        \n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    def fit(self, X_train, y_train):\n",
    "        # 데이터 전처리\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 특성 선택 (새로 추가된 특성들 포함)\n",
    "        self.feature_columns = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간', '제조사',\n",
    "            '모델별_평균가격', '모델별_가격편차', '모델별_가격변동성',\n",
    "            '제조사별_평균가격', '제조사별_가격편차', '제조사별_가격변동성',\n",
    "            '연식_보증_비율', '연식별_배터리효율', '상태_배터리_점수',\n",
    "            '모델별_주행효율', '모델_효율_차이', '주행거리_배터리_보정',\n",
    "            '보증_연식_효율', '세그먼트별_평균가격', '세그먼트별_가격편차',\n",
    "            '세그먼트내_상대가격', '배터리효율_보증기간', '주행거리_연식_비율',\n",
    "            '모델_주행거리_평균', '주행거리_편차', '배터리성능지수'\n",
    "        ]\n",
    "        \n",
    "        # 세그먼트별로 모델 학습\n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = train_processed[mask][self.feature_columns]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            print(f\"데이터 수: {len(X)}개\")\n",
    "            \n",
    "            # XGBoost와 LightGBM 최적화\n",
    "            xgb_model = self.optimize_xgboost(X, y, segment)\n",
    "            lgb_model = self.optimize_lightgbm(X, y, segment)\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'xgb': xgb_model,\n",
    "                'lgb': lgb_model\n",
    "            }\n",
    "            \n",
    "            # 특성 중요도 저장\n",
    "            self.feature_importance[segment] = {\n",
    "                'xgb': dict(zip(self.feature_columns, xgb_model.feature_importances_)),\n",
    "                'lgb': dict(zip(self.feature_columns, lgb_model.feature_importances_))\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{segment} 세그먼트 Top 5 중요 특성:\")\n",
    "            xgb_importance = sorted(self.feature_importance[segment]['xgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            lgb_importance = sorted(self.feature_importance[segment]['lgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            \n",
    "            print(\"XGBoost:\")\n",
    "            for feat, imp in xgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "            \n",
    "            print(\"\\nLightGBM:\")\n",
    "            for feat, imp in lgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        # 데이터 전처리\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        # 세그먼트별 최적 가중치\n",
    "        weights = {\n",
    "            'Luxury': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'High-Premium': {'xgb': 0.3, 'lgb': 0.7},\n",
    "            'Mid-Entry': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            'Basic': {'xgb': 0.6, 'lgb': 0.4}\n",
    "        }\n",
    "        \n",
    "        # 세그먼트별 예측\n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = test_processed[mask][self.feature_columns]\n",
    "            \n",
    "            # XGBoost와 LightGBM 예측값\n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 세그먼트별 가중치 적용\n",
    "            if segment in weights:\n",
    "                w = weights[segment]\n",
    "                predictions[mask] = w['xgb'] * xgb_pred + w['lgb'] * lgb_pred\n",
    "            else:\n",
    "                predictions[mask] = 0.4 * xgb_pred + 0.6 * lgb_pred\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        # 데이터 전처리\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<15} {'데이터 수':>10} {'XGBoost RMSE':>15} {'LightGBM RMSE':>15} {'앙상블 RMSE':>15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # 세그먼트별 가중치\n",
    "        weights = {\n",
    "            'Luxury': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'High-Premium': {'xgb': 0.3, 'lgb': 0.7},\n",
    "            'Mid-Entry': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            'Basic': {'xgb': 0.6, 'lgb': 0.4}\n",
    "        }\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = val_processed[mask][self.feature_columns]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            # XGBoost와 LightGBM 예측\n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 앙상블 예측 (세그먼트별 가중치 적용)\n",
    "            if segment in weights:\n",
    "                w = weights[segment]\n",
    "                ensemble_pred = w['xgb'] * xgb_pred + w['lgb'] * lgb_pred\n",
    "            else:\n",
    "                ensemble_pred = 0.4 * xgb_pred + 0.6 * lgb_pred\n",
    "            \n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            # RMSE 계산\n",
    "            xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "            lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            \n",
    "            # 결과 출력\n",
    "            print(f\"{segment:<15} {mask.sum():>10d} {xgb_rmse:>15.4f} {lgb_rmse:>15.4f} {ensemble_rmse:>15.4f}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'xgb_rmse': xgb_rmse,\n",
    "                'lgb_rmse': lgb_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse\n",
    "            }\n",
    "        \n",
    "        # 전체 RMSE 계산\n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'전체':<15} {len(y_val):>10d} {'':>15} {'':>15} {total_rmse:>15.4f}\")\n",
    "        \n",
    "        return segment_metrics, total_rmse\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    # 'id' 컬럼 확인 및 추가\n",
    "    if 'ID' not in test.columns:\n",
    "        test['ID'] = range(len(test))\n",
    "    \n",
    "    # 학습/검증 분할\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # 모델 학습\n",
    "    print(\"세그먼트 기반 모델 학습 시작...\")\n",
    "    model = SegmentBasedModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 성능 평가\n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    \n",
    "    # 테스트 예측 및 제출 파일 생성\n",
    "    print(\"\\n테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission13.csv', index=False, encoding='utf-8')\n",
    "    print(\"제출 파일 생성 완료: submission12.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세그먼트 기반 모델 학습 시작...\n",
      "\n",
      "=== Premium 세그먼트 최적화 시작 ===\n",
      "데이터 수: 295개\n",
      "\n",
      "Premium 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 배터리용량: 0.3421\n",
      "- 배터리_연식_효율: 0.3185\n",
      "- 주행거리(km): 0.1851\n",
      "- 배터리_효율: 0.1206\n",
      "- km_per_year: 0.0174\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_연식_효율: 186.0000\n",
      "- 주행거리(km): 175.0000\n",
      "- 배터리_효율: 155.0000\n",
      "- 배터리용량: 31.0000\n",
      "- km_per_year: 16.0000\n",
      "\n",
      "=== Luxury 세그먼트 최적화 시작 ===\n",
      "데이터 수: 266개\n",
      "\n",
      "Luxury 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량연식: 0.2142\n",
      "- 연식(년): 0.1783\n",
      "- 보증기간(년): 0.1348\n",
      "- 차량상태: 0.1043\n",
      "- 배터리_연식_효율: 0.0897\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 187.0000\n",
      "- 주행거리(km): 166.0000\n",
      "- 연식(년): 39.0000\n",
      "- 배터리_연식_효율: 33.0000\n",
      "- km_per_year: 16.0000\n",
      "\n",
      "=== High-Premium 세그먼트 최적화 시작 ===\n",
      "데이터 수: 293개\n",
      "\n",
      "High-Premium 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.5387\n",
      "- km_per_year: 0.2619\n",
      "- 주행거리(km): 0.1510\n",
      "- 배터리용량: 0.0155\n",
      "- 배터리_연식_효율: 0.0140\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 809.0000\n",
      "- 배터리_연식_효율: 630.0000\n",
      "- 주행거리(km): 574.0000\n",
      "- 차량상태: 294.0000\n",
      "- 배터리용량: 77.0000\n",
      "\n",
      "=== High 세그먼트 최적화 시작 ===\n",
      "데이터 수: 811개\n",
      "\n",
      "High 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.4624\n",
      "- 제조사: 0.3982\n",
      "- 보증기간(년): 0.0317\n",
      "- 모델: 0.0251\n",
      "- km_per_year: 0.0212\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_연식_효율: 328.0000\n",
      "- 주행거리(km): 252.0000\n",
      "- 보증기간(년): 252.0000\n",
      "- 제조사: 173.0000\n",
      "- 배터리_효율: 170.0000\n",
      "\n",
      "=== Mid-High 세그먼트 최적화 시작 ===\n",
      "데이터 수: 743개\n",
      "\n",
      "Mid-High 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.6890\n",
      "- km_per_year: 0.0852\n",
      "- 모델: 0.0798\n",
      "- 주행거리(km): 0.0342\n",
      "- 배터리용량: 0.0301\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 817.0000\n",
      "- 배터리_효율: 770.0000\n",
      "- 배터리_연식_효율: 489.0000\n",
      "- km_per_year: 354.0000\n",
      "- 보증기간(년): 262.0000\n",
      "\n",
      "=== Mid 세그먼트 최적화 시작 ===\n",
      "데이터 수: 866개\n",
      "\n",
      "Mid 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 제조사: 0.6056\n",
      "- 차량상태: 0.2342\n",
      "- 보증기간(년): 0.0355\n",
      "- 배터리용량: 0.0234\n",
      "- 모델: 0.0217\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 324.0000\n",
      "- 배터리_연식_효율: 258.0000\n",
      "- 보증기간(년): 155.0000\n",
      "- 배터리_효율: 133.0000\n",
      "- 제조사: 109.0000\n",
      "\n",
      "=== Mid-Entry 세그먼트 최적화 시작 ===\n",
      "데이터 수: 1373개\n",
      "\n",
      "Mid-Entry 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델: 0.5462\n",
      "- 보증기간(년): 0.2307\n",
      "- 제조사: 0.0816\n",
      "- 차량상태: 0.0472\n",
      "- 배터리_연식_효율: 0.0323\n",
      "\n",
      "LightGBM:\n",
      "- 주행거리(km): 890.0000\n",
      "- 배터리_효율: 436.0000\n",
      "- 보증기간(년): 414.0000\n",
      "- 배터리_연식_효율: 302.0000\n",
      "- 모델: 300.0000\n",
      "\n",
      "=== Entry 세그먼트 최적화 시작 ===\n",
      "데이터 수: 622개\n",
      "\n",
      "Entry 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.6009\n",
      "- km_per_year: 0.2066\n",
      "- 보증기간(년): 0.1014\n",
      "- 주행거리(km): 0.0776\n",
      "- 배터리_효율: 0.0031\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 241.0000\n",
      "- 보증기간(년): 128.0000\n",
      "- 주행거리(km): 117.0000\n",
      "- 차량상태: 60.0000\n",
      "- 배터리_연식_효율: 59.0000\n",
      "\n",
      "=== Basic 세그먼트 최적화 시작 ===\n",
      "데이터 수: 728개\n",
      "\n",
      "Basic 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델: 0.3972\n",
      "- 보증기간(년): 0.0856\n",
      "- 제조사: 0.0768\n",
      "- 배터리용량: 0.0745\n",
      "- 배터리_연식_효율: 0.0583\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_연식_효율: 160.0000\n",
      "- 주행거리(km): 90.0000\n",
      "- 보증기간(년): 88.0000\n",
      "- 모델: 51.0000\n",
      "- 제조사: 35.0000\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트                 데이터 수    XGBoost RMSE   LightGBM RMSE        앙상블 RMSE\n",
      "----------------------------------------------------------------------\n",
      "Premium                 80          0.3287          0.3138          0.3178\n",
      "Luxury                  69          3.4210          3.4574          3.4355\n",
      "High-Premium            68          2.8721          2.9433          2.8811\n",
      "High                   205          0.5350          0.5043          0.5103\n",
      "Mid-High               202          0.6052          0.8484          0.6547\n",
      "Mid                    205          0.5274          0.5567          0.5346\n",
      "Mid-Entry              333          0.4888          0.5093          0.4937\n",
      "Entry                  141          0.6245          0.6249          0.6208\n",
      "Basic                  197          2.4637          2.4398          2.4492\n",
      "======================================================================\n",
      "전체                    1500                                          1.3911\n",
      "\n",
      "테스트 데이터 예측 중...\n",
      "제출 파일 생성 완료: submission14.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SegmentBasedModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segments = {\n",
    "            'Premium': {'min_price': 150, 'models': ['TayGTS']},\n",
    "            'Luxury': {'min_price': 120, 'models': ['TayCT', 'TayS', 'TayX']},\n",
    "            'High-Premium': {'min_price': 95, 'models': ['Tay', 'RSe', 'EQS']},\n",
    "            'High': {'min_price': 80, 'models': ['RSeTGT', 'MX', 'iX']},\n",
    "            'Mid-High': {'min_price': 65, 'models': ['MS', 'MY', 'eT']},\n",
    "            'Mid': {'min_price': 50, 'models': ['i5', 'Q4eT', 'M3']},\n",
    "            'Mid-Entry': {'min_price': 35, 'models': ['EV6', 'ID4', 'ION6', 'ION5']},\n",
    "            'Entry': {'min_price': 25, 'models': ['Niro', 'KNE']},\n",
    "            'Basic': {'min_price': 0, 'models': ['i3', 'Soul', 'IONIQ', 'Leaf', 'Bolt']}\n",
    "        }\n",
    "        # 세그먼트별 최적화된 특성 정의\n",
    "        self.segment_features = {\n",
    "            'Premium': ['차량상태', '배터리용량', '배터리_연식_효율', '주행거리(km)', '배터리_효율'],\n",
    "            'Luxury': ['보증기간(년)', '연식(년)', '배터리용량', '차량상태', '배터리_효율', '주행거리(km)'],\n",
    "            'High-Premium': ['차량상태', '주행거리(km)', 'km_per_year', '배터리용량', '배터리_연식_효율'],\n",
    "            'High': ['제조사', '모델', '차량상태', '배터리용량', '보증기간(년)'],\n",
    "            'Mid-High': ['차량상태', '모델', '배터리_효율', '배터리용량', '주행거리(km)'],\n",
    "            'Mid': ['모델', '제조사', '보증기간(년)', '차량상태', '배터리용량'],\n",
    "            'Mid-Entry': ['모델', '보증기간(년)', '주행거리(km)', '차량상태', '배터리용량'],\n",
    "            'Entry': ['차량상태', '주행거리(km)', '보증기간(년)', '배터리용량', '배터리_효율'],\n",
    "            'Basic': ['모델', '보증기간(년)', '차량상태', '배터리용량', '주행거리(km)']\n",
    "        }\n",
    "        self.segment_models = {}\n",
    "        self.price_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def assign_segment(self, model):\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "        \n",
    "    def add_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # 가격 통계는 학습 데이터일 때만 계산\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['모델'] = {\n",
    "                'mean': model_stats['mean'].to_dict(),\n",
    "                'std': model_stats['std'].to_dict()\n",
    "            }\n",
    "            \n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['제조사'] = {\n",
    "                'mean': manufacturer_stats['mean'].to_dict(),\n",
    "                'std': manufacturer_stats['std'].to_dict()\n",
    "            }\n",
    "        \n",
    "        if '모델' in self.price_stats:\n",
    "            df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "            df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "            df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "            df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "        else:\n",
    "            df['모델별_평균가격'] = 0\n",
    "            df['모델별_가격편차'] = 0\n",
    "            df['제조사별_평균가격'] = 0\n",
    "            df['제조사별_가격편차'] = 0\n",
    "\n",
    "        # 무한대 값과 이상치 처리\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "            q99 = df[col].quantile(0.99)\n",
    "            df[col] = df[col].clip(upper=q99)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def optimize_xgboost(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300, 400],\n",
    "            'learning_rate': [0.01, 0.03, 0.05, 0.07],\n",
    "            'max_depth': [3, 4, 5, 6],\n",
    "            'min_child_weight': [3, 5, 7, 9],\n",
    "            'gamma': [0, 0.1, 0.2, 0.3],\n",
    "            'subsample': [0.7, 0.8, 0.9],\n",
    "            'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = XGBRegressor(\n",
    "            random_state=42,\n",
    "            missing=np.nan,\n",
    "            tree_method='hist',\n",
    "            max_bin=256\n",
    "        )\n",
    "        \n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def optimize_lightgbm(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300, 400],\n",
    "            'learning_rate': [0.01, 0.03, 0.05, 0.07],\n",
    "            'max_depth': [3, 4, 6, 8],\n",
    "            'num_leaves': [31, 63, 127],\n",
    "            'min_child_samples': [20, 30, 40, 50],\n",
    "            'subsample': [0.7, 0.8, 0.9],\n",
    "            'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = LGBMRegressor(\n",
    "            random_state=42,\n",
    "            verbose=-1,\n",
    "            min_data_in_leaf=20\n",
    "        )\n",
    "        \n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 기본 특성\n",
    "        self.base_features = [\n",
    "        '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식',\n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간', '제조사',\n",
    "            '모델별_평균가격', '모델별_가격편차', '제조사별_평균가격', '제조사별_가격편차',\n",
    "            '품질점수', 'P사_브랜드파워', 'T사_기술가치', 'SW_업데이트_가치',\n",
    "            'H사_서비스망', 'K사_서비스망', '국내_AS_가치', '수입_프리미엄',\n",
    "            '유럽인증_가치', 'P사_가격프리미엄'\n",
    "        ]\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            # 세그먼트별 최적화된 특성 사용\n",
    "            selected_features = list(set(self.base_features + self.segment_features[segment]))\n",
    "            X = train_processed[mask][selected_features]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            print(f\"데이터 수: {len(X)}개\")\n",
    "            \n",
    "            xgb_model = self.optimize_xgboost(X, y, segment)\n",
    "            lgb_model = self.optimize_lightgbm(X, y, segment)\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'xgb': xgb_model,\n",
    "                'lgb': lgb_model,\n",
    "                'features': selected_features\n",
    "            }\n",
    "            \n",
    "            self.feature_importance[segment] = {\n",
    "                'xgb': dict(zip(selected_features, xgb_model.feature_importances_)),\n",
    "                'lgb': dict(zip(selected_features, lgb_model.feature_importances_))\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{segment} 세그먼트 Top 5 중요 특성:\")\n",
    "            xgb_importance = sorted(self.feature_importance[segment]['xgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            lgb_importance = sorted(self.feature_importance[segment]['lgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            \n",
    "            print(\"XGBoost:\")\n",
    "            for feat, imp in xgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "            \n",
    "            print(\"\\nLightGBM:\")\n",
    "            for feat, imp in lgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        # 조정된 세그먼트별 가중치\n",
    "        weights = {\n",
    "            'Premium': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Luxury': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'High-Premium': {'xgb': 0.7, 'lgb': 0.3},  # XGBoost 비중 증가\n",
    "            'High': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Mid-High': {'xgb': 0.7, 'lgb': 0.3},     # XGBoost 비중 증가\n",
    "            'Mid': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Mid-Entry': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            'Entry': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Basic': {'xgb': 0.6, 'lgb': 0.4}\n",
    "        }\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = test_processed[mask][selected_features]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 세그먼트별 가중치 적용\n",
    "            w = weights.get(segment, {'xgb': 0.4, 'lgb': 0.6})\n",
    "            predictions[mask] = w['xgb'] * xgb_pred + w['lgb'] * lgb_pred\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<15} {'데이터 수':>10} {'XGBoost RMSE':>15} {'LightGBM RMSE':>15} {'앙상블 RMSE':>15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # 세그먼트별 가중치\n",
    "        weights = {\n",
    "            'Premium': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Luxury': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'High-Premium': {'xgb': 0.7, 'lgb': 0.3},\n",
    "            'High': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Mid-High': {'xgb': 0.7, 'lgb': 0.3},\n",
    "            'Mid': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Mid-Entry': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            'Entry': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Basic': {'xgb': 0.6, 'lgb': 0.4}\n",
    "        }\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = val_processed[mask][selected_features]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            w = weights.get(segment, {'xgb': 0.4, 'lgb': 0.6})\n",
    "            ensemble_pred = w['xgb'] * xgb_pred + w['lgb'] * lgb_pred\n",
    "            \n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "            lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            \n",
    "            print(f\"{segment:<15} {mask.sum():>10d} {xgb_rmse:>15.4f} {lgb_rmse:>15.4f} {ensemble_rmse:>15.4f}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'xgb_rmse': xgb_rmse,\n",
    "                'lgb_rmse': lgb_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse\n",
    "            }\n",
    "        \n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'전체':<15} {len(y_val):>10d} {'':>15} {'':>15} {total_rmse:>15.4f}\")\n",
    "        \n",
    "        return segment_metrics, total_rmse\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    if 'ID' not in test.columns:\n",
    "        test['ID'] = range(len(test))\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"세그먼트 기반 모델 학습 시작...\")\n",
    "    model = SegmentBasedModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    \n",
    "    print(\"\\n테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission14.csv', index=False, encoding='utf-8')\n",
    "    print(\"제출 파일 생성 완료: submission14.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "세그먼트 기반 모델 학습 시작...\n",
      "\n",
      "=== Premium-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 295개\n",
      "\n",
      "Premium-P 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 배터리용량: 0.6836\n",
      "- 배터리_연식_효율: 0.1785\n",
      "- 배터리_효율: 0.1276\n",
      "- km_per_year: 0.0059\n",
      "- 주행거리(km): 0.0019\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 208.0000\n",
      "- 배터리_효율: 178.0000\n",
      "- km_per_year: 156.0000\n",
      "- 배터리_연식_효율: 23.0000\n",
      "- 주행거리(km): 7.0000\n",
      "\n",
      "=== Luxury-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 266개\n",
      "\n",
      "Luxury-P 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량연식: 0.2233\n",
      "- 보증기간(년): 0.2132\n",
      "- 연식(년): 0.2121\n",
      "- 배터리_연식_효율: 0.1088\n",
      "- 배터리용량: 0.0766\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 177.0000\n",
      "- km_per_year: 163.0000\n",
      "- 보증기간(년): 40.0000\n",
      "- 배터리_연식_효율: 24.0000\n",
      "- 주행거리(km): 22.0000\n",
      "\n",
      "=== High-Premium-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 293개\n",
      "\n",
      "High-Premium-P 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 차량상태: 0.5378\n",
      "- km_per_year: 0.1997\n",
      "- 주행거리(km): 0.1953\n",
      "- 보증기간(년): 0.0392\n",
      "- 배터리_연식_효율: 0.0139\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 221.0000\n",
      "- km_per_year: 143.0000\n",
      "- 배터리용량: 139.0000\n",
      "- 차량상태: 59.0000\n",
      "- 주행거리(km): 18.0000\n",
      "\n",
      "=== High-Premium-A 세그먼트 최적화 시작 ===\n",
      "데이터 수: 315개\n",
      "\n",
      "High-Premium-A 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.9287\n",
      "- km_per_year: 0.0461\n",
      "- 배터리_효율: 0.0184\n",
      "- 주행거리(km): 0.0042\n",
      "- 배터리_연식_효율: 0.0026\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 181.0000\n",
      "- 보증기간(년): 133.0000\n",
      "- km_per_year: 128.0000\n",
      "- 주행거리(km): 19.0000\n",
      "- 차량상태: 15.0000\n",
      "\n",
      "=== High-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 198개\n",
      "\n",
      "High-T 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 배터리용량: 0.6109\n",
      "- 보증기간(년): 0.3559\n",
      "- 배터리_효율: 0.0150\n",
      "- km_per_year: 0.0132\n",
      "- 사고이력: 0.0015\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 422.0000\n",
      "- 배터리용량: 301.0000\n",
      "- km_per_year: 273.0000\n",
      "- 보증기간(년): 96.0000\n",
      "- 주행거리(km): 39.0000\n",
      "\n",
      "=== High-B 세그먼트 최적화 시작 ===\n",
      "데이터 수: 298개\n",
      "\n",
      "High-B 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 배터리_효율: 0.2111\n",
      "- 사고이력: 0.1740\n",
      "- km_per_year: 0.1604\n",
      "- 구동방식: 0.1559\n",
      "- 주행거리(km): 0.1512\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 1056.0000\n",
      "- 구동방식: 144.0000\n",
      "- 보증기간(년): 91.0000\n",
      "- 제조사: 0.0000\n",
      "- 배터리용량: 0.0000\n",
      "\n",
      "=== Mid-High-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 448개\n",
      "\n",
      "Mid-High-T 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.6419\n",
      "- 배터리_연식_효율: 0.1676\n",
      "- 배터리용량: 0.1526\n",
      "- km_per_year: 0.0335\n",
      "- 배터리_효율: 0.0017\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 212.0000\n",
      "- 보증기간(년): 118.0000\n",
      "- km_per_year: 101.0000\n",
      "- 배터리_효율: 81.0000\n",
      "- 주행거리(km): 18.0000\n",
      "\n",
      "=== Mid-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 234개\n",
      "\n",
      "Mid-T 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.7714\n",
      "- 배터리용량: 0.1714\n",
      "- 배터리_효율: 0.0334\n",
      "- km_per_year: 0.0129\n",
      "- 주행거리(km): 0.0067\n",
      "\n",
      "LightGBM:\n",
      "- 보증기간(년): 177.0000\n",
      "- 배터리_효율: 152.0000\n",
      "- km_per_year: 79.0000\n",
      "- 배터리용량: 72.0000\n",
      "- 주행거리(km): 6.0000\n",
      "\n",
      "=== Mid-B 세그먼트 최적화 시작 ===\n",
      "데이터 수: 329개\n",
      "\n",
      "Mid-B 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.3747\n",
      "- 배터리용량: 0.2020\n",
      "- 차량연식: 0.1868\n",
      "- 연식(년): 0.1438\n",
      "- 배터리_효율: 0.0437\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 229.0000\n",
      "- 배터리_효율: 214.0000\n",
      "- km_per_year: 176.0000\n",
      "- 보증기간(년): 58.0000\n",
      "- 구동방식: 28.0000\n",
      "\n",
      "=== Mid-A 세그먼트 최적화 시작 ===\n",
      "데이터 수: 303개\n",
      "\n",
      "Mid-A 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- km_per_year: 0.2625\n",
      "- 차량연식: 0.2452\n",
      "- 보증기간(년): 0.1839\n",
      "- 배터리용량: 0.1666\n",
      "- 연식(년): 0.1349\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 948.0000\n",
      "- km_per_year: 529.0000\n",
      "- 배터리용량: 192.0000\n",
      "- 보증기간(년): 145.0000\n",
      "- 차량연식: 85.0000\n",
      "\n",
      "=== Mid-A2 세그먼트 최적화 시작 ===\n",
      "데이터 수: 295개\n",
      "\n",
      "Mid-A2 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.5019\n",
      "- 배터리용량: 0.4524\n",
      "- 배터리_효율: 0.0334\n",
      "- km_per_year: 0.0059\n",
      "- 연식(년): 0.0025\n",
      "\n",
      "LightGBM:\n",
      "- 배터리용량: 383.0000\n",
      "- 배터리_효율: 313.0000\n",
      "- km_per_year: 246.0000\n",
      "- 주행거리(km): 31.0000\n",
      "- 보증기간(년): 22.0000\n",
      "\n",
      "=== Mid-Entry-K 세그먼트 최적화 시작 ===\n",
      "데이터 수: 296개\n",
      "\n",
      "Mid-Entry-K 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.9863\n",
      "- 구동방식: 0.0042\n",
      "- 배터리_효율: 0.0038\n",
      "- km_per_year: 0.0035\n",
      "- 사고이력: 0.0013\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 763.0000\n",
      "- km_per_year: 163.0000\n",
      "- 보증기간(년): 119.0000\n",
      "- 구동방식: 63.0000\n",
      "- 제조사: 0.0000\n",
      "\n",
      "=== Mid-Entry-V 세그먼트 최적화 시작 ===\n",
      "데이터 수: 498개\n",
      "\n",
      "Mid-Entry-V 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.8563\n",
      "- 배터리용량: 0.0926\n",
      "- 배터리_효율: 0.0316\n",
      "- km_per_year: 0.0073\n",
      "- 주행거리(km): 0.0052\n",
      "\n",
      "LightGBM:\n",
      "- 보증기간(년): 190.0000\n",
      "- km_per_year: 168.0000\n",
      "- 배터리_효율: 152.0000\n",
      "- 배터리용량: 102.0000\n",
      "- 주행거리(km): 16.0000\n",
      "\n",
      "=== Mid-Entry-H 세그먼트 최적화 시작 ===\n",
      "데이터 수: 579개\n",
      "\n",
      "Mid-Entry-H 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 모델: 0.8103\n",
      "- 보증기간(년): 0.1195\n",
      "- 배터리_효율: 0.0339\n",
      "- 배터리용량: 0.0169\n",
      "- km_per_year: 0.0107\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 209.0000\n",
      "- km_per_year: 156.0000\n",
      "- 배터리용량: 153.0000\n",
      "- 모델: 90.0000\n",
      "- 보증기간(년): 32.0000\n",
      "\n",
      "=== Entry-K 세그먼트 최적화 시작 ===\n",
      "데이터 수: 338개\n",
      "\n",
      "Entry-K 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.8788\n",
      "- km_per_year: 0.0524\n",
      "- 배터리용량: 0.0302\n",
      "- 주행거리(km): 0.0087\n",
      "- 배터리_효율: 0.0072\n",
      "\n",
      "LightGBM:\n",
      "- 보증기간(년): 557.0000\n",
      "- 배터리_효율: 510.0000\n",
      "- 배터리용량: 215.0000\n",
      "- km_per_year: 159.0000\n",
      "- 구동방식: 47.0000\n",
      "\n",
      "=== Entry-H 세그먼트 최적화 시작 ===\n",
      "데이터 수: 284개\n",
      "\n",
      "Entry-H 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 배터리용량: 0.7822\n",
      "- 보증기간(년): 0.1993\n",
      "- 배터리_연식_효율: 0.0064\n",
      "- 배터리_효율: 0.0028\n",
      "- 차량연식: 0.0025\n",
      "\n",
      "LightGBM:\n",
      "- km_per_year: 230.0000\n",
      "- 보증기간(년): 133.0000\n",
      "- 배터리_효율: 131.0000\n",
      "- 배터리용량: 60.0000\n",
      "- 주행거리(km): 30.0000\n",
      "\n",
      "=== Basic-B 세그먼트 최적화 시작 ===\n",
      "데이터 수: 308개\n",
      "\n",
      "Basic-B 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 배터리용량: 0.4711\n",
      "- 주행거리(km): 0.3610\n",
      "- km_per_year: 0.0722\n",
      "- 보증기간(년): 0.0610\n",
      "- 배터리_효율: 0.0225\n",
      "\n",
      "LightGBM:\n",
      "- 배터리_효율: 569.0000\n",
      "- 보증기간(년): 568.0000\n",
      "- km_per_year: 204.0000\n",
      "- 구동방식: 164.0000\n",
      "- 주행거리(km): 125.0000\n",
      "\n",
      "=== Basic-K 세그먼트 최적화 시작 ===\n",
      "데이터 수: 309개\n",
      "\n",
      "Basic-K 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- 보증기간(년): 0.8535\n",
      "- 배터리_효율: 0.0458\n",
      "- km_per_year: 0.0391\n",
      "- 배터리용량: 0.0269\n",
      "- 주행거리(km): 0.0109\n",
      "\n",
      "LightGBM:\n",
      "- 보증기간(년): 113.0000\n",
      "- 배터리_효율: 112.0000\n",
      "- km_per_year: 80.0000\n",
      "- 배터리용량: 47.0000\n",
      "- 구동방식: 23.0000\n",
      "\n",
      "=== Basic-H 세그먼트 최적화 시작 ===\n",
      "데이터 수: 111개\n",
      "\n",
      "Basic-H 세그먼트 Top 5 중요 특성:\n",
      "XGBoost:\n",
      "- km_per_year: 0.1339\n",
      "- 주행거리(km): 0.1305\n",
      "- 배터리_연식_효율: 0.1295\n",
      "- 배터리용량: 0.1208\n",
      "- 연식(년): 0.1130\n",
      "\n",
      "LightGBM:\n",
      "- km_per_year: 157.0000\n",
      "- 배터리용량: 110.0000\n",
      "- 차량연식: 26.0000\n",
      "- 주행거리(km): 20.0000\n",
      "- 배터리_연식_효율: 17.0000\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트                 데이터 수    XGBoost RMSE   LightGBM RMSE        앙상블 RMSE\n",
      "----------------------------------------------------------------------\n",
      "Premium-P               80          0.3178          0.3146          0.3161\n",
      "Luxury-P                69          3.4267          3.4521          3.4245\n",
      "High-Premium-P          68          2.8277          2.9325          2.8552\n",
      "High-Premium-A          70          0.3228          0.3272          0.3247\n",
      "High-T                  66          0.6751          0.7113          0.6701\n",
      "High-B                  69          0.5178          0.5251          0.5203\n",
      "Mid-High-T             118          0.6461          0.6304          0.6350\n",
      "Mid-T                   45          0.4368          0.4257          0.4289\n",
      "Mid-B                   85          0.6275          0.6210          0.6221\n",
      "Mid-A                   75          0.4329          0.4375          0.4336\n",
      "Mid-A2                  84          0.5178          0.5229          0.5131\n",
      "Mid-Entry-K             73          0.5820          0.5939          0.5866\n",
      "Mid-Entry-V            107          0.5834          0.5695          0.5753\n",
      "Mid-Entry-H            153          0.3449          0.3879          0.3665\n",
      "Entry-K                 60          0.6468          0.6384          0.6386\n",
      "Entry-H                 81          2.4193          2.4539          2.4398\n",
      "Basic-B                 80          0.3381          0.3407          0.3387\n",
      "Basic-K                 88          0.5530          0.5559          0.5525\n",
      "Basic-H                 29          6.0945          6.0657          6.0688\n",
      "======================================================================\n",
      "전체                    1500                                          1.4706\n",
      "\n",
      "테스트 데이터 예측 중...\n",
      "제출 파일 생성 완료: submission15.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class SegmentBasedModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.segments = {\n",
    "            # Premium 세그먼트\n",
    "            'Premium-P': {'min_price': 150, 'models': ['TayGTS'], 'brand': 'P사'},\n",
    "            \n",
    "            # Luxury 세그먼트\n",
    "            'Luxury-P': {'min_price': 120, 'models': ['TayCT'], 'brand': 'P사'},\n",
    "            \n",
    "            # High-Premium 세그먼트\n",
    "            'High-Premium-P': {'min_price': 95, 'models': ['Tay'], 'brand': 'P사'},\n",
    "            'High-Premium-A': {'min_price': 95, 'models': ['RSeTGT'], 'brand': 'A사'},\n",
    "            \n",
    "            # High 세그먼트\n",
    "            'High-T': {'min_price': 80, 'models': ['MX'], 'brand': 'T사'},\n",
    "            'High-B': {'min_price': 80, 'models': ['iX'], 'brand': 'B사'},\n",
    "            \n",
    "            # Mid-High 세그먼트\n",
    "            'Mid-High-T': {'min_price': 65, 'models': ['MS', 'MY'], 'brand': 'T사'},\n",
    "            \n",
    "            # Mid 세그먼트\n",
    "            'Mid-T': {'min_price': 50, 'models': ['M3'], 'brand': 'T사'},\n",
    "            'Mid-B': {'min_price': 50, 'models': ['i5'], 'brand': 'B사'},\n",
    "            'Mid-A': {'min_price': 50, 'models': ['Q4eT'], 'brand': 'A사'},\n",
    "            'Mid-A2': {'min_price': 50, 'models': ['eT'], 'brand': 'A사'},\n",
    "            \n",
    "            # Mid-Entry 세그먼트\n",
    "            'Mid-Entry-K': {'min_price': 35, 'models': ['EV6'], 'brand': 'K사'},\n",
    "            'Mid-Entry-V': {'min_price': 35, 'models': ['ID4'], 'brand': 'V사'},\n",
    "            'Mid-Entry-H': {'min_price': 35, 'models': ['ION6', 'ION5'], 'brand': 'H사'},\n",
    "            \n",
    "            # Entry 세그먼트\n",
    "            'Entry-K': {'min_price': 25, 'models': ['Niro'], 'brand': 'K사'},\n",
    "            'Entry-H': {'min_price': 25, 'models': ['KNE'], 'brand': 'H사'},\n",
    "            \n",
    "            # Basic 세그먼트\n",
    "            'Basic-B': {'min_price': 0, 'models': ['i3'], 'brand': 'B사'},\n",
    "            'Basic-K': {'min_price': 0, 'models': ['Soul'], 'brand': 'K사'},\n",
    "            'Basic-H': {'min_price': 0, 'models': ['IONIQ'], 'brand': 'H사'}\n",
    "        }\n",
    "        \n",
    "        self.segment_features = {\n",
    "            # P사 특화 특성 (프리미엄)\n",
    "            'Premium-P': ['차량상태', '배터리용량', '배터리_연식_효율', '주행거리(km)', '배터리_효율', '프리미엄_가치'],\n",
    "            'Luxury-P': ['보증기간(년)', '연식(년)', '배터리용량', '차량상태', '배터리_효율', '프리미엄_가치'],\n",
    "            'High-Premium-P': ['차량상태', '주행거리(km)', 'km_per_year', '배터리용량', '프리미엄_가치'],\n",
    "            \n",
    "            # T사 특화 특성\n",
    "            'High-T': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '기술가치'],\n",
    "            'Mid-High-T': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '기술가치'],\n",
    "            'Mid-T': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '기술가치'],\n",
    "            \n",
    "            # H사/K사 특화 특성\n",
    "            'Mid-Entry-K': ['모델', '보증기간(년)', '주행거리(km)', '차량상태', '국내_AS_가치'],\n",
    "            'Mid-Entry-H': ['모델', '보증기간(년)', '주행거리(km)', '차량상태', '국내_AS_가치'],\n",
    "            'Entry-K': ['차량상태', '주행거리(km)', '보증기간(년)', '국내_AS_가치'],\n",
    "            'Entry-H': ['차량상태', '주행거리(km)', '보증기간(년)', '국내_AS_가치'],\n",
    "            'Basic-K': ['차량상태', '주행거리(km)', '보증기간(년)', '국내_AS_가치'],\n",
    "            'Basic-H': ['차량상태', '주행거리(km)', '보증기간(년)', '국내_AS_가치'],\n",
    "            \n",
    "            # A사/B사/V사 특화 특성 (수입 프리미엄)\n",
    "            'High-Premium-A': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '수입_프리미엄'],\n",
    "            'High-B': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '수입_프리미엄'],\n",
    "            'Mid-B': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '수입_프리미엄'],\n",
    "            'Mid-A': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '수입_프리미엄'],\n",
    "            'Mid-A2': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '수입_프리미엄'],\n",
    "            'Mid-Entry-V': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '수입_프리미엄'],\n",
    "            'Basic-B': ['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '수입_프리미엄']\n",
    "        }\n",
    "        \n",
    "        self.segment_models = {}\n",
    "        self.price_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def assign_segment(self, model):\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "        \n",
    "    def add_features(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # 브랜드별 특화 피처\n",
    "        # P사(프리미엄) 특화 피처\n",
    "        df['프리미엄_가치'] = ((df['제조사'] == 'P사') & \n",
    "                           (df['차량상태'].isin(['우수', '양호']))).astype(int)\n",
    "        \n",
    "        # T사 특화 피처 (기술 가치)\n",
    "        df['기술가치'] = ((df['제조사'] == 'T사') & \n",
    "                       (df['잔여보증기간'] > 0)).astype(int)\n",
    "        \n",
    "        # 국내 브랜드(H사/K사) 특화 피처\n",
    "        df['국내_AS_가치'] = ((df['제조사'].isin(['H사', 'K사'])) & \n",
    "                          (df['잔여보증기간'] > 0)).astype(int)\n",
    "        \n",
    "        # 수입 브랜드 특화 피처\n",
    "        premium_brands = ['A사', 'B사', 'V사']\n",
    "        df['수입_프리미엄'] = ((df['제조사'].isin(premium_brands)) & \n",
    "                           (df['차량상태'].isin(['우수', '양호']))).astype(int)\n",
    "        \n",
    "        # 가격 통계는 학습 데이터일 때만 계산\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "            # 모델별 통계\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['모델'] = {\n",
    "                'mean': model_stats['mean'].to_dict(),\n",
    "                'std': model_stats['std'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 제조사별 통계\n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['제조사'] = {\n",
    "                'mean': manufacturer_stats['mean'].to_dict(),\n",
    "                'std': manufacturer_stats['std'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 브랜드 카테고리별 통계\n",
    "            df['brand_category'] = df['제조사'].map(lambda x: 'P사' if x == 'P사'\n",
    "                                                  else '국내' if x in ['H사', 'K사']\n",
    "                                                  else 'T사' if x == 'T사'\n",
    "                                                  else '수입')\n",
    "            brand_category_stats = df.groupby('brand_category')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['brand_category'] = {\n",
    "                'mean': brand_category_stats['mean'].to_dict(),\n",
    "                'std': brand_category_stats['std'].to_dict()\n",
    "            }\n",
    "        \n",
    "        if '모델' in self.price_stats:\n",
    "            df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "            df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "            df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "            df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "        else:\n",
    "            df['모델별_평균가격'] = 0\n",
    "            df['모델별_가격편차'] = 0\n",
    "            df['제조사별_평균가격'] = 0\n",
    "            df['제조사별_가격편차'] = 0\n",
    "\n",
    "        # 무한대 값과 이상치 처리\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "            q99 = df[col].quantile(0.99)\n",
    "            df[col] = df[col].clip(upper=q99)\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        df = df.copy()\n",
    "        \n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def optimize_xgboost(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 4, 5],\n",
    "            'min_child_weight': [3, 5, 7],\n",
    "            'gamma': [0, 0.1, 0.2],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = XGBRegressor(\n",
    "            random_state=42,\n",
    "            missing=np.nan,\n",
    "            tree_method='hist',\n",
    "            max_bin=256\n",
    "        )\n",
    "        \n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def optimize_lightgbm(self, X, y, segment):\n",
    "        param_grid = {\n",
    "            'n_estimators': [100, 200, 300],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'max_depth': [3, 4, 6],\n",
    "            'num_leaves': [31, 63],\n",
    "            'min_child_samples': [20, 30],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "        \n",
    "        model = LGBMRegressor(\n",
    "            random_state=42,\n",
    "            verbose=-1,\n",
    "            min_data_in_leaf=20\n",
    "        )\n",
    "        \n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 기본 특성\n",
    "        self.base_features = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식', \n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간', '제조사',\n",
    "            '모델별_평균가격', '모델별_가격편차', '제조사별_평균가격', '제조사별_가격편차'\n",
    "        ]\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            selected_features = list(set(self.base_features + self.segment_features.get(segment, [])))\n",
    "            X = train_processed[mask][selected_features]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            print(f\"데이터 수: {len(X)}개\")\n",
    "            \n",
    "            xgb_model = self.optimize_xgboost(X, y, segment)\n",
    "            lgb_model = self.optimize_lightgbm(X, y, segment)\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'xgb': xgb_model,\n",
    "                'lgb': lgb_model,\n",
    "                'features': selected_features\n",
    "            }\n",
    "            \n",
    "            self.feature_importance[segment] = {\n",
    "                'xgb': dict(zip(selected_features, xgb_model.feature_importances_)),\n",
    "                'lgb': dict(zip(selected_features, lgb_model.feature_importances_))\n",
    "            }\n",
    "            \n",
    "            print(f\"\\n{segment} 세그먼트 Top 5 중요 특성:\")\n",
    "            xgb_importance = sorted(self.feature_importance[segment]['xgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            lgb_importance = sorted(self.feature_importance[segment]['lgb'].items(), \n",
    "                                  key=lambda x: x[1], reverse=True)[:5]\n",
    "            \n",
    "            print(\"XGBoost:\")\n",
    "            for feat, imp in xgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "            \n",
    "            print(\"\\nLightGBM:\")\n",
    "            for feat, imp in lgb_importance:\n",
    "                print(f\"- {feat}: {imp:.4f}\")\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        # 브랜드별 세그먼트 가중치\n",
    "        weights = {\n",
    "            # P사 세그먼트 가중치 (프리미엄)\n",
    "            'Premium-P': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            'Luxury-P': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            'High-Premium-P': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            \n",
    "            # T사 세그먼트 가중치\n",
    "            'High-T': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-High-T': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-T': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            \n",
    "            # H사/K사 세그먼트 가중치\n",
    "            'Mid-Entry-K': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Mid-Entry-H': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Entry-K': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Entry-H': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Basic-K': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Basic-H': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            \n",
    "            # 수입차 세그먼트 가중치\n",
    "            'High-Premium-A': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'High-B': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-B': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-A': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-A2': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-Entry-V': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Basic-B': {'xgb': 0.5, 'lgb': 0.5}\n",
    "        }\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = test_processed[mask][selected_features]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            w = weights.get(segment, {'xgb': 0.5, 'lgb': 0.5})\n",
    "            predictions[mask] = w['xgb'] * xgb_pred + w['lgb'] * lgb_pred\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<15} {'데이터 수':>10} {'XGBoost RMSE':>15} {'LightGBM RMSE':>15} {'앙상블 RMSE':>15}\")\n",
    "        print(\"-\" * 70)\n",
    "        \n",
    "        # 브랜드별 세그먼트 가중치 (predict 메서드와 동일)\n",
    "        weights = {\n",
    "            # P사 세그먼트 가중치 (프리미엄)\n",
    "            'Premium-P': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            'Luxury-P': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            'High-Premium-P': {'xgb': 0.6, 'lgb': 0.4},\n",
    "            \n",
    "            # T사 세그먼트 가중치\n",
    "            'High-T': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-High-T': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-T': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            \n",
    "            # H사/K사 세그먼트 가중치\n",
    "            'Mid-Entry-K': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Mid-Entry-H': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Entry-K': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Entry-H': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Basic-K': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            'Basic-H': {'xgb': 0.4, 'lgb': 0.6},\n",
    "            \n",
    "            # 수입차 세그먼트 가중치\n",
    "            'High-Premium-A': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'High-B': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-B': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-A': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-A2': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Mid-Entry-V': {'xgb': 0.5, 'lgb': 0.5},\n",
    "            'Basic-B': {'xgb': 0.5, 'lgb': 0.5}\n",
    "        }\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = val_processed[mask][selected_features]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            w = weights.get(segment, {'xgb': 0.5, 'lgb': 0.5})\n",
    "            ensemble_pred = w['xgb'] * xgb_pred + w['lgb'] * lgb_pred\n",
    "            \n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "            lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            \n",
    "            print(f\"{segment:<15} {mask.sum():>10d} {xgb_rmse:>15.4f} {lgb_rmse:>15.4f} {ensemble_rmse:>15.4f}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'xgb_rmse': xgb_rmse,\n",
    "                'lgb_rmse': lgb_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse\n",
    "            }\n",
    "        \n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{'전체':<15} {len(y_val):>10d} {'':>15} {'':>15} {total_rmse:>15.4f}\")\n",
    "        \n",
    "        return segment_metrics, total_rmse\n",
    "\n",
    "def main():\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    if 'ID' not in test.columns:\n",
    "        test['ID'] = range(len(test))\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"세그먼트 기반 모델 학습 시작...\")\n",
    "    model = SegmentBasedModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    \n",
    "    print(\"\\n테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission15.csv', index=False, encoding='utf-8')\n",
    "    print(\"제출 파일 생성 완료: submission15.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "향상된 세그먼트 기반 모델 학습 시작...\n",
      "\n",
      "=== Premium-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 295개\n",
      "\n",
      "Premium-P 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 배터리용량: 0.5710\n",
      "- 배터리_연식_효율: 0.2520\n",
      "- 배터리_효율: 0.1585\n",
      "- 주행거리(km): 0.0102\n",
      "- km_per_year: 0.0066\n",
      "\n",
      "LGB:\n",
      "- 배터리용량: 193.0000\n",
      "- 배터리_효율: 169.0000\n",
      "- km_per_year: 134.0000\n",
      "- 배터리_연식_효율: 36.0000\n",
      "- 주행거리(km): 25.0000\n",
      "\n",
      "=== Luxury-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 266개\n",
      "\n",
      "Luxury-P 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.2463\n",
      "- 차량연식: 0.2251\n",
      "- 배터리_연식_효율: 0.1298\n",
      "- 배터리용량: 0.1148\n",
      "- 배터리_효율: 0.0632\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 184.0000\n",
      "- km_per_year: 166.0000\n",
      "- 보증기간(년): 36.0000\n",
      "- 배터리_연식_효율: 24.0000\n",
      "- 주행거리(km): 20.0000\n",
      "\n",
      "=== High-Premium-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 293개\n",
      "\n",
      "High-Premium-P 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.5839\n",
      "- 주행거리(km): 0.2142\n",
      "- km_per_year: 0.1497\n",
      "- 주행성능: 0.0297\n",
      "- 배터리_연식_효율: 0.0118\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 205.0000\n",
      "- km_per_year: 143.0000\n",
      "- 배터리용량: 135.0000\n",
      "- 차량상태: 61.0000\n",
      "- 주행거리(km): 25.0000\n",
      "\n",
      "=== High-Performance-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 646개\n",
      "\n",
      "High-Performance-T 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 배터리_연식_효율: 0.3349\n",
      "- 보증기간(년): 0.2734\n",
      "- 차량연식: 0.1389\n",
      "- 모델: 0.0939\n",
      "- 배터리용량: 0.0750\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 885.0000\n",
      "- km_per_year: 721.0000\n",
      "- 배터리용량: 348.0000\n",
      "- 보증기간(년): 342.0000\n",
      "- 주행거리(km): 140.0000\n",
      "\n",
      "=== Mid-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 234개\n",
      "\n",
      "Mid-T 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량연식: 0.3770\n",
      "- 보증기간(년): 0.3642\n",
      "- 배터리_연식_효율: 0.1730\n",
      "- 배터리용량: 0.0648\n",
      "- 배터리_효율: 0.0144\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 301.0000\n",
      "- km_per_year: 175.0000\n",
      "- 보증기간(년): 121.0000\n",
      "- 배터리용량: 83.0000\n",
      "- 주행거리(km): 31.0000\n",
      "\n",
      "=== Mid-Entry-Domestic 세그먼트 최적화 시작 ===\n",
      "데이터 수: 875개\n",
      "\n",
      "Mid-Entry-Domestic 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 제조사: 0.6409\n",
      "- 보증기간(년): 0.1881\n",
      "- 모델: 0.1559\n",
      "- km_per_year: 0.0048\n",
      "- 배터리용량: 0.0047\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 204.0000\n",
      "- 배터리용량: 112.0000\n",
      "- 보증기간(년): 112.0000\n",
      "- 모델: 82.0000\n",
      "- 제조사: 73.0000\n",
      "\n",
      "=== Entry-Domestic 세그먼트 최적화 시작 ===\n",
      "데이터 수: 622개\n",
      "\n",
      "Entry-Domestic 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.8592\n",
      "- km_per_year: 0.0954\n",
      "- 배터리_연식_효율: 0.0160\n",
      "- 배터리용량: 0.0057\n",
      "- 주행거리(km): 0.0041\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 236.0000\n",
      "- 보증기간(년): 149.0000\n",
      "- km_per_year: 143.0000\n",
      "- 제조사: 31.0000\n",
      "- 배터리용량: 30.0000\n",
      "\n",
      "=== Basic-Domestic 세그먼트 최적화 시작 ===\n",
      "데이터 수: 420개\n",
      "\n",
      "Basic-Domestic 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 모델: 0.2993\n",
      "- 제조사: 0.2088\n",
      "- 보증기간(년): 0.0718\n",
      "- 배터리_연식_효율: 0.0523\n",
      "- km_per_year: 0.0507\n",
      "\n",
      "LGB:\n",
      "- 배터리용량: 806.0000\n",
      "- km_per_year: 760.0000\n",
      "- 배터리_효율: 642.0000\n",
      "- 보증기간(년): 482.0000\n",
      "- 제조사: 189.0000\n",
      "\n",
      "=== High-Premium-Import 세그먼트 최적화 시작 ===\n",
      "데이터 수: 315개\n",
      "\n",
      "High-Premium-Import 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.7336\n",
      "- km_per_year: 0.2371\n",
      "- 배터리_효율: 0.0156\n",
      "- 주행거리(km): 0.0072\n",
      "- 배터리용량: 0.0034\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 202.0000\n",
      "- 보증기간(년): 133.0000\n",
      "- km_per_year: 111.0000\n",
      "- 차량상태: 15.0000\n",
      "- 주행거리(km): 12.0000\n",
      "\n",
      "=== High-Import 세그먼트 최적화 시작 ===\n",
      "데이터 수: 298개\n",
      "\n",
      "High-Import 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 배터리_효율: 0.1949\n",
      "- 주행거리(km): 0.1928\n",
      "- km_per_year: 0.1816\n",
      "- 사고이력: 0.1525\n",
      "- 구동방식: 0.1430\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 539.0000\n",
      "- km_per_year: 477.0000\n",
      "- 구동방식: 87.0000\n",
      "- 주행거리(km): 80.0000\n",
      "- 보증기간(년): 40.0000\n",
      "\n",
      "=== Mid-Import 세그먼트 최적화 시작 ===\n",
      "데이터 수: 927개\n",
      "\n",
      "Mid-Import 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 모델: 0.5105\n",
      "- 제조사: 0.1719\n",
      "- 배터리_연식_효율: 0.1173\n",
      "- 배터리용량: 0.0720\n",
      "- 보증기간(년): 0.0609\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 909.0000\n",
      "- km_per_year: 761.0000\n",
      "- 배터리용량: 582.0000\n",
      "- 보증기간(년): 235.0000\n",
      "- 차량연식: 111.0000\n",
      "\n",
      "=== Mid-Entry-Import 세그먼트 최적화 시작 ===\n",
      "데이터 수: 498개\n",
      "\n",
      "Mid-Entry-Import 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량연식: 0.5381\n",
      "- 보증기간(년): 0.2930\n",
      "- 배터리_연식_효율: 0.1172\n",
      "- 배터리용량: 0.0262\n",
      "- 배터리_효율: 0.0153\n",
      "\n",
      "LGB:\n",
      "- 보증기간(년): 208.0000\n",
      "- 배터리_효율: 167.0000\n",
      "- km_per_year: 160.0000\n",
      "- 배터리용량: 97.0000\n",
      "- 주행거리(km): 23.0000\n",
      "\n",
      "=== Basic-Import 세그먼트 최적화 시작 ===\n",
      "데이터 수: 308개\n",
      "\n",
      "Basic-Import 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 배터리용량: 0.5080\n",
      "- 보증기간(년): 0.1840\n",
      "- 배터리_효율: 0.1454\n",
      "- km_per_year: 0.0910\n",
      "- 주행거리(km): 0.0303\n",
      "\n",
      "LGB:\n",
      "- 보증기간(년): 635.0000\n",
      "- km_per_year: 393.0000\n",
      "- 배터리_효율: 307.0000\n",
      "- 구동방식: 182.0000\n",
      "- 주행성능: 83.0000\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트                      데이터 수     XGB RMSE     LGB RMSE     앙상블 RMSE    가중치(XGB/LGB)\n",
      "---------------------------------------------------------------------------\n",
      "Premium-P                    80       0.3174       0.3145       0.3156 0.50/0.50\n",
      "Luxury-P                     69       3.4228       3.4560       3.4263 0.50/0.50\n",
      "High-Premium-P               68       2.8435       2.9520       2.8823 0.50/0.50\n",
      "High-Performance-T          184       0.7502       0.7238       0.7191 0.60/0.40\n",
      "Mid-T                        45       0.4398       0.4458       0.4397 0.40/0.60\n",
      "Mid-Entry-Domestic          226       0.4374       0.4715       0.4471 0.60/0.40\n",
      "Entry-Domestic              141       0.6254       0.6313       0.6262 0.60/0.40\n",
      "Basic-Domestic              117       3.1411       3.1470       3.1323 0.60/0.40\n",
      "High-Premium-Import          70       0.3247       0.3270       0.3245 0.60/0.40\n",
      "High-Import                  69       0.5176       0.5169       0.5162 0.40/0.60\n",
      "Mid-Import                  244       0.5448       0.5705       0.5389 0.60/0.40\n",
      "Mid-Entry-Import            107       0.5882       0.5721       0.5804 0.60/0.40\n",
      "Basic-Import                 80       0.3397       0.3387       0.3383 0.50/0.50\n",
      "===========================================================================\n",
      "전체                         1500                                 1.3849\n",
      "\n",
      "테스트 데이터 예측 중...\n",
      "제출 파일 생성 완료: submission16.csv\n",
      "\n",
      "=== 성능 분석 리포트 ===\n",
      "\n",
      "브랜드별 평균 RMSE:\n",
      "P          1.8709\n",
      "Premium    1.6034\n",
      "Performance 0.7191\n",
      "T          0.4397\n",
      "Entry      0.5137\n",
      "Domestic   1.8793\n",
      "Import     0.4644\n",
      "\n",
      "데이터 크기별 성능:\n",
      "중(200-300)      0.4930\n",
      "소(200미만)        1.2092\n",
      "\n",
      "최고 성능 Top 3 세그먼트:\n",
      "Premium-P            RMSE: 0.3156 (데이터 수: 80)\n",
      "High-Premium-Import  RMSE: 0.3245 (데이터 수: 70)\n",
      "Basic-Import         RMSE: 0.3383 (데이터 수: 80)\n",
      "\n",
      "최저 성능 Bottom 3 세그먼트:\n",
      "High-Premium-P       RMSE: 2.8823 (데이터 수: 68)\n",
      "Basic-Domestic       RMSE: 3.1323 (데이터 수: 117)\n",
      "Luxury-P             RMSE: 3.4263 (데이터 수: 69)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ImprovedSegmentModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.outlier_thresholds = {}\n",
    "    \n",
    "    # 세그먼트 재구성\n",
    "        self.segments = {\n",
    "            # P사 세그먼트 (프리미엄)\n",
    "            'Premium-P': {'min_price': 150, 'models': ['TayGTS'], 'brand': 'P사',\n",
    "                         'features': ['프리미엄_가치', '품질점수', '주행성능']},\n",
    "            'Luxury-P': {'min_price': 120, 'models': ['TayCT'], 'brand': 'P사',\n",
    "                        'features': ['프리미엄_가치', '품질점수', '주행성능']},\n",
    "            'High-Premium-P': {'min_price': 95, 'models': ['Tay'], 'brand': 'P사',\n",
    "                             'features': ['프리미엄_가치', '품질점수', '주행성능']},\n",
    "        \n",
    "            # T사 세그먼트 (기술)\n",
    "            'High-Performance-T': {'min_price': 80, 'models': ['MX', 'MS', 'MY'],\n",
    "                                 'brand': 'T사', 'features': ['기술가치', '품질점수', '주행성능']},\n",
    "            'Mid-T': {'min_price': 50, 'models': ['M3'], 'brand': 'T사',\n",
    "                     'features': ['기술가치', '품질점수', '주행성능']},\n",
    "        \n",
    "            # H사/K사 세그먼트 (실용)\n",
    "            'Mid-Entry-Domestic': {'min_price': 35, 'models': ['EV6', 'ION6', 'ION5'],\n",
    "                                 'brands': ['H사', 'K사'], 'features': ['국내_AS_가치', '품질점수']},\n",
    "            'Entry-Domestic': {'min_price': 25, 'models': ['Niro', 'KNE'],\n",
    "                             'brands': ['H사', 'K사'], 'features': ['국내_AS_가치', '품질점수']},\n",
    "            'Basic-Domestic': {'min_price': 0, 'models': ['Soul', 'IONIQ'],\n",
    "                             'brands': ['H사', 'K사'], 'features': ['국내_AS_가치', '품질점수']},\n",
    "        \n",
    "            # 수입차 세그먼트\n",
    "            'High-Premium-Import': {'min_price': 95, 'models': ['RSeTGT'],\n",
    "                                  'brand': 'A사', 'features': ['수입_프리미엄', '품질점수']},\n",
    "            'High-Import': {'min_price': 80, 'models': ['iX'],\n",
    "                          'brand': 'B사', 'features': ['수입_프리미엄', '품질점수']},\n",
    "            'Mid-Import': {'min_price': 50, 'models': ['i5', 'Q4eT', 'eT'],\n",
    "                         'brands': ['B사', 'A사'], 'features': ['수입_프리미엄', '품질점수']},\n",
    "            'Mid-Entry-Import': {'min_price': 35, 'models': ['ID4'],\n",
    "                               'brand': 'V사', 'features': ['수입_프리미엄', '품질점수']},\n",
    "            'Basic-Import': {'min_price': 0, 'models': ['i3'],\n",
    "                           'brand': 'B사', 'features': ['수입_프리미엄', '품질점수']}\n",
    "        }\n",
    "    \n",
    "    # 브랜드별 기본 특성\n",
    "        self.brand_features = {\n",
    "            'P사': ['프리미엄_가치', '품질점수', '주행성능'],\n",
    "            'T사': ['기술가치', '품질점수', '주행성능'],\n",
    "            'H사': ['국내_AS_가치', '품질점수'],\n",
    "            'K사': ['국내_AS_가치', '품질점수'],\n",
    "            'A사': ['수입_프리미엄', '품질점수'],\n",
    "            'B사': ['수입_프리미엄', '품질점수'],\n",
    "            'V사': ['수입_프리미엄', '품질점수']\n",
    "        }\n",
    "    \n",
    "        self.segment_models = {}\n",
    "        self.price_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        self.data_size_stats = {}\n",
    "\n",
    "    def get_brand_from_model(self, model):\n",
    "        \"\"\"모델명으로 브랜드 찾기\"\"\"\n",
    "        for segment_info in self.segments.values():\n",
    "            if model in segment_info['models']:\n",
    "                return segment_info.get('brand') or segment_info.get('brands', [None])[0]\n",
    "        return None\n",
    "\n",
    "    def get_dynamic_weights(self, data_size, segment):\n",
    "        \"\"\"데이터 크기와 세그먼트 특성에 따른 동적 가중치 결정\"\"\"\n",
    "        # 기본 가중치 설정\n",
    "        if data_size < 200:\n",
    "            weights = {'xgb': 0.3, 'lgb': 0.7}  # 보수적 접근\n",
    "        elif data_size < 300:\n",
    "            weights = {'xgb': 0.4, 'lgb': 0.6}\n",
    "        elif data_size < 400:\n",
    "            weights = {'xgb': 0.5, 'lgb': 0.5}\n",
    "        else:\n",
    "            weights = {'xgb': 0.6, 'lgb': 0.4}  # 충분한 데이터\n",
    "            \n",
    "        # 세그먼트별 추가 보정\n",
    "        if 'Premium' in segment or 'Luxury' in segment:\n",
    "            weights['xgb'] = min(0.7, weights['xgb'] + 0.1)  # 프리미엄 세그먼트는 XGBoost 비중 증가\n",
    "            weights['lgb'] = 1 - weights['xgb']\n",
    "        elif 'Basic' in segment and data_size < 300:\n",
    "            weights['lgb'] = min(0.8, weights['lgb'] + 0.1)  # Basic 세그먼트의 적은 데이터는 LightGBM 비중 증가\n",
    "            weights['xgb'] = 1 - weights['lgb']\n",
    "            \n",
    "        return weights\n",
    "        \n",
    "    def assign_segment(self, model):\n",
    "        \"\"\"개선된 세그먼트 할당 로직\"\"\"\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "        \n",
    "    def calculate_quality_score(self, row):\n",
    "        \"\"\"차량 품질 점수 계산\"\"\"\n",
    "        score = 0\n",
    "        if row['차량상태'] == '우수':\n",
    "            score += 1\n",
    "        if row['잔여보증기간'] > 0:\n",
    "            score += 0.5\n",
    "        if row['사고이력'] == '무사고':\n",
    "            score += 0.5\n",
    "        return score\n",
    "        \n",
    "    def add_features(self, df, is_train=True):\n",
    "        \"\"\"향상된 특성 엔지니어링\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # 품질 점수 계산\n",
    "        df['품질점수'] = df.apply(self.calculate_quality_score, axis=1)\n",
    "        \n",
    "        # 브랜드별 특화 피처\n",
    "        # P사(프리미엄) 특화 피처\n",
    "        df['프리미엄_가치'] = ((df['제조사'] == 'P사') & \n",
    "                           (df['품질점수'] >= 1.5)).astype(float) * df['품질점수']\n",
    "        df['배터리품질'] = df.apply(lambda x: \n",
    "            x['배터리_효율'] * 1.2 if x['제조사'] == 'P사' else x['배터리_효율'], axis=1)\n",
    "        df['주행성능'] = df.apply(lambda x:\n",
    "            x['km_per_year'] * 1.1 if x['제조사'] == 'P사' else x['km_per_year'], axis=1)\n",
    "        \n",
    "        # T사 특화 피처\n",
    "        df['기술가치'] = ((df['제조사'] == 'T사') & \n",
    "                       (df['잔여보증기간'] > 0)).astype(float) * (df['잔여보증기간'] / df['보증기간(년)'])\n",
    "        df['충전성능'] = df.apply(lambda x:\n",
    "            x['배터리_효율'] * 1.15 if x['제조사'] == 'T사' else x['배터리_효율'], axis=1)\n",
    "        df['소프트웨어가치'] = ((df['제조사'] == 'T사') & \n",
    "                            (df['차량연식'] < 3)).astype(float)\n",
    "        \n",
    "        # 국내 브랜드(H사/K사) 특화 피처\n",
    "        df['국내_AS_가치'] = ((df['제조사'].isin(['H사', 'K사'])) & \n",
    "                          (df['잔여보증기간'] > 0)).astype(float) * df['잔여보증기간']\n",
    "        df['유지보수_가치'] = ((df['제조사'].isin(['H사', 'K사'])) &\n",
    "                           (df['차량상태'].isin(['우수', '양호']))).astype(float) * df['품질점수']\n",
    "        df['비용효율성'] = df.apply(lambda x:\n",
    "            (x['배터리_효율'] * 1.1) if x['제조사'] in ['H사', 'K사'] else x['배터리_효율'], axis=1)\n",
    "        \n",
    "        # 수입 브랜드 특화 피처\n",
    "        premium_brands = ['A사', 'B사', 'V사']\n",
    "        df['수입_프리미엄'] = ((df['제조사'].isin(premium_brands)) & \n",
    "                           (df['품질점수'] >= 1.5)).astype(float) * df['품질점수']\n",
    "        df['브랜드가치'] = df.apply(lambda x:\n",
    "            x['품질점수'] * 1.2 if x['제조사'] in premium_brands else x['품질점수'], axis=1)\n",
    "        df['유럽인증'] = df['제조사'].isin(premium_brands).astype(float)\n",
    "        \n",
    "        # 가격 통계 계산 (학습 데이터일 때만)\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "            # 모델별 통계\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std', 'count'])\n",
    "            self.price_stats['모델'] = {\n",
    "                'mean': model_stats['mean'].to_dict(),\n",
    "                'std': model_stats['std'].to_dict(),\n",
    "                'count': model_stats['count'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 제조사별 통계\n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std', 'count'])\n",
    "            self.price_stats['제조사'] = {\n",
    "                'mean': manufacturer_stats['mean'].to_dict(),\n",
    "                'std': manufacturer_stats['std'].to_dict(),\n",
    "                'count': manufacturer_stats['count'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 세그먼트별 통계\n",
    "            df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "            segment_stats = df.groupby('segment')['가격(백만원)'].agg(['mean', 'std', 'count'])\n",
    "            self.price_stats['segment'] = {\n",
    "                'mean': segment_stats['mean'].to_dict(),\n",
    "                'std': segment_stats['std'].to_dict(),\n",
    "                'count': segment_stats['count'].to_dict()\n",
    "            }\n",
    "        \n",
    "        # 가격 통계 기반 특성 추가\n",
    "        if '모델' in self.price_stats:\n",
    "            df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "            df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "            df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "            df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "        else:\n",
    "            df['모델별_평균가격'] = 0\n",
    "            df['모델별_가격편차'] = 0\n",
    "            df['제조사별_평균가격'] = 0\n",
    "            df['제조사별_가격편차'] = 0\n",
    "\n",
    "        # 이상치 처리\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "                # 이상치 처리 (계속)\n",
    "            if is_train:\n",
    "                q99 = df[col].quantile(0.99)\n",
    "                q01 = df[col].quantile(0.01)\n",
    "                self.outlier_thresholds[col] = {'upper': q99, 'lower': q01}\n",
    "            df[col] = df[col].clip(\n",
    "                lower=self.outlier_thresholds.get(col, {}).get('lower', df[col].min()),\n",
    "                upper=self.outlier_thresholds.get(col, {}).get('upper', df[col].max())\n",
    "            )\n",
    "            \n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        \"\"\"개선된 데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        # 범주형 변수 처리\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                # 새로운 카테고리 처리\n",
    "                unknown_values = set(df[col].unique()) - set(self.label_encoders[col].classes_)\n",
    "                if unknown_values:\n",
    "                    print(f\"Warning: Unknown categories in {col}: {unknown_values}\")\n",
    "                    df[col] = df[col].map(lambda x: x if x in self.label_encoders[col].classes_ else self.label_encoders[col].classes_[0])\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리 - 배터리 용량\n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        # 특성 추가\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def optimize_xgboost(self, X, y, segment, data_size):\n",
    "        \"\"\"데이터 크기를 고려한 XGBoost 최적화\"\"\"\n",
    "        # 데이터 크기에 따른 파라미터 그리드 조정\n",
    "        if data_size < 200:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.05],\n",
    "                'max_depth': [3, 4],\n",
    "                'min_child_weight': [3, 5],\n",
    "                'gamma': [0, 0.1],\n",
    "                'subsample': [0.8],\n",
    "                'colsample_bytree': [0.8]\n",
    "            }\n",
    "        else:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'learning_rate': [0.01, 0.05, 0.1],\n",
    "                'max_depth': [3, 4, 5],\n",
    "                'min_child_weight': [3, 5, 7],\n",
    "                'gamma': [0, 0.1, 0.2],\n",
    "                'subsample': [0.8, 0.9],\n",
    "                'colsample_bytree': [0.8, 0.9]\n",
    "            }\n",
    "        \n",
    "        model = XGBRegressor(\n",
    "            random_state=42,\n",
    "            missing=np.nan,\n",
    "            tree_method='hist',\n",
    "            max_bin=256\n",
    "        )\n",
    "        \n",
    "        cv = KFold(n_splits=min(5, data_size // 50), shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def optimize_lightgbm(self, X, y, segment, data_size):\n",
    "        \"\"\"데이터 크기를 고려한 LightGBM 최적화\"\"\"\n",
    "        # 데이터 크기에 따른 파라미터 그리드 조정\n",
    "        if data_size < 200:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.05],\n",
    "                'max_depth': [3, 4],\n",
    "                'num_leaves': [31],\n",
    "                'min_child_samples': [20],\n",
    "                'subsample': [0.8],\n",
    "                'colsample_bytree': [0.8]\n",
    "            }\n",
    "        else:\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200, 300],\n",
    "                'learning_rate': [0.01, 0.05, 0.1],\n",
    "                'max_depth': [3, 4, 6],\n",
    "                'num_leaves': [31, 63],\n",
    "                'min_child_samples': [20, 30],\n",
    "                'subsample': [0.8, 0.9],\n",
    "                'colsample_bytree': [0.8, 0.9]\n",
    "            }\n",
    "        \n",
    "        model = LGBMRegressor(\n",
    "            random_state=42,\n",
    "            verbose=-1,\n",
    "            min_data_in_leaf=max(20, data_size // 20)\n",
    "        )\n",
    "        \n",
    "        cv = KFold(n_splits=min(5, data_size // 50), shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"향상된 모델 학습\"\"\"\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 기본 특성 (실제 존재하는 컬럼들만)\n",
    "        self.base_features = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식',\n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간', '제조사',\n",
    "            '모델별_평균가격', '모델별_가격편차', '제조사별_평균가격', '제조사별_가격편차',\n",
    "            '품질점수', '프리미엄_가치', '주행성능', '기술가치',\n",
    "            '국내_AS_가치', '수입_프리미엄'\n",
    "        ]\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            data_size = mask.sum()\n",
    "            print(f\"데이터 수: {data_size}개\")\n",
    "            self.data_size_stats[segment] = data_size\n",
    "            \n",
    "            # 세그먼트별 특성 선택\n",
    "            segment_info = self.segments[segment]\n",
    "            brand = segment_info.get('brand') or segment_info.get('brands', [None])[0]\n",
    "            selected_features = list(set(\n",
    "                self.base_features +\n",
    "                segment_info.get('features', []) +\n",
    "                self.brand_features.get(brand, [])\n",
    "            ))\n",
    "            \n",
    "            X = train_processed[mask][selected_features]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            # 데이터 크기에 따른 모델 최적화\n",
    "            xgb_model = self.optimize_xgboost(X, y, segment, data_size)\n",
    "            lgb_model = self.optimize_lightgbm(X, y, segment, data_size)\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'xgb': xgb_model,\n",
    "                'lgb': lgb_model,\n",
    "                'features': selected_features\n",
    "            }\n",
    "            \n",
    "            self.feature_importance[segment] = {\n",
    "                'xgb': dict(zip(selected_features, xgb_model.feature_importances_)),\n",
    "                'lgb': dict(zip(selected_features, lgb_model.feature_importances_))\n",
    "            }\n",
    "            \n",
    "            # 중요 특성 출력\n",
    "            print(f\"\\n{segment} 세그먼트 Top 5 중요 특성:\")\n",
    "            for model_type, importance in self.feature_importance[segment].items():\n",
    "                top_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                print(f\"\\n{model_type.upper()}:\")\n",
    "                for feat, imp in top_features:\n",
    "                    print(f\"- {feat}: {imp:.4f}\")\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"향상된 예측\"\"\"\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = test_processed[mask][selected_features]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 데이터 크기 기반 동적 가중치 적용\n",
    "            weights = self.get_dynamic_weights(self.data_size_stats[segment], segment)\n",
    "            predictions[mask] = weights['xgb'] * xgb_pred + weights['lgb'] * lgb_pred\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        \"\"\"세부적인 성능 평가\"\"\"\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<20} {'데이터 수':>10} {'XGB RMSE':>12} {'LGB RMSE':>12} {'앙상블 RMSE':>12} {'가중치(XGB/LGB)':>15}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = val_processed[mask][selected_features]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            weights = self.get_dynamic_weights(self.data_size_stats[segment], segment)\n",
    "            ensemble_pred = weights['xgb'] * xgb_pred + weights['lgb'] * lgb_pred\n",
    "            \n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "            lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            \n",
    "            print(f\"{segment:<20} {mask.sum():>10d} {xgb_rmse:>12.4f} {lgb_rmse:>12.4f} \"\n",
    "                  f\"{ensemble_rmse:>12.4f} {weights['xgb']:.2f}/{weights['lgb']:.2f}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'xgb_rmse': xgb_rmse,\n",
    "                'lgb_rmse': lgb_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse,\n",
    "                'weights': weights\n",
    "            }\n",
    "        \n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 75)\n",
    "        print(f\"{'전체':<20} {len(y_val):>10d} {'':>12} {'':>12} {total_rmse:>12.4f}\")\n",
    "        \n",
    "        return segment_metrics, total_rmse\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    if 'ID' not in test.columns:\n",
    "        test['ID'] = range(len(test))\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"향상된 세그먼트 기반 모델 학습 시작...\")\n",
    "    model = ImprovedSegmentModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    \n",
    "    print(\"\\n테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission16.csv', index=False, encoding='utf-8')\n",
    "    print(\"제출 파일 생성 완료: submission16.csv\")\n",
    "    \n",
    "    # 성능 분석 리포트 생성\n",
    "    print(\"\\n=== 성능 분석 리포트 ===\")\n",
    "    \n",
    "    # 브랜드별 성능 분석\n",
    "    print(\"\\n브랜드별 평균 RMSE:\")\n",
    "    brand_metrics = {}\n",
    "    for segment, metrics in segment_metrics.items():\n",
    "        brand = segment.split('-')[1] if '-' in segment else 'Other'\n",
    "        if brand not in brand_metrics:\n",
    "            brand_metrics[brand] = []\n",
    "        brand_metrics[brand].append(metrics['ensemble_rmse'])\n",
    "    \n",
    "    for brand, rmse_list in brand_metrics.items():\n",
    "        avg_rmse = np.mean(rmse_list)\n",
    "        print(f\"{brand:<10} {avg_rmse:.4f}\")\n",
    "    \n",
    "    # 데이터 크기별 성능 분석\n",
    "    print(\"\\n데이터 크기별 성능:\")\n",
    "    size_categories = {\n",
    "        '대(300+)': [],\n",
    "        '중(200-300)': [],\n",
    "        '소(200미만)': []\n",
    "    }\n",
    "    \n",
    "    for segment, metrics in segment_metrics.items():\n",
    "        if metrics['count'] >= 300:\n",
    "            size_categories['대(300+)'].append(metrics['ensemble_rmse'])\n",
    "        elif metrics['count'] >= 200:\n",
    "            size_categories['중(200-300)'].append(metrics['ensemble_rmse'])\n",
    "        else:\n",
    "            size_categories['소(200미만)'].append(metrics['ensemble_rmse'])\n",
    "    \n",
    "    for size, rmse_list in size_categories.items():\n",
    "        if rmse_list:\n",
    "            avg_rmse = np.mean(rmse_list)\n",
    "            print(f\"{size:<15} {avg_rmse:.4f}\")\n",
    "    \n",
    "    # 최고/최저 성능 세그먼트\n",
    "    sorted_segments = sorted(segment_metrics.items(), \n",
    "                           key=lambda x: x[1]['ensemble_rmse'])\n",
    "    \n",
    "    print(\"\\n최고 성능 Top 3 세그먼트:\")\n",
    "    for segment, metrics in sorted_segments[:3]:\n",
    "        print(f\"{segment:<20} RMSE: {metrics['ensemble_rmse']:.4f} \"\n",
    "              f\"(데이터 수: {metrics['count']})\")\n",
    "    \n",
    "    print(\"\\n최저 성능 Bottom 3 세그먼트:\")\n",
    "    for segment, metrics in sorted_segments[-3:]:\n",
    "        print(f\"{segment:<20} RMSE: {metrics['ensemble_rmse']:.4f} \"\n",
    "              f\"(데이터 수: {metrics['count']})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "향상된 세그먼트 기반 모델 학습 시작...\n",
      "\n",
      "=== Ultra-Premium-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 295개\n",
      "\n",
      "Ultra-Premium-P 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 배터리용량: 0.6031\n",
      "- 배터리_효율: 0.1740\n",
      "- 배터리_연식_효율: 0.1592\n",
      "- 차량상태: 0.0487\n",
      "- km_per_year: 0.0098\n",
      "\n",
      "LGB:\n",
      "- 배터리용량: 1138.0000\n",
      "- 배터리_효율: 726.0000\n",
      "- km_per_year: 708.0000\n",
      "- 배터리_연식_효율: 115.0000\n",
      "- 주행거리(km): 63.0000\n",
      "\n",
      "=== Premium-P-Combined 세그먼트 최적화 시작 ===\n",
      "데이터 수: 559개\n",
      "\n",
      "Premium-P-Combined 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 모델: 0.4885\n",
      "- km_per_year: 0.1454\n",
      "- 주행거리(km): 0.1257\n",
      "- 배터리용량: 0.0808\n",
      "- 차량상태: 0.0572\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 656.0000\n",
      "- km_per_year: 593.0000\n",
      "- 배터리용량: 258.0000\n",
      "- 모델: 125.0000\n",
      "- 배터리_연식_효율: 103.0000\n",
      "\n",
      "=== High-Performance-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 646개\n",
      "\n",
      "High-Performance-T 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.3957\n",
      "- 배터리_연식_효율: 0.2202\n",
      "- 모델: 0.1314\n",
      "- 배터리용량: 0.1228\n",
      "- km_per_year: 0.0819\n",
      "\n",
      "LGB:\n",
      "- 배터리용량: 559.0000\n",
      "- 보증기간(년): 516.0000\n",
      "- 배터리_효율: 481.0000\n",
      "- km_per_year: 428.0000\n",
      "- 모델: 221.0000\n",
      "\n",
      "=== Mid-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 234개\n",
      "\n",
      "Mid-T 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.6311\n",
      "- 차량연식: 0.1811\n",
      "- 배터리용량: 0.1280\n",
      "- 배터리_효율: 0.0238\n",
      "- km_per_year: 0.0207\n",
      "\n",
      "LGB:\n",
      "- 보증기간(년): 328.0000\n",
      "- 배터리_효율: 265.0000\n",
      "- km_per_year: 225.0000\n",
      "- 배터리용량: 129.0000\n",
      "- 주행거리(km): 19.0000\n",
      "\n",
      "=== Mid-Entry-Domestic-H 세그먼트 최적화 시작 ===\n",
      "데이터 수: 579개\n",
      "\n",
      "Mid-Entry-Domestic-H 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 모델: 0.4285\n",
      "- 차량상태: 0.2986\n",
      "- 배터리_연식_효율: 0.1381\n",
      "- 보증기간(년): 0.0685\n",
      "- 배터리_효율: 0.0195\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 359.0000\n",
      "- km_per_year: 333.0000\n",
      "- 배터리용량: 283.0000\n",
      "- 모델: 161.0000\n",
      "- 보증기간(년): 36.0000\n",
      "\n",
      "=== Mid-Entry-Domestic-K 세그먼트 최적화 시작 ===\n",
      "데이터 수: 296개\n",
      "\n",
      "Mid-Entry-Domestic-K 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.9871\n",
      "- 배터리_효율: 0.0045\n",
      "- km_per_year: 0.0033\n",
      "- 구동방식: 0.0032\n",
      "- 주행거리(km): 0.0018\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 1110.0000\n",
      "- km_per_year: 278.0000\n",
      "- 보증기간(년): 195.0000\n",
      "- 구동방식: 84.0000\n",
      "- 제조사: 0.0000\n",
      "\n",
      "=== Entry-Domestic-Combined 세그먼트 최적화 시작 ===\n",
      "데이터 수: 622개\n",
      "\n",
      "Entry-Domestic-Combined 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.8869\n",
      "- km_per_year: 0.0770\n",
      "- 배터리용량: 0.0065\n",
      "- 주행거리(km): 0.0059\n",
      "- 배터리_효율: 0.0048\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 1014.0000\n",
      "- 보증기간(년): 647.0000\n",
      "- km_per_year: 402.0000\n",
      "- 제조사: 122.0000\n",
      "- 배터리용량: 101.0000\n",
      "\n",
      "=== Basic-Domestic-Combined 세그먼트 최적화 시작 ===\n",
      "데이터 수: 420개\n",
      "\n",
      "Basic-Domestic-Combined 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 모델: 0.2735\n",
      "- 제조사: 0.2359\n",
      "- 보증기간(년): 0.0755\n",
      "- 배터리_연식_효율: 0.0664\n",
      "- km_per_year: 0.0553\n",
      "\n",
      "LGB:\n",
      "- km_per_year: 602.0000\n",
      "- 배터리용량: 497.0000\n",
      "- 보증기간(년): 406.0000\n",
      "- 배터리_효율: 343.0000\n",
      "- 제조사: 149.0000\n",
      "\n",
      "=== High-Premium-Import 세그먼트 최적화 시작 ===\n",
      "데이터 수: 315개\n",
      "\n",
      "High-Premium-Import 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.6769\n",
      "- SW_업데이트_가치: 0.1705\n",
      "- km_per_year: 0.1258\n",
      "- 배터리_효율: 0.0162\n",
      "- 주행거리(km): 0.0067\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 856.0000\n",
      "- 보증기간(년): 593.0000\n",
      "- km_per_year: 501.0000\n",
      "- 주행거리(km): 148.0000\n",
      "- SW_업데이트_가치: 107.0000\n",
      "\n",
      "=== High-Import 세그먼트 최적화 시작 ===\n",
      "데이터 수: 298개\n",
      "\n",
      "High-Import 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 배터리_효율: 0.2354\n",
      "- km_per_year: 0.2174\n",
      "- 주행거리(km): 0.2040\n",
      "- 구동방식: 0.1827\n",
      "- 보증기간(년): 0.1605\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 584.0000\n",
      "- km_per_year: 167.0000\n",
      "- 구동방식: 112.0000\n",
      "- 보증기간(년): 47.0000\n",
      "- 제조사: 0.0000\n",
      "\n",
      "=== Mid-Import-Combined 세그먼트 최적화 시작 ===\n",
      "데이터 수: 927개\n",
      "\n",
      "Mid-Import-Combined 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 모델: 0.4419\n",
      "- 제조사: 0.2110\n",
      "- 보증기간(년): 0.1084\n",
      "- 배터리용량: 0.0828\n",
      "- 배터리_연식_효율: 0.0669\n",
      "\n",
      "LGB:\n",
      "- 배터리용량: 608.0000\n",
      "- 배터리_효율: 537.0000\n",
      "- km_per_year: 355.0000\n",
      "- 보증기간(년): 226.0000\n",
      "- 배터리_연식_효율: 181.0000\n",
      "\n",
      "=== Mid-Entry-Import 세그먼트 최적화 시작 ===\n",
      "데이터 수: 498개\n",
      "\n",
      "Mid-Entry-Import 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.8208\n",
      "- 배터리용량: 0.1028\n",
      "- 배터리_효율: 0.0399\n",
      "- km_per_year: 0.0127\n",
      "- 차량연식: 0.0126\n",
      "\n",
      "LGB:\n",
      "- 보증기간(년): 995.0000\n",
      "- km_per_year: 890.0000\n",
      "- 배터리_효율: 754.0000\n",
      "- 배터리용량: 510.0000\n",
      "- 주행거리(km): 74.0000\n",
      "\n",
      "=== Basic-Import 세그먼트 최적화 시작 ===\n",
      "데이터 수: 308개\n",
      "\n",
      "Basic-Import 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 배터리용량: 0.2949\n",
      "- km_per_year: 0.1911\n",
      "- SW_업데이트_가치: 0.1595\n",
      "- 주행거리(km): 0.1486\n",
      "- 차량상태: 0.1374\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 794.0000\n",
      "- 보증기간(년): 567.0000\n",
      "- km_per_year: 255.0000\n",
      "- 구동방식: 216.0000\n",
      "- SW_업데이트_가치: 63.0000\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트                      데이터 수     XGB RMSE     LGB RMSE     앙상블 RMSE    가중치(XGB/LGB)\n",
      "---------------------------------------------------------------------------\n",
      "Ultra-Premium-P              80       0.3149       0.3141       0.3141 0.50/0.50\n",
      "Premium-P-Combined          137       3.2175       3.1530       3.1531 0.50/0.50\n",
      "High-Performance-T          184       0.7003       0.7181       0.6941 0.60/0.40\n",
      "Mid-T                        45       0.4349       0.4250       0.4267 0.50/0.50\n",
      "Mid-Entry-Domestic-H        153       0.3799       0.3781       0.3789 0.70/0.30\n",
      "Mid-Entry-Domestic-K         73       0.5835       0.5935       0.5891 0.30/0.70\n",
      "Entry-Domestic-Combined        141       0.6292       0.6274       0.6275 0.60/0.40\n",
      "Basic-Domestic-Combined        117       3.1381       3.1241       3.1268 0.50/0.50\n",
      "High-Premium-Import          70       0.3116       0.3165       0.3129 0.60/0.40\n",
      "High-Import                  69       0.5197       0.5220       0.5203 0.40/0.60\n",
      "Mid-Import-Combined         244       0.5383       0.5807       0.5390 0.60/0.40\n",
      "Mid-Entry-Import            107       0.5809       0.5822       0.5807 0.60/0.40\n",
      "Basic-Import                 80       0.3366       0.3412       0.3377 0.60/0.40\n",
      "===========================================================================\n",
      "전체                         1500                                 1.3797\n",
      "\n",
      "=== 상세 성능 분석 리포트 ===\n",
      "\n",
      "브랜드별 평균 RMSE:\n",
      "Ultra      0.3141\n",
      "Premium    3.1531\n",
      "High       0.5091\n",
      "Mid        0.5029\n",
      "Entry      0.6275\n",
      "Basic      1.7323\n",
      "\n",
      "P사 세그먼트 상세 분석:\n",
      "\n",
      "가격대별 성능:\n",
      "Ultra-Premium-P      RMSE: 0.3141 (XGB/LGB 가중치: 0.50/0.50)\n",
      "Premium-P-Combined   RMSE: 3.1531 (XGB/LGB 가중치: 0.50/0.50)\n",
      "High-Performance-T   RMSE: 0.6941 (XGB/LGB 가중치: 0.60/0.40)\n",
      "High-Premium-Import  RMSE: 0.3129 (XGB/LGB 가중치: 0.60/0.40)\n",
      "\n",
      "데이터 크기별 성능:\n",
      "중(200-300)      0.5390\n",
      "소(200미만)        0.9218\n",
      "\n",
      "최고 성능 Top 3 세그먼트:\n",
      "High-Premium-Import  RMSE: 0.3129 (데이터 수: 70)\n",
      "Ultra-Premium-P      RMSE: 0.3141 (데이터 수: 80)\n",
      "Basic-Import         RMSE: 0.3377 (데이터 수: 80)\n",
      "\n",
      "최저 성능 Bottom 3 세그먼트:\n",
      "High-Performance-T   RMSE: 0.6941 (데이터 수: 184)\n",
      "Basic-Domestic-Combined RMSE: 3.1268 (데이터 수: 117)\n",
      "Premium-P-Combined   RMSE: 3.1531 (데이터 수: 137)\n",
      "\n",
      "테스트 데이터 예측 중...\n",
      "제출 파일 생성 완료: submission17.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedSegmentModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.outlier_thresholds = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "        # 세그먼트 재구성 (실제 생성되는 특성들과 매칭)\n",
    "        self.segments = {\n",
    "            # P사 세그먼트 \n",
    "            'Ultra-Premium-P': {'min_price': 150, 'models': ['TayGTS'], \n",
    "                       'brand': 'P사', 'price_range': 'ultra',\n",
    "                       'features': ['P사_브랜드파워', '품질점수', 'P사_가격프리미엄', 'P사_모델_가중치']},\n",
    "            'Premium-P-Combined': {'min_price': 95, 'models': ['TayCT', 'Tay'], \n",
    "                          'brand': 'P사', 'price_range': 'high',\n",
    "                          'features': ['P사_브랜드파워', '품질점수', 'P사_가격프리미엄', 'P사_모델_가중치']},\n",
    "            \n",
    "            # T사 세그먼트\n",
    "            'High-Performance-T': {'min_price': 80, 'models': ['MX', 'MS', 'MY'],\n",
    "                          'brand': 'T사', 'price_range': 'high',\n",
    "                          'features': ['T사_기술가치', '품질점수', 'SW_업데이트_가치']},\n",
    "            'Mid-T': {'min_price': 50, 'models': ['M3'], \n",
    "                     'brand': 'T사', 'price_range': 'mid',\n",
    "                     'features': ['T사_기술가치', '품질점수', 'SW_업데이트_가치']},\n",
    "            \n",
    "            # H사/K사 세그먼트\n",
    "            'Mid-Entry-Domestic-H': {'min_price': 35, 'models': ['ION6', 'ION5'],\n",
    "                            'brand': 'H사', 'price_range': 'mid',\n",
    "                            'features': ['국내_AS_가치', '품질점수', 'H사_서비스망']},\n",
    "            'Mid-Entry-Domestic-K': {'min_price': 35, 'models': ['EV6'],\n",
    "                            'brand': 'K사', 'price_range': 'mid',\n",
    "                            'features': ['국내_AS_가치', '품질점수', 'K사_서비스망']},\n",
    "            'Entry-Domestic-Combined': {'min_price': 25, 'models': ['Niro', 'KNE'],\n",
    "                               'brands': ['H사', 'K사'], 'price_range': 'entry',\n",
    "                               'features': ['국내_AS_가치', '품질점수']},\n",
    "            'Basic-Domestic-Combined': {'min_price': 0, 'models': ['Soul', 'IONIQ'],\n",
    "                               'brands': ['H사', 'K사'], 'price_range': 'basic',\n",
    "                               'features': ['국내_AS_가치', '품질점수']},\n",
    "            \n",
    "            # 수입차 세그먼트\n",
    "            'High-Premium-Import': {'min_price': 95, 'models': ['RSeTGT'],\n",
    "                           'brand': 'A사', 'price_range': 'high',\n",
    "                           'features': ['수입_프리미엄', '품질점수', '유럽인증_가치']},\n",
    "            'High-Import': {'min_price': 80, 'models': ['iX'],\n",
    "                    'brand': 'B사', 'price_range': 'high',\n",
    "                    'features': ['수입_프리미엄', '품질점수', '유럽인증_가치']},\n",
    "            'Mid-Import-Combined': {'min_price': 50, 'models': ['i5', 'Q4eT', 'eT'],\n",
    "                           'brands': ['B사', 'A사'], 'price_range': 'mid',\n",
    "                           'features': ['수입_프리미엄', '품질점수', '유럽인증_가치']},\n",
    "            'Mid-Entry-Import': {'min_price': 35, 'models': ['ID4'],\n",
    "                        'brand': 'V사', 'price_range': 'entry',\n",
    "                        'features': ['수입_프리미엄', '품질점수', '유럽인증_가치']},\n",
    "            'Basic-Import': {'min_price': 0, 'models': ['i3'],\n",
    "                    'brand': 'B사', 'price_range': 'basic',\n",
    "                    'features': ['수입_프리미엄', '품질점수', '유럽인증_가치']}\n",
    "        }\n",
    "        \n",
    "        # 브랜드별 특성 가중치\n",
    "        self.brand_importance = {\n",
    "            'P사': {\n",
    "                'ultra': {'품질점수': 1.3, 'P사_브랜드파워': 1.4},\n",
    "                'high': {'품질점수': 1.2, 'P사_브랜드파워': 1.3},\n",
    "            },\n",
    "            'T사': {\n",
    "                'high': {'T사_기술가치': 1.3, 'SW_업데이트_가치': 1.2},\n",
    "                'mid': {'T사_기술가치': 1.2, 'SW_업데이트_가치': 1.1},\n",
    "            },\n",
    "            'H사': {'국내_AS_가치': 1.2, 'H사_서비스망': 1.1},\n",
    "            'K사': {'국내_AS_가치': 1.2, 'K사_서비스망': 1.1}\n",
    "        }\n",
    "        \n",
    "        self.segment_models = {}\n",
    "        self.price_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        self.data_size_stats = {}\n",
    "        self.performance_history = {}\n",
    "    def calculate_quality_score(self, row):\n",
    "        \"\"\"향상된 품질 점수 계산\"\"\"\n",
    "        score = 0\n",
    "        \n",
    "        # 기본 품질 점수\n",
    "        if row['차량상태'] == '우수':\n",
    "            score += 1.0\n",
    "        elif row['차량상태'] == '양호':\n",
    "            score += 0.8\n",
    "        else:\n",
    "            score += 0.6\n",
    "            \n",
    "        # 주행거리 기반 점수\n",
    "        km_per_year = row['km_per_year']\n",
    "        if km_per_year < 10000:\n",
    "            score += 0.3\n",
    "        elif km_per_year < 15000:\n",
    "            score += 0.2\n",
    "        elif km_per_year < 20000:\n",
    "            score += 0.1\n",
    "            \n",
    "        # 잔여 보증기간 점수\n",
    "        if row['잔여보증기간'] > 2:\n",
    "            score += 0.3\n",
    "        elif row['잔여보증기간'] > 1:\n",
    "            score += 0.2\n",
    "        elif row['잔여보증기간'] > 0:\n",
    "            score += 0.1\n",
    "            \n",
    "        # 사고이력 점수\n",
    "        if row['사고이력'] == '무사고':\n",
    "            score += 0.4\n",
    "            \n",
    "        return score\n",
    "\n",
    "    def assign_segment(self, model):\n",
    "        \"\"\"모델별 세그먼트 할당\"\"\"\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "\n",
    "    def handle_outliers(self, df, col):\n",
    "        \"\"\"향상된 이상치 처리\"\"\"\n",
    "        if col not in self.outlier_thresholds:\n",
    "            q1 = df[col].quantile(0.05)\n",
    "            q3 = df[col].quantile(0.95)\n",
    "            iqr = q3 - q1\n",
    "            self.outlier_thresholds[col] = {\n",
    "                'lower': q1 - 1.5 * iqr,\n",
    "                'upper': q3 + 1.5 * iqr\n",
    "            }\n",
    "        \n",
    "        bounds = self.outlier_thresholds[col]\n",
    "        return df[col].clip(bounds['lower'], bounds['upper'])\n",
    "    \n",
    "    def get_dynamic_weights(self, data_size, segment, current_rmse=None):\n",
    "        \"\"\"향상된 동적 가중치 결정\"\"\"\n",
    "        # 기본 가중치 (데이터 크기 기반)\n",
    "        if data_size < 200:\n",
    "            weights = {'xgb': 0.3, 'lgb': 0.7}\n",
    "        elif data_size < 300:\n",
    "            weights = {'xgb': 0.4, 'lgb': 0.6}\n",
    "        elif data_size < 400:\n",
    "            weights = {'xgb': 0.5, 'lgb': 0.5}\n",
    "        else:\n",
    "            weights = {'xgb': 0.6, 'lgb': 0.4}\n",
    "            \n",
    "        # 성능 기반 조정\n",
    "        if current_rmse is not None:\n",
    "            if current_rmse > 2.0:  # 성능이 매우 나쁜 경우\n",
    "                weights['lgb'] = min(0.8, weights['lgb'] + 0.1)\n",
    "                weights['xgb'] = 1 - weights['lgb']\n",
    "            elif current_rmse < 0.5:  # 성능이 매우 좋은 경우\n",
    "                weights['xgb'] = min(0.7, weights['xgb'] + 0.1)\n",
    "                weights['lgb'] = 1 - weights['xgb']\n",
    "                \n",
    "        # 세그먼트별 추가 보정\n",
    "        if 'P사' in segment:\n",
    "            weights['xgb'] = min(0.7, weights['xgb'] + 0.1)\n",
    "            weights['lgb'] = 1 - weights['xgb']\n",
    "        elif 'Domestic' in segment and data_size < 300:\n",
    "            weights['lgb'] = min(0.8, weights['lgb'] + 0.1)\n",
    "            weights['xgb'] = 1 - weights['lgb']\n",
    "            \n",
    "        return weights\n",
    "\n",
    "    def add_features(self, df, is_train=True):\n",
    "        \"\"\"향상된 특성 엔지니어링\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # 품질 점수\n",
    "        df['품질점수'] = df.apply(self.calculate_quality_score, axis=1)\n",
    "        \n",
    "        # 브랜드별 특화 피처\n",
    "        # P사 특화 피처\n",
    "        df['P사_브랜드파워'] = ((df['제조사'] == 'P사') & \n",
    "                            (df['품질점수'] >= 1.5)).astype(float) * df['품질점수'] * 1.3\n",
    "        df['P사_모델_가중치'] = df.apply(\n",
    "            lambda x: 1.3 if x['제조사'] == 'P사' and x['차량상태'] == '우수' else 1.0,\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # T사 특화 피처\n",
    "        df['T사_기술가치'] = ((df['제조사'] == 'T사') & \n",
    "                          (df['차량연식'] < 3)).astype(float) * df['품질점수'] * 1.2\n",
    "        df['SW_업데이트_가치'] = ((df['제조사'] == 'T사') & \n",
    "                              (df['잔여보증기간'] > 0)).astype(float) * df['잔여보증기간'] / df['보증기간(년)']\n",
    "        \n",
    "        # H사/K사 특화 피처\n",
    "        df['H사_서비스망'] = (df['제조사'] == 'H사').astype(float) * df['품질점수'] * 1.1\n",
    "        df['K사_서비스망'] = (df['제조사'] == 'K사').astype(float) * df['품질점수'] * 1.1\n",
    "        df['국내_AS_가치'] = ((df['제조사'].isin(['H사', 'K사'])) & \n",
    "                          (df['잔여보증기간'] > 0)).astype(float) * df['잔여보증기간']\n",
    "        \n",
    "        # 수입차 특화 피처\n",
    "        premium_brands = ['A사', 'B사', 'V사']\n",
    "        df['수입_프리미엄'] = ((df['제조사'].isin(premium_brands)) & \n",
    "                           (df['품질점수'] >= 1.5)).astype(float) * df['품질점수']\n",
    "        df['유럽인증_가치'] = df['제조사'].isin(premium_brands).astype(float)\n",
    "        \n",
    "        # 가격 통계는 학습 데이터일 때만 계산\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "            # 모델별 통계\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std', 'count'])\n",
    "            self.price_stats['모델'] = {\n",
    "                'mean': model_stats['mean'].to_dict(),\n",
    "                'std': model_stats['std'].to_dict(),\n",
    "                'count': model_stats['count'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 제조사별 통계\n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std', 'count'])\n",
    "            self.price_stats['제조사'] = {\n",
    "                'mean': manufacturer_stats['mean'].to_dict(),\n",
    "                'std': manufacturer_stats['std'].to_dict(),\n",
    "                'count': manufacturer_stats['count'].to_dict()\n",
    "            }\n",
    "            \n",
    "            # 가격 구간별 통계\n",
    "            df['price_range'] = pd.qcut(df['가격(백만원)'], q=5, labels=['lowest', 'low', 'medium', 'high', 'highest'])\n",
    "            price_range_stats = df.groupby('price_range')['가격(백만원)'].agg(['mean', 'std', 'count'])\n",
    "            self.price_stats['price_range'] = {\n",
    "                'mean': price_range_stats['mean'].to_dict(),\n",
    "                'std': price_range_stats['std'].to_dict(),\n",
    "                'count': price_range_stats['count'].to_dict()\n",
    "            }\n",
    "        \n",
    "        # 가격 관련 특성 추가\n",
    "        if '모델' in self.price_stats:\n",
    "            df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "            df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "            df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "            df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "            df['P사_가격프리미엄'] = 0.0\n",
    "            \n",
    "            p사_mean = self.price_stats['제조사']['mean'].get('P사', 0)\n",
    "            mask = df['제조사'] == 'P사'\n",
    "            if '가격(백만원)' in df.columns:\n",
    "                df.loc[mask, 'P사_가격프리미엄'] = (df.loc[mask, '가격(백만원)'] / p사_mean - 1).clip(-0.5, 0.5)\n",
    "        else:\n",
    "            df['모델별_평균가격'] = 0\n",
    "            df['모델별_가격편차'] = 0\n",
    "            df['제조사별_평균가격'] = 0\n",
    "            df['제조사별_가격편차'] = 0\n",
    "            df['P사_가격프리미엄'] = 0\n",
    "\n",
    "        # 이상치 처리 및 스케일링\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            df[col] = self.handle_outliers(df, col)\n",
    "            if is_train:\n",
    "                self.scalers[col] = StandardScaler()\n",
    "                df[col] = self.scalers[col].fit_transform(df[[col]])\n",
    "            else:\n",
    "                if col in self.scalers:\n",
    "                    df[col] = self.scalers[col].transform(df[[col]])\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        \"\"\"향상된 데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        # 범주형 변수 처리\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                # 새로운 카테고리 처리\n",
    "                unknown_values = set(df[col].unique()) - set(self.label_encoders[col].classes_)\n",
    "                if unknown_values:\n",
    "                    print(f\"Warning: Unknown categories in {col}: {unknown_values}\")\n",
    "                    df[col] = df[col].map(lambda x: x if x in self.label_encoders[col].classes_ else self.label_encoders[col].classes_[0])\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리 - 배터리 용량\n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        # P사 모델 특별 처리\n",
    "        if 'P사' in set(df['제조사']):\n",
    "            df['P사_모델_가중치'] = df.apply(\n",
    "                lambda x: 1.3 if x['제조사'] == 'P사' and x['차량상태'] == '우수' else 1.0,\n",
    "                axis=1\n",
    "            )\n",
    "        \n",
    "        # 특성 추가\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def optimize_model_params(self, X, y, segment, data_size, model_type='xgb'):\n",
    "        \"\"\"향상된 모델 파라미터 최적화\"\"\"\n",
    "        # 실행시간 ~6시간으로 조정된 파라미터 그리드\n",
    "        if model_type == 'xgb':\n",
    "            param_grid = {\n",
    "                'n_estimators': [200, 300, 400, 500],\n",
    "                'learning_rate': [0.01, 0.03, 0.05, 0.07],\n",
    "                'max_depth': [3, 4, 5, 6, 7],\n",
    "                'min_child_weight': [3, 5, 7, 9],\n",
    "                'gamma': [0, 0.1, 0.2, 0.3],\n",
    "                'subsample': [0.7, 0.8, 0.9],\n",
    "                'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "            }\n",
    "            base_model = XGBRegressor(\n",
    "                random_state=42,\n",
    "                missing=np.nan,\n",
    "                tree_method='hist',\n",
    "                max_bin=256\n",
    "            )\n",
    "        else:  # lightgbm\n",
    "            param_grid = {\n",
    "                'n_estimators': [200, 300, 400, 500],\n",
    "                'learning_rate': [0.01, 0.03, 0.05, 0.07],\n",
    "                'max_depth': [3, 4, 5, 6, 7],\n",
    "                'num_leaves': [31, 63],\n",
    "                'min_child_samples': [20, 30, 40],\n",
    "                'subsample': [0.7, 0.8, 0.9],\n",
    "                'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "            }\n",
    "            base_model = LGBMRegressor(\n",
    "                random_state=42,\n",
    "                verbose=-1,\n",
    "                min_data_in_leaf=max(20, data_size // 20)\n",
    "            )\n",
    "        \n",
    "        # P사 세그먼트 특별 처리\n",
    "        if 'P사' in segment:\n",
    "            param_grid.update({\n",
    "                'max_depth': [3, 4, 5],\n",
    "                'min_child_weight': [5, 7, 9] if model_type == 'xgb' else None,\n",
    "                'min_child_samples': [30, 40, 50] if model_type == 'lgb' else None,\n",
    "                'subsample': [0.7, 0.8],\n",
    "                'colsample_bytree': [0.7, 0.8]\n",
    "            })\n",
    "        \n",
    "        # 데이터 크기에 따른 CV Fold 수 조정\n",
    "        cv = KFold(n_splits=min(7, max(3, data_size // 30)), shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=base_model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"향상된 모델 학습\"\"\"\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 기본 특성\n",
    "        self.base_features = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식',\n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간', '제조사',\n",
    "            '모델별_평균가격', '모델별_가격편차', '제조사별_평균가격', '제조사별_가격편차',\n",
    "            '품질점수', 'P사_브랜드파워', 'T사_기술가치', 'SW_업데이트_가치',\n",
    "            'H사_서비스망', 'K사_서비스망', '국내_AS_가치', '수입_프리미엄',\n",
    "            '유럽인증_가치', 'P사_가격프리미엄', 'P사_모델_가중치'\n",
    "        ]\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            data_size = mask.sum()\n",
    "            print(f\"데이터 수: {data_size}개\")\n",
    "            self.data_size_stats[segment] = data_size\n",
    "            \n",
    "            # 세그먼트별 특성 선택\n",
    "            segment_info = self.segments[segment]\n",
    "            brand = segment_info.get('brand') or segment_info.get('brands', [None])[0]\n",
    "            selected_features = list(set(\n",
    "                self.base_features +\n",
    "                segment_info.get('features', [])\n",
    "            ))\n",
    "            \n",
    "            X = train_processed[mask][selected_features]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            # 모델 최적화 및 학습\n",
    "            xgb_model = self.optimize_model_params(X, y, segment, data_size, 'xgb')\n",
    "            lgb_model = self.optimize_model_params(X, y, segment, data_size, 'lgb')\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'xgb': xgb_model,\n",
    "                'lgb': lgb_model,\n",
    "                'features': selected_features\n",
    "            }\n",
    "            \n",
    "            # 특성 중요도 저장\n",
    "            self.feature_importance[segment] = {\n",
    "                'xgb': dict(zip(selected_features, xgb_model.feature_importances_)),\n",
    "                'lgb': dict(zip(selected_features, lgb_model.feature_importances_))\n",
    "            }\n",
    "            \n",
    "            # 중요 특성 출력\n",
    "            print(f\"\\n{segment} 세그먼트 Top 5 중요 특성:\")\n",
    "            for model_type, importance in self.feature_importance[segment].items():\n",
    "                top_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                print(f\"\\n{model_type.upper()}:\")\n",
    "                for feat, imp in top_features:\n",
    "                    print(f\"- {feat}: {imp:.4f}\")\n",
    "                    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"향상된 예측\"\"\"\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = test_processed[mask][selected_features]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 현재 RMSE 기반 동적 가중치 적용\n",
    "            current_rmse = self.performance_history.get(segment, {}).get('last_rmse')\n",
    "            weights = self.get_dynamic_weights(self.data_size_stats[segment], \n",
    "                                            segment, current_rmse)\n",
    "            \n",
    "            predictions[mask] = weights['xgb'] * xgb_pred + weights['lgb'] * lgb_pred\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        \"\"\"세부적인 성능 평가\"\"\"\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<20} {'데이터 수':>10} {'XGB RMSE':>12} {'LGB RMSE':>12} \"\n",
    "              f\"{'앙상블 RMSE':>12} {'가중치(XGB/LGB)':>15}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = val_processed[mask][selected_features]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 현재 RMSE 기반 동적 가중치 계산\n",
    "            current_rmse = np.sqrt(mean_squared_error(y, (xgb_pred + lgb_pred) / 2))\n",
    "            weights = self.get_dynamic_weights(self.data_size_stats[segment], \n",
    "                                            segment, current_rmse)\n",
    "            \n",
    "            ensemble_pred = weights['xgb'] * xgb_pred + weights['lgb'] * lgb_pred\n",
    "            \n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "            lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            \n",
    "            # 성능 이력 업데이트\n",
    "            self.performance_history[segment] = {\n",
    "                'last_rmse': ensemble_rmse,\n",
    "                'improvement': self.performance_history.get(segment, {}).get('last_rmse', float('inf')) - ensemble_rmse\n",
    "            }\n",
    "            \n",
    "            print(f\"{segment:<20} {mask.sum():>10d} {xgb_rmse:>12.4f} {lgb_rmse:>12.4f} \"\n",
    "                  f\"{ensemble_rmse:>12.4f} {weights['xgb']:.2f}/{weights['lgb']:.2f}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'xgb_rmse': xgb_rmse,\n",
    "                'lgb_rmse': lgb_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse,\n",
    "                'weights': weights\n",
    "            }\n",
    "        \n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 75)\n",
    "        print(f\"{'전체':<20} {len(y_val):>10d} {'':>12} {'':>12} {total_rmse:>12.4f}\")\n",
    "        \n",
    "        # 상세 분석 리포트\n",
    "        print(\"\\n=== 상세 성능 분석 리포트 ===\")\n",
    "        \n",
    "        # 브랜드별 성능 분석\n",
    "        print(\"\\n브랜드별 평균 RMSE:\")\n",
    "        brand_metrics = {}\n",
    "        for segment, metrics in segment_metrics.items():\n",
    "            brand = segment.split('-')[0] if '-' in segment else 'Other'\n",
    "            if brand not in brand_metrics:\n",
    "                brand_metrics[brand] = []\n",
    "            brand_metrics[brand].append(metrics['ensemble_rmse'])\n",
    "        \n",
    "        for brand, rmse_list in brand_metrics.items():\n",
    "            avg_rmse = np.mean(rmse_list)\n",
    "            print(f\"{brand:<10} {avg_rmse:.4f}\")\n",
    "        \n",
    "        # P사 세그먼트 특별 분석\n",
    "        print(\"\\nP사 세그먼트 상세 분석:\")\n",
    "        p_segments = {k: v for k, v in segment_metrics.items() if 'P' in k}\n",
    "        if p_segments:\n",
    "            print(\"\\n가격대별 성능:\")\n",
    "            for segment, metrics in p_segments.items():\n",
    "                print(f\"{segment:<20} RMSE: {metrics['ensemble_rmse']:.4f} \"\n",
    "                      f\"(XGB/LGB 가중치: {metrics['weights']['xgb']:.2f}/{metrics['weights']['lgb']:.2f})\")\n",
    "        \n",
    "        # 데이터 크기별 성능\n",
    "        print(\"\\n데이터 크기별 성능:\")\n",
    "        size_categories = {\n",
    "            '대(300+)': [],\n",
    "            '중(200-300)': [],\n",
    "            '소(200미만)': []\n",
    "        }\n",
    "        \n",
    "        for segment, metrics in segment_metrics.items():\n",
    "            if metrics['count'] >= 300:\n",
    "                size_categories['대(300+)'].append(metrics['ensemble_rmse'])\n",
    "            elif metrics['count'] >= 200:\n",
    "                size_categories['중(200-300)'].append(metrics['ensemble_rmse'])\n",
    "            else:\n",
    "                size_categories['소(200미만)'].append(metrics['ensemble_rmse'])\n",
    "        \n",
    "        for size, rmse_list in size_categories.items():\n",
    "            if rmse_list:\n",
    "                avg_rmse = np.mean(rmse_list)\n",
    "                print(f\"{size:<15} {avg_rmse:.4f}\")\n",
    "        \n",
    "        # 최고/최저 성능 세그먼트\n",
    "        sorted_segments = sorted(segment_metrics.items(), \n",
    "                               key=lambda x: x[1]['ensemble_rmse'])\n",
    "        \n",
    "        print(\"\\n최고 성능 Top 3 세그먼트:\")\n",
    "        for segment, metrics in sorted_segments[:3]:\n",
    "            print(f\"{segment:<20} RMSE: {metrics['ensemble_rmse']:.4f} \"\n",
    "                  f\"(데이터 수: {metrics['count']})\")\n",
    "        \n",
    "        print(\"\\n최저 성능 Bottom 3 세그먼트:\")\n",
    "        for segment, metrics in sorted_segments[-3:]:\n",
    "            print(f\"{segment:<20} RMSE: {metrics['ensemble_rmse']:.4f} \"\n",
    "                  f\"(데이터 수: {metrics['count']})\")\n",
    "            \n",
    "        return segment_metrics, total_rmse\n",
    "    \n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    if 'ID' not in test.columns:\n",
    "        test['ID'] = range(len(test))\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"향상된 세그먼트 기반 모델 학습 시작...\")\n",
    "    model = EnhancedSegmentModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    \n",
    "    print(\"\\n테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission17.csv', index=False, encoding='utf-8')\n",
    "    print(\"제출 파일 생성 완료: submission17.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IONIQ 특화 세그먼트 기반 모델 학습 시작...\n",
      "\n",
      "=== Premium-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 295개\n",
      "\n",
      "Premium-P 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.7408\n",
      "- 배터리_연식_효율: 0.1429\n",
      "- 배터리용량: 0.1018\n",
      "- 주행거리(km): 0.0063\n",
      "- 배터리_효율: 0.0030\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 435.0000\n",
      "- 배터리_효율: 401.0000\n",
      "- 배터리용량: 294.0000\n",
      "- km_per_year: 129.0000\n",
      "- 차량상태: 77.0000\n",
      "\n",
      "=== Luxury-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 266개\n",
      "\n",
      "Luxury-P 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.2732\n",
      "- 연식(년): 0.2186\n",
      "- 차량상태: 0.1674\n",
      "- 배터리_연식_효율: 0.1118\n",
      "- km_per_year: 0.0674\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 591.0000\n",
      "- 배터리_효율: 551.0000\n",
      "- km_per_year: 179.0000\n",
      "- 보증기간(년): 90.0000\n",
      "- 차량상태: 50.0000\n",
      "\n",
      "=== High-Premium-P 세그먼트 최적화 시작 ===\n",
      "데이터 수: 293개\n",
      "\n",
      "High-Premium-P 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.8915\n",
      "- km_per_year: 0.0461\n",
      "- 배터리_연식_효율: 0.0267\n",
      "- 배터리용량: 0.0173\n",
      "- 주행거리(km): 0.0142\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 640.0000\n",
      "- 배터리_효율: 509.0000\n",
      "- 배터리용량: 276.0000\n",
      "- km_per_year: 165.0000\n",
      "- 차량상태: 134.0000\n",
      "\n",
      "=== High-Premium-A 세그먼트 최적화 시작 ===\n",
      "데이터 수: 315개\n",
      "\n",
      "High-Premium-A 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.7632\n",
      "- 보증기간(년): 0.2133\n",
      "- km_per_year: 0.0096\n",
      "- 주행거리(km): 0.0064\n",
      "- 배터리_효율: 0.0027\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 462.0000\n",
      "- 주행거리(km): 415.0000\n",
      "- 보증기간(년): 187.0000\n",
      "- km_per_year: 110.0000\n",
      "- 차량상태: 75.0000\n",
      "\n",
      "=== High-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 198개\n",
      "\n",
      "High-T 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.8855\n",
      "- 배터리용량: 0.0351\n",
      "- 보증기간(년): 0.0304\n",
      "- 배터리_연식_효율: 0.0250\n",
      "- 연식(년): 0.0167\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 647.0000\n",
      "- 배터리용량: 436.0000\n",
      "- 배터리_효율: 364.0000\n",
      "- km_per_year: 165.0000\n",
      "- 보증기간(년): 156.0000\n",
      "\n",
      "=== High-B 세그먼트 최적화 시작 ===\n",
      "데이터 수: 298개\n",
      "\n",
      "High-B 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 배터리_효율: 0.2176\n",
      "- 구동방식: 0.2175\n",
      "- km_per_year: 0.2062\n",
      "- 주행거리(km): 0.1909\n",
      "- 보증기간(년): 0.1677\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 603.0000\n",
      "- 배터리_효율: 290.0000\n",
      "- 보증기간(년): 89.0000\n",
      "- 구동방식: 75.0000\n",
      "- km_per_year: 25.0000\n",
      "\n",
      "=== Mid-High-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 448개\n",
      "\n",
      "Mid-High-T 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.3063\n",
      "- km_per_year: 0.1750\n",
      "- 모델: 0.1516\n",
      "- 차량상태: 0.1246\n",
      "- 배터리_연식_효율: 0.1060\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 453.0000\n",
      "- 배터리_효율: 384.0000\n",
      "- 배터리용량: 264.0000\n",
      "- 보증기간(년): 216.0000\n",
      "- 모델: 154.0000\n",
      "\n",
      "=== Mid-T 세그먼트 최적화 시작 ===\n",
      "데이터 수: 234개\n",
      "\n",
      "Mid-T 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.6101\n",
      "- 보증기간(년): 0.2673\n",
      "- 배터리용량: 0.0503\n",
      "- 배터리_연식_효율: 0.0217\n",
      "- 연식(년): 0.0201\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 337.0000\n",
      "- 주행거리(km): 334.0000\n",
      "- 보증기간(년): 285.0000\n",
      "- 배터리용량: 175.0000\n",
      "- 차량상태: 96.0000\n",
      "\n",
      "=== Mid-B 세그먼트 최적화 시작 ===\n",
      "데이터 수: 329개\n",
      "\n",
      "Mid-B 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.2982\n",
      "- 배터리_연식_효율: 0.2138\n",
      "- 배터리용량: 0.1852\n",
      "- 차량상태: 0.1456\n",
      "- 연식(년): 0.0703\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 425.0000\n",
      "- 배터리_효율: 339.0000\n",
      "- 배터리용량: 328.0000\n",
      "- 보증기간(년): 118.0000\n",
      "- km_per_year: 65.0000\n",
      "\n",
      "=== Mid-A 세그먼트 최적화 시작 ===\n",
      "데이터 수: 303개\n",
      "\n",
      "Mid-A 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.3062\n",
      "- 연식(년): 0.2288\n",
      "- 차량연식: 0.2242\n",
      "- 배터리용량: 0.0743\n",
      "- 보증기간(년): 0.0654\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 701.0000\n",
      "- 주행거리(km): 605.0000\n",
      "- km_per_year: 258.0000\n",
      "- 배터리용량: 201.0000\n",
      "- 차량연식: 146.0000\n",
      "\n",
      "=== Mid-Entry-K 세그먼트 최적화 시작 ===\n",
      "데이터 수: 296개\n",
      "\n",
      "Mid-Entry-K 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.9687\n",
      "- km_per_year: 0.0154\n",
      "- 배터리_효율: 0.0071\n",
      "- 구동방식: 0.0054\n",
      "- 주행거리(km): 0.0035\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 1614.0000\n",
      "- 배터리_효율: 416.0000\n",
      "- 보증기간(년): 209.0000\n",
      "- 구동방식: 131.0000\n",
      "- 모델: 0.0000\n",
      "\n",
      "=== Mid-Entry-V 세그먼트 최적화 시작 ===\n",
      "데이터 수: 498개\n",
      "\n",
      "Mid-Entry-V 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 보증기간(년): 0.5733\n",
      "- 차량상태: 0.2055\n",
      "- 연식(년): 0.1027\n",
      "- 배터리용량: 0.0438\n",
      "- 배터리_연식_효율: 0.0279\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 564.0000\n",
      "- 배터리_효율: 455.0000\n",
      "- 보증기간(년): 273.0000\n",
      "- 배터리용량: 222.0000\n",
      "- km_per_year: 188.0000\n",
      "\n",
      "=== Mid-Entry-H 세그먼트 최적화 시작 ===\n",
      "데이터 수: 579개\n",
      "\n",
      "Mid-Entry-H 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 모델: 0.6516\n",
      "- 차량상태: 0.2808\n",
      "- 배터리용량: 0.0218\n",
      "- 보증기간(년): 0.0111\n",
      "- 주행거리(km): 0.0107\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 718.0000\n",
      "- 배터리_효율: 505.0000\n",
      "- 배터리용량: 327.0000\n",
      "- 모델: 154.0000\n",
      "- km_per_year: 104.0000\n",
      "\n",
      "=== Entry-K 세그먼트 최적화 시작 ===\n",
      "데이터 수: 338개\n",
      "\n",
      "Entry-K 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.8653\n",
      "- 보증기간(년): 0.0981\n",
      "- 배터리_연식_효율: 0.0101\n",
      "- 배터리용량: 0.0085\n",
      "- 주행거리(km): 0.0050\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 392.0000\n",
      "- 주행거리(km): 297.0000\n",
      "- 보증기간(년): 180.0000\n",
      "- 배터리용량: 115.0000\n",
      "- 차량상태: 58.0000\n",
      "\n",
      "=== Entry-H 세그먼트 최적화 시작 ===\n",
      "데이터 수: 284개\n",
      "\n",
      "Entry-H 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.8472\n",
      "- 보증기간(년): 0.0983\n",
      "- 배터리용량: 0.0431\n",
      "- 주행거리(km): 0.0033\n",
      "- 배터리_효율: 0.0019\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 622.0000\n",
      "- 배터리_효율: 344.0000\n",
      "- 보증기간(년): 259.0000\n",
      "- km_per_year: 117.0000\n",
      "- 차량상태: 70.0000\n",
      "\n",
      "=== Basic-B 세그먼트 최적화 시작 ===\n",
      "데이터 수: 308개\n",
      "\n",
      "Basic-B 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.4375\n",
      "- km_per_year: 0.2732\n",
      "- 보증기간(년): 0.1281\n",
      "- 주행거리(km): 0.0712\n",
      "- 배터리용량: 0.0345\n",
      "\n",
      "LGB:\n",
      "- 배터리_효율: 606.0000\n",
      "- 보증기간(년): 262.0000\n",
      "- 주행거리(km): 257.0000\n",
      "- 구동방식: 96.0000\n",
      "- km_per_year: 74.0000\n",
      "\n",
      "=== Basic-K 세그먼트 최적화 시작 ===\n",
      "데이터 수: 309개\n",
      "\n",
      "Basic-K 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- 차량상태: 0.8031\n",
      "- 보증기간(년): 0.1535\n",
      "- 배터리_연식_효율: 0.0097\n",
      "- 배터리용량: 0.0079\n",
      "- km_per_year: 0.0066\n",
      "\n",
      "LGB:\n",
      "- 주행거리(km): 337.0000\n",
      "- 배터리_효율: 310.0000\n",
      "- 보증기간(년): 189.0000\n",
      "- 배터리용량: 94.0000\n",
      "- 차량상태: 60.0000\n",
      "\n",
      "=== Basic-H 세그먼트 최적화 시작 ===\n",
      "데이터 수: 111개\n",
      "\n",
      "Basic-H 세그먼트 Top 5 중요 특성:\n",
      "\n",
      "XGB:\n",
      "- km_per_year: 0.1940\n",
      "- 배터리_연식_효율: 0.1465\n",
      "- 배터리용량: 0.1136\n",
      "- 주행거리(km): 0.1076\n",
      "- 배터리_효율: 0.1029\n",
      "\n",
      "LGB:\n",
      "- 배터리용량: 214.0000\n",
      "- 주행거리(km): 210.0000\n",
      "- 배터리_효율: 121.0000\n",
      "- km_per_year: 57.0000\n",
      "- 차량상태: 47.0000\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트                      데이터 수     XGB RMSE     LGB RMSE     앙상블 RMSE    가중치(XGB/LGB)\n",
      "---------------------------------------------------------------------------\n",
      "Premium-P                    80       0.3172       0.3160       0.3152 0.50/0.50\n",
      "Luxury-P                     69       3.7753       3.4162       3.5037 0.30/0.70\n",
      "High-Premium-P               68       2.9806       2.9879       2.9597 0.30/0.70\n",
      "High-Premium-A               70       0.3197       0.3187       0.3182 0.60/0.40\n",
      "High-T                       66       0.6724       0.7072       0.6856 0.30/0.70\n",
      "High-B                       69       0.5499       0.5441       0.5435 0.40/0.60\n",
      "Mid-High-T                  118       0.7438       0.6775       0.6857 0.50/0.50\n",
      "Mid-T                        45       0.4942       0.4439       0.4589 0.50/0.50\n",
      "Mid-B                        85       0.6496       0.6237       0.6332 0.50/0.50\n",
      "Mid-A                        75       0.4456       0.4437       0.4433 0.60/0.40\n",
      "Mid-Entry-K                  73       0.6027       0.6155       0.6036 0.40/0.60\n",
      "Mid-Entry-V                 107       0.6041       0.5963       0.5982 0.50/0.50\n",
      "Mid-Entry-H                 153       0.3897       0.4572       0.4123 0.60/0.40\n",
      "Entry-K                      60       0.6649       0.6310       0.6434 0.50/0.50\n",
      "Entry-H                      81       0.6592       0.7936       0.7297 0.40/0.60\n",
      "Basic-B                      80       0.3387       0.3469       0.3409 0.60/0.40\n",
      "Basic-K                      88       0.5771       0.5447       0.5566 0.50/0.50\n",
      "Basic-H                      29       6.9315       6.4201       6.4816 0.20/0.80\n",
      "===========================================================================\n",
      "전체                         1500                                15.9601\n",
      "\n",
      "테스트 데이터 예측 중...\n",
      "제출 파일 생성 완료: submission18.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedSegmentModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.outlier_thresholds = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "        # IONIQ 보조금 정보\n",
    "        self.ioniq_subsidy = {\n",
    "            2016: {'국가보조금': 1200, '지자체보조금': 600},  # 만원 단위\n",
    "            2017: {'국가보조금': 1400, '지자체보조금': 700},\n",
    "            2018: {'국가보조금': 1200, '지자체보조금': 600},\n",
    "            2019: {'국가보조금': 900, '지자체보조금': 450},\n",
    "            2020: {'국가보조금': 800, '지자체보조금': 400}\n",
    "        }\n",
    "        \n",
    "        # IONIQ 세대별 특성\n",
    "        self.generation_premium = {\n",
    "            2016: {'세대': 1, '프리미엄': 0.8},  # 1세대 초기\n",
    "            2017: {'세대': 1, '프리미엄': 0.85},\n",
    "            2018: {'세대': 1.5, '프리미엄': 0.9},  # 1세대 페이스리프트\n",
    "            2019: {'세대': 1.5, '프리미엄': 0.95},\n",
    "            2020: {'세대': 2, '프리미엄': 1.0}    # 2세대\n",
    "        }\n",
    "        \n",
    "        # 주행거리별 감가율\n",
    "        self.mileage_depreciation = {\n",
    "            10000: 0.02,   # 1만km 당 2% 추가 감가\n",
    "            20000: 0.03,   # 2만km 당 3% 추가 감가\n",
    "            30000: 0.04,   # 3만km 당 4% 추가 감가\n",
    "            40000: 0.05    # 4만km 이상 5% 추가 감가\n",
    "        }\n",
    "        \n",
    "        # 기존 세그먼트 정의는 유지\n",
    "        self.segments = {\n",
    "            'Premium-P': {'min_price': 150, 'models': ['TayGTS'], 'brand': 'P사'},\n",
    "            'Luxury-P': {'min_price': 120, 'models': ['TayCT'], 'brand': 'P사'},\n",
    "            'High-Premium-P': {'min_price': 95, 'models': ['Tay'], 'brand': 'P사'},\n",
    "            'High-Premium-A': {'min_price': 95, 'models': ['RSeTGT'], 'brand': 'A사'},\n",
    "            'High-T': {'min_price': 80, 'models': ['MX'], 'brand': 'T사'},\n",
    "            'High-B': {'min_price': 80, 'models': ['iX'], 'brand': 'B사'},\n",
    "            'Mid-High-T': {'min_price': 65, 'models': ['MS', 'MY'], 'brand': 'T사'},\n",
    "            'Mid-T': {'min_price': 50, 'models': ['M3'], 'brand': 'T사'},\n",
    "            'Mid-B': {'min_price': 50, 'models': ['i5'], 'brand': 'B사'},\n",
    "            'Mid-A': {'min_price': 50, 'models': ['Q4eT'], 'brand': 'A사'},\n",
    "            'Mid-Entry-K': {'min_price': 35, 'models': ['EV6'], 'brand': 'K사'},\n",
    "            'Mid-Entry-V': {'min_price': 35, 'models': ['ID4'], 'brand': 'V사'},\n",
    "            'Mid-Entry-H': {'min_price': 35, 'models': ['ION6', 'ION5'], 'brand': 'H사'},\n",
    "            'Entry-K': {'min_price': 25, 'models': ['Niro'], 'brand': 'K사'},\n",
    "            'Entry-H': {'min_price': 25, 'models': ['KNE'], 'brand': 'H사'},\n",
    "            'Basic-B': {'min_price': 0, 'models': ['i3'], 'brand': 'B사'},\n",
    "            'Basic-K': {'min_price': 0, 'models': ['Soul'], 'brand': 'K사'},\n",
    "            'Basic-H': {'min_price': 0, 'models': ['IONIQ'], 'brand': 'H사'}\n",
    "        }\n",
    "        \n",
    "        self.segment_models = {}\n",
    "        self.price_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        self.data_size_stats = {}\n",
    "        self.performance_history = {}\n",
    "\n",
    "    def add_ioniq_features(self, df):\n",
    "        \"\"\"IONIQ 특화 특성 추가\"\"\"\n",
    "        mask = df['모델'] == 'IONIQ'\n",
    "        if not mask.any():\n",
    "            return df\n",
    "            \n",
    "        # 보조금 적용\n",
    "        df.loc[mask, '출고시_보조금'] = df.loc[mask, '연식(년)'].map(\n",
    "            lambda x: (self.ioniq_subsidy.get(x, {}).get('국가보조금', 0) + \n",
    "                      self.ioniq_subsidy.get(x, {}).get('지자체보조금', 0))\n",
    "        )\n",
    "        \n",
    "        # 실구매가 추정 (백만원 단위)\n",
    "        if '가격(백만원)' in df.columns:\n",
    "            df.loc[mask, '추정_실구매가'] = df.loc[mask, '가격(백만원)'] - (df.loc[mask, '출고시_보조금'] / 10000)\n",
    "        \n",
    "        # 감가상각 계산\n",
    "        base_depreciation = 0.15  # 기본 연간 감가율 15%\n",
    "        \n",
    "        # 연식 기반 감가율\n",
    "        df.loc[mask, '연식_감가율'] = (1 - base_depreciation) ** (2024 - df.loc[mask, '연식(년)'])\n",
    "        \n",
    "        # 주행거리 기반 감가율\n",
    "        df.loc[mask, '주행_감가율'] = df.loc[mask].apply(\n",
    "            lambda x: 1 - sum(\n",
    "                rate for threshold, rate in self.mileage_depreciation.items()\n",
    "                if x['주행거리(km)'] > threshold\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # 복합 감가율\n",
    "        df.loc[mask, '복합_감가율'] = df.loc[mask, '연식_감가율'] * df.loc[mask, '주행_감가율']\n",
    "        \n",
    "        # 세대 프리미엄\n",
    "        df.loc[mask, '세대_프리미엄'] = df.loc[mask, '연식(년)'].map(\n",
    "            lambda x: self.generation_premium.get(x, {}).get('프리미엄', 1.0)\n",
    "        )\n",
    "        \n",
    "        # 예상 가치\n",
    "        if '가격(백만원)' in df.columns:\n",
    "            df.loc[mask, '예상_가치'] = (df.loc[mask, '추정_실구매가'] * \n",
    "                                     df.loc[mask, '복합_감가율'] * \n",
    "                                     df.loc[mask, '세대_프리미엄'])\n",
    "        \n",
    "        return df\n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        \"\"\"데이터 전처리 및 IONIQ 특화 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        # IONIQ 특화 특성 추가\n",
    "        df = self.add_ioniq_features(df)\n",
    "        \n",
    "        # 범주형 변수 처리\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                unknown_values = set(df[col].unique()) - set(self.label_encoders[col].classes_)\n",
    "                if unknown_values:\n",
    "                    print(f\"Warning: Unknown categories in {col}: {unknown_values}\")\n",
    "                    df[col] = df[col].map(lambda x: x if x in self.label_encoders[col].classes_ else self.label_encoders[col].classes_[0])\n",
    "                df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "            lambda x: x.fillna(x.mean())\n",
    "        )\n",
    "        df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def add_features(self, df, is_train=True):\n",
    "        \"\"\"기본 특성 엔지니어링\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 피처 엔지니어링\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['배터리_효율'] = df['배터리용량'] / df['주행거리(km)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식']\n",
    "        df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식']\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # 가격 통계 계산 (학습 데이터일 때만)\n",
    "        if is_train and '가격(백만원)' in df.columns:\n",
    "            model_stats = df.groupby('모델')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['모델'] = {\n",
    "                'mean': model_stats['mean'].to_dict(),\n",
    "                'std': model_stats['std'].to_dict()\n",
    "            }\n",
    "            \n",
    "            manufacturer_stats = df.groupby('제조사')['가격(백만원)'].agg(['mean', 'std'])\n",
    "            self.price_stats['제조사'] = {\n",
    "                'mean': manufacturer_stats['mean'].to_dict(),\n",
    "                'std': manufacturer_stats['std'].to_dict()\n",
    "            }\n",
    "        \n",
    "        # 가격 관련 특성 추가\n",
    "        if '모델' in self.price_stats:\n",
    "            df['모델별_평균가격'] = df['모델'].map(self.price_stats['모델']['mean']).fillna(0)\n",
    "            df['모델별_가격편차'] = df['모델'].map(self.price_stats['모델']['std']).fillna(0)\n",
    "            df['제조사별_평균가격'] = df['제조사'].map(self.price_stats['제조사']['mean']).fillna(0)\n",
    "            df['제조사별_가격편차'] = df['제조사'].map(self.price_stats['제조사']['std']).fillna(0)\n",
    "        else:\n",
    "            df['모델별_평균가격'] = 0\n",
    "            df['모델별_가격편차'] = 0\n",
    "            df['제조사별_평균가격'] = 0\n",
    "            df['제조사별_가격편차'] = 0\n",
    "\n",
    "        # 이상치 처리 및 스케일링\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            df[col] = self.handle_outliers(df, col)\n",
    "            if is_train:\n",
    "                self.scalers[col] = StandardScaler()\n",
    "                df[col] = self.scalers[col].fit_transform(df[[col]])\n",
    "            else:\n",
    "                if col in self.scalers:\n",
    "                    df[col] = self.scalers[col].transform(df[[col]])\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def handle_outliers(self, df, col):\n",
    "        \"\"\"향상된 이상치 처리\"\"\"\n",
    "        if col not in self.outlier_thresholds:\n",
    "            q1 = df[col].quantile(0.05)\n",
    "            q3 = df[col].quantile(0.95)\n",
    "            iqr = q3 - q1\n",
    "            self.outlier_thresholds[col] = {\n",
    "                'lower': q1 - 1.5 * iqr,\n",
    "                'upper': q3 + 1.5 * iqr\n",
    "            }\n",
    "        \n",
    "        bounds = self.outlier_thresholds[col]\n",
    "        return df[col].clip(bounds['lower'], bounds['upper'])\n",
    "    def optimize_model_params(self, X, y, segment, data_size, model_type='xgb'):\n",
    "        \"\"\"축소된 그리드서치 범위의 모델 파라미터 최적화\"\"\"\n",
    "        if model_type == 'xgb':\n",
    "            param_grid = {\n",
    "                'n_estimators': [200, 300],\n",
    "                'learning_rate': [0.03, 0.05],\n",
    "                'max_depth': [4, 5],\n",
    "                'min_child_weight': [3, 5],\n",
    "                'gamma': [0.1],\n",
    "                'subsample': [0.8],\n",
    "                'colsample_bytree': [0.8]\n",
    "            }\n",
    "            base_model = XGBRegressor(\n",
    "                random_state=42,\n",
    "                missing=np.nan,\n",
    "                tree_method='hist',\n",
    "                max_bin=256\n",
    "            )\n",
    "        else:  # lightgbm\n",
    "            param_grid = {\n",
    "                'n_estimators': [200, 300],\n",
    "                'learning_rate': [0.03, 0.05],\n",
    "                'max_depth': [4, 5],\n",
    "                'num_leaves': [31],\n",
    "                'min_child_samples': [20],\n",
    "                'subsample': [0.8],\n",
    "                'colsample_bytree': [0.8]\n",
    "            }\n",
    "            base_model = LGBMRegressor(\n",
    "                random_state=42,\n",
    "                verbose=-1,\n",
    "                min_data_in_leaf=max(20, data_size // 20)\n",
    "            )\n",
    "        \n",
    "        # IONIQ 세그먼트에 대한 특별 처리\n",
    "        if 'IONIQ' in segment:\n",
    "            param_grid.update({\n",
    "                'max_depth': [3, 4],\n",
    "                'min_child_weight': [5, 7] if model_type == 'xgb' else None,\n",
    "                'min_child_samples': [25, 35] if model_type == 'lgb' else None\n",
    "            })\n",
    "        \n",
    "        cv = KFold(n_splits=min(5, max(3, data_size // 30)), shuffle=True, random_state=42)\n",
    "        \n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=base_model,\n",
    "                param_grid=param_grid,\n",
    "                cv=cv,\n",
    "                scoring='neg_root_mean_squared_error',\n",
    "                n_jobs=-1,\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            grid_search.fit(X, y)\n",
    "            \n",
    "        return grid_search.best_estimator_\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        # 기본 특성 + IONIQ 특화 특성\n",
    "        self.base_features = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '배터리_효율', '차량연식',\n",
    "            'km_per_year', '배터리_연식_효율', '잔여보증기간', '제조사',\n",
    "            '모델별_평균가격', '모델별_가격편차', '제조사별_평균가격', '제조사별_가격편차'\n",
    "        ]\n",
    "        \n",
    "        # IONIQ 특화 특성 추가\n",
    "        ioniq_features = [\n",
    "            '출고시_보조금', '연식_감가율', '주행_감가율', '복합_감가율', \n",
    "            '세대_프리미엄', '예상_가치'\n",
    "        ]\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            data_size = mask.sum()\n",
    "            print(f\"데이터 수: {data_size}개\")\n",
    "            self.data_size_stats[segment] = data_size\n",
    "            \n",
    "            # 특성 선택 (IONIQ인 경우 특화 특성 추가)\n",
    "            selected_features = self.base_features.copy()\n",
    "            if 'IONIQ' in segment:\n",
    "                selected_features.extend([f for f in ioniq_features if f in train_processed.columns])\n",
    "            \n",
    "            X = train_processed[mask][selected_features]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            # 모델 최적화 및 학습\n",
    "            xgb_model = self.optimize_model_params(X, y, segment, data_size, 'xgb')\n",
    "            lgb_model = self.optimize_model_params(X, y, segment, data_size, 'lgb')\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'xgb': xgb_model,\n",
    "                'lgb': lgb_model,\n",
    "                'features': selected_features\n",
    "            }\n",
    "            \n",
    "            # 특성 중요도 저장\n",
    "            self.feature_importance[segment] = {\n",
    "                'xgb': dict(zip(selected_features, xgb_model.feature_importances_)),\n",
    "                'lgb': dict(zip(selected_features, lgb_model.feature_importances_))\n",
    "            }\n",
    "            \n",
    "            # 중요 특성 출력\n",
    "            print(f\"\\n{segment} 세그먼트 Top 5 중요 특성:\")\n",
    "            for model_type, importance in self.feature_importance[segment].items():\n",
    "                top_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                print(f\"\\n{model_type.upper()}:\")\n",
    "                for feat, imp in top_features:\n",
    "                    print(f\"- {feat}: {imp:.4f}\")\n",
    "\n",
    "    def assign_segment(self, model):\n",
    "        \"\"\"모델별 세그먼트 할당\"\"\"\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info.get('models', []):\n",
    "                return segment\n",
    "        return 'Other'\n",
    "    def get_dynamic_weights(self, data_size, segment, current_rmse=None):\n",
    "        \"\"\"동적 가중치 결정\"\"\"\n",
    "        if data_size < 200:\n",
    "            weights = {'xgb': 0.3, 'lgb': 0.7}\n",
    "        elif data_size < 300:\n",
    "            weights = {'xgb': 0.4, 'lgb': 0.6}\n",
    "        else:\n",
    "            weights = {'xgb': 0.5, 'lgb': 0.5}\n",
    "            \n",
    "        # RMSE 기반 조정\n",
    "        if current_rmse is not None:\n",
    "            if current_rmse > 2.0:\n",
    "                weights['lgb'] = min(0.8, weights['lgb'] + 0.1)\n",
    "                weights['xgb'] = 1 - weights['lgb']\n",
    "            elif current_rmse < 0.5:\n",
    "                weights['xgb'] = min(0.7, weights['xgb'] + 0.1)\n",
    "                weights['lgb'] = 1 - weights['xgb']\n",
    "        \n",
    "        # IONIQ 특별 처리\n",
    "        if 'IONIQ' in segment:\n",
    "            weights['lgb'] = min(0.8, weights['lgb'] + 0.15)  # LightGBM 가중치 증가\n",
    "            weights['xgb'] = 1 - weights['lgb']\n",
    "            \n",
    "        return weights\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"예측\"\"\"\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = test_processed[mask][selected_features]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # 현재 RMSE 기반 동적 가중치 적용\n",
    "            current_rmse = self.performance_history.get(segment, {}).get('last_rmse')\n",
    "            weights = self.get_dynamic_weights(self.data_size_stats[segment], segment, current_rmse)\n",
    "            \n",
    "            predictions[mask] = weights['xgb'] * xgb_pred + weights['lgb'] * lgb_pred\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        \"\"\"성능 평가\"\"\"\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<20} {'데이터 수':>10} {'XGB RMSE':>12} {'LGB RMSE':>12} \"\n",
    "              f\"{'앙상블 RMSE':>12} {'가중치(XGB/LGB)':>15}\")\n",
    "        print(\"-\" * 75)\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            selected_features = self.segment_models[segment]['features']\n",
    "            X = val_processed[mask][selected_features]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            xgb_pred = self.segment_models[segment]['xgb'].predict(X)\n",
    "            lgb_pred = self.segment_models[segment]['lgb'].predict(X)\n",
    "            \n",
    "            # RMSE 기반 동적 가중치\n",
    "            current_rmse = np.sqrt(mean_squared_error(y, (xgb_pred + lgb_pred) / 2))\n",
    "            weights = self.get_dynamic_weights(self.data_size_stats[segment], segment, current_rmse)\n",
    "            \n",
    "            ensemble_pred = weights['xgb'] * xgb_pred + weights['lgb'] * lgb_pred\n",
    "            \n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            xgb_rmse = np.sqrt(mean_squared_error(y, xgb_pred))\n",
    "            lgb_rmse = np.sqrt(mean_squared_error(y, lgb_pred))\n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            \n",
    "            # 성능 이력 업데이트\n",
    "            self.performance_history[segment] = {\n",
    "                'last_rmse': ensemble_rmse,\n",
    "                'improvement': self.performance_history.get(segment, {}).get('last_rmse', float('inf')) - ensemble_rmse\n",
    "            }\n",
    "            \n",
    "            print(f\"{segment:<20} {mask.sum():>10d} {xgb_rmse:>12.4f} {lgb_rmse:>12.4f} \"\n",
    "                  f\"{ensemble_rmse:>12.4f} {weights['xgb']:.2f}/{weights['lgb']:.2f}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'xgb_rmse': xgb_rmse,\n",
    "                'lgb_rmse': lgb_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse,\n",
    "                'weights': weights\n",
    "            }\n",
    "            \n",
    "            # IONIQ 특별 분석\n",
    "            if 'IONIQ' in segment:\n",
    "                ioniq_features = [f for f in X.columns if f in [\n",
    "                    '출고시_보조금', '연식_감가율', '주행_감가율', '복합_감가율', \n",
    "                    '세대_프리미엄', '예상_가치'\n",
    "                ]]\n",
    "                if ioniq_features:\n",
    "                    print(\"\\nIONIQ 특화 특성 중요도:\")\n",
    "                    for feat in ioniq_features:\n",
    "                        print(f\"- {feat}: XGB={self.feature_importance[segment]['xgb'].get(feat, 0):.4f}, \"\n",
    "                              f\"LGB={self.feature_importance[segment]['lgb'].get(feat, 0):.4f}\")\n",
    "        \n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 75)\n",
    "        print(f\"{'전체':<20} {len(y_val):>10d} {'':>12} {'':>12} {total_rmse:>12.4f}\")\n",
    "        \n",
    "        return segment_metrics, total_rmse\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    # 데이터 로드\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    if 'ID' not in test.columns:\n",
    "        test['ID'] = range(len(test))\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"IONIQ 특화 세그먼트 기반 모델 학습 시작...\")\n",
    "    model = EnhancedSegmentModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    \n",
    "    print(\"\\n테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission18.csv', index=False, encoding='utf-8')\n",
    "    print(\"제출 파일 생성 완료: submission18.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== IONIQ 특화 개선 모델 학습 시작 ===\n",
      "\n",
      "1. 데이터 로딩...\n",
      "학습 데이터 크기: (7497, 11)\n",
      "테스트 데이터 크기: (846, 10)\n",
      "\n",
      "2. 데이터 분할...\n",
      "학습 세트 크기: (5997, 10)\n",
      "검증 세트 크기: (1500, 10)\n",
      "\n",
      "3. 모델 학습 시작...\n",
      "\n",
      "=== Premium-P 세그먼트 학습 ===\n",
      "데이터 수: 295개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 523.0000\n",
      "- 배터리_효율: 365.0000\n",
      "- 배터리용량: 326.0000\n",
      "- 연평균주행거리: 60.0000\n",
      "- 배터리_연식_효율: 53.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 배터리용량: 0.4113\n",
      "- 차량상태_점수: 0.3630\n",
      "- 배터리_연식_효율: 0.1783\n",
      "- 주행거리(km): 0.0358\n",
      "- 배터리_효율: 0.0041\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 배터리용량: 33.9507\n",
      "- 배터리_연식_효율: 31.3656\n",
      "- 차량상태_점수: 17.5318\n",
      "- 연평균주행거리: 6.1016\n",
      "- 주행거리(km): 3.9840\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 배터리용량: 0.3049\n",
      "- 배터리_연식_효율: 0.2540\n",
      "- 배터리_효율: 0.2012\n",
      "- 연평균주행거리: 0.0864\n",
      "- 차량상태_점수: 0.0788\n",
      "\n",
      "=== Luxury-P 세그먼트 학습 ===\n",
      "데이터 수: 266개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 820.0000\n",
      "- 배터리_효율: 396.0000\n",
      "- 연평균주행거리: 120.0000\n",
      "- 보증기간(년): 60.0000\n",
      "- 종합_상태_점수: 53.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 보증기간(년): 0.2323\n",
      "- 차량연식: 0.1843\n",
      "- 연식(년): 0.1625\n",
      "- 배터리_연식_효율: 0.1073\n",
      "- 차량상태_점수: 0.0911\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 차량연식: 19.4319\n",
      "- 보증기간(년): 15.1235\n",
      "- 배터리_연식_효율: 12.0739\n",
      "- 차량상태_점수: 10.1234\n",
      "- 배터리_효율: 9.7494\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 배터리_효율: 0.2241\n",
      "- 연평균주행거리: 0.1383\n",
      "- 연식(년): 0.1299\n",
      "- 주행거리(km): 0.1278\n",
      "- 차량연식: 0.1114\n",
      "\n",
      "=== High-Premium-P 세그먼트 학습 ===\n",
      "데이터 수: 293개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 배터리_효율: 817.0000\n",
      "- 주행거리(km): 505.0000\n",
      "- 배터리용량: 278.0000\n",
      "- 차량상태_점수: 131.0000\n",
      "- 연평균주행거리: 64.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.8444\n",
      "- 주행거리(km): 0.0815\n",
      "- 연평균주행거리: 0.0329\n",
      "- 배터리용량: 0.0146\n",
      "- 배터리_연식_효율: 0.0137\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 차량상태_점수: 43.9841\n",
      "- 연평균주행거리: 31.4902\n",
      "- 주행거리(km): 10.9239\n",
      "- 종합_상태_점수: 7.8026\n",
      "- 배터리_연식_효율: 1.8698\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.5161\n",
      "- 주행거리(km): 0.2445\n",
      "- 연평균주행거리: 0.1748\n",
      "- 배터리_효율: 0.0297\n",
      "- 배터리용량: 0.0178\n",
      "\n",
      "=== High-Premium-A 세그먼트 학습 ===\n",
      "데이터 수: 315개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 589.0000\n",
      "- 배터리_효율: 297.0000\n",
      "- 보증기간(년): 224.0000\n",
      "- 연평균주행거리: 66.0000\n",
      "- 주행거리_구간: 41.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.6895\n",
      "- 보증기간(년): 0.2085\n",
      "- 주행거리(km): 0.0775\n",
      "- 주행거리_구간: 0.0095\n",
      "- 연평균주행거리: 0.0086\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 68.4891\n",
      "- 차량상태_점수: 9.1487\n",
      "- 주행거리(km): 6.5305\n",
      "- 연평균주행거리: 5.9663\n",
      "- 종합_상태_점수: 2.8242\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.5144\n",
      "- 주행거리(km): 0.1716\n",
      "- 차량상태_점수: 0.1279\n",
      "- 연평균주행거리: 0.1176\n",
      "- 배터리_효율: 0.0661\n",
      "\n",
      "=== High-T 세그먼트 학습 ===\n",
      "데이터 수: 198개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 620.0000\n",
      "- 배터리_효율: 478.0000\n",
      "- 배터리용량: 435.0000\n",
      "- 보증기간(년): 141.0000\n",
      "- 연평균주행거리: 81.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 배터리용량: 0.5642\n",
      "- 보증기간(년): 0.2073\n",
      "- 차량상태_점수: 0.1274\n",
      "- 주행거리(km): 0.0506\n",
      "- 연식(년): 0.0257\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 34.8376\n",
      "- 차량상태_점수: 25.0033\n",
      "- 배터리_연식_효율: 18.5180\n",
      "- 배터리용량: 9.2154\n",
      "- 주행거리(km): 3.1447\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 배터리용량: 0.2020\n",
      "- 배터리_효율: 0.1841\n",
      "- 배터리_연식_효율: 0.1743\n",
      "- 보증기간(년): 0.1707\n",
      "- 차량상태_점수: 0.1080\n",
      "\n",
      "=== High-B 세그먼트 학습 ===\n",
      "데이터 수: 298개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 686.0000\n",
      "- 연평균주행거리: 190.0000\n",
      "- 보증기간(년): 92.0000\n",
      "- 종합_상태_점수: 55.0000\n",
      "- 배터리_효율: 42.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 연평균주행거리: 0.1851\n",
      "- 배터리_효율: 0.1752\n",
      "- 종합_상태_점수: 0.1744\n",
      "- 주행거리(km): 0.1690\n",
      "- 구동방식_점수: 0.1633\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 배터리_효율: 21.9016\n",
      "- 주행거리(km): 21.7000\n",
      "- 연평균주행거리: 20.1031\n",
      "- 종합_상태_점수: 15.7956\n",
      "- 보증기간(년): 11.2167\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 배터리_효율: 0.3521\n",
      "- 연평균주행거리: 0.2397\n",
      "- 주행거리(km): 0.2180\n",
      "- 종합_상태_점수: 0.1044\n",
      "- 보증기간(년): 0.0566\n",
      "\n",
      "=== Mid-High-T 세그먼트 학습 ===\n",
      "데이터 수: 448개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 818.0000\n",
      "- 배터리_효율: 605.0000\n",
      "- 배터리용량: 517.0000\n",
      "- 보증기간(년): 379.0000\n",
      "- 모델: 264.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.3793\n",
      "- 보증기간(년): 0.2328\n",
      "- 모델: 0.1178\n",
      "- 배터리_연식_효율: 0.0732\n",
      "- 주행거리(km): 0.0612\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 48.3776\n",
      "- 모델: 19.5115\n",
      "- 차량상태_점수: 12.4159\n",
      "- 배터리_연식_효율: 4.7128\n",
      "- 배터리용량: 4.4431\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.6993\n",
      "- 배터리_연식_효율: 0.1136\n",
      "- 배터리용량: 0.1078\n",
      "- 모델: 0.0280\n",
      "- 연평균주행거리: 0.0130\n",
      "\n",
      "=== Mid-T 세그먼트 학습 ===\n",
      "데이터 수: 234개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 630.0000\n",
      "- 배터리_효율: 524.0000\n",
      "- 보증기간(년): 344.0000\n",
      "- 배터리용량: 227.0000\n",
      "- 연평균주행거리: 75.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 보증기간(년): 0.5095\n",
      "- 주행거리(km): 0.2088\n",
      "- 배터리용량: 0.0947\n",
      "- 연식(년): 0.0661\n",
      "- 차량상태_점수: 0.0480\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 74.9513\n",
      "- 차량상태_점수: 10.8617\n",
      "- 종합_상태_점수: 3.8681\n",
      "- 주행거리(km): 2.0949\n",
      "- 연평균주행거리: 2.0641\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.4697\n",
      "- 차량상태_점수: 0.1215\n",
      "- 배터리_효율: 0.1190\n",
      "- 연평균주행거리: 0.1035\n",
      "- 주행거리(km): 0.1017\n",
      "\n",
      "=== Mid-B 세그먼트 학습 ===\n",
      "데이터 수: 329개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 463.0000\n",
      "- 배터리용량: 324.0000\n",
      "- 배터리_효율: 277.0000\n",
      "- 보증기간(년): 115.0000\n",
      "- 연평균주행거리: 90.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 보증기간(년): 0.3556\n",
      "- 배터리용량: 0.3520\n",
      "- 차량연식: 0.0890\n",
      "- 연식(년): 0.0696\n",
      "- 배터리_연식_효율: 0.0484\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 20.2148\n",
      "- 차량연식: 17.9436\n",
      "- 배터리_연식_효율: 16.2332\n",
      "- 연식(년): 13.7417\n",
      "- 배터리용량: 12.6084\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.4063\n",
      "- 배터리_연식_효율: 0.1915\n",
      "- 배터리용량: 0.1881\n",
      "- 차량연식: 0.0532\n",
      "- 연식(년): 0.0391\n",
      "\n",
      "=== Mid-A 세그먼트 학습 ===\n",
      "데이터 수: 303개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 배터리_효율: 773.0000\n",
      "- 주행거리(km): 619.0000\n",
      "- 배터리용량: 162.0000\n",
      "- 보증기간(년): 124.0000\n",
      "- 연식(년): 111.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.5586\n",
      "- 차량연식: 0.1562\n",
      "- 연식(년): 0.1155\n",
      "- 보증기간(년): 0.0623\n",
      "- 배터리용량: 0.0612\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 차량연식: 21.9068\n",
      "- 연식(년): 20.7392\n",
      "- 배터리_연식_효율: 14.1335\n",
      "- 배터리용량: 13.1130\n",
      "- 차량상태_점수: 10.7732\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 차량연식: 0.2154\n",
      "- 연식(년): 0.1908\n",
      "- 주행거리(km): 0.1544\n",
      "- 연평균주행거리: 0.1433\n",
      "- 보증기간(년): 0.0897\n",
      "\n",
      "=== Mid-Entry-K 세그먼트 학습 ===\n",
      "데이터 수: 296개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 1613.0000\n",
      "- 연평균주행거리: 398.0000\n",
      "- 보증기간(년): 206.0000\n",
      "- 구동방식_점수: 109.0000\n",
      "- 종합_상태_점수: 30.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 보증기간(년): 0.9801\n",
      "- 연평균주행거리: 0.0052\n",
      "- 배터리_효율: 0.0050\n",
      "- 구동방식_점수: 0.0047\n",
      "- 주행거리(km): 0.0031\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 99.2773\n",
      "- 종합_상태_점수: 0.1895\n",
      "- 연평균주행거리: 0.1565\n",
      "- 배터리_효율: 0.1555\n",
      "- 주행거리(km): 0.1433\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.9950\n",
      "- 배터리_효율: 0.0018\n",
      "- 연평균주행거리: 0.0014\n",
      "- 주행거리(km): 0.0013\n",
      "- 종합_상태_점수: 0.0003\n",
      "\n",
      "=== Mid-Entry-V 세그먼트 학습 ===\n",
      "데이터 수: 498개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 698.0000\n",
      "- 배터리_효율: 535.0000\n",
      "- 보증기간(년): 257.0000\n",
      "- 배터리용량: 208.0000\n",
      "- 연평균주행거리: 104.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 보증기간(년): 0.7630\n",
      "- 연식(년): 0.1083\n",
      "- 배터리용량: 0.0648\n",
      "- 배터리_효율: 0.0212\n",
      "- 주행거리(km): 0.0193\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 73.1920\n",
      "- 차량상태_점수: 8.8418\n",
      "- 종합_상태_점수: 3.5741\n",
      "- 주행거리(km): 3.2842\n",
      "- 연평균주행거리: 2.9365\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.9094\n",
      "- 배터리_효율: 0.0174\n",
      "- 배터리용량: 0.0149\n",
      "- 배터리_연식_효율: 0.0129\n",
      "- 연식(년): 0.0124\n",
      "\n",
      "=== Mid-Entry-H 세그먼트 학습 ===\n",
      "데이터 수: 579개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 679.0000\n",
      "- 배터리_효율: 491.0000\n",
      "- 배터리용량: 361.0000\n",
      "- 모델: 159.0000\n",
      "- 연평균주행거리: 159.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 모델: 0.7387\n",
      "- 보증기간(년): 0.0764\n",
      "- 배터리용량: 0.0428\n",
      "- 배터리_연식_효율: 0.0407\n",
      "- 차량상태_점수: 0.0327\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 모델: 91.1447\n",
      "- 차량상태_점수: 2.0591\n",
      "- 보증기간(년): 1.5845\n",
      "- 배터리_효율: 1.1053\n",
      "- 연평균주행거리: 0.8637\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 모델: 0.8389\n",
      "- 연평균주행거리: 0.0394\n",
      "- 주행거리(km): 0.0390\n",
      "- 보증기간(년): 0.0277\n",
      "- 배터리_효율: 0.0244\n",
      "\n",
      "=== Entry-K 세그먼트 학습 ===\n",
      "데이터 수: 338개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 배터리_효율: 397.0000\n",
      "- 주행거리(km): 334.0000\n",
      "- 보증기간(년): 183.0000\n",
      "- 배터리용량: 147.0000\n",
      "- 종합_상태_점수: 111.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.8033\n",
      "- 보증기간(년): 0.1164\n",
      "- 주행거리(km): 0.0542\n",
      "- 배터리용량: 0.0083\n",
      "- 배터리_효율: 0.0049\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 49.1401\n",
      "- 차량상태_점수: 30.9796\n",
      "- 주행거리(km): 5.8365\n",
      "- 연평균주행거리: 4.8390\n",
      "- 배터리_효율: 3.7084\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.4752\n",
      "- 차량상태_점수: 0.3388\n",
      "- 주행거리(km): 0.0650\n",
      "- 배터리_효율: 0.0570\n",
      "- 연평균주행거리: 0.0478\n",
      "\n",
      "=== Entry-H 세그먼트 학습 ===\n",
      "데이터 수: 284개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 677.0000\n",
      "- 배터리_효율: 294.0000\n",
      "- 보증기간(년): 268.0000\n",
      "- 연평균주행거리: 100.0000\n",
      "- 배터리용량: 81.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 배터리용량: 0.7799\n",
      "- 보증기간(년): 0.1238\n",
      "- 차량상태_점수: 0.0642\n",
      "- 주행거리(km): 0.0184\n",
      "- 배터리_효율: 0.0026\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 48.8538\n",
      "- 차량상태_점수: 23.8812\n",
      "- 배터리용량: 10.1626\n",
      "- 배터리_연식_효율: 7.7467\n",
      "- 주행거리(km): 3.8694\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.2852\n",
      "- 배터리용량: 0.2684\n",
      "- 배터리_연식_효율: 0.1307\n",
      "- 배터리_효율: 0.0914\n",
      "- 차량상태_점수: 0.0797\n",
      "\n",
      "=== Basic-B 세그먼트 학습 ===\n",
      "데이터 수: 308개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 547.0000\n",
      "- 배터리_효율: 355.0000\n",
      "- 보증기간(년): 271.0000\n",
      "- 연평균주행거리: 104.0000\n",
      "- 종합_상태_점수: 57.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 배터리용량: 0.6260\n",
      "- 차량상태_점수: 0.1593\n",
      "- 보증기간(년): 0.0899\n",
      "- 연평균주행거리: 0.0490\n",
      "- 주행거리(km): 0.0403\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 40.6175\n",
      "- 차량상태_점수: 12.8129\n",
      "- 주행거리(km): 11.3350\n",
      "- 배터리_효율: 8.5169\n",
      "- 배터리_연식_효율: 6.3717\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.3045\n",
      "- 주행거리(km): 0.2301\n",
      "- 배터리_효율: 0.1717\n",
      "- 연평균주행거리: 0.1676\n",
      "- 차량상태_점수: 0.0858\n",
      "\n",
      "=== Basic-K 세그먼트 학습 ===\n",
      "데이터 수: 309개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 380.0000\n",
      "- 배터리_효율: 245.0000\n",
      "- 보증기간(년): 190.0000\n",
      "- 배터리용량: 104.0000\n",
      "- 연평균주행거리: 60.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.8224\n",
      "- 보증기간(년): 0.1178\n",
      "- 주행거리(km): 0.0345\n",
      "- 배터리용량: 0.0062\n",
      "- 종합_상태_점수: 0.0042\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 45.0943\n",
      "- 차량상태_점수: 17.4553\n",
      "- 종합_상태_점수: 13.3356\n",
      "- 주행거리(km): 11.3138\n",
      "- 배터리_효율: 6.2669\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.4250\n",
      "- 차량상태_점수: 0.2303\n",
      "- 배터리_효율: 0.1499\n",
      "- 주행거리(km): 0.0945\n",
      "- 연평균주행거리: 0.0734\n",
      "\n",
      "=== Basic-H 세그먼트 학습 ===\n",
      "데이터 수: 111개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 213.0000\n",
      "- 배터리용량: 202.0000\n",
      "- 배터리_효율: 112.0000\n",
      "- 주행거리_구간: 33.0000\n",
      "- 배터리_연식_효율: 30.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 연평균주행거리: 0.1225\n",
      "- 차량연식: 0.1210\n",
      "- 배터리용량: 0.1178\n",
      "- 주행거리(km): 0.1059\n",
      "- 배터리_효율: 0.1010\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 배터리_연식_효율: 17.1219\n",
      "- 배터리용량: 16.9271\n",
      "- 주행거리(km): 10.9958\n",
      "- 연평균주행거리: 9.2850\n",
      "- 주행거리_구간: 8.6639\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 주행거리(km): 0.2307\n",
      "- 연평균주행거리: 0.2013\n",
      "- 배터리용량: 0.1896\n",
      "- 배터리_효율: 0.1327\n",
      "- 배터리_연식_효율: 0.1044\n",
      "\n",
      "4. 검증 데이터로 성능 평가...\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트               데이터 수        LGB         RF        CAT        XGB        앙상블         가중치(L/R/C/X)\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Premium-P             80     0.3152     0.3189     0.3214     0.3216     0.3153  0.25/0.25/0.25/0.25\n",
      "Luxury-P              69     3.4545     3.3842     3.3554     3.7018     3.4134  0.25/0.26/0.26/0.23\n",
      "High-Premium-P        68     2.9505     2.8574     2.9486     2.9743     2.8973  0.25/0.26/0.25/0.25\n",
      "High-Premium-A        70     0.3246     0.3129     0.3067     0.3561     0.3168  0.25/0.26/0.26/0.23\n",
      "High-T                66     0.6968     0.7202     0.7168     0.6721     0.6867  0.35/0.35/0.20/0.10\n",
      "High-B                69     0.5383     0.5260     0.5375     0.5444     0.5320  0.25/0.25/0.25/0.25\n",
      "Mid-High-T           118     0.7015     0.6298     0.6638     0.7307     0.6531  0.24/0.27/0.26/0.23\n",
      "Mid-T                 45     0.4411     0.4440     0.4780     0.4948     0.4464  0.26/0.26/0.24/0.23\n",
      "Mid-B                 85     0.6280     0.6403     0.6395     0.6461     0.6329  0.25/0.25/0.25/0.25\n",
      "Mid-A                 75     0.4394     0.4375     0.4283     0.4493     0.4343  0.25/0.25/0.26/0.24\n",
      "Mid-Entry-K           73     0.6171     0.5728     0.5811     0.5848     0.5815  0.24/0.26/0.25/0.25\n",
      "Mid-Entry-V          107     0.5803     0.5724     0.5894     0.5967     0.5780  0.25/0.26/0.25/0.24\n",
      "Mid-Entry-H          153     0.6277     0.3283     0.3363     0.5694     0.3811  0.17/0.33/0.32/0.19\n",
      "Entry-K               60     0.6377     0.6418     0.6324     0.6715     0.6395  0.25/0.25/0.26/0.24\n",
      "Entry-H               81     1.6660     1.7286     1.0230     2.1824     1.5103  0.23/0.22/0.37/0.18\n",
      "Basic-B               80     0.3464     0.3360     0.3380     0.3386     0.3374  0.25/0.25/0.25/0.25\n",
      "Basic-K               88     0.5464     0.5450     0.5563     0.5724     0.5480  0.25/0.25/0.25/0.24\n",
      "Basic-H               29     6.4843     6.1486     6.2533     6.7887     6.3416  0.45/0.25/0.20/0.10\n",
      "===============================================================================================\n",
      "전체                  1500                                                15.9602\n",
      "\n",
      "전체 RMSE: 15.9602\n",
      "\n",
      "5. 테스트 데이터 예측 중...\n",
      "\n",
      "6. 제출 파일 생성...\n",
      "제출 파일 생성 완료: submission19.csv\n",
      "\n",
      "=== 모델 성능 요약 ===\n",
      "검증 세트 전체 RMSE: 15.9602\n",
      "\n",
      "IONIQ 세그먼트 성능:\n",
      "- Basic-H:\n",
      "  데이터 수: 29\n",
      "  앙상블 RMSE: 6.3416\n",
      "  최종 가중치: LGB=0.45, RF=0.25, CAT=0.20, XGB=0.10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedSegmentModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.outlier_thresholds = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "        # 차량 상태 매핑\n",
    "        self.status_map = {\n",
    "            'Brand New': 1.0,\n",
    "            'Nearly New': 0.9,\n",
    "            'Pre-Owned': 0.7,\n",
    "            '신차': 1.0,\n",
    "            '거의 신차': 0.9,\n",
    "            '중고': 0.7\n",
    "        }\n",
    "        \n",
    "        # 사고이력 매핑\n",
    "        self.accident_map = {\n",
    "            'No': 1.0,\n",
    "            'Minor': 0.8,\n",
    "            'Yes': 0.6,\n",
    "            '무사고': 1.0,\n",
    "            '경미': 0.8,\n",
    "            '사고': 0.6\n",
    "        }\n",
    "        \n",
    "        # 구동방식 매핑\n",
    "        self.drive_map = {\n",
    "            'AWD': 1.0,\n",
    "            'FWD': 0.8,\n",
    "            'RWD': 0.9\n",
    "        }\n",
    "        \n",
    "        # Define available models\n",
    "        self.models = {\n",
    "            'lgb': LGBMRegressor,\n",
    "            'xgb': XGBRegressor,\n",
    "            'cat': CatBoostRegressor,\n",
    "            'rf': RandomForestRegressor\n",
    "        }\n",
    "        \n",
    "        # Initialize storage\n",
    "        self.segment_models = {}\n",
    "        self.performance_history = {}\n",
    "        self.data_size_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        self.price_stats = {}\n",
    "        \n",
    "        # 세그먼트 정의\n",
    "        self.segments = {\n",
    "            'Premium-P': {'models': ['TayGTS']},\n",
    "            'Luxury-P': {'models': ['TayCT']},\n",
    "            'High-Premium-P': {'models': ['Tay']},\n",
    "            'High-Premium-A': {'models': ['RSeTGT']},\n",
    "            'High-T': {'models': ['MX']},\n",
    "            'High-B': {'models': ['iX']},\n",
    "            'Mid-High-T': {'models': ['MS', 'MY']},\n",
    "            'Mid-T': {'models': ['M3']},\n",
    "            'Mid-B': {'models': ['i5']},\n",
    "            'Mid-A': {'models': ['Q4eT']},\n",
    "            'Mid-Entry-K': {'models': ['EV6']},\n",
    "            'Mid-Entry-V': {'models': ['ID4']},\n",
    "            'Mid-Entry-H': {'models': ['ION6', 'ION5']},\n",
    "            'Entry-K': {'models': ['Niro']},\n",
    "            'Entry-H': {'models': ['KNE']},\n",
    "            'Basic-B': {'models': ['i3']},\n",
    "            'Basic-K': {'models': ['Soul']},\n",
    "            'Basic-H': {'models': ['IONIQ']}\n",
    "        }\n",
    "\n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        # 범주형 변수의 수치형 매핑\n",
    "        df['차량상태_점수'] = df['차량상태'].map(self.status_map).fillna(0.7)\n",
    "        df['사고이력_점수'] = df['사고이력'].map(self.accident_map).fillna(0.7)\n",
    "        df['구동방식_점수'] = df['구동방식'].map(self.drive_map).fillna(0.8)\n",
    "        \n",
    "        # 범주형 변수 처리\n",
    "        categorical_cols = ['모델', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                if col in df.columns:\n",
    "                    unknown_values = set(df[col].unique()) - set(self.label_encoders[col].classes_)\n",
    "                    if unknown_values:\n",
    "                        print(f\"Warning: Unknown categories in {col}: {unknown_values}\")\n",
    "                        df[col] = df[col].map(lambda x: x if x in self.label_encoders[col].classes_ \n",
    "                                            else self.label_encoders[col].classes_[0])\n",
    "                    df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리 - 배터리 용량\n",
    "        if '배터리용량' in df.columns:\n",
    "            # 1. 같은 모델, 같은 연식의 평균으로 채우기\n",
    "            df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "                lambda x: x.fillna(x.mean())\n",
    "            )\n",
    "            \n",
    "            # 2. 같은 모델의 전체 평균으로 채우기\n",
    "            df['배터리용량'] = df.groupby('모델')['배터리용량'].transform(\n",
    "                lambda x: x.fillna(x.mean())\n",
    "            )\n",
    "            \n",
    "            # 3. 전체 평균으로 채우기\n",
    "            df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].mean())\n",
    "        \n",
    "        # 기본 특성 추가\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def assign_segment(self, model):\n",
    "        \"\"\"세그먼트 할당\"\"\"\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "\n",
    "    def add_features(self, df, is_train=True):\n",
    "        \"\"\"기본 특성 엔지니어링\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 차량 연식 계산\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        \n",
    "        # 주행거리 관련 특성\n",
    "        df['연평균주행거리'] = df['주행거리(km)'] / df['차량연식']\n",
    "        \n",
    "        # 주행거리 구간을 숫자형으로 변경\n",
    "        def km_to_group(km):\n",
    "            if km <= 20000: return 1\n",
    "            elif km <= 40000: return 2\n",
    "            elif km <= 60000: return 3\n",
    "            else: return 4\n",
    "        df['주행거리_구간'] = df['주행거리(km)'].apply(km_to_group)\n",
    "        \n",
    "        # 배터리 효율성 특성\n",
    "        if '배터리용량' in df.columns:\n",
    "            df['배터리_효율'] = (df['배터리용량'] / df['주행거리(km)'].clip(lower=1)) * 1000  # km당 배터리 효율\n",
    "            df['배터리_연식_효율'] = df['배터리용량'] / df['차량연식'].clip(lower=1)\n",
    "        \n",
    "        # 보증 관련 특성\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        df['보증비율'] = (df['잔여보증기간'] / df['보증기간(년)']).fillna(0)\n",
    "        \n",
    "        # 종합 점수\n",
    "        df['종합_상태_점수'] = (\n",
    "            df['차량상태_점수'] * 0.4 +\n",
    "            df['사고이력_점수'] * 0.3 +\n",
    "            df['보증비율'] * 0.2 +\n",
    "            df['구동방식_점수'] * 0.1\n",
    "        )\n",
    "\n",
    "        # 이상치 처리\n",
    "        numeric_cols = [col for col in df.select_dtypes(include=[np.number]).columns \n",
    "                       if col not in ['ID', 'segment']]\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if is_train:\n",
    "                q1 = df[col].quantile(0.05)\n",
    "                q3 = df[col].quantile(0.95)\n",
    "                iqr = q3 - q1\n",
    "                self.outlier_thresholds[col] = {\n",
    "                    'lower': q1 - 1.5 * iqr,\n",
    "                    'upper': q3 + 1.5 * iqr\n",
    "                }\n",
    "            \n",
    "            if col in self.outlier_thresholds:\n",
    "                df[col] = df[col].clip(\n",
    "                    self.outlier_thresholds[col]['lower'],\n",
    "                    self.outlier_thresholds[col]['upper']\n",
    "                )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_dynamic_weights(self, data_size, segment, model_scores=None):\n",
    "        \"\"\"향상된 동적 가중치 결정\"\"\"\n",
    "        # Base weights from Autogluon insights\n",
    "        weights = {\n",
    "            'lgb': 0.417,\n",
    "            'rf': 0.292,\n",
    "            'cat': 0.292,\n",
    "            'xgb': 0.0\n",
    "        }\n",
    "        \n",
    "        # Adjust weights based on model performance if available\n",
    "        if model_scores is not None:\n",
    "            total_score = sum(1/score for score in model_scores.values() if score > 0)\n",
    "            if total_score > 0:\n",
    "                for model, score in model_scores.items():\n",
    "                    if score > 0:\n",
    "                        weights[model] = (1/score) / total_score\n",
    "        \n",
    "        # Segment-specific adjustments\n",
    "        if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "            weights.update({\n",
    "                'lgb': 0.45,\n",
    "                'rf': 0.25,\n",
    "                'cat': 0.20,\n",
    "                'xgb': 0.10\n",
    "            })\n",
    "        elif data_size < 200:\n",
    "            weights.update({\n",
    "                'rf': 0.35,\n",
    "                'lgb': 0.35,\n",
    "                'cat': 0.20,\n",
    "                'xgb': 0.10\n",
    "            })\n",
    "        \n",
    "        # Normalize weights\n",
    "        total = sum(weights.values())\n",
    "        return {k: v/total for k, v in weights.items()}\n",
    "\n",
    "    def optimize_model_params(self, X, y, segment, data_size, model_type):\n",
    "        \"\"\"모델 파라미터 최적화\"\"\"\n",
    "        param_grids = {\n",
    "            'lgb': {\n",
    "                'n_estimators': [200, 300],\n",
    "                'learning_rate': [0.03, 0.05],\n",
    "                'max_depth': [4, 5],\n",
    "                'num_leaves': [31],\n",
    "                'min_child_samples': [20],\n",
    "                'subsample': [0.8],\n",
    "                'colsample_bytree': [0.8]\n",
    "            },\n",
    "            'xgb': {\n",
    "                'n_estimators': [200, 300],\n",
    "                'learning_rate': [0.03, 0.05],\n",
    "                'max_depth': [4, 5],\n",
    "                'min_child_weight': [3, 5],\n",
    "                'gamma': [0.1],\n",
    "                'subsample': [0.8],\n",
    "                'colsample_bytree': [0.8]\n",
    "            },\n",
    "            'cat': {\n",
    "                'iterations': [200, 300],\n",
    "                'learning_rate': [0.03, 0.05],\n",
    "                'depth': [4, 5],\n",
    "                'l2_leaf_reg': [3, 5],\n",
    "                'subsample': [0.8]\n",
    "            },\n",
    "            'rf': {\n",
    "                'n_estimators': [200, 300],\n",
    "                'max_depth': [4, 5],\n",
    "                'min_samples_split': [5, 10],\n",
    "                'min_samples_leaf': [4, 8]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Adjust parameters for IONIQ segment\n",
    "        if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "            for model_params in param_grids.values():\n",
    "                if 'max_depth' in model_params:\n",
    "                    model_params['max_depth'] = [3, 4]\n",
    "                if 'min_samples_leaf' in model_params:\n",
    "                    model_params['min_samples_leaf'] = [6, 10]\n",
    "        \n",
    "        # Base model initialization\n",
    "        base_models = {\n",
    "            'lgb': LGBMRegressor(random_state=42, verbose=-1),\n",
    "            'xgb': XGBRegressor(random_state=42, tree_method='hist'),\n",
    "            'cat': CatBoostRegressor(random_state=42, verbose=False),\n",
    "            'rf': RandomForestRegressor(random_state=42)\n",
    "        }\n",
    "\n",
    "        cv = KFold(n_splits=min(5, max(3, data_size // 30)), shuffle=True, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_models[model_type],\n",
    "            param_grid=param_grids[model_type],\n",
    "            cv=cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        return grid_search.best_estimator_\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 학습 ===\")\n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            data_size = mask.sum()\n",
    "            print(f\"데이터 수: {data_size}개\")\n",
    "            self.data_size_stats[segment] = data_size\n",
    "            \n",
    "            # 특성 선택\n",
    "            feature_cols = [col for col in train_processed.columns \n",
    "                          if col not in ['ID', 'segment', '가격(백만원)', '차량상태', '구동방식', '사고이력']]\n",
    "            \n",
    "            X = train_processed[mask][feature_cols]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            # 모든 모델 학습\n",
    "            self.segment_models[segment] = {}\n",
    "            for model_type in self.models.keys():\n",
    "                print(f\"\\n{model_type.upper()} 모델 최적화 중...\")\n",
    "                model = self.optimize_model_params(X, y, segment, data_size, model_type)\n",
    "                self.segment_models[segment][model_type] = model\n",
    "                \n",
    "                # 특성 중요도 저장 (지원되는 모델만)\n",
    "                if hasattr(model, 'feature_importances_'):\n",
    "                    if segment not in self.feature_importance:\n",
    "                        self.feature_importance[segment] = {}\n",
    "                    self.feature_importance[segment][model_type] = dict(\n",
    "                        zip(feature_cols, model.feature_importances_)\n",
    "                    )\n",
    "                    \n",
    "                    # 상위 5개 중요 특성 출력\n",
    "                    print(f\"\\n{model_type.upper()} Top 5 중요 특성:\")\n",
    "                    top_features = sorted(\n",
    "                        self.feature_importance[segment][model_type].items(),\n",
    "                        key=lambda x: x[1],\n",
    "                        reverse=True\n",
    "                    )[:5]\n",
    "                    for feat, imp in top_features:\n",
    "                        print(f\"- {feat}: {imp:.4f}\")\n",
    "            \n",
    "            self.segment_models[segment]['features'] = feature_cols\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"예측 수행\"\"\"\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            # 특성 선택\n",
    "            feature_cols = self.segment_models[segment]['features']\n",
    "            X = test_processed[mask][feature_cols]\n",
    "            \n",
    "            # 각 모델별 예측\n",
    "            model_preds = {}\n",
    "            for model_type in self.models.keys():\n",
    "                model_preds[model_type] = self.segment_models[segment][model_type].predict(X)\n",
    "            \n",
    "            # 모델별 RMSE 기반 가중치 계산\n",
    "            model_scores = None\n",
    "            if segment in self.performance_history:\n",
    "                model_scores = {\n",
    "                    model: self.performance_history[segment].get(f'{model}_rmse', 1.0)\n",
    "                    for model in self.models.keys()\n",
    "                }\n",
    "            \n",
    "            weights = self.get_dynamic_weights(\n",
    "                self.data_size_stats[segment],\n",
    "                segment,\n",
    "                model_scores\n",
    "            )\n",
    "            \n",
    "            # 가중 평균 예측\n",
    "            segment_pred = sum(\n",
    "                weights[model_type] * model_preds[model_type]\n",
    "                for model_type in weights.keys()\n",
    "            )\n",
    "            \n",
    "            # IONIQ 예측값 보정\n",
    "            if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "                ioniq_mask = mask & (test_processed['모델'] == 'IONIQ')\n",
    "                if ioniq_mask.any():\n",
    "                    segment_pred[ioniq_mask] = segment_pred[ioniq_mask].clip(\n",
    "                        lower=10,  # IONIQ의 최소 예상 가격\n",
    "                        upper=30   # IONIQ의 최대 예상 가격\n",
    "                    )\n",
    "            \n",
    "            predictions[mask] = segment_pred\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        \"\"\"성능 평가\"\"\"\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<15} {'데이터 수':>8} {'LGB':>10} {'RF':>10} {'CAT':>10} {'XGB':>10} {'앙상블':>10} {'가중치(L/R/C/X)':>20}\")\n",
    "        print(\"-\" * 95)\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            feature_cols = self.segment_models[segment]['features']\n",
    "            X = val_processed[mask][feature_cols]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            # 각 모델별 예측 및 RMSE 계산\n",
    "            model_preds = {}\n",
    "            model_rmse = {}\n",
    "            for model_type in self.models.keys():\n",
    "                model_preds[model_type] = self.segment_models[segment][model_type].predict(X)\n",
    "                model_rmse[model_type] = np.sqrt(mean_squared_error(y, model_preds[model_type]))\n",
    "            \n",
    "            # 성능 기록 업데이트\n",
    "            self.performance_history[segment] = {\n",
    "                f'{model_type}_rmse': rmse\n",
    "                for model_type, rmse in model_rmse.items()\n",
    "            }\n",
    "            \n",
    "            # 가중치 계산\n",
    "            weights = self.get_dynamic_weights(\n",
    "                self.data_size_stats[segment],\n",
    "                segment,\n",
    "                model_rmse\n",
    "            )\n",
    "            \n",
    "            # 앙상블 예측\n",
    "            ensemble_pred = sum(\n",
    "                weights[model_type] * model_preds[model_type]\n",
    "                for model_type in weights.keys()\n",
    "            )\n",
    "            \n",
    "            # IONIQ 예측값 보정\n",
    "            if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "                ioniq_mask = mask & (val_processed['모델'] == 'IONIQ')\n",
    "                if ioniq_mask.any():\n",
    "                    ensemble_pred[ioniq_mask] = ensemble_pred[ioniq_mask].clip(\n",
    "                        lower=10,  # IONIQ의 최소 예상 가격\n",
    "                        upper=30   # IONIQ의 최대 예상 가격\n",
    "                    )\n",
    "            \n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            # 결과 출력\n",
    "            weight_str = f\"{weights['lgb']:.2f}/{weights['rf']:.2f}/{weights['cat']:.2f}/{weights['xgb']:.2f}\"\n",
    "            print(f\"{segment:<15} {mask.sum():>8d} \"\n",
    "                  f\"{model_rmse['lgb']:>10.4f} {model_rmse['rf']:>10.4f} \"\n",
    "                  f\"{model_rmse['cat']:>10.4f} {model_rmse['xgb']:>10.4f} \"\n",
    "                  f\"{ensemble_rmse:>10.4f} {weight_str:>20}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'model_rmse': model_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse,\n",
    "                'weights': weights\n",
    "            }\n",
    "            \n",
    "            # IONIQ 세그먼트 상세 분석\n",
    "            if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "                ioniq_mask = mask & (val_processed['모델'] == 'IONIQ')\n",
    "                if ioniq_mask.any():\n",
    "                    print(f\"\\n{segment} IONIQ 상세 성능:\")\n",
    "                    y_ioniq = y_val[ioniq_mask]\n",
    "                    pred_ioniq = ensemble_pred[ioniq_mask]\n",
    "                    \n",
    "                    # 연식별 성능 분석\n",
    "                    rmse_by_year = {}\n",
    "                    for year in val_processed.loc[ioniq_mask, '연식(년)'].unique():\n",
    "                        year_mask = val_processed.loc[ioniq_mask, '연식(년)'] == year\n",
    "                        year_rmse = np.sqrt(mean_squared_error(\n",
    "                            y_ioniq[year_mask], pred_ioniq[year_mask]\n",
    "                        ))\n",
    "                        rmse_by_year[year] = year_rmse\n",
    "                        print(f\"- {year}년식 RMSE: {year_rmse:.4f}\")\n",
    "                    \n",
    "                    # 주행거리 구간별 성능 분석\n",
    "                    print(\"\\n주행거리별 성능:\")\n",
    "                    for km_group in range(1, 5):\n",
    "                        km_mask = val_processed.loc[ioniq_mask, '주행거리_구간'] == km_group\n",
    "                        if km_mask.any():\n",
    "                            km_rmse = np.sqrt(mean_squared_error(\n",
    "                                y_ioniq[km_mask], pred_ioniq[km_mask]\n",
    "                            ))\n",
    "                            km_range = ['0-2만km', '2-4만km', '4-6만km', '6만km이상'][km_group-1]\n",
    "                            print(f\"- {km_range} RMSE: {km_rmse:.4f}\")\n",
    "        \n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 95)\n",
    "        print(f\"{'전체':<15} {len(y_val):>8d} {'':<10} {'':<10} {'':<10} {'':<10} {total_rmse:>10.4f}\")\n",
    "        \n",
    "        return segment_metrics, total_rmse\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    print(\"\\n=== IONIQ 특화 개선 모델 학습 시작 ===\")\n",
    "    \n",
    "    # 데이터 로드\n",
    "    try:\n",
    "        print(\"\\n1. 데이터 로딩...\")\n",
    "        train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "        test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "        \n",
    "        if 'ID' not in test.columns:\n",
    "            test['ID'] = range(len(test))\n",
    "        \n",
    "        print(f\"학습 데이터 크기: {train.shape}\")\n",
    "        print(f\"테스트 데이터 크기: {test.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"데이터 로딩 중 오류 발생: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 학습/검증 데이터 분할\n",
    "    print(\"\\n2. 데이터 분할...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"학습 세트 크기: {X_train.shape}\")\n",
    "    print(f\"검증 세트 크기: {X_val.shape}\")\n",
    "    \n",
    "    # 모델 초기화 및 학습\n",
    "    print(\"\\n3. 모델 학습 시작...\")\n",
    "    model = EnhancedSegmentModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 모델 성능 평가\n",
    "    print(\"\\n4. 검증 데이터로 성능 평가...\")\n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    print(f\"\\n전체 RMSE: {total_rmse:.4f}\")\n",
    "    \n",
    "    # 테스트 데이터 예측\n",
    "    print(\"\\n5. 테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    # 결과 저장\n",
    "    print(\"\\n6. 제출 파일 생성...\")\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    output_file = 'submission19.csv'\n",
    "    submission.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"제출 파일 생성 완료: {output_file}\")\n",
    "    \n",
    "    # 주요 메트릭 요약\n",
    "    print(\"\\n=== 모델 성능 요약 ===\")\n",
    "    print(f\"검증 세트 전체 RMSE: {total_rmse:.4f}\")\n",
    "    \n",
    "    ioniq_segments = [seg for seg in segment_metrics.keys() if 'IONIQ' in seg or 'Basic-H' in seg]\n",
    "    if ioniq_segments:\n",
    "        print(\"\\nIONIQ 세그먼트 성능:\")\n",
    "        for seg in ioniq_segments:\n",
    "            metrics = segment_metrics[seg]\n",
    "            print(f\"- {seg}:\")\n",
    "            print(f\"  데이터 수: {metrics['count']}\")\n",
    "            print(f\"  앙상블 RMSE: {metrics['ensemble_rmse']:.4f}\")\n",
    "            weights = metrics['weights']\n",
    "            print(f\"  최종 가중치: LGB={weights['lgb']:.2f}, RF={weights['rf']:.2f}, \"\n",
    "                  f\"CAT={weights['cat']:.2f}, XGB={weights['xgb']:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-4.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-4 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-4 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-4 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-4 .h2o-table th,\n",
       "#h2o-table-4 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-4 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-4\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>1 hour 46 mins</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Seoul</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>2 months and 7 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Admin_oq2gwv</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>7.181 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.12.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         1 hour 46 mins\n",
       "H2O_cluster_timezone:       Asia/Seoul\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    2 months and 7 days\n",
       "H2O_cluster_name:           H2O_from_python_Admin_oq2gwv\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    7.181 Gb\n",
       "H2O_cluster_total_cores:    16\n",
       "H2O_cluster_allowed_cores:  16\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.12.7 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |█\n",
      "11:56:29.678: AutoML: XGBoost is not available; skipping it.\n",
      "11:56:29.680: _train param, Dropping bad and constant columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "11:56:29.680: _min_rows param, The dataset size is too small to split for min_rows=100.0: must have at least 200.0 (weighted) rows, but have only 140.0.\n",
      "11:56:29.680: _train param, Dropping bad and constant columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "11:56:29.921: _train param, Dropping bad and constant columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "11:56:30.34: _train param, Dropping bad and constant columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "11:56:30.178: _train param, Dropping bad and constant columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "11:56:30.354: _train param, Dropping bad and constant columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "11:56:30.612: _train param, Dropping bad and constant columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "11:56:31.706: _train param, Dropping bad and constant columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "11:56:31.760: _train param, Dropping unused columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "11:56:31.870: _train param, Dropping unused columns: [제조사, 사고이력, 구동방식, 모델]\n",
      "\n",
      "██████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |█\n",
      "11:57:29.542: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "██████████████████████████████████████████████████████████████| (done) 100%\n",
      "IONIQ 모델 리더보드:\n",
      "model_id                                                             rmse      mse      mae     rmsle    mean_residual_deviance\n",
      "StackedEnsemble_BestOfFamily_1_AutoML_7_20250109_115629           5.41425  29.3141  4.73231  0.30315                    29.3141\n",
      "XRT_1_AutoML_7_20250109_115629                                    5.44966  29.6988  4.7688   0.305103                   29.6988\n",
      "GBM_lr_annealing_selection_AutoML_7_20250109_115629_select_model  5.46312  29.8457  4.73117  0.304639                   29.8457\n",
      "StackedEnsemble_AllModels_1_AutoML_7_20250109_115629              5.47638  29.9907  4.77565  0.306082                   29.9907\n",
      "GBM_grid_1_AutoML_7_20250109_115629_model_4                       5.48242  30.0569  4.77314  0.306058                   30.0569\n",
      "GBM_grid_1_AutoML_7_20250109_115629_model_12                      5.50654  30.3219  4.78532  0.30847                    30.3219\n",
      "GBM_grid_1_AutoML_7_20250109_115629_model_10                      5.51866  30.4556  4.7715   0.307774                   30.4556\n",
      "DRF_1_AutoML_7_20250109_115629                                    5.52843  30.5636  4.81139  0.307939                   30.5636\n",
      "GBM_3_AutoML_7_20250109_115629                                    5.52892  30.569   4.83014  0.307645                   30.569\n",
      "GBM_4_AutoML_7_20250109_115629                                    5.55452  30.8527  4.80184  0.309175                   30.8527\n",
      "[10 rows x 6 columns]\n",
      "\n",
      "non-IONIQ 모델 리더보드:\n",
      "model_id                                                    rmse      mse       mae      rmsle    mean_residual_deviance\n",
      "StackedEnsemble_AllModels_1_AutoML_8_20250109_115729     1.11064  1.23351  0.626988  0.0155724                   1.23351\n",
      "GBM_grid_1_AutoML_8_20250109_115729_model_12             1.11189  1.23629  0.633549  0.0154535                   1.23629\n",
      "StackedEnsemble_BestOfFamily_1_AutoML_8_20250109_115729  1.12054  1.2556   0.644262  0.0160475                   1.2556\n",
      "GBM_grid_1_AutoML_8_20250109_115729_model_2              1.12329  1.26177  0.618273  0.0156089                   1.26177\n",
      "GBM_grid_1_AutoML_8_20250109_115729_model_1              1.12878  1.27415  0.625196  0.0155189                   1.27415\n",
      "GBM_2_AutoML_8_20250109_115729                           1.13164  1.28061  0.63703   0.0158065                   1.28061\n",
      "GBM_grid_1_AutoML_8_20250109_115729_model_6              1.13236  1.28223  0.668822  0.0164726                   1.28223\n",
      "GBM_5_AutoML_8_20250109_115729                           1.13272  1.28305  0.643727  0.0160483                   1.28305\n",
      "GBM_1_AutoML_8_20250109_115729                           1.13583  1.2901   0.666165  0.0160692                   1.2901\n",
      "GBM_grid_1_AutoML_8_20250109_115729_model_5              1.13884  1.29696  0.637151  0.0166297                   1.29696\n",
      "[10 rows x 6 columns]\n",
      "\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "ename": "H2OValueError",
     "evalue": "Argument `fun` (= <function predict_price at 0x00000208A7A46F20>) does not satisfy the condition fun.__name__ == \"<lambda>\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OValueError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m aml_non_ioniq\u001b[38;5;241m.\u001b[39mleader\u001b[38;5;241m.\u001b[39mpredict(model_data[features])\u001b[38;5;241m.\u001b[39mas_data_frame()\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 56\u001b[0m test_h2o[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtest_h2o\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m모델\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_price\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# 제출 파일 생성\u001b[39;00m\n\u001b[0;32m     59\u001b[0m submission \u001b[38;5;241m=\u001b[39m test_h2o[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcbind(test_h2o[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m가격(백만원)\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\h2o\\frame.py:4839\u001b[0m, in \u001b[0;36mH2OFrame.apply\u001b[1;34m(self, fun, axis)\u001b[0m\n\u001b[0;32m   4837\u001b[0m assert_is_type(axis, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   4838\u001b[0m assert_is_type(fun, FunctionType)\n\u001b[1;32m-> 4839\u001b[0m \u001b[43massert_satisfies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m<lambda>\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4840\u001b[0m res \u001b[38;5;241m=\u001b[39m lambda_to_expr(fun)\n\u001b[0;32m   4841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m H2OFrame\u001b[38;5;241m.\u001b[39m_expr(expr\u001b[38;5;241m=\u001b[39mExprNode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m (axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m*\u001b[39mres))\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\Lib\\site-packages\\h2o\\utils\\typechecks.py:477\u001b[0m, in \u001b[0;36massert_satisfies\u001b[1;34m(v, cond, message)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message:\n\u001b[0;32m    475\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `\u001b[39m\u001b[38;5;132;01m{var}\u001b[39;00m\u001b[38;5;124m` (= \u001b[39m\u001b[38;5;132;01m{val!r}\u001b[39;00m\u001b[38;5;124m) does not satisfy the condition \u001b[39m\u001b[38;5;132;01m{expr}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[0;32m    476\u001b[0m               \u001b[38;5;241m.\u001b[39mformat(var\u001b[38;5;241m=\u001b[39mvname, val\u001b[38;5;241m=\u001b[39mv, expr\u001b[38;5;241m=\u001b[39mvexpr)\n\u001b[1;32m--> 477\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m H2OValueError(message\u001b[38;5;241m=\u001b[39mmessage, var_name\u001b[38;5;241m=\u001b[39mvname, skip_frames\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mH2OValueError\u001b[0m: Argument `fun` (= <function predict_price at 0x00000208A7A46F20>) does not satisfy the condition fun.__name__ == \"<lambda>\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from h2o.automl import H2OAutoML\n",
    "import h2o\n",
    "\n",
    "# 데이터 로드\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# IONIQ 모델 데이터 분리\n",
    "ioniq_data = train_data[train_data['모델'] == 'IONIQ']\n",
    "non_ioniq_data = train_data[train_data['모델'] != 'IONIQ']\n",
    "\n",
    "# H2O 초기화\n",
    "h2o.init()\n",
    "\n",
    "# IONIQ 데이터를 H2OFrame으로 변환\n",
    "ioniq_h2o = h2o.H2OFrame(ioniq_data)\n",
    "non_ioniq_h2o = h2o.H2OFrame(non_ioniq_data)\n",
    "\n",
    "# 특성과 타겟 설정\n",
    "features = ['제조사', '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', '보증기간(년)', '사고이력', '연식(년)']\n",
    "target = '가격(백만원)'\n",
    "\n",
    "# AutoML 모델 학습 (IONIQ)\n",
    "aml_ioniq = H2OAutoML(max_models=20, seed=42, exclude_algos=[\"DeepLearning\", \"GLM\"])\n",
    "aml_ioniq.train(x=features, y=target, training_frame=ioniq_h2o)\n",
    "\n",
    "# AutoML 모델 학습 (non-IONIQ)\n",
    "aml_non_ioniq = H2OAutoML(max_models=20, seed=42, exclude_algos=[\"DeepLearning\", \"GLM\"])\n",
    "aml_non_ioniq.train(x=features, y=target, training_frame=non_ioniq_h2o)\n",
    "\n",
    "# 리더보드 출력 (IONIQ)\n",
    "lb_ioniq = aml_ioniq.leaderboard\n",
    "print(\"IONIQ 모델 리더보드:\")\n",
    "print(lb_ioniq.head())\n",
    "\n",
    "# 리더보드 출력 (non-IONIQ)\n",
    "lb_non_ioniq = aml_non_ioniq.leaderboard\n",
    "print(\"non-IONIQ 모델 리더보드:\")\n",
    "print(lb_non_ioniq.head())\n",
    "\n",
    "# 테스트 데이터를 H2OFrame으로 변환\n",
    "test_h2o = h2o.H2OFrame(test_data)\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "def predict_price(model):\n",
    "    model_data = test_h2o[test_h2o['모델'] == model]\n",
    "    if model_data.nrow == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        if model == 'IONIQ':\n",
    "            return aml_ioniq.leader.predict(model_data[features]).as_data_frame().iloc[:, 0]\n",
    "        else:\n",
    "            return aml_non_ioniq.leader.predict(model_data[features]).as_data_frame().iloc[:, 0]\n",
    "\n",
    "test_h2o['가격(백만원)'] = test_h2o['ID'].apply(predict_price)\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission = test_h2o['ID'].cbind(test_h2o['가격(백만원)'])\n",
    "h2o.download_csv(submission, filename=\"submission_ioniq_automl.csv\")\n",
    "\n",
    "# H2O 종료\n",
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== IONIQ 특화 개선 모델 학습 시작 ===\n",
      "\n",
      "1. 데이터 로딩...\n",
      "학습 데이터 크기: (7497, 11)\n",
      "테스트 데이터 크기: (846, 10)\n",
      "\n",
      "2. 데이터 분할...\n",
      "학습 세트 크기: (5997, 10)\n",
      "검증 세트 크기: (1500, 10)\n",
      "\n",
      "3. 모델 학습 시작...\n",
      "\n",
      "=== Premium-P 세그먼트 학습 ===\n",
      "데이터 수: 295개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 681.0000\n",
      "- 배터리용량: 404.0000\n",
      "- 배터리_효율: 337.0000\n",
      "- 배터리_효율_점수: 332.0000\n",
      "- 연평균주행거리: 137.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 배터리용량: 0.2761\n",
      "- 차량상태_점수: 0.2427\n",
      "- 배터리_연식_점수: 0.1112\n",
      "- 배터리_성능예상: 0.1057\n",
      "- 배터리_연식_효율: 0.1007\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 배터리_성능예상: 27.3650\n",
      "- 배터리용량: 18.9063\n",
      "- 배터리_연식_점수: 15.3974\n",
      "- 배터리_연식_효율: 13.9711\n",
      "- 차량상태_점수: 6.8008\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 배터리용량: 0.1930\n",
      "- 배터리_연식_점수: 0.1757\n",
      "- 배터리_연식_효율: 0.1756\n",
      "- 배터리_효율_점수: 0.1040\n",
      "- 배터리_효율: 0.0880\n",
      "\n",
      "=== Luxury-P 세그먼트 학습 ===\n",
      "데이터 수: 266개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 배터리_효율: 722.0000\n",
      "- 주행거리(km): 386.0000\n",
      "- 배터리_효율_점수: 340.0000\n",
      "- 종합_상태_점수: 320.0000\n",
      "- 연평균주행거리: 156.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 보증가치: 0.1448\n",
      "- 차량연식: 0.1368\n",
      "- 배터리_연식_점수: 0.1309\n",
      "- 연식(년): 0.1263\n",
      "- 주행거리_구간: 0.1243\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 종합_상태_점수: 11.3307\n",
      "- 차량상태_점수: 10.6566\n",
      "- 보증기간(년): 9.3695\n",
      "- 배터리_성능예상: 7.7058\n",
      "- 주행거리_연식_비율: 7.3616\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 종합_상태_점수: 0.1923\n",
      "- 배터리_효율_점수: 0.1199\n",
      "- 배터리_효율: 0.1131\n",
      "- 연식(년): 0.1049\n",
      "- 차량연식: 0.0887\n",
      "\n",
      "=== High-Premium-P 세그먼트 학습 ===\n",
      "데이터 수: 293개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 539.0000\n",
      "- 배터리_효율: 518.0000\n",
      "- 배터리용량: 394.0000\n",
      "- 차량상태_점수: 267.0000\n",
      "- 배터리_효율_점수: 157.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.8007\n",
      "- 주행거리(km): 0.0701\n",
      "- 연평균주행거리: 0.0333\n",
      "- 주행거리_연식_비율: 0.0326\n",
      "- 배터리_연식_점수: 0.0153\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 차량상태_점수: 30.2884\n",
      "- 주행거리_연식_비율: 23.8658\n",
      "- 주행거리(km): 19.1763\n",
      "- 종합_상태_점수: 9.7455\n",
      "- 연평균주행거리: 8.5019\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.5058\n",
      "- 주행거리(km): 0.1654\n",
      "- 연평균주행거리: 0.1467\n",
      "- 주행거리_연식_비율: 0.1336\n",
      "- 배터리_연식_점수: 0.0121\n",
      "\n",
      "=== High-Premium-A 세그먼트 학습 ===\n",
      "데이터 수: 315개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 843.0000\n",
      "- 보증기간(년): 346.0000\n",
      "- 배터리_효율: 303.0000\n",
      "- 연평균주행거리: 230.0000\n",
      "- 배터리_효율_점수: 100.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.3850\n",
      "- 보증기간(년): 0.1558\n",
      "- 보증가치: 0.1506\n",
      "- 주행거리(km): 0.1182\n",
      "- 주행거리_연식_비율: 0.0853\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증가치: 26.4880\n",
      "- 종합_상태_점수: 21.1993\n",
      "- 차량상태_점수: 14.1016\n",
      "- 보증기간(년): 12.3956\n",
      "- 주행거리_연식_비율: 7.2661\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.3755\n",
      "- 연평균주행거리: 0.1336\n",
      "- 차량상태_점수: 0.1271\n",
      "- 주행거리(km): 0.1161\n",
      "- 종합_상태_점수: 0.1141\n",
      "\n",
      "=== High-T 세그먼트 학습 ===\n",
      "데이터 수: 198개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 배터리_효율: 541.0000\n",
      "- 배터리용량: 383.0000\n",
      "- 주행거리(km): 276.0000\n",
      "- 보증기간(년): 274.0000\n",
      "- 배터리_효율_점수: 184.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.6542\n",
      "- 보증기간(년): 0.1171\n",
      "- 주행거리(km): 0.0742\n",
      "- 배터리_연식_효율: 0.0389\n",
      "- 배터리용량: 0.0269\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 차량상태_점수: 21.9152\n",
      "- 보증기간(년): 19.0240\n",
      "- 배터리_효율_점수: 11.3240\n",
      "- 주행거리_연식_비율: 9.5415\n",
      "- 배터리_성능예상: 7.4936\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.2247\n",
      "- 차량상태_점수: 0.1601\n",
      "- 배터리_효율_점수: 0.1573\n",
      "- 배터리_효율: 0.1521\n",
      "- 연평균주행거리: 0.0739\n",
      "\n",
      "=== High-B 세그먼트 학습 ===\n",
      "데이터 수: 298개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 991.0000\n",
      "- 연평균주행거리: 292.0000\n",
      "- 종합_상태_점수: 111.0000\n",
      "- 보증기간(년): 51.0000\n",
      "- 배터리_효율: 36.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 종합_상태_점수: 0.1251\n",
      "- 배터리_효율_점수: 0.1225\n",
      "- 배터리_효율: 0.1196\n",
      "- 구동방식_점수: 0.1158\n",
      "- 연평균주행거리: 0.1129\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 종합_상태_점수: 15.8705\n",
      "- 연평균주행거리: 14.6973\n",
      "- 주행거리(km): 13.8430\n",
      "- 주행거리_연식_비율: 13.7064\n",
      "- 배터리_효율: 12.7325\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 배터리_효율_점수: 0.1876\n",
      "- 배터리_효율: 0.1848\n",
      "- 연평균주행거리: 0.1531\n",
      "- 주행거리(km): 0.1495\n",
      "- 주행거리_연식_비율: 0.1312\n",
      "\n",
      "=== Mid-High-T 세그먼트 학습 ===\n",
      "데이터 수: 448개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 1178.0000\n",
      "- 배터리_효율: 723.0000\n",
      "- 배터리용량: 652.0000\n",
      "- 보증기간(년): 608.0000\n",
      "- 모델: 438.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 주행거리_연식_비율: 0.2902\n",
      "- 보증기간(년): 0.1574\n",
      "- 모델: 0.1029\n",
      "- 배터리_성능예상: 0.0828\n",
      "- 배터리_연식_효율: 0.0717\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 48.9693\n",
      "- 모델: 10.8796\n",
      "- 차량상태_점수: 9.9501\n",
      "- 연평균주행거리: 4.2060\n",
      "- 배터리_연식_점수: 3.7154\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.6939\n",
      "- 배터리_연식_점수: 0.0800\n",
      "- 배터리용량: 0.0764\n",
      "- 배터리_연식_효율: 0.0708\n",
      "- 모델: 0.0211\n",
      "\n",
      "=== Mid-T 세그먼트 학습 ===\n",
      "데이터 수: 234개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 보증기간(년): 335.0000\n",
      "- 주행거리(km): 312.0000\n",
      "- 배터리_효율: 233.0000\n",
      "- 배터리용량: 209.0000\n",
      "- 연평균주행거리: 83.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 보증기간(년): 0.4105\n",
      "- 주행거리(km): 0.1518\n",
      "- 배터리_연식_효율: 0.1125\n",
      "- 종합_상태_점수: 0.0896\n",
      "- 배터리용량: 0.0723\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 64.7106\n",
      "- 차량상태_점수: 5.7485\n",
      "- 종합_상태_점수: 4.7539\n",
      "- 주행거리_연식_비율: 4.7022\n",
      "- 배터리_효율_점수: 4.4405\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.4181\n",
      "- 차량상태_점수: 0.1017\n",
      "- 배터리_효율_점수: 0.0849\n",
      "- 주행거리_연식_비율: 0.0795\n",
      "- 배터리_효율: 0.0774\n",
      "\n",
      "=== Mid-B 세그먼트 학습 ===\n",
      "데이터 수: 329개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 542.0000\n",
      "- 배터리용량: 368.0000\n",
      "- 배터리_효율: 358.0000\n",
      "- 보증기간(년): 228.0000\n",
      "- 연평균주행거리: 172.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.4738\n",
      "- 주행거리_구간: 0.0943\n",
      "- 배터리용량: 0.0921\n",
      "- 종합_상태_점수: 0.0798\n",
      "- 보증기간(년): 0.0783\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 차량연식: 16.7781\n",
      "- 보증기간(년): 12.7216\n",
      "- 배터리_성능예상: 11.9880\n",
      "- 연식(년): 10.0078\n",
      "- 배터리_연식_효율: 9.7371\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.3141\n",
      "- 종합_상태_점수: 0.2047\n",
      "- 배터리_연식_효율: 0.1155\n",
      "- 배터리용량: 0.0909\n",
      "- 배터리_연식_점수: 0.0840\n",
      "\n",
      "=== Mid-A 세그먼트 학습 ===\n",
      "데이터 수: 303개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 배터리_효율: 1101.0000\n",
      "- 주행거리(km): 797.0000\n",
      "- 배터리_효율_점수: 273.0000\n",
      "- 보증기간(년): 247.0000\n",
      "- 배터리용량: 241.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.3180\n",
      "- 연식(년): 0.1412\n",
      "- 차량연식: 0.1139\n",
      "- 보증기간(년): 0.0970\n",
      "- 배터리_연식_효율: 0.0767\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 차량연식: 20.1681\n",
      "- 연식(년): 18.9000\n",
      "- 보증기간(년): 11.2912\n",
      "- 배터리_연식_점수: 8.4903\n",
      "- 배터리용량: 7.6245\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 연식(년): 0.2176\n",
      "- 차량연식: 0.1832\n",
      "- 연평균주행거리: 0.1143\n",
      "- 주행거리(km): 0.1077\n",
      "- 주행거리_연식_비율: 0.0943\n",
      "\n",
      "=== Mid-Entry-K 세그먼트 학습 ===\n",
      "데이터 수: 296개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 1362.0000\n",
      "- 연평균주행거리: 438.0000\n",
      "- 보증기간(년): 201.0000\n",
      "- 배터리_효율_점수: 186.0000\n",
      "- 구동방식_점수: 116.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 보증기간(년): 0.9553\n",
      "- 배터리_효율: 0.0140\n",
      "- 배터리_효율_점수: 0.0084\n",
      "- 주행거리(km): 0.0077\n",
      "- 구동방식_점수: 0.0058\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 99.0842\n",
      "- 종합_상태_점수: 0.1933\n",
      "- 배터리_효율_점수: 0.1358\n",
      "- 배터리_효율: 0.1262\n",
      "- 주행거리_연식_비율: 0.1253\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.9957\n",
      "- 배터리_효율_점수: 0.0009\n",
      "- 배터리_효율: 0.0009\n",
      "- 주행거리(km): 0.0008\n",
      "- 연평균주행거리: 0.0007\n",
      "\n",
      "=== Mid-Entry-V 세그먼트 학습 ===\n",
      "데이터 수: 498개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 911.0000\n",
      "- 배터리_효율: 827.0000\n",
      "- 보증기간(년): 390.0000\n",
      "- 배터리용량: 233.0000\n",
      "- 연평균주행거리: 183.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 보증기간(년): 0.6077\n",
      "- 연식(년): 0.1272\n",
      "- 배터리용량: 0.0635\n",
      "- 배터리_연식_효율: 0.0550\n",
      "- 종합_상태_점수: 0.0365\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 77.2931\n",
      "- 차량상태_점수: 4.3496\n",
      "- 배터리_효율_점수: 3.2818\n",
      "- 배터리_효율: 3.0148\n",
      "- 종합_상태_점수: 2.5288\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.9007\n",
      "- 종합_상태_점수: 0.0164\n",
      "- 배터리_효율_점수: 0.0108\n",
      "- 배터리_효율: 0.0101\n",
      "- 차량상태_점수: 0.0086\n",
      "\n",
      "=== Mid-Entry-H 세그먼트 학습 ===\n",
      "데이터 수: 579개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 1100.0000\n",
      "- 배터리_효율: 746.0000\n",
      "- 연평균주행거리: 264.0000\n",
      "- 배터리용량: 248.0000\n",
      "- 모델: 243.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 모델: 0.6196\n",
      "- 차량상태_점수: 0.1997\n",
      "- 보증기간(년): 0.0636\n",
      "- 연평균주행거리: 0.0288\n",
      "- 주행거리(km): 0.0220\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 모델: 90.8503\n",
      "- 배터리_효율_점수: 1.2537\n",
      "- 주행거리_연식_비율: 1.1396\n",
      "- 배터리_효율: 1.0885\n",
      "- 종합_상태_점수: 0.7683\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 모델: 0.8390\n",
      "- 주행거리(km): 0.0283\n",
      "- 주행거리_연식_비율: 0.0270\n",
      "- 연평균주행거리: 0.0249\n",
      "- 보증기간(년): 0.0238\n",
      "\n",
      "=== Entry-K 세그먼트 학습 ===\n",
      "데이터 수: 338개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 배터리_효율: 523.0000\n",
      "- 주행거리(km): 351.0000\n",
      "- 보증기간(년): 242.0000\n",
      "- 배터리용량: 127.0000\n",
      "- 배터리_효율_점수: 126.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.6360\n",
      "- 보증기간(년): 0.1894\n",
      "- 주행거리(km): 0.0769\n",
      "- 주행거리_연식_비율: 0.0272\n",
      "- 연평균주행거리: 0.0255\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 39.8045\n",
      "- 차량상태_점수: 38.1597\n",
      "- 연평균주행거리: 4.8536\n",
      "- 배터리_효율: 3.8685\n",
      "- 종합_상태_점수: 3.0396\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.4851\n",
      "- 차량상태_점수: 0.3458\n",
      "- 주행거리_연식_비율: 0.0481\n",
      "- 연평균주행거리: 0.0464\n",
      "- 주행거리(km): 0.0423\n",
      "\n",
      "=== Entry-H 세그먼트 학습 ===\n",
      "데이터 수: 284개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 809.0000\n",
      "- 배터리_효율_점수: 713.0000\n",
      "- 보증기간(년): 459.0000\n",
      "- 배터리_효율: 244.0000\n",
      "- 연평균주행거리: 197.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.7257\n",
      "- 보증기간(년): 0.1680\n",
      "- 주행거리(km): 0.0546\n",
      "- 연평균주행거리: 0.0203\n",
      "- 배터리_효율_점수: 0.0096\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 43.8308\n",
      "- 차량상태_점수: 19.1187\n",
      "- 주행거리(km): 11.3659\n",
      "- 종합_상태_점수: 10.3237\n",
      "- 주행거리_연식_비율: 6.1111\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.3160\n",
      "- 주행거리_연식_비율: 0.1420\n",
      "- 배터리_효율_점수: 0.1253\n",
      "- 차량상태_점수: 0.1142\n",
      "- 연평균주행거리: 0.1056\n",
      "\n",
      "=== Basic-B 세그먼트 학습 ===\n",
      "데이터 수: 308개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 559.0000\n",
      "- 보증기간(년): 290.0000\n",
      "- 배터리_효율: 290.0000\n",
      "- 연평균주행거리: 148.0000\n",
      "- 종합_상태_점수: 118.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.3681\n",
      "- 연평균주행거리: 0.1236\n",
      "- 보증가치: 0.1215\n",
      "- 보증기간(년): 0.1111\n",
      "- 주행거리(km): 0.1044\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 16.6397\n",
      "- 종합_상태_점수: 13.2442\n",
      "- 차량상태_점수: 12.0881\n",
      "- 보증가치: 11.3499\n",
      "- 배터리_효율_점수: 7.3901\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.1762\n",
      "- 주행거리_연식_비율: 0.1652\n",
      "- 연평균주행거리: 0.1632\n",
      "- 주행거리(km): 0.1497\n",
      "- 종합_상태_점수: 0.1068\n",
      "\n",
      "=== Basic-K 세그먼트 학습 ===\n",
      "데이터 수: 309개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 527.0000\n",
      "- 배터리_효율: 310.0000\n",
      "- 보증기간(년): 286.0000\n",
      "- 배터리용량: 142.0000\n",
      "- 연평균주행거리: 136.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량상태_점수: 0.6811\n",
      "- 보증기간(년): 0.2176\n",
      "- 주행거리(km): 0.0358\n",
      "- 배터리_연식_효율: 0.0146\n",
      "- 연평균주행거리: 0.0099\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 보증기간(년): 49.2227\n",
      "- 차량상태_점수: 16.4552\n",
      "- 주행거리(km): 7.7318\n",
      "- 주행거리_연식_비율: 7.6411\n",
      "- 연평균주행거리: 6.1585\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 보증기간(년): 0.4524\n",
      "- 차량상태_점수: 0.2397\n",
      "- 주행거리(km): 0.0841\n",
      "- 주행거리_연식_비율: 0.0752\n",
      "- 연평균주행거리: 0.0741\n",
      "\n",
      "=== Basic-H 세그먼트 학습 ===\n",
      "데이터 수: 111개\n",
      "\n",
      "LGB 모델 최적화 중...\n",
      "\n",
      "LGB Top 5 중요 특성:\n",
      "- 주행거리(km): 225.0000\n",
      "- 배터리_효율: 154.0000\n",
      "- 배터리용량: 122.0000\n",
      "- 연평균주행거리: 112.0000\n",
      "- 배터리_효율_점수: 96.0000\n",
      "\n",
      "XGB 모델 최적화 중...\n",
      "\n",
      "XGB Top 5 중요 특성:\n",
      "- 차량연식: 0.0835\n",
      "- 주행거리_연식_비율: 0.0831\n",
      "- 배터리_연식_효율: 0.0776\n",
      "- 종합_상태_점수: 0.0755\n",
      "- 연평균주행거리: 0.0718\n",
      "\n",
      "CAT 모델 최적화 중...\n",
      "\n",
      "CAT Top 5 중요 특성:\n",
      "- 배터리_연식_효율: 11.8537\n",
      "- 배터리용량: 9.4990\n",
      "- 배터리_연식_점수: 9.2189\n",
      "- 연평균주행거리: 8.6815\n",
      "- 주행거리_연식_비율: 7.9918\n",
      "\n",
      "RF 모델 최적화 중...\n",
      "\n",
      "RF Top 5 중요 특성:\n",
      "- 연평균주행거리: 0.1512\n",
      "- 주행거리_연식_비율: 0.1444\n",
      "- 주행거리(km): 0.1443\n",
      "- 배터리_연식_효율: 0.0963\n",
      "- 배터리_연식_점수: 0.0949\n",
      "\n",
      "4. 검증 데이터로 성능 평가...\n",
      "\n",
      "=== 세그먼트별 성능 평가 ===\n",
      "세그먼트               데이터 수        LGB         RF        CAT        XGB        앙상블         가중치(L/R/C/X)\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Premium-P             80     0.3211     0.3213     0.3202     0.3244     0.3156  0.25/0.25/0.25/0.25\n",
      "Luxury-P              69     3.4525     3.3964     3.4584     3.7052     3.4364  0.45/0.25/0.20/0.10\n",
      "High-Premium-P        68     2.9861     2.8006     3.1317     3.0311     2.9016  0.45/0.25/0.20/0.10\n",
      "High-Premium-A        70     0.3126     0.3117     0.3047     0.3785     0.3131  0.26/0.26/0.27/0.21\n",
      "High-T                66     0.6705     0.7374     1.0677     0.6919     0.7307  0.35/0.40/0.20/0.05\n",
      "High-B                69     0.5294     0.5230     0.5268     0.5383     0.5271  0.25/0.25/0.25/0.25\n",
      "Mid-High-T           118     0.6767     0.6273     0.6578     0.7499     2.6698  0.25/0.27/0.26/0.23\n",
      "Mid-T                 45     0.5490     0.4346     0.5476     0.4842     0.4455  0.23/0.29/0.23/0.26\n",
      "Mid-B                 85     0.6262     0.6343     0.6313     0.6502     0.6284  0.25/0.25/0.25/0.24\n",
      "Mid-A                 75     0.4452     0.4359     0.4291     0.4429     0.4344  0.25/0.25/0.26/0.25\n",
      "Mid-Entry-K           73     0.6136     0.5746     0.5777     0.5940     0.5811  0.24/0.26/0.26/0.25\n",
      "Mid-Entry-V          107     0.6032     0.5738     0.5841     0.6011     0.8350  0.24/0.26/0.25/0.25\n",
      "Mid-Entry-H          153     0.3434     0.3294     0.3386     0.3502     0.4745  0.25/0.26/0.25/0.24\n",
      "Entry-K               60     0.6296     0.6407     0.6278     0.6377     1.1771  0.25/0.25/0.25/0.25\n",
      "Entry-H               81     0.6121     0.6219     0.6294     0.6290     1.7409  0.25/0.25/0.25/0.25\n",
      "Basic-B               80     0.3467     0.3364     0.3377     0.3348     0.3373  0.24/0.25/0.25/0.25\n",
      "Basic-K               88     0.5493     0.5417     0.5652     0.5681     0.5473  0.25/0.26/0.25/0.24\n",
      "Basic-H               29     5.9932     6.1174     6.2697     6.6968     6.0758  0.50/0.30/0.15/0.05\n",
      "\n",
      "Basic-H 상세 분석:\n",
      "- 0년식 (n=16): RMSE=6.1868\n",
      "- 1년식 (n=5): RMSE=6.3764\n",
      "- 2년식 (n=8): RMSE=5.6439\n",
      "- 0-30.0천km (n=8): RMSE=5.7253\n",
      "- 30-60.0천km (n=12): RMSE=5.2764\n",
      "- 60-inf천km (n=9): RMSE=7.2590\n",
      "===============================================================================================\n",
      "전체                  1500                                                15.9786\n",
      "\n",
      "전체 RMSE: 15.9786\n",
      "\n",
      "5. 테스트 데이터 예측 중...\n",
      "\n",
      "6. 제출 파일 생성...\n",
      "제출 파일 생성 완료: submission20.csv\n",
      "\n",
      "=== 모델 성능 요약 ===\n",
      "검증 세트 전체 RMSE: 15.9786\n",
      "\n",
      "IONIQ 세그먼트 성능:\n",
      "- Basic-H:\n",
      "  데이터 수: 29\n",
      "  앙상블 RMSE: 6.0758\n",
      "  최종 가중치: LGB=0.50, RF=0.30, CAT=0.15, XGB=0.05\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedSegmentModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.outlier_thresholds = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "        # 차량 상태 매핑 (보수적으로 조정)\n",
    "        self.status_map = {\n",
    "            'Brand New': 1.0,\n",
    "            'Nearly New': 0.85,\n",
    "            'Pre-Owned': 0.65,\n",
    "            '신차': 1.0,\n",
    "            '거의 신차': 0.85,\n",
    "            '중고': 0.65\n",
    "        }\n",
    "        \n",
    "        # 사고이력 매핑 (보수적으로 조정)\n",
    "        self.accident_map = {\n",
    "            'No': 1.0,\n",
    "            'Minor': 0.75,\n",
    "            'Yes': 0.5,\n",
    "            '무사고': 1.0,\n",
    "            '경미': 0.75,\n",
    "            '사고': 0.5\n",
    "        }\n",
    "        \n",
    "        # 구동방식 매핑 (차이 축소)\n",
    "        self.drive_map = {\n",
    "            'AWD': 1.0,\n",
    "            'FWD': 0.85,\n",
    "            'RWD': 0.90\n",
    "        }\n",
    "        \n",
    "        # Define available models\n",
    "        self.models = {\n",
    "            'lgb': LGBMRegressor,\n",
    "            'xgb': XGBRegressor,\n",
    "            'cat': CatBoostRegressor,\n",
    "            'rf': RandomForestRegressor\n",
    "        }\n",
    "        \n",
    "        # Initialize storage\n",
    "        self.segment_models = {}\n",
    "        self.performance_history = {}\n",
    "        self.data_size_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        self.price_stats = {}\n",
    "        \n",
    "        # 세그먼트 정의\n",
    "        self.segments = {\n",
    "            'Premium-P': {'models': ['TayGTS']},\n",
    "            'Luxury-P': {'models': ['TayCT']},\n",
    "            'High-Premium-P': {'models': ['Tay']},\n",
    "            'High-Premium-A': {'models': ['RSeTGT']},\n",
    "            'High-T': {'models': ['MX']},\n",
    "            'High-B': {'models': ['iX']},\n",
    "            'Mid-High-T': {'models': ['MS', 'MY']},\n",
    "            'Mid-T': {'models': ['M3']},\n",
    "            'Mid-B': {'models': ['i5']},\n",
    "            'Mid-A': {'models': ['Q4eT']},\n",
    "            'Mid-Entry-K': {'models': ['EV6']},\n",
    "            'Mid-Entry-V': {'models': ['ID4']},\n",
    "            'Mid-Entry-H': {'models': ['ION6', 'ION5']},\n",
    "            'Entry-K': {'models': ['Niro']},\n",
    "            'Entry-H': {'models': ['KNE']},\n",
    "            'Basic-B': {'models': ['i3']},\n",
    "            'Basic-K': {'models': ['Soul']},\n",
    "            'Basic-H': {'models': ['IONIQ']}\n",
    "        }\n",
    "\n",
    "    def add_advanced_features(self, df):\n",
    "        \"\"\"고급 특성 추가\"\"\"\n",
    "        # 배터리 효율성 지표 강화\n",
    "        df['배터리_효율_점수'] = (df['배터리용량'] / df['주행거리(km)'].clip(lower=1)) * 10000\n",
    "        df['배터리_연식_점수'] = df['배터리용량'] / np.sqrt(df['차량연식'])\n",
    "        \n",
    "        # 주행거리 기반 특성 강화\n",
    "        df['주행거리_연식_비율'] = df['주행거리(km)'] / (df['차량연식'] * 15000)  # 연간 15000km 기준\n",
    "        df['주행거리_페널티'] = np.where(df['주행거리_연식_비율'] > 1.5, \n",
    "                                    0.9 ** (df['주행거리_연식_비율'] - 1.5), 1)\n",
    "        \n",
    "        # 보증 관련 특성 강화\n",
    "        df['보증가치'] = (df['잔여보증기간'] / df['보증기간(년)']) * (1 + df['보증기간(년)'] * 0.1)\n",
    "        \n",
    "        # 차량 상태 종합 점수 개선\n",
    "        df['종합_상태_점수'] = (\n",
    "            df['차량상태_점수'] * 0.35 +\n",
    "            df['사고이력_점수'] * 0.25 +\n",
    "            df['보증가치'] * 0.25 +\n",
    "            df['구동방식_점수'] * 0.15\n",
    "        ) * df['주행거리_페널티']\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].apply(self.assign_segment)\n",
    "        \n",
    "        # 범주형 변수의 수치형 매핑\n",
    "        df['차량상태_점수'] = df['차량상태'].map(self.status_map).fillna(0.65)\n",
    "        df['사고이력_점수'] = df['사고이력'].map(self.accident_map).fillna(0.75)\n",
    "        df['구동방식_점수'] = df['구동방식'].map(self.drive_map).fillna(0.85)\n",
    "        \n",
    "        # 범주형 변수 처리\n",
    "        categorical_cols = ['모델', '제조사']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                if col in df.columns:\n",
    "                    unknown_values = set(df[col].unique()) - set(self.label_encoders[col].classes_)\n",
    "                    if unknown_values:\n",
    "                        print(f\"Warning: Unknown categories in {col}: {unknown_values}\")\n",
    "                        df[col] = df[col].map(lambda x: x if x in self.label_encoders[col].classes_ \n",
    "                                            else self.label_encoders[col].classes_[0])\n",
    "                    df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 결측치 처리 - 배터리 용량 (세그먼트별 처리)\n",
    "        if '배터리용량' in df.columns:\n",
    "            # 1. 같은 모델, 같은 연식의 중앙값으로 채우기\n",
    "            df['배터리용량'] = df.groupby(['모델', '연식(년)'])['배터리용량'].transform(\n",
    "                lambda x: x.fillna(x.median())\n",
    "            )\n",
    "            \n",
    "            # 2. 같은 세그먼트의 중앙값으로 채우기\n",
    "            df['배터리용량'] = df.groupby('segment')['배터리용량'].transform(\n",
    "                lambda x: x.fillna(x.median())\n",
    "            )\n",
    "            \n",
    "            # 3. 전체 중앙값으로 채우기\n",
    "            df['배터리용량'] = df['배터리용량'].fillna(df['배터리용량'].median())\n",
    "        \n",
    "        # 기본 특성 추가\n",
    "        df = self.add_features(df, is_train)\n",
    "        \n",
    "        # 고급 특성 추가\n",
    "        df = self.add_advanced_features(df)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def assign_segment(self, model):\n",
    "        \"\"\"세그먼트 할당\"\"\"\n",
    "        for segment, info in self.segments.items():\n",
    "            if model in info['models']:\n",
    "                return segment\n",
    "        return 'Other'\n",
    "\n",
    "    def add_features(self, df, is_train=True):\n",
    "        \"\"\"기본 특성 엔지니어링\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 차량 연식 계산\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        \n",
    "        # 주행거리 관련 특성\n",
    "        df['연평균주행거리'] = df['주행거리(km)'] / df['차량연식']\n",
    "        \n",
    "        # 주행거리 구간을 더 세분화\n",
    "        def km_to_group(km):\n",
    "            if km <= 15000: return 1\n",
    "            elif km <= 30000: return 2\n",
    "            elif km <= 45000: return 3\n",
    "            elif km <= 60000: return 4\n",
    "            else: return 5\n",
    "        df['주행거리_구간'] = df['주행거리(km)'].apply(km_to_group)\n",
    "        \n",
    "        # 배터리 효율성 특성 (개선)\n",
    "        if '배터리용량' in df.columns:\n",
    "            df['배터리_효율'] = (df['배터리용량'] / df['주행거리(km)'].clip(lower=1)) * 1000\n",
    "            df['배터리_연식_효율'] = df['배터리용량'] / np.sqrt(df['차량연식'])\n",
    "            \n",
    "            # 추가: 배터리 성능 감소 예상치\n",
    "            df['배터리_성능예상'] = df['배터리용량'] * (0.95 ** df['차량연식'])\n",
    "        \n",
    "        # 보증 관련 특성\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        df['보증비율'] = (df['잔여보증기간'] / df['보증기간(년)']).fillna(0)\n",
    "        \n",
    "        # 이상치 처리 (3-97 퍼센타일로 조정)\n",
    "        numeric_cols = [col for col in df.select_dtypes(include=[np.number]).columns \n",
    "                       if col not in ['ID', 'segment']]\n",
    "        \n",
    "        if is_train:\n",
    "            for col in numeric_cols:\n",
    "                q1 = df[col].quantile(0.03)\n",
    "                q3 = df[col].quantile(0.97)\n",
    "                iqr = q3 - q1\n",
    "                self.outlier_thresholds[col] = {\n",
    "                    'lower': q1 - 1.5 * iqr,\n",
    "                    'upper': q3 + 1.5 * iqr\n",
    "                }\n",
    "        \n",
    "        for col in numeric_cols:\n",
    "            if col in self.outlier_thresholds:\n",
    "                df[col] = df[col].clip(\n",
    "                    self.outlier_thresholds[col]['lower'],\n",
    "                    self.outlier_thresholds[col]['upper']\n",
    "                )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_dynamic_weights(self, data_size, segment, model_scores=None):\n",
    "        \"\"\"향상된 동적 가중치 결정\"\"\"\n",
    "        # 기본 가중치\n",
    "        weights = {\n",
    "            'lgb': 0.417,\n",
    "            'rf': 0.292,\n",
    "            'cat': 0.292,\n",
    "            'xgb': 0.0\n",
    "        }\n",
    "        \n",
    "        # 성능 기반 가중치 조정\n",
    "        if model_scores is not None:\n",
    "            total_score = sum(1/score for score in model_scores.values() if score > 0)\n",
    "            if total_score > 0:\n",
    "                for model, score in model_scores.items():\n",
    "                    if score > 0:\n",
    "                        weights[model] = (1/score) / total_score\n",
    "        \n",
    "        # 세그먼트별 특화 가중치\n",
    "        if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "            weights.update({\n",
    "                'lgb': 0.50,\n",
    "                'rf': 0.30,\n",
    "                'cat': 0.15,\n",
    "                'xgb': 0.05\n",
    "            })\n",
    "        elif 'Luxury-P' in segment or 'High-Premium-P' in segment:\n",
    "            weights.update({\n",
    "                'lgb': 0.45,\n",
    "                'rf': 0.25,\n",
    "                'cat': 0.20,\n",
    "                'xgb': 0.10\n",
    "            })\n",
    "        elif data_size < 200:\n",
    "            weights.update({\n",
    "                'rf': 0.40,\n",
    "                'lgb': 0.35,\n",
    "                'cat': 0.20,\n",
    "                'xgb': 0.05\n",
    "            })\n",
    "        \n",
    "        # 정규화\n",
    "        total = sum(weights.values())\n",
    "        return {k: v/total for k, v in weights.items()}\n",
    "\n",
    "    def optimize_model_params(self, X, y, segment, data_size, model_type):\n",
    "        \"\"\"개선된 모델 파라미터 최적화\"\"\"\n",
    "        # 기본 파라미터 그리드\n",
    "        param_grids = {\n",
    "            'lgb': {\n",
    "                'n_estimators': [300, 500],\n",
    "                'learning_rate': [0.02, 0.03],\n",
    "                'max_depth': [4, 5],\n",
    "                'num_leaves': [24, 31],\n",
    "                'min_child_samples': [20, 30],\n",
    "                'subsample': [0.7, 0.8],\n",
    "                'colsample_bytree': [0.7, 0.8]\n",
    "            },\n",
    "            'xgb': {\n",
    "                'n_estimators': [300, 500],\n",
    "                'learning_rate': [0.02, 0.03],\n",
    "                'max_depth': [4, 5],\n",
    "                'min_child_weight': [5, 7],\n",
    "                'gamma': [0.1, 0.2],\n",
    "                'subsample': [0.7, 0.8],\n",
    "                'colsample_bytree': [0.7, 0.8]\n",
    "            },\n",
    "            'cat': {\n",
    "                'iterations': [300, 500],\n",
    "                'learning_rate': [0.02, 0.03],\n",
    "                'depth': [4, 5],\n",
    "                'l2_leaf_reg': [3, 5],\n",
    "                'subsample': [0.7, 0.8]\n",
    "            },\n",
    "            'rf': {\n",
    "                'n_estimators': [300, 500],\n",
    "                'max_depth': [4, 5],\n",
    "                'min_samples_split': [5, 10],\n",
    "                'min_samples_leaf': [4, 8]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # IONIQ 및 특수 세그먼트 파라미터 조정\n",
    "        if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "            param_grids.update({\n",
    "                'lgb': {\n",
    "                    'n_estimators': [500, 700],\n",
    "                    'learning_rate': [0.01, 0.02],\n",
    "                    'max_depth': [3, 4],\n",
    "                    'num_leaves': [16, 24],\n",
    "                    'min_child_samples': [30, 40],\n",
    "                    'subsample': [0.6, 0.7],\n",
    "                    'colsample_bytree': [0.6, 0.7]\n",
    "                },\n",
    "                'rf': {\n",
    "                    'n_estimators': [500, 700],\n",
    "                    'max_depth': [3, 4],\n",
    "                    'min_samples_split': [8, 12],\n",
    "                    'min_samples_leaf': [6, 10]\n",
    "                }\n",
    "            })\n",
    "        elif 'Luxury-P' in segment or 'High-Premium-P' in segment:\n",
    "            param_grids.update({\n",
    "                'lgb': {\n",
    "                    'n_estimators': [400, 600],\n",
    "                    'learning_rate': [0.015, 0.025],\n",
    "                    'max_depth': [3, 4],\n",
    "                    'num_leaves': [20, 28],\n",
    "                    'min_child_samples': [25, 35],\n",
    "                    'subsample': [0.65, 0.75],\n",
    "                    'colsample_bytree': [0.65, 0.75]\n",
    "                }\n",
    "            })\n",
    "        \n",
    "        # 기본 모델 초기화\n",
    "        base_models = {\n",
    "            'lgb': LGBMRegressor(random_state=42, verbose=-1),\n",
    "            'xgb': XGBRegressor(random_state=42, tree_method='hist'),\n",
    "            'cat': CatBoostRegressor(random_state=42, verbose=False),\n",
    "            'rf': RandomForestRegressor(random_state=42)\n",
    "        }\n",
    "\n",
    "        # 교차 검증 폴드 수 조정\n",
    "        if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "            n_splits = min(3, max(2, data_size // 40))\n",
    "        else:\n",
    "            n_splits = min(5, max(3, data_size // 30))\n",
    "            \n",
    "        cv = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_models[model_type],\n",
    "            param_grid=param_grids[model_type],\n",
    "            cv=cv,\n",
    "            scoring='neg_root_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        return grid_search.best_estimator_\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 학습 ===\")\n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            data_size = mask.sum()\n",
    "            print(f\"데이터 수: {data_size}개\")\n",
    "            self.data_size_stats[segment] = data_size\n",
    "            \n",
    "            # 특성 선택\n",
    "            feature_cols = [col for col in train_processed.columns \n",
    "                          if col not in ['ID', 'segment', '가격(백만원)', \n",
    "                                       '차량상태', '구동방식', '사고이력']]\n",
    "            \n",
    "            X = train_processed[mask][feature_cols]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            # 모든 모델 학습\n",
    "            self.segment_models[segment] = {}\n",
    "            for model_type in self.models.keys():\n",
    "                print(f\"\\n{model_type.upper()} 모델 최적화 중...\")\n",
    "                model = self.optimize_model_params(X, y, segment, data_size, model_type)\n",
    "                self.segment_models[segment][model_type] = model\n",
    "                \n",
    "                # 특성 중요도 저장 (지원되는 모델만)\n",
    "                if hasattr(model, 'feature_importances_'):\n",
    "                    if segment not in self.feature_importance:\n",
    "                        self.feature_importance[segment] = {}\n",
    "                    self.feature_importance[segment][model_type] = dict(\n",
    "                        zip(feature_cols, model.feature_importances_)\n",
    "                    )\n",
    "                    \n",
    "                    # 상위 5개 중요 특성 출력\n",
    "                    print(f\"\\n{model_type.upper()} Top 5 중요 특성:\")\n",
    "                    top_features = sorted(\n",
    "                        self.feature_importance[segment][model_type].items(),\n",
    "                        key=lambda x: x[1],\n",
    "                        reverse=True\n",
    "                    )[:5]\n",
    "                    for feat, imp in top_features:\n",
    "                        print(f\"- {feat}: {imp:.4f}\")\n",
    "            \n",
    "            self.segment_models[segment]['features'] = feature_cols\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        \"\"\"향상된 예측 로직\"\"\"\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            feature_cols = self.segment_models[segment]['features']\n",
    "            X = test_processed[mask][feature_cols]\n",
    "            \n",
    "            # 모델별 예측\n",
    "            model_preds = {}\n",
    "            for model_type in self.models.keys():\n",
    "                model_preds[model_type] = self.segment_models[segment][model_type].predict(X)\n",
    "            \n",
    "            # 가중치 계산\n",
    "            model_scores = None\n",
    "            if segment in self.performance_history:\n",
    "                model_scores = {\n",
    "                    model: self.performance_history[segment].get(f'{model}_rmse', 1.0)\n",
    "                    for model in self.models.keys()\n",
    "                }\n",
    "            \n",
    "            weights = self.get_dynamic_weights(\n",
    "                self.data_size_stats[segment],\n",
    "                segment,\n",
    "                model_scores\n",
    "            )\n",
    "            \n",
    "            # 가중 평균 예측\n",
    "            segment_pred = sum(\n",
    "                weights[model_type] * model_preds[model_type]\n",
    "                for model_type in weights.keys()\n",
    "            )\n",
    "            \n",
    "            # 세그먼트별 보정\n",
    "            if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "                segment_pred = np.clip(segment_pred, 15, 30)\n",
    "            elif 'Luxury-P' in segment or 'High-Premium-P' in segment:\n",
    "                segment_pred = np.clip(segment_pred, 100, 150)\n",
    "            elif 'High-Premium-A' in segment:\n",
    "                segment_pred = np.clip(segment_pred, 80, 120)\n",
    "            elif 'High-T' in segment or 'High-B' in segment:\n",
    "                segment_pred = np.clip(segment_pred, 70, 100)\n",
    "            elif 'Mid-High-T' in segment:\n",
    "                segment_pred = np.clip(segment_pred, 60, 90)\n",
    "            elif 'Mid-T' in segment or 'Mid-B' in segment or 'Mid-A' in segment:\n",
    "                segment_pred = np.clip(segment_pred, 45, 75)\n",
    "            elif 'Mid-Entry' in segment:\n",
    "                segment_pred = np.clip(segment_pred, 35, 55)\n",
    "            elif 'Entry' in segment:\n",
    "                segment_pred = np.clip(segment_pred, 25, 45)\n",
    "            elif 'Basic' in segment:\n",
    "                segment_pred = np.clip(segment_pred, 15, 35)\n",
    "            \n",
    "            predictions[mask] = segment_pred\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def evaluate_performance(self, X_val, y_val):\n",
    "        \"\"\"향상된 성능 평가\"\"\"\n",
    "        val_processed = self.preprocess_data(X_val, is_train=False)\n",
    "        segment_metrics = {}\n",
    "        total_predictions = np.zeros(len(val_processed))\n",
    "        \n",
    "        print(\"\\n=== 세그먼트별 성능 평가 ===\")\n",
    "        print(f\"{'세그먼트':<15} {'데이터 수':>8} {'LGB':>10} {'RF':>10} {'CAT':>10} {'XGB':>10} {'앙상블':>10} {'가중치(L/R/C/X)':>20}\")\n",
    "        print(\"-\" * 95)\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = val_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            feature_cols = self.segment_models[segment]['features']\n",
    "            X = val_processed[mask][feature_cols]\n",
    "            y = y_val[mask]\n",
    "            \n",
    "            # 각 모델별 예측 및 RMSE 계산\n",
    "            model_preds = {}\n",
    "            model_rmse = {}\n",
    "            for model_type in self.models.keys():\n",
    "                model_preds[model_type] = self.segment_models[segment][model_type].predict(X)\n",
    "                model_rmse[model_type] = np.sqrt(mean_squared_error(y, model_preds[model_type]))\n",
    "            \n",
    "            # 성능 기록 업데이트\n",
    "            self.performance_history[segment] = {\n",
    "                f'{model_type}_rmse': rmse\n",
    "                for model_type, rmse in model_rmse.items()\n",
    "            }\n",
    "            \n",
    "            # 가중치 계산\n",
    "            weights = self.get_dynamic_weights(\n",
    "                self.data_size_stats[segment],\n",
    "                segment,\n",
    "                model_rmse\n",
    "            )\n",
    "            \n",
    "            # 앙상블 예측\n",
    "            ensemble_pred = sum(\n",
    "                weights[model_type] * model_preds[model_type]\n",
    "                for model_type in weights.keys()\n",
    "            )\n",
    "            \n",
    "            # 세그먼트별 보정\n",
    "            if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "                ensemble_pred = np.clip(ensemble_pred, 15, 30)\n",
    "            elif 'Luxury-P' in segment or 'High-Premium-P' in segment:\n",
    "                ensemble_pred = np.clip(ensemble_pred, 100, 150)\n",
    "            elif 'High-Premium-A' in segment:\n",
    "                ensemble_pred = np.clip(ensemble_pred, 80, 120)\n",
    "            elif 'High-T' in segment or 'High-B' in segment:\n",
    "                ensemble_pred = np.clip(ensemble_pred, 70, 100)\n",
    "            elif 'Mid-High-T' in segment:\n",
    "                ensemble_pred = np.clip(ensemble_pred, 60, 90)\n",
    "            elif 'Mid-T' in segment or 'Mid-B' in segment or 'Mid-A' in segment:\n",
    "                ensemble_pred = np.clip(ensemble_pred, 45, 75)\n",
    "            elif 'Mid-Entry' in segment:\n",
    "                ensemble_pred = np.clip(ensemble_pred, 35, 55)\n",
    "            elif 'Entry' in segment:\n",
    "                ensemble_pred = np.clip(ensemble_pred, 25, 45)\n",
    "            elif 'Basic' in segment:\n",
    "                ensemble_pred = np.clip(ensemble_pred, 15, 35)\n",
    "            \n",
    "            ensemble_rmse = np.sqrt(mean_squared_error(y, ensemble_pred))\n",
    "            total_predictions[mask] = ensemble_pred\n",
    "            \n",
    "            # 결과 출력\n",
    "            weight_str = f\"{weights['lgb']:.2f}/{weights['rf']:.2f}/{weights['cat']:.2f}/{weights['xgb']:.2f}\"\n",
    "            print(f\"{segment:<15} {mask.sum():>8d} \"\n",
    "                  f\"{model_rmse['lgb']:>10.4f} {model_rmse['rf']:>10.4f} \"\n",
    "                  f\"{model_rmse['cat']:>10.4f} {model_rmse['xgb']:>10.4f} \"\n",
    "                  f\"{ensemble_rmse:>10.4f} {weight_str:>20}\")\n",
    "            \n",
    "            segment_metrics[segment] = {\n",
    "                'count': mask.sum(),\n",
    "                'model_rmse': model_rmse,\n",
    "                'ensemble_rmse': ensemble_rmse,\n",
    "                'weights': weights\n",
    "            }\n",
    "            \n",
    "            # IONIQ 세그먼트 상세 분석\n",
    "            if 'IONIQ' in segment or 'Basic-H' in segment:\n",
    "                print(f\"\\n{segment} 상세 분석:\")\n",
    "                \n",
    "                # 연식별 성능\n",
    "                for year in sorted(val_processed.loc[mask, '연식(년)'].unique()):\n",
    "                    year_mask = val_processed.loc[mask, '연식(년)'] == year\n",
    "                    if year_mask.any():\n",
    "                        year_rmse = np.sqrt(mean_squared_error(\n",
    "                            y[year_mask], ensemble_pred[year_mask]\n",
    "                        ))\n",
    "                        year_count = year_mask.sum()\n",
    "                        print(f\"- {year}년식 (n={year_count}): RMSE={year_rmse:.4f}\")\n",
    "                \n",
    "                # 주행거리별 성능\n",
    "                distance_ranges = [(0, 30000), (30000, 60000), (60000, float('inf'))]\n",
    "                for start, end in distance_ranges:\n",
    "                    range_mask = (val_processed.loc[mask, '주행거리(km)'] >= start) & \\\n",
    "                               (val_processed.loc[mask, '주행거리(km)'] < end)\n",
    "                    if range_mask.any():\n",
    "                        range_rmse = np.sqrt(mean_squared_error(\n",
    "                            y[range_mask], ensemble_pred[range_mask]\n",
    "                        ))\n",
    "                        range_count = range_mask.sum()\n",
    "                        print(f\"- {start/1000:.0f}-{end/1000 if end != float('inf') else 'inf'}천km (n={range_count}): RMSE={range_rmse:.4f}\")\n",
    "        \n",
    "        total_rmse = np.sqrt(mean_squared_error(y_val, total_predictions))\n",
    "        print(\"=\" * 95)\n",
    "        print(f\"{'전체':<15} {len(y_val):>8d} {'':<10} {'':<10} {'':<10} {'':<10} {total_rmse:>10.4f}\")\n",
    "        \n",
    "        return segment_metrics, total_rmse\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    print(\"\\n=== IONIQ 특화 개선 모델 학습 시작 ===\")\n",
    "    \n",
    "    # 데이터 로드\n",
    "    try:\n",
    "        print(\"\\n1. 데이터 로딩...\")\n",
    "        train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "        test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "        \n",
    "        if 'ID' not in test.columns:\n",
    "            test['ID'] = range(len(test))\n",
    "        \n",
    "        print(f\"학습 데이터 크기: {train.shape}\")\n",
    "        print(f\"테스트 데이터 크기: {test.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"데이터 로딩 중 오류 발생: {e}\")\n",
    "        return\n",
    "    \n",
    "    # 학습/검증 데이터 분할\n",
    "    print(\"\\n2. 데이터 분할...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    print(f\"학습 세트 크기: {X_train.shape}\")\n",
    "    print(f\"검증 세트 크기: {X_val.shape}\")\n",
    "    \n",
    "    # 모델 초기화 및 학습\n",
    "    print(\"\\n3. 모델 학습 시작...\")\n",
    "    model = EnhancedSegmentModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 모델 성능 평가\n",
    "    print(\"\\n4. 검증 데이터로 성능 평가...\")\n",
    "    segment_metrics, total_rmse = model.evaluate_performance(X_val, y_val)\n",
    "    print(f\"\\n전체 RMSE: {total_rmse:.4f}\")\n",
    "    \n",
    "    # 테스트 데이터 예측\n",
    "    print(\"\\n5. 테스트 데이터 예측 중...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    # 결과 저장\n",
    "    print(\"\\n6. 제출 파일 생성...\")\n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    output_file = 'submission20.csv'\n",
    "    submission.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"제출 파일 생성 완료: {output_file}\")\n",
    "    \n",
    "    # 주요 메트릭 요약\n",
    "    print(\"\\n=== 모델 성능 요약 ===\")\n",
    "    print(f\"검증 세트 전체 RMSE: {total_rmse:.4f}\")\n",
    "    \n",
    "    ioniq_segments = [seg for seg in segment_metrics.keys() if 'IONIQ' in seg or 'Basic-H' in seg]\n",
    "    if ioniq_segments:\n",
    "        print(\"\\nIONIQ 세그먼트 성능:\")\n",
    "        for seg in ioniq_segments:\n",
    "            metrics = segment_metrics[seg]\n",
    "            print(f\"- {seg}:\")\n",
    "            print(f\"  데이터 수: {metrics['count']}\")\n",
    "            print(f\"  앙상블 RMSE: {metrics['ensemble_rmse']:.4f}\")\n",
    "            weights = metrics['weights']\n",
    "            print(f\"  최종 가중치: LGB={weights['lgb']:.2f}, RF={weights['rf']:.2f}, \"\n",
    "                  f\"CAT={weights['cat']:.2f}, XGB={weights['xgb']:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중...\n",
      "모델 학습 시작...\n",
      "\n",
      "=== Ultra-Premium-P 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Premium-P-TayCT 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Premium-P-Tay 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== High-Performance-T 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-T 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-Entry-Domestic-H 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-Entry-Domestic-K 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Basic-Domestic-K 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Basic-Domestic-H 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== High-Premium-Import 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== High-Import 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-Import-Combined 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-Entry-Import 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Basic-Import 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "검증 데이터 평가...\n",
      "검증 RMSE: 8.2526\n",
      "\n",
      "테스트 데이터 예측...\n",
      "예측 완료: submission21.csv 생성됨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedSegmentModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.outlier_thresholds = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "        # 모델별 기본 배터리 용량\n",
    "        self.base_battery = {\n",
    "            'IONIQ': 85.0,\n",
    "            'TayCT': 90.0,\n",
    "            'Tay': 95.0,\n",
    "            'TayGTS': 93.4,\n",
    "            'Soul': 58.0,\n",
    "            'EV6': 90.0,\n",
    "            'ION6': 90.0,\n",
    "            'ION5': 90.0,\n",
    "            'M3': 70.0,\n",
    "            'MS': 99.8,\n",
    "            'MY': 69.12,\n",
    "            'MX': 96.0,\n",
    "            'i5': 71.841,\n",
    "            'i3': 56.0,\n",
    "            'iX': 90.0,\n",
    "            'ID4': 90.0,\n",
    "            'RSeTGT': 90.0,\n",
    "            'Q4eT': 75.571,\n",
    "            'eT': 91.2\n",
    "        }\n",
    "        \n",
    "        self.segments = {\n",
    "            'Ultra-Premium-P': {'models': ['TayGTS'], 'brand': 'P사'},\n",
    "            'Premium-P-TayCT': {'models': ['TayCT'], 'brand': 'P사'},\n",
    "            'Premium-P-Tay': {'models': ['Tay'], 'brand': 'P사'},\n",
    "            'High-Performance-T': {'models': ['MX', 'MS', 'MY'], 'brand': 'T사'},\n",
    "            'Mid-T': {'models': ['M3'], 'brand': 'T사'},\n",
    "            'Mid-Entry-Domestic-H': {'models': ['ION6', 'ION5'], 'brand': 'H사'},\n",
    "            'Mid-Entry-Domestic-K': {'models': ['EV6'], 'brand': 'K사'},\n",
    "            'Basic-Domestic-K': {'models': ['Soul'], 'brand': 'K사'},\n",
    "            'Basic-Domestic-H': {'models': ['IONIQ'], 'brand': 'H사'},\n",
    "            'High-Premium-Import': {'models': ['RSeTGT'], 'brand': 'A사'},\n",
    "            'High-Import': {'models': ['iX'], 'brand': 'B사'},\n",
    "            'Mid-Import-Combined': {'models': ['i5', 'Q4eT', 'eT'], 'brands': ['B사', 'A사']},\n",
    "            'Mid-Entry-Import': {'models': ['ID4'], 'brand': 'V사'},\n",
    "            'Basic-Import': {'models': ['i3'], 'brand': 'B사'}\n",
    "        }\n",
    "        \n",
    "        self.segment_models = {}\n",
    "        self.data_size_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def handle_battery_missing(self, df):\n",
    "        \"\"\"배터리 용량 결측치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        for model in df['모델'].unique():\n",
    "            model_mask = df['모델'] == model\n",
    "            model_data = df[model_mask].copy()\n",
    "            \n",
    "            # Brand New 차량은 기본 배터리 용량으로\n",
    "            brand_new_mask = model_data['차량상태'] == 'Brand New'\n",
    "            if brand_new_mask.any():\n",
    "                model_data.loc[brand_new_mask & model_data['배터리용량'].isna(), '배터리용량'] = \\\n",
    "                    self.base_battery.get(model, model_data['배터리용량'].mean())\n",
    "            \n",
    "            # 차량상태별 평균으로 채우기\n",
    "            for status in model_data['차량상태'].unique():\n",
    "                status_mask = model_data['차량상태'] == status\n",
    "                mean_capacity = model_data.loc[status_mask, '배터리용량'].mean()\n",
    "                if pd.isna(mean_capacity):\n",
    "                    mean_capacity = self.base_battery.get(model, 0)\n",
    "                model_data.loc[status_mask & model_data['배터리용량'].isna(), '배터리용량'] = mean_capacity\n",
    "            \n",
    "            # 결과 반영\n",
    "            df.loc[model_mask, '배터리용량'] = model_data['배터리용량']\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 파생 특성\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식'].clip(lower=1)\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # 배터리 관련 특성\n",
    "        df['배터리_상태_점수'] = df.apply(lambda row: \n",
    "            (self.base_battery.get(row['모델'], row['배터리용량']) - row['배터리용량']) \n",
    "            / self.base_battery.get(row['모델'], row['배터리용량']) \n",
    "            if row['배터리용량'] > 0 else 0, axis=1)\n",
    "        \n",
    "        df['배터리_효율성'] = df['배터리용량'] / df['주행거리(km)'].clip(lower=1) * 1000\n",
    "        \n",
    "        # 주행거리 구간\n",
    "        df['주행거리_구간'] = pd.qcut(df['주행거리(km)'], q=4, labels=['낮음', '중하', '중상', '높음'])\n",
    "        \n",
    "        # 프리미엄 모델 점수\n",
    "        df['프리미엄_모델_점수'] = df.apply(lambda row:\n",
    "            row['배터리용량'] / self.base_battery.get(row['모델'], row['배터리용량'])\n",
    "            if row['제조사'] == 'P사' else 1, axis=1)\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df = self.handle_battery_missing(df)\n",
    "        \n",
    "        # 특성 생성\n",
    "        df = self.create_features(df)\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].map(lambda x: next(\n",
    "            (seg for seg, info in self.segments.items() \n",
    "             if x in info['models']), 'Other'))\n",
    "        \n",
    "        # 범주형 변수 처리\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사', '주행거리_구간']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                if col in self.label_encoders:\n",
    "                    df[col] = df[col].map(lambda x: x if x in self.label_encoders[col].classes_ \n",
    "                                        else self.label_encoders[col].classes_[0])\n",
    "                    df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 수치형 변수 스케일링\n",
    "        numeric_cols = [\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)',\n",
    "            '차량연식', 'km_per_year', '잔여보증기간', \n",
    "            '배터리_상태_점수', '배터리_효율성', '프리미엄_모델_점수'\n",
    "        ]\n",
    "        \n",
    "        if is_train:\n",
    "            for col in numeric_cols:\n",
    "                self.scalers[col] = StandardScaler()\n",
    "                df[col] = self.scalers[col].fit_transform(df[[col]])\n",
    "        else:\n",
    "            for col in numeric_cols:\n",
    "                if col in self.scalers:\n",
    "                    df[col] = self.scalers[col].transform(df[[col]])\n",
    "                    \n",
    "        return df\n",
    "\n",
    "    def get_segment_weights(self, segment):\n",
    "        \"\"\"세그먼트별 모델 가중치 결정\"\"\"\n",
    "        if 'IONIQ' in segment:\n",
    "            return {'lgb': 0.3, 'xgb': 0.2, 'cat': 0.3, 'rf': 0.2}\n",
    "        elif any(name in segment for name in ['Tay', 'TayCT']):\n",
    "            return {'lgb': 0.3, 'xgb': 0.3, 'cat': 0.2, 'rf': 0.2}\n",
    "        else:\n",
    "            return {'lgb': 0.4, 'xgb': 0.2, 'cat': 0.2, 'rf': 0.2}\n",
    "            \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        selected_features = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '차량연식', 'km_per_year',\n",
    "            '잔여보증기간', '제조사', '배터리_상태_점수', '배터리_효율성',\n",
    "            '주행거리_구간', '프리미엄_모델_점수'\n",
    "        ]\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = train_processed[mask][selected_features]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            weights = self.get_segment_weights(segment)\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'lgb': LGBMRegressor(\n",
    "                    n_estimators=300, learning_rate=0.03, num_leaves=31,\n",
    "                    feature_fraction=0.8, subsample=0.8, random_state=42\n",
    "                ),\n",
    "                'xgb': XGBRegressor(\n",
    "                    n_estimators=300, learning_rate=0.03, max_depth=6,\n",
    "                    colsample_bytree=0.8, subsample=0.8, random_state=42\n",
    "                ),\n",
    "                'cat': CatBoostRegressor(\n",
    "                    iterations=300, learning_rate=0.03, depth=6,\n",
    "                    random_state=42, verbose=False\n",
    "                ),\n",
    "                'rf': RandomForestRegressor(\n",
    "                    n_estimators=300, max_depth=None, min_samples_split=5,\n",
    "                    random_state=42\n",
    "                )\n",
    "            }\n",
    "            \n",
    "            # 모델 학습\n",
    "            for name, model in self.segment_models[segment].items():\n",
    "                print(f\"{name.upper()} 모델 학습 중...\")\n",
    "                model.fit(X, y)\n",
    "            \n",
    "            self.data_size_stats[segment] = len(y)\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"예측\"\"\"\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        selected_features = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '차량연식', 'km_per_year',\n",
    "            '잔여보증기간', '제조사', '배터리_상태_점수', '배터리_효율성',\n",
    "            '주행거리_구간', '프리미엄_모델_점수'\n",
    "        ]\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = test_processed[mask][selected_features]\n",
    "            weights = self.get_segment_weights(segment)\n",
    "            \n",
    "            segment_pred = np.zeros(mask.sum())\n",
    "            for name, model in self.segment_models[segment].items():\n",
    "                segment_pred += weights[name] * model.predict(X)\n",
    "                \n",
    "            predictions[mask] = segment_pred\n",
    "            \n",
    "        return predictions\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    print(\"데이터 로딩 중...\")\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"모델 학습 시작...\")\n",
    "    model = EnhancedSegmentModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\n검증 데이터 평가...\")\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    print(f\"검증 RMSE: {val_rmse:.4f}\")\n",
    "    \n",
    "    print(\"\\n테스트 데이터 예측...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission21.csv', index=False, encoding='utf-8')\n",
    "    print(\"예측 완료: submission21.csv 생성됨\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로딩 중...\n",
      "모델 학습 시작...\n",
      "\n",
      "=== Ultra-Premium-P 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== High-Premium-P 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Premium-P 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== High-Premium-Import-A 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-Premium-Import-A 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== High-Import-B 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-Import-B 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Basic-Import-B 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== High-Performance-T 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-T 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-Domestic-H 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Entry-Domestic-H 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Basic-Domestic-H 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Mid-Domestic-K 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Entry-Domestic-K 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Basic-Domestic-K 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "=== Entry-Import-V 세그먼트 최적화 시작 ===\n",
      "LGB 모델 학습 중...\n",
      "XGB 모델 학습 중...\n",
      "CAT 모델 학습 중...\n",
      "RF 모델 학습 중...\n",
      "\n",
      "검증 데이터 평가...\n",
      "검증 RMSE: 1.4608\n",
      "\n",
      "테스트 데이터 예측...\n",
      "예측 완료: submission22.csv 생성됨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EnhancedSegmentModel:\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "        self.outlier_thresholds = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "        # 모델별 통계 정보\n",
    "        self.model_stats = {\n",
    "            'TayGTS': {'mean': 158.30, 'std': 3.02, 'min': 151.00, 'max': 161.09},\n",
    "            'TayCT': {'mean': 126.31, 'std': 4.48, 'min': 119.00, 'max': 132.00},\n",
    "            'Tay': {'mean': 109.93, 'std': 10.04, 'min': 95.00, 'max': 122.07},\n",
    "            'RSeTGT': {'mean': 98.80, 'std': 2.09, 'min': 94.00, 'max': 101.19},\n",
    "            'MX': {'mean': 83.05, 'std': 8.15, 'min': 70.89, 'max': 94.75},\n",
    "            'iX': {'mean': 80.03, 'std': 0.57, 'min': 78.92, 'max': 81.15},\n",
    "            'MS': {'mean': 74.54, 'std': 7.30, 'min': 63.11, 'max': 84.55},\n",
    "            'MY': {'mean': 72.05, 'std': 5.31, 'min': 62.81, 'max': 78.99},\n",
    "            'eT': {'mean': 68.10, 'std': 5.35, 'min': 58.92, 'max': 74.75},\n",
    "            'i5': {'mean': 62.87, 'std': 1.76, 'min': 59.76, 'max': 66.06},\n",
    "            'Q4eT': {'mean': 58.07, 'std': 2.14, 'min': 52.01, 'max': 60.00},\n",
    "            'M3': {'mean': 51.63, 'std': 3.04, 'min': 45.72, 'max': 55.00},\n",
    "            'EV6': {'mean': 44.20, 'std': 3.63, 'min': 39.75, 'max': 49.08},\n",
    "            'ID4': {'mean': 38.41, 'std': 2.80, 'min': 32.81, 'max': 42.11},\n",
    "            'ION6': {'mean': 38.10, 'std': 0.74, 'min': 36.35, 'max': 39.00},\n",
    "            'ION5': {'mean': 35.07, 'std': 0.70, 'min': 33.32, 'max': 36.00},\n",
    "            'Niro': {'mean': 26.97, 'std': 2.08, 'min': 20.61, 'max': 29.12},\n",
    "            'KNE': {'mean': 25.74, 'std': 2.60, 'min': 20.55, 'max': 29.19},\n",
    "            'i3': {'mean': 23.56, 'std': 0.80, 'min': 21.72, 'max': 25.00},\n",
    "            'Soul': {'mean': 22.12, 'std': 1.71, 'min': 16.56, 'max': 24.09},\n",
    "            'IONIQ': {'mean': 17.99, 'std': 5.42, 'min': 9.00, 'max': 27.53}\n",
    "        }\n",
    "        \n",
    "        # 세그먼트 정의\n",
    "        self.segments = {\n",
    "            # P사 세그먼트\n",
    "            'Ultra-Premium-P': {\n",
    "                'models': ['TayGTS'],\n",
    "                'brand': 'P사',\n",
    "                'price_range': 'ultra',\n",
    "                'min_price': 150.0,\n",
    "                'max_price': 165.0\n",
    "            },\n",
    "            'High-Premium-P': {\n",
    "                'models': ['TayCT'],\n",
    "                'brand': 'P사',\n",
    "                'price_range': 'high_premium',\n",
    "                'min_price': 119.0,\n",
    "                'max_price': 132.0\n",
    "            },\n",
    "            'Premium-P': {\n",
    "                'models': ['Tay'],\n",
    "                'brand': 'P사',\n",
    "                'price_range': 'premium',\n",
    "                'min_price': 95.0,\n",
    "                'max_price': 122.0\n",
    "            },\n",
    "            \n",
    "            # A사 세그먼트\n",
    "            'High-Premium-Import-A': {\n",
    "                'models': ['RSeTGT'],\n",
    "                'brand': 'A사',\n",
    "                'price_range': 'high_import',\n",
    "                'min_price': 94.0,\n",
    "                'max_price': 102.0\n",
    "            },\n",
    "            'Mid-Premium-Import-A': {\n",
    "                'models': ['eT', 'Q4eT'],\n",
    "                'brand': 'A사',\n",
    "                'price_range': 'mid_import',\n",
    "                'min_price': 52.0,\n",
    "                'max_price': 75.0\n",
    "            },\n",
    "            \n",
    "            # B사 세그먼트\n",
    "            'High-Import-B': {\n",
    "                'models': ['iX'],\n",
    "                'brand': 'B사',\n",
    "                'price_range': 'high_import',\n",
    "                'min_price': 78.0,\n",
    "                'max_price': 82.0\n",
    "            },\n",
    "            'Mid-Import-B': {\n",
    "                'models': ['i5'],\n",
    "                'brand': 'B사',\n",
    "                'price_range': 'mid_import',\n",
    "                'min_price': 59.0,\n",
    "                'max_price': 67.0\n",
    "            },\n",
    "            'Basic-Import-B': {\n",
    "                'models': ['i3'],\n",
    "                'brand': 'B사',\n",
    "                'price_range': 'basic_import',\n",
    "                'min_price': 21.0,\n",
    "                'max_price': 25.0\n",
    "            },\n",
    "            \n",
    "            # T사 세그먼트\n",
    "            'High-Performance-T': {\n",
    "                'models': ['MX', 'MS', 'MY'],\n",
    "                'brand': 'T사',\n",
    "                'price_range': 'high_tech',\n",
    "                'min_price': 62.0,\n",
    "                'max_price': 95.0\n",
    "            },\n",
    "            'Mid-T': {\n",
    "                'models': ['M3'],\n",
    "                'brand': 'T사',\n",
    "                'price_range': 'mid_tech',\n",
    "                'min_price': 45.0,\n",
    "                'max_price': 55.0\n",
    "            },\n",
    "            \n",
    "            # H사 세그먼트\n",
    "            'Mid-Domestic-H': {\n",
    "                'models': ['ION6', 'ION5'],\n",
    "                'brand': 'H사',\n",
    "                'price_range': 'mid_domestic',\n",
    "                'min_price': 33.0,\n",
    "                'max_price': 39.0\n",
    "            },\n",
    "            'Entry-Domestic-H': {\n",
    "                'models': ['KNE'],\n",
    "                'brand': 'H사',\n",
    "                'price_range': 'entry_domestic',\n",
    "                'min_price': 20.0,\n",
    "                'max_price': 30.0\n",
    "            },\n",
    "            'Basic-Domestic-H': {\n",
    "                'models': ['IONIQ'],\n",
    "                'brand': 'H사',\n",
    "                'price_range': 'basic_domestic',\n",
    "                'min_price': 9.0,\n",
    "                'max_price': 28.0\n",
    "            },\n",
    "            \n",
    "            # K사 세그먼트\n",
    "            'Mid-Domestic-K': {\n",
    "                'models': ['EV6'],\n",
    "                'brand': 'K사',\n",
    "                'price_range': 'mid_domestic',\n",
    "                'min_price': 39.0,\n",
    "                'max_price': 50.0\n",
    "            },\n",
    "            'Entry-Domestic-K': {\n",
    "                'models': ['Niro'],\n",
    "                'brand': 'K사',\n",
    "                'price_range': 'entry_domestic',\n",
    "                'min_price': 20.0,\n",
    "                'max_price': 30.0\n",
    "            },\n",
    "            'Basic-Domestic-K': {\n",
    "                'models': ['Soul'],\n",
    "                'brand': 'K사',\n",
    "                'price_range': 'basic_domestic',\n",
    "                'min_price': 16.0,\n",
    "                'max_price': 25.0\n",
    "            },\n",
    "            \n",
    "            # V사 세그먼트\n",
    "            'Entry-Import-V': {\n",
    "                'models': ['ID4'],\n",
    "                'brand': 'V사',\n",
    "                'price_range': 'entry_import',\n",
    "                'min_price': 32.0,\n",
    "                'max_price': 43.0\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.segment_models = {}\n",
    "        self.data_size_stats = {}\n",
    "        self.feature_importance = {}\n",
    "        \n",
    "    def handle_battery_missing(self, df):\n",
    "        \"\"\"배터리 용량 결측치 처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        for model in df['모델'].unique():\n",
    "            model_mask = df['모델'] == model\n",
    "            model_data = df[model_mask].copy()\n",
    "            \n",
    "            # 차량상태별 평균으로 채우기\n",
    "            for status in model_data['차량상태'].unique():\n",
    "                status_mask = model_data['차량상태'] == status\n",
    "                mean_capacity = model_data.loc[status_mask, '배터리용량'].mean()\n",
    "                \n",
    "                if pd.isna(mean_capacity):\n",
    "                    # 전체 모델 평균으로 대체\n",
    "                    mean_capacity = model_data['배터리용량'].mean()\n",
    "                    if pd.isna(mean_capacity):\n",
    "                        # 여전히 결측인 경우 기본값 설정\n",
    "                        if model in ['TayGTS', 'TayCT', 'Tay']:\n",
    "                            mean_capacity = 90.0  # P사 모델 기본값\n",
    "                        elif model in ['MX', 'MS', 'MY']:\n",
    "                            mean_capacity = 85.0  # T사 모델 기본값\n",
    "                        else:\n",
    "                            mean_capacity = 70.0  # 기타 모델 기본값\n",
    "                            \n",
    "                model_data.loc[status_mask & model_data['배터리용량'].isna(), '배터리용량'] = mean_capacity\n",
    "            \n",
    "            # 결과 반영\n",
    "            df.loc[model_mask, '배터리용량'] = model_data['배터리용량']\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    def create_features(self, df):\n",
    "        \"\"\"특성 생성\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 기본 파생 특성\n",
    "        df['차량연식'] = 2024 - df['연식(년)']\n",
    "        df['km_per_year'] = df['주행거리(km)'] / df['차량연식'].clip(lower=1)\n",
    "        df['잔여보증기간'] = (df['보증기간(년)'] - df['차량연식']).clip(lower=0)\n",
    "        \n",
    "        # 가격 관련 특성\n",
    "        df['모델_평균가격'] = df['모델'].map({k: v['mean'] for k, v in self.model_stats.items()})\n",
    "        df['모델_가격편차'] = df['모델'].map({k: v['std'] for k, v in self.model_stats.items()})\n",
    "        \n",
    "        # 배터리 관련 특성\n",
    "        df['배터리_효율성'] = df['배터리용량'] / df['주행거리(km)'].clip(lower=1) * 1000\n",
    "        \n",
    "        # 주행거리 구간\n",
    "        df['주행거리_구간'] = pd.qcut(df['주행거리(km)'], q=4, labels=['낮음', '중하', '중상', '높음'])\n",
    "        \n",
    "        # 차량상태 점수\n",
    "        status_scores = {'Brand New': 1.0, 'Nearly New': 0.8, 'Pre-Owned': 0.6}\n",
    "        df['상태_점수'] = df['차량상태'].map(status_scores)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def preprocess_data(self, df, is_train=True):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # 결측치 처리\n",
    "        df = self.handle_battery_missing(df)\n",
    "        \n",
    "        # 특성 생성\n",
    "        df = self.create_features(df)\n",
    "        \n",
    "        # 세그먼트 할당\n",
    "        df['segment'] = df['모델'].map(lambda x: next(\n",
    "            (seg for seg, info in self.segments.items() \n",
    "             if x in info['models']), 'Other'))\n",
    "        \n",
    "        # 범주형 변수 처리\n",
    "        categorical_cols = ['모델', '차량상태', '구동방식', '사고이력', '제조사', '주행거리_구간']\n",
    "        \n",
    "        if is_train:\n",
    "            for col in categorical_cols:\n",
    "                self.label_encoders[col] = LabelEncoder()\n",
    "                df[col] = self.label_encoders[col].fit_transform(df[col])\n",
    "        else:\n",
    "            for col in categorical_cols:\n",
    "                if col in self.label_encoders:\n",
    "                    df[col] = df[col].map(lambda x: x if x in self.label_encoders[col].classes_ \n",
    "                                        else self.label_encoders[col].classes_[0])\n",
    "                    df[col] = self.label_encoders[col].transform(df[col])\n",
    "        \n",
    "        # 수치형 변수 스케일링\n",
    "        numeric_cols = [\n",
    "            '배터리용량', '주행거리(km)', '보증기간(년)', '연식(년)',\n",
    "            '차량연식', 'km_per_year', '잔여보증기간', \n",
    "            '배터리_효율성', '모델_평균가격', '모델_가격편차', '상태_점수'\n",
    "        ]\n",
    "        \n",
    "        if is_train:\n",
    "            for col in numeric_cols:\n",
    "                self.scalers[col] = StandardScaler()\n",
    "                df[col] = self.scalers[col].fit_transform(df[[col]])\n",
    "        else:\n",
    "            for col in numeric_cols:\n",
    "                if col in self.scalers:\n",
    "                    df[col] = self.scalers[col].transform(df[[col]])\n",
    "                    \n",
    "        return df\n",
    "    \n",
    "    def get_segment_weights(self, segment):\n",
    "        \"\"\"세그먼트별 모델 가중치 결정\"\"\"\n",
    "        if 'Premium-P' in segment:\n",
    "            return {'lgb': 0.3, 'xgb': 0.3, 'cat': 0.2, 'rf': 0.2}\n",
    "        elif 'High-Performance-T' in segment:\n",
    "            return {'lgb': 0.25, 'xgb': 0.25, 'cat': 0.25, 'rf': 0.25}\n",
    "        elif 'Domestic' in segment:\n",
    "            if 'Basic' in segment:\n",
    "                return {'lgb': 0.4, 'xgb': 0.2, 'cat': 0.2, 'rf': 0.2}\n",
    "            else:\n",
    "                return {'lgb': 0.3, 'xgb': 0.3, 'cat': 0.2, 'rf': 0.2}\n",
    "        elif 'Import' in segment:\n",
    "            return {'lgb': 0.3, 'xgb': 0.2, 'cat': 0.3, 'rf': 0.2}\n",
    "        else:\n",
    "            return {'lgb': 0.4, 'xgb': 0.2, 'cat': 0.2, 'rf': 0.2}\n",
    "            \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"모델 학습\"\"\"\n",
    "        train_processed = self.preprocess_data(X_train, is_train=True)\n",
    "        \n",
    "        selected_features = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '차량연식', 'km_per_year',\n",
    "            '잔여보증기간', '제조사', '배터리_효율성', '모델_평균가격', \n",
    "            '모델_가격편차', '상태_점수', '주행거리_구간'\n",
    "        ]\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            print(f\"\\n=== {segment} 세그먼트 최적화 시작 ===\")\n",
    "            \n",
    "            mask = train_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = train_processed[mask][selected_features]\n",
    "            y = y_train[mask]\n",
    "            \n",
    "            # 세그먼트별 모델 파라미터 설정\n",
    "            model_params = {\n",
    "                'lgb': {\n",
    "                    'n_estimators': 300,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'num_leaves': 31,\n",
    "                    'subsample': 0.8,\n",
    "                    'colsample_bytree': 0.8,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'xgb': {\n",
    "                    'n_estimators': 300,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'max_depth': 5,\n",
    "                    'subsample': 0.8,\n",
    "                    'colsample_bytree': 0.8,\n",
    "                    'random_state': 42\n",
    "                },\n",
    "                'cat': {\n",
    "                    'iterations': 300,\n",
    "                    'learning_rate': 0.03,\n",
    "                    'depth': 6,\n",
    "                    'random_state': 42,\n",
    "                    'verbose': False\n",
    "                },\n",
    "                'rf': {\n",
    "                    'n_estimators': 300,\n",
    "                    'max_depth': None,\n",
    "                    'min_samples_split': 5,\n",
    "                    'random_state': 42\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Premium 세그먼트는 더 복잡한 모델 사용\n",
    "            if 'Premium' in segment:\n",
    "                model_params['lgb']['num_leaves'] = 63\n",
    "                model_params['xgb']['max_depth'] = 6\n",
    "                model_params['cat']['depth'] = 8\n",
    "            \n",
    "            # Basic 세그먼트는 더 단순한 모델 사용\n",
    "            elif 'Basic' in segment:\n",
    "                model_params['lgb']['num_leaves'] = 15\n",
    "                model_params['xgb']['max_depth'] = 4\n",
    "                model_params['cat']['depth'] = 4\n",
    "            \n",
    "            self.segment_models[segment] = {\n",
    "                'lgb': LGBMRegressor(**model_params['lgb']),\n",
    "                'xgb': XGBRegressor(**model_params['xgb']),\n",
    "                'cat': CatBoostRegressor(**model_params['cat']),\n",
    "                'rf': RandomForestRegressor(**model_params['rf'])\n",
    "            }\n",
    "            \n",
    "            # 모델 학습\n",
    "            for name, model in self.segment_models[segment].items():\n",
    "                print(f\"{name.upper()} 모델 학습 중...\")\n",
    "                model.fit(X, y)\n",
    "            \n",
    "            self.data_size_stats[segment] = len(y)\n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"예측\"\"\"\n",
    "        test_processed = self.preprocess_data(X_test, is_train=False)\n",
    "        predictions = np.zeros(len(test_processed))\n",
    "        \n",
    "        selected_features = [\n",
    "            '모델', '차량상태', '배터리용량', '구동방식', '주행거리(km)', \n",
    "            '보증기간(년)', '사고이력', '연식(년)', '차량연식', 'km_per_year',\n",
    "            '잔여보증기간', '제조사', '배터리_효율성', '모델_평균가격', \n",
    "            '모델_가격편차', '상태_점수', '주행거리_구간'\n",
    "        ]\n",
    "        \n",
    "        for segment in self.segments.keys():\n",
    "            mask = test_processed['segment'] == segment\n",
    "            if mask.sum() == 0:\n",
    "                continue\n",
    "                \n",
    "            X = test_processed[mask][selected_features]\n",
    "            weights = self.get_segment_weights(segment)\n",
    "            \n",
    "            segment_pred = np.zeros(mask.sum())\n",
    "            for name, model in self.segment_models[segment].items():\n",
    "                model_pred = model.predict(X)\n",
    "                # 음수 예측값 처리\n",
    "                model_pred = np.maximum(model_pred, self.segments[segment]['min_price'])\n",
    "                model_pred = np.minimum(model_pred, self.segments[segment]['max_price'])\n",
    "                segment_pred += weights[name] * model_pred\n",
    "                \n",
    "            predictions[mask] = segment_pred\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    print(\"데이터 로딩 중...\")\n",
    "    train = pd.read_csv('train.csv', encoding='utf-8')\n",
    "    test = pd.read_csv('test.csv', encoding='utf-8')\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train.drop('가격(백만원)', axis=1),\n",
    "        train['가격(백만원)'],\n",
    "        test_size=0.2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"모델 학습 시작...\")\n",
    "    model = EnhancedSegmentModel()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\n검증 데이터 평가...\")\n",
    "    val_pred = model.predict(X_val)\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    print(f\"검증 RMSE: {val_rmse:.4f}\")\n",
    "    \n",
    "    print(\"\\n테스트 데이터 예측...\")\n",
    "    test_pred = model.predict(test)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'ID': test['ID'],\n",
    "        '가격(백만원)': test_pred\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission22.csv', index=False, encoding='utf-8')\n",
    "    print(\"예측 완료: submission22.csv 생성됨\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
